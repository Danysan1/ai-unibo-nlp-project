{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/Danysan1/ai-unibo-nlp-project/blob/main/a2/execution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: pandas in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (1.5.0)\n",
      "Requirement already satisfied: numpy in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (1.23.3)\n",
      "Requirement already satisfied: matplotlib in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (3.5.3)\n",
      "Requirement already satisfied: transformers in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (4.25.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from pandas) (2022.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from matplotlib) (9.2.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from matplotlib) (4.37.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: filelock in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from transformers) (3.8.2)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from transformers) (0.11.1)\n",
      "Requirement already satisfied: requests in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from requests->transformers) (2022.6.15.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from requests->transformers) (1.26.12)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from requests->transformers) (2.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas numpy matplotlib transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "from tqdm import tqdm\n",
    "\n",
    "class DownloadProgressBar(tqdm):\n",
    "    def update_to(self, b=1, bsize=1, tsize=None):\n",
    "        if tsize is not None:\n",
    "            self.total = tsize\n",
    "        self.update(b * bsize - self.n)\n",
    "        \n",
    "def download_url(url, output_path):\n",
    "    with DownloadProgressBar(unit='B', unit_scale=True,\n",
    "                             miniters=1, desc=url.split('/')[-1]) as t:\n",
    "        urllib.request.urlretrieve(url, filename=output_path, reporthook=t.update_to)\n",
    "\n",
    "def download_data(data_path, url_path, suffix):    \n",
    "    if not os.path.exists(data_path):\n",
    "        os.makedirs(data_path)\n",
    "        \n",
    "    data_path = os.path.join(data_path, f'{suffix}.json')\n",
    "    if not os.path.exists(data_path):\n",
    "        print(f\"Downloading CoQA {suffix} data split... (it may take a while)\")\n",
    "        download_url(url=url_path, output_path=data_path)\n",
    "        print(\"Download completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'Dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data\n",
    "train_url = \"https://nlp.stanford.edu/data/coqa/coqa-train-v1.0.json\"\n",
    "download_data(data_path=data_folder, url_path=train_url, suffix='train')\n",
    "\n",
    "# Test data\n",
    "test_url = \"https://nlp.stanford.edu/data/coqa/coqa-dev-v1.0.json\"\n",
    "download_data(data_path=data_folder, url_path=test_url, suffix='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from os import path\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataset(filename):\n",
    "    with open(path.join(data_folder, filename)) as file_obj:\n",
    "        df = json.load(file_obj)[\"data\"]\n",
    "    print(f'{len(df)} stories / {len(df[0][\"questions\"])} questions in the first row')\n",
    "\n",
    "    storyDType = pd.CategoricalDtype(pd.unique([story[\"story\"] for story in df]))\n",
    "    print(f\"{storyDType.categories.size} distinct stories\")\n",
    "\n",
    "    sourceDType = pd.CategoricalDtype(pd.unique([story[\"source\"] for story in df]))\n",
    "    print(f\"{sourceDType.categories.size} distinct sources: {sourceDType.categories}\")\n",
    "\n",
    "    df = np.array([\n",
    "        [\n",
    "            sourceDType.categories.get_loc(story[\"source\"]), # Sources factorization\n",
    "            storyDType.categories.get_loc(story[\"story\"]), # Sources factorization\n",
    "            story[\"questions\"][question_index][\"input_text\"],\n",
    "            story[\"answers\"][question_index][\"input_text\"],\n",
    "            story[\"answers\"][question_index][\"span_text\"],\n",
    "        ]\n",
    "        for story in df\n",
    "        for question_index in range(len(story[\"questions\"]))\n",
    "        if story[\"answers\"][question_index][\"input_text\"] != 'unknown'\n",
    "    ])\n",
    "    print(f'{df.shape} question-answer pairs x columns')\n",
    "    print(f'First row: {df[0]}')\n",
    "    \n",
    "    # https://marcobonzanini.com/2021/09/15/tips-for-saving-memory-with-pandas/\n",
    "    # https://pandas.pydata.org/docs/user_guide/categorical.html\n",
    "    df = pd.DataFrame({\n",
    "        \"source\": pd.Series(pd.Categorical.from_codes(df[:,0].astype(np.int16), dtype=sourceDType)),\n",
    "        \"p\": pd.Series(pd.Categorical.from_codes(df[:,1].astype(np.int16), dtype=storyDType)),\n",
    "        \"q\": df[:,2],\n",
    "        \"a\": df[:,3],\n",
    "        \"span\": df[:,4],\n",
    "    })\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7199 stories / 20 questions in the first row\n",
      "6605 distinct stories\n",
      "5 distinct sources: Index(['wikipedia', 'cnn', 'gutenberg', 'race', 'mctest'], dtype='object')\n",
      "(107276, 5) question-answer pairs x columns\n",
      "First row: ['0' '0' 'When was the Vat formally opened?'\n",
      " 'It was formally established in 1475' 'Formally established in 1475']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "source    107276\n",
       "p         107276\n",
       "q         107276\n",
       "a         107276\n",
       "span      107276\n",
       "dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = loadDataset(\"train.json\")\n",
    "train_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6605"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.unique(train_df[\"p\"]).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99470"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.unique(train_df[\"span\"]).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.unique(train_df[\"source\"]).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>p</th>\n",
       "      <th>q</th>\n",
       "      <th>a</th>\n",
       "      <th>span</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wikipedia</td>\n",
       "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
       "      <td>When was the Vat formally opened?</td>\n",
       "      <td>It was formally established in 1475</td>\n",
       "      <td>Formally established in 1475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wikipedia</td>\n",
       "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
       "      <td>what is the library for?</td>\n",
       "      <td>research</td>\n",
       "      <td>he Vatican Library is a research library</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wikipedia</td>\n",
       "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
       "      <td>for what subjects?</td>\n",
       "      <td>history, and law</td>\n",
       "      <td>Vatican Library is a research library for hist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wikipedia</td>\n",
       "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
       "      <td>and?</td>\n",
       "      <td>philosophy, science and theology</td>\n",
       "      <td>Vatican Library is a research library for hist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wikipedia</td>\n",
       "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
       "      <td>what was started in 2014?</td>\n",
       "      <td>a  project</td>\n",
       "      <td>March 2014, the Vatican Library began an initi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      source                                                  p  \\\n",
       "0  wikipedia  The Vatican Apostolic Library (), more commonl...   \n",
       "1  wikipedia  The Vatican Apostolic Library (), more commonl...   \n",
       "2  wikipedia  The Vatican Apostolic Library (), more commonl...   \n",
       "3  wikipedia  The Vatican Apostolic Library (), more commonl...   \n",
       "4  wikipedia  The Vatican Apostolic Library (), more commonl...   \n",
       "\n",
       "                                   q                                    a  \\\n",
       "0  When was the Vat formally opened?  It was formally established in 1475   \n",
       "1           what is the library for?                             research   \n",
       "2                 for what subjects?                     history, and law   \n",
       "3                               and?     philosophy, science and theology   \n",
       "4          what was started in 2014?                           a  project   \n",
       "\n",
       "                                                span  \n",
       "0                       Formally established in 1475  \n",
       "1           he Vatican Library is a research library  \n",
       "2  Vatican Library is a research library for hist...  \n",
       "3  Vatican Library is a research library for hist...  \n",
       "4  March 2014, the Vatican Library began an initi...  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index          128\n",
       "source      107764\n",
       "p         14241201\n",
       "q          9110271\n",
       "a          7714559\n",
       "span      12090637\n",
       "dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.memory_usage(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_df = loadDataset(\"test.json\")\n",
    "#test_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check unanswerable questions in the Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = (train_df.a == 'unknown')\n",
    "unanswerable = train_df[idx]\n",
    "unanswerable.q.count()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All unanswerable questions in the Train Dataset have been already removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CHAPTER VII. THE DAUGHTER OF WITHERSTEEN \\n\\n\"Lassiter, will you be my rider?\" Jane had asked him. \\n\\n\"I reckon so,\" he had replied. \\n\\nFew as the words were, Jane knew how infinitely much they implied. She wanted him to take charge of her cattle and horse and ranges, and save them if that were possible. Yet, though she could not have spoken aloud all she meant, she was perfectly honest with herself. Whatever the price to be paid, she must keep Lassiter close to her; she must shield from him the man who had led Milly Erne to Cottonwoods. In her fear she so controlled her mind that she did not whisper this Mormon\\'s name to her own soul, she did not even think it. Besides, beyond this thing she regarded as a sacred obligation thrust upon her, was the need of a helper, of a friend, of a champion in this critical time. If she could rule this gun-man, as Venters had called him, if she could even keep him from shedding blood, what strategy to play his flame and his presence against the game of oppression her churchmen were waging against her? Never would she forget the effect on Tull and his men when Venters shouted Lassiter\\'s name. If she could not wholly control Lassiter, then what she could do might put off the fatal day. \\n\\nOne of her safe racers was a dark bay, and she called him Bells because of the way he struck his iron shoes on the stones. When Jerd led out this slender, beautifully built horse Lassiter suddenly became all eyes. A rider\\'s love of a thoroughbred shone in them. Round and round Bells he walked, plainly weakening all the time in his determination not to take one of Jane\\'s favorite racers. '"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"p\"][42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Was Lassiter impressed with the horse?'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"q\"][42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"a\"][42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'When Jerd led out this slender, beautifully built horse Lassiter suddenly became all eyes.'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"span\"][42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gutenberg'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"source\"][42]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df[\"source\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1790/3127963000.py:2: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  story_counts[:25].plot(kind=\"bar\", figsize=(15,5))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABMIAAAHCCAYAAAANT2UHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAABbOklEQVR4nO3deVxUdd//8c8M+46gbIrijuaSYpJLuZGI5pbZVWlamZkXWulVGXeaaSVme+aVV11ptphmpWXdWe5moiaGS6m5LxeihgqKCiif3x/+nNu5WJQCzxzP6/l4nEfO+Q7DG5oZznnPOd9jU1UVAAAAAAAA4DpnNzoAAAAAAAAAcC1QhAEAAAAAAMASKMIAAAAAAABgCRRhAAAAAAAAsASKMAAAAAAAAFgCRRgAAAAAAAAsgSIMAAAAAAAAlkARBgAAAAAAAEtwNzrAn1FUVCSZmZkSEBAgNpvN6DgAAAAAAAAwkKrKqVOnJCoqSuz20o/7MmURlpmZKdHR0UbHAAAAAAAAgAs5ePCg1KhRo9RxUxZhAQEBInLxhwsMDDQ4DQAAAAAAAIyUm5sr0dHRjs6oNKYswi6dDhkYGEgRBgAAAAAAABGRK06hxWT5AAAAAAAAsASKMAAAAAAAAFgCRRgAAAAAAAAsgSIMAAAAAAAAlkARBgAAAAAAAEugCAMAAAAAAIAlUIQBAAAAAADAEijCAAAAAAAAYAkUYQAAAAAAALCEchVhqampctNNN0lAQICEhYVJnz59ZMeOHU73OXfunCQnJ0toaKj4+/tLv3795MiRI073OXDggPTo0UN8fX0lLCxMnnzySTl//vxf/2kAAAAAAACAUpSrCFu5cqUkJyfL2rVrZfHixVJYWChdu3aVvLw8x31GjRolCxculHnz5snKlSslMzNT7rjjDsf4hQsXpEePHlJQUCBr1qyRWbNmyQcffCDPPvtsxf1UAAAAAAAAwH+xqar+2S8+duyYhIWFycqVK+XWW2+VnJwcqVatmsyePVvuvPNOERHZvn27NGrUSNLS0uTmm2+W7777Tm6//XbJzMyU8PBwERGZPn26jBkzRo4dOyaenp5X/L65ubkSFBQkOTk5EhgY+GfjAwAAAAAA4DpwtV3RX5ojLCcnR0REQkJCREQkPT1dCgsLJSEhwXGf2NhYqVmzpqSlpYmISFpamjRt2tRRgomIJCYmSm5urvz6668lfp/8/HzJzc11WgAAAAAAAIDy+NNFWFFRkTz++OPSrl07adKkiYiIZGVliaenpwQHBzvdNzw8XLKyshz3ubwEuzR+aawkqampEhQU5Fiio6P/bGwAAAAAAABY1J8uwpKTk2Xr1q0yZ86cisxTopSUFMnJyXEsBw8erPTvCQAAAAAAgOuL+5/5ohEjRsg333wjq1atkho1ajjWR0RESEFBgZw8edLpqLAjR45IRESE4z7r1693erxLV5W8dJ//5uXlJV5eXn8mqkPM09/+pa8vy77JPSrtsQEAAAAAAFAxynVEmKrKiBEjZP78+bJs2TKpXbu203hcXJx4eHjI0qVLHet27NghBw4ckDZt2oiISJs2bWTLli1y9OhRx30WL14sgYGB0rhx47/yswAAAAAAAAClKtcRYcnJyTJ79mz56quvJCAgwDGnV1BQkPj4+EhQUJAMGTJERo8eLSEhIRIYGCgjR46UNm3ayM033ywiIl27dpXGjRvLfffdJ1OmTJGsrCwZO3asJCcn/+WjvgAAAAAAAIDSlKsIe+edd0REpGPHjk7rZ86cKffff7+IiLz++utit9ulX79+kp+fL4mJifLPf/7TcV83Nzf55ptvZPjw4dKmTRvx8/OTwYMHy8SJE//aTwIAAAAAAACUwaaqanSI8srNzZWgoCDJycmRwMDAq/oa5ggDAAAAAAC4Pl1tV/SnrxoJAAAAAAAAmAlFGAAAAAAAACyBIgwAAAAAAACWQBEGAAAAAAAAS6AIAwAAAAAAgCVQhAEAAAAAAMASKMIAAAAAAABgCRRhAAAAAAAAsASKMAAAAAAAAFgCRRgAAAAAAAAsgSIMAAAAAAAAlkARBgAAAAAAAEugCAMAAAAAAIAlUIQBAAAAAADAEijCAAAAAAAAYAkUYQAAAAAAALAEijAAAAAAAABYAkUYAAAAAAAALIEiDAAAAAAAAJZAEQYAAAAAAABLoAgDAAAAAACAJVCEAQAAAAAAwBIowgAAAAAAAGAJFGEAAAAAAACwBIowAAAAAAAAWAJFGAAAAAAAACyBIgwAAAAAAACWQBEGAAAAAAAAS6AIAwAAAAAAgCVQhAEAAAAAAMASKMIAAAAAAABgCRRhAAAAAAAAsASKMAAAAAAAAFgCRRgAAAAAAAAsgSIMAAAAAAAAllDuImzVqlXSs2dPiYqKEpvNJgsWLHAat9lsJS4vv/yy4z4xMTHFxidPnvyXfxgAAAAAAACgNOUuwvLy8qR58+Yybdq0EscPHz7stMyYMUNsNpv069fP6X4TJ050ut/IkSP/3E8AAAAAAAAAXAX38n5BUlKSJCUllToeERHhdPurr76STp06SZ06dZzWBwQEFLsvAAAAAAAAUFkqdY6wI0eOyLfffitDhgwpNjZ58mQJDQ2VFi1ayMsvvyznz58v9XHy8/MlNzfXaQEAAAAAAADKo9xHhJXHrFmzJCAgQO644w6n9Y8++qi0bNlSQkJCZM2aNZKSkiKHDx+W1157rcTHSU1NlQkTJlRmVAAAAAAAAFznKrUImzFjhgwYMEC8vb2d1o8ePdrx72bNmomnp6cMGzZMUlNTxcvLq9jjpKSkOH1Nbm6uREdHV15wAAAAAAAAXHcqrQj78ccfZceOHTJ37twr3jc+Pl7Onz8v+/btk4YNGxYb9/LyKrEgAwAAAAAAAK5Wpc0R9v7770tcXJw0b978ivfNyMgQu90uYWFhlRUHAAAAAAAAFlfuI8JOnz4tu3btctzeu3evZGRkSEhIiNSsWVNELp66OG/ePHn11VeLfX1aWpqsW7dOOnXqJAEBAZKWliajRo2SgQMHSpUqVf7CjwIAAAAAAACUrtxF2IYNG6RTp06O25fm7ho8eLB88MEHIiIyZ84cUVW55557in29l5eXzJkzR5577jnJz8+X2rVry6hRo5zmAAMAAAAAAAAqmk1V1egQ5ZWbmytBQUGSk5MjgYGBV/U1MU9/W2l59k3uUWmPDQAAAAAAgLJdbVdUaXOEAQAAAAAAAK6EIgwAAAAAAACWQBEGAAAAAAAAS6AIAwAAAAAAgCVQhAEAAAAAAMASKMIAAAAAAABgCRRhAAAAAAAAsASKMAAAAAAAAFgCRRgAAAAAAAAsgSIMAAAAAAAAlkARBgAAAAAAAEugCAMAAAAAAIAlUIQBAAAAAADAEijCAAAAAAAAYAkUYQAAAAAAALAEijAAAAAAAABYAkUYAAAAAAAALIEiDAAAAAAAAJZAEQYAAAAAAABLoAgDAAAAAACAJVCEAQAAAAAAwBIowgAAAAAAAGAJFGEAAAAAAACwBIowAAAAAAAAWAJFGAAAAAAAACyBIgwAAAAAAACWQBEGAAAAAAAAS6AIAwAAAAAAgCVQhAEAAAAAAMASKMIAAAAAAABgCRRhAAAAAAAAsASKMAAAAAAAAFgCRRgAAAAAAAAsgSIMAAAAAAAAlkARBgAAAAAAAEsodxG2atUq6dmzp0RFRYnNZpMFCxY4jd9///1is9mclm7dujnd5/jx4zJgwAAJDAyU4OBgGTJkiJw+ffov/SAAAAAAAABAWdzL+wV5eXnSvHlzefDBB+WOO+4o8T7dunWTmTNnOm57eXk5jQ8YMEAOHz4sixcvlsLCQnnggQfk4YcfltmzZ5c3znUv5ulvK+2x903uUWmPDQAAAAAA4GrKXYQlJSVJUlJSmffx8vKSiIiIEse2bdsmixYtkp9//llatWolIiJTp06V7t27yyuvvCJRUVHljQQAAAAAAABcUaXMEbZixQoJCwuThg0byvDhwyU7O9sxlpaWJsHBwY4STEQkISFB7Ha7rFu3rsTHy8/Pl9zcXKcFAAAAAAAAKI8KL8K6desmH374oSxdulReeuklWblypSQlJcmFCxdERCQrK0vCwsKcvsbd3V1CQkIkKyurxMdMTU2VoKAgxxIdHV3RsQEAAAAAAHCdK/epkVdy9913O/7dtGlTadasmdStW1dWrFghXbp0+VOPmZKSIqNHj3bczs3NpQwDAAAAAABAuVTKqZGXq1OnjlStWlV27dolIiIRERFy9OhRp/ucP39ejh8/Xuq8Yl5eXhIYGOi0AAAAAAAAAOVR6UXYoUOHJDs7WyIjI0VEpE2bNnLy5ElJT0933GfZsmVSVFQk8fHxlR0HAAAAAAAAFlXuUyNPnz7tOLpLRGTv3r2SkZEhISEhEhISIhMmTJB+/fpJRESE7N69W5566impV6+eJCYmiohIo0aNpFu3bjJ06FCZPn26FBYWyogRI+Tuu+/mipEAAAAAAACoNOU+ImzDhg3SokULadGihYiIjB49Wlq0aCHPPvusuLm5yebNm6VXr17SoEEDGTJkiMTFxcmPP/4oXl5ejsf45JNPJDY2Vrp06SLdu3eX9u3by7vvvltxPxUAAAAAAADwX8p9RFjHjh1FVUsd//7776/4GCEhITJ79uzyfmsAAAAAAADgT6v0OcIAAAAAAAAAV0ARBgAAAAAAAEugCAMAAAAAAIAlUIQBAAAAAADAEijCAAAAAAAAYAkUYQAAAAAAALAEijAAAAAAAABYAkUYAAAAAAAALIEiDAAAAAAAAJZAEQYAAAAAAABLoAgDAAAAAACAJVCEAQAAAAAAwBIowgAAAAAAAGAJFGEAAAAAAACwBIowAAAAAAAAWAJFGAAAAAAAACyBIgwAAAAAAACWQBEGAAAAAAAAS6AIAwAAAAAAgCVQhAEAAAAAAMASKMIAAAAAAABgCRRhAAAAAAAAsASKMAAAAAAAAFgCRRgAAAAAAAAsgSIMAAAAAAAAlkARBgAAAAAAAEugCAMAAAAAAIAlUIQBAAAAAADAEijCAAAAAAAAYAkUYQAAAAAAALAEijAAAAAAAABYAkUYAAAAAAAALIEiDAAAAAAAAJZAEQYAAAAAAABLoAgDAAAAAACAJZS7CFu1apX07NlToqKixGazyYIFCxxjhYWFMmbMGGnatKn4+flJVFSUDBo0SDIzM50eIyYmRmw2m9MyefLkv/zDAAAAAAAAAKUpdxGWl5cnzZs3l2nTphUbO3PmjGzcuFHGjRsnGzdulC+//FJ27NghvXr1KnbfiRMnyuHDhx3LyJEj/9xPAAAAAAAAAFwF9/J+QVJSkiQlJZU4FhQUJIsXL3Za9/bbb0vr1q3lwIEDUrNmTcf6gIAAiYiIKO+3BwAAAAAAAP6USp8jLCcnR2w2mwQHBzutnzx5soSGhkqLFi3k5ZdflvPnz5f6GPn5+ZKbm+u0AAAAAAAAAOVR7iPCyuPcuXMyZswYueeeeyQwMNCx/tFHH5WWLVtKSEiIrFmzRlJSUuTw4cPy2muvlfg4qampMmHChMqMCgAAAAAAgOtcpRVhhYWFctddd4mqyjvvvOM0Nnr0aMe/mzVrJp6enjJs2DBJTU0VLy+vYo+VkpLi9DW5ubkSHR1dWdEBAAAAAABwHaqUIuxSCbZ//35ZtmyZ09FgJYmPj5fz58/Lvn37pGHDhsXGvby8SizIAAAAAAAAgKtV4UXYpRJs586dsnz5cgkNDb3i12RkZIjdbpewsLCKjgMAAAAAAACIyJ8owk6fPi27du1y3N67d69kZGRISEiIREZGyp133ikbN26Ub775Ri5cuCBZWVkiIhISEiKenp6SlpYm69atk06dOklAQICkpaXJqFGjZODAgVKlSpWK+8kAAAAAAACAy5S7CNuwYYN06tTJcfvS3F2DBw+W5557Tr7++msREbnxxhudvm758uXSsWNH8fLykjlz5shzzz0n+fn5Urt2bRk1apTTHGAAAAAAAABARSt3EdaxY0dR1VLHyxoTEWnZsqWsXbu2vN8WAAAAAAAA+EvsRgcAAAAAAAAArgWKMAAAAAAAAFgCRRgAAAAAAAAsgSIMAAAAAAAAlkARBgAAAAAAAEugCAMAAAAAAIAlUIQBAAAAAADAEijCAAAAAAAAYAkUYQAAAAAAALAEijAAAAAAAABYAkUYAAAAAAAALIEiDAAAAAAAAJZAEQYAAAAAAABLoAgDAAAAAACAJbgbHQDXr5inv620x943uUelPTYAAAAAALg+cUQYAAAAAAAALIEiDAAAAAAAAJZAEQYAAAAAAABLoAgDAAAAAACAJVCEAQAAAAAAwBIowgAAAAAAAGAJFGEAAAAAAACwBIowAAAAAAAAWAJFGAAAAAAAACyBIgwAAAAAAACWQBEGAAAAAAAAS6AIAwAAAAAAgCVQhAEAAAAAAMASKMIAAAAAAABgCRRhAAAAAAAAsASKMAAAAAAAAFgCRRgAAAAAAAAsgSIMAAAAAAAAlkARBgAAAAAAAEugCAMAAAAAAIAllLsIW7VqlfTs2VOioqLEZrPJggULnMZVVZ599lmJjIwUHx8fSUhIkJ07dzrd5/jx4zJgwAAJDAyU4OBgGTJkiJw+ffov/SAAAAAAAABAWcpdhOXl5Unz5s1l2rRpJY5PmTJF3nrrLZk+fbqsW7dO/Pz8JDExUc6dO+e4z4ABA+TXX3+VxYsXyzfffCOrVq2Shx9++M//FAAAAAAAAMAVuJf3C5KSkiQpKanEMVWVN954Q8aOHSu9e/cWEZEPP/xQwsPDZcGCBXL33XfLtm3bZNGiRfLzzz9Lq1atRERk6tSp0r17d3nllVckKirqL/w4AAAAAAAAQMkqdI6wvXv3SlZWliQkJDjWBQUFSXx8vKSlpYmISFpamgQHBztKMBGRhIQEsdvtsm7duoqMAwAAAAAAADiU+4iwsmRlZYmISHh4uNP68PBwx1hWVpaEhYU5h3B3l5CQEMd9/lt+fr7k5+c7bufm5lZkbAAAAAAAAFhAhRZhlSU1NVUmTJhgdAxYRMzT31baY++b3KPSHlvE3NkBAAAAAKhsFXpqZEREhIiIHDlyxGn9kSNHHGMRERFy9OhRp/Hz58/L8ePHHff5bykpKZKTk+NYDh48WJGxAQAAAAAAYAEVWoTVrl1bIiIiZOnSpY51ubm5sm7dOmnTpo2IiLRp00ZOnjwp6enpjvssW7ZMioqKJD4+vsTH9fLyksDAQKcFAAAAAAAAKI9ynxp5+vRp2bVrl+P23r17JSMjQ0JCQqRmzZry+OOPywsvvCD169eX2rVry7hx4yQqKkr69OkjIiKNGjWSbt26ydChQ2X69OlSWFgoI0aMkLvvvpsrRgIAAAAAAKDSlLsI27Bhg3Tq1Mlxe/To0SIiMnjwYPnggw/kqaeekry8PHn44Yfl5MmT0r59e1m0aJF4e3s7vuaTTz6RESNGSJcuXcRut0u/fv3krbfeqoAfBwAAAAAAAChZuYuwjh07iqqWOm6z2WTixIkyceLEUu8TEhIis2fPLu+3BnCdYpJ/AAAAAMC1UKFzhAEAAAAAAACuiiIMAAAAAAAAlkARBgAAAAAAAEugCAMAAAAAAIAlUIQBAAAAAADAEijCAAAAAAAAYAkUYQAAAAAAALAEijAAAAAAAABYAkUYAAAAAAAALIEiDAAAAAAAAJZAEQYAAAAAAABLoAgDAAAAAACAJVCEAQAAAAAAwBIowgAAAAAAAGAJFGEAAAAAAACwBIowAAAAAAAAWIK70QEAwMxinv620h573+QelfbYAAAAAGBFHBEGAAAAAAAAS6AIAwAAAAAAgCVwaiQAWJCZT+k0c3YAAAAAxuKIMAAAAAAAAFgCRRgAAAAAAAAsgSIMAAAAAAAAlkARBgAAAAAAAEugCAMAAAAAAIAlcNVIAACuAa52CQAAABiPI8IAAAAAAABgCRRhAAAAAAAAsASKMAAAAAAAAFgCRRgAAAAAAAAsgSIMAAAAAAAAlkARBgAAAAAAAEugCAMAAAAAAIAlUIQBAAAAAADAEtyNDgAAAFxbzNPfVtpj75vco9Ie26y5AQAAUHkq/IiwmJgYsdlsxZbk5GQREenYsWOxsUceeaSiYwAAAAAAAABOKvyIsJ9//lkuXLjguL1161a57bbbpH///o51Q4cOlYkTJzpu+/r6VnQMAAAAAAAAwEmFF2HVqlVzuj158mSpW7eudOjQwbHO19dXIiIiKvpbAwAAAAAAAKWq1MnyCwoK5OOPP5YHH3xQbDabY/0nn3wiVatWlSZNmkhKSoqcOXOmMmMAAAAAAAAAlTtZ/oIFC+TkyZNy//33O9bde++9UqtWLYmKipLNmzfLmDFjZMeOHfLll1+W+jj5+fmSn5/vuJ2bm1uZsQEAAAAAAHAdqtQi7P3335ekpCSJiopyrHv44Ycd/27atKlERkZKly5dZPfu3VK3bt0SHyc1NVUmTJhQmVEBAAAAAABwnau0UyP3798vS5YskYceeqjM+8XHx4uIyK5du0q9T0pKiuTk5DiWgwcPVmhWAAAAAAAAXP8q7YiwmTNnSlhYmPTo0aPM+2VkZIiISGRkZKn38fLyEi8vr4qMBwAAAAAAAIuplCKsqKhIZs6cKYMHDxZ39//7Frt375bZs2dL9+7dJTQ0VDZv3iyjRo2SW2+9VZo1a1YZUQAAAAAAAAARqaQibMmSJXLgwAF58MEHndZ7enrKkiVL5I033pC8vDyJjo6Wfv36ydixYysjBgAAAAAAAOBQKUVY165dRVWLrY+OjpaVK1dWxrcEAAAAAAAAylRpk+UDAAAAAAAAroQiDAAAAAAAAJZAEQYAAAAAAABLoAgDAAAAAACAJVCEAQAAAAAAwBIowgAAAAAAAGAJFGEAAAAAAACwBIowAAAAAAAAWIK70QEAAADgLObpbyvtsfdN7lFpjw0AAODqOCIMAAAAAAAAlkARBgAAAAAAAEugCAMAAAAAAIAlUIQBAAAAAADAEijCAAAAAAAAYAlcNRIAAAAVgqtdAgAAV8cRYQAAAAAAALAEjggDAACA5XE0GwAA1sARYQAAAAAAALAEijAAAAAAAABYAqdGAgAAACbFKZ0AAJQPR4QBAAAAAADAEijCAAAAAAAAYAkUYQAAAAAAALAEijAAAAAAAABYAkUYAAAAAAAALIGrRgIAAAC45rjiJQDACBwRBgAAAAAAAEugCAMAAAAAAIAlUIQBAAAAAADAEijCAAAAAAAAYAlMlg8AAAAAV4lJ/gHA3DgiDAAAAAAAAJbAEWEAAAAAYAEczQYAHBEGAAAAAAAAi6AIAwAAAAAAgCVUeBH23HPPic1mc1piY2Md4+fOnZPk5GQJDQ0Vf39/6devnxw5cqSiYwAAAAAAAABOKmWOsBtuuEGWLFnyf9/E/f++zahRo+Tbb7+VefPmSVBQkIwYMULuuOMO+emnnyojCgAAAADAxJjbDEBFqpQizN3dXSIiIoqtz8nJkffff19mz54tnTt3FhGRmTNnSqNGjWTt2rVy8803V0YcAAAAAAAAoHLmCNu5c6dERUVJnTp1ZMCAAXLgwAEREUlPT5fCwkJJSEhw3Dc2NlZq1qwpaWlplREFAAAAAAAAEJFKOCIsPj5ePvjgA2nYsKEcPnxYJkyYILfccots3bpVsrKyxNPTU4KDg52+Jjw8XLKyskp9zPz8fMnPz3fczs3NrejYAAAAAAAAuM5VeBGWlJTk+HezZs0kPj5eatWqJZ999pn4+Pj8qcdMTU2VCRMmVFREAAAAAAAAWFClnBp5ueDgYGnQoIHs2rVLIiIipKCgQE6ePOl0nyNHjpQ4p9glKSkpkpOT41gOHjxYyakBAAAAAABwvan0Iuz06dOye/duiYyMlLi4OPHw8JClS5c6xnfs2CEHDhyQNm3alPoYXl5eEhgY6LQAAAAAAAAA5VHhp0Y+8cQT0rNnT6lVq5ZkZmbK+PHjxc3NTe655x4JCgqSIUOGyOjRoyUkJEQCAwNl5MiR0qZNG64YCQAAAAAAgEpV4UXYoUOH5J577pHs7GypVq2atG/fXtauXSvVqlUTEZHXX39d7Ha79OvXT/Lz8yUxMVH++c9/VnQMAAAAAAAAwEmFF2Fz5swpc9zb21umTZsm06ZNq+hvDQAAAACAy4h5+ttKe+x9k3tU2mMD17NKnyMMAAAAAAAAcAUUYQAAAAAAALAEijAAAAAAAABYAkUYAAAAAAAALIEiDAAAAAAAAJZAEQYAAAAAAABLoAgDAAAAAACAJVCEAQAAAAAAwBLcjQ4AAAAAAABcR8zT31baY++b3KPSHhu4GhwRBgAAAAAAAEugCAMAAAAAAIAlUIQBAAAAAADAEpgjDAAAAAAAXBeY3wxXwhFhAAAAAAAAsASOCAMAAAAAADCQmY9kM1t2jggDAAAAAACAJVCEAQAAAAAAwBIowgAAAAAAAGAJFGEAAAAAAACwBIowAAAAAAAAWAJFGAAAAAAAACyBIgwAAAAAAACWQBEGAAAAAAAAS6AIAwAAAAAAgCVQhAEAAAAAAMASKMIAAAAAAABgCRRhAAAAAAAAsASKMAAAAAAAAFgCRRgAAAAAAAAsgSIMAAAAAAAAlkARBgAAAAAAAEugCAMAAAAAAIAlUIQBAAAAAADAEijCAAAAAAAAYAkUYQAAAAAAALCECi/CUlNT5aabbpKAgAAJCwuTPn36yI4dO5zu07FjR7HZbE7LI488UtFRAAAAAAAAAIcKL8JWrlwpycnJsnbtWlm8eLEUFhZK165dJS8vz+l+Q4cOlcOHDzuWKVOmVHQUAAAAAAAAwMG9oh9w0aJFTrc/+OADCQsLk/T0dLn11lsd6319fSUiIqKivz0AAAAAAABQokqfIywnJ0dEREJCQpzWf/LJJ1K1alVp0qSJpKSkyJkzZyo7CgAAAAAAACyswo8Iu1xRUZE8/vjj0q5dO2nSpIlj/b333iu1atWSqKgo2bx5s4wZM0Z27NghX375ZYmPk5+fL/n5+Y7bubm5lRkbAAAAAAAA16FKLcKSk5Nl69atsnr1aqf1Dz/8sOPfTZs2lcjISOnSpYvs3r1b6tatW+xxUlNTZcKECZUZFQAAAAAAANe5Sjs1csSIEfLNN9/I8uXLpUaNGmXeNz4+XkREdu3aVeJ4SkqK5OTkOJaDBw9WeF4AAAAAAABc3yr8iDBVlZEjR8r8+fNlxYoVUrt27St+TUZGhoiIREZGljju5eUlXl5eFRkTAAAAAAAAFlPhRVhycrLMnj1bvvrqKwkICJCsrCwREQkKChIfHx/ZvXu3zJ49W7p37y6hoaGyefNmGTVqlNx6663SrFmzio4DAAAAAAAAiEglFGHvvPOOiIh07NjRaf3MmTPl/vvvF09PT1myZIm88cYbkpeXJ9HR0dKvXz8ZO3ZsRUcBAAAAAAAAHCrl1MiyREdHy8qVKyv62wIAAAAAAABlqrTJ8gEAAAAAAABXQhEGAAAAAAAAS6AIAwAAAAAAgCVQhAEAAAAAAMASKMIAAAAAAABgCRRhAAAAAAAAsASKMAAAAAAAAFgCRRgAAAAAAAAsgSIMAAAAAAAAlkARBgAAAAAAAEugCAMAAAAAAIAlUIQBAAAAAADAEijCAAAAAAAAYAkUYQAAAAAAALAEijAAAAAAAABYAkUYAAAAAAAALIEiDAAAAAAAAJZAEQYAAAAAAABLoAgDAAAAAACAJVCEAQAAAAAAwBIowgAAAAAAAGAJFGEAAAAAAACwBIowAAAAAAAAWAJFGAAAAAAAACyBIgwAAAAAAACWQBEGAAAAAAAAS6AIAwAAAAAAgCVQhAEAAAAAAMASKMIAAAAAAABgCRRhAAAAAAAAsASKMAAAAAAAAFgCRRgAAAAAAAAsgSIMAAAAAAAAlkARBgAAAAAAAEugCAMAAAAAAIAlUIQBAAAAAADAEgwtwqZNmyYxMTHi7e0t8fHxsn79eiPjAAAAAAAA4DpmWBE2d+5cGT16tIwfP142btwozZs3l8TERDl69KhRkQAAAAAAAHAdM6wIe+2112To0KHywAMPSOPGjWX69Oni6+srM2bMMCoSAAAAAAAArmPuRnzTgoICSU9Pl5SUFMc6u90uCQkJkpaWVuz++fn5kp+f77idk5MjIiK5ublX/T2L8s/8hcRlK0+O8jJrbhHzZjdrbhHzZjdrbhHzZjdrbhHzZjdrbhHzZjdrbhHzZjdrbhHzZjdrbhHzZjdrbhHzZjdrbhHzZjdrbhHzZjdrbhHXyX7pvqpa5v1seqV7VILMzEypXr26rFmzRtq0aeNY/9RTT8nKlStl3bp1Tvd/7rnnZMKECdc6JgAAAAAAAEzk4MGDUqNGjVLHDTkirLxSUlJk9OjRjttFRUVy/PhxCQ0NFZvNVqHfKzc3V6Kjo+XgwYMSGBhYoY9d2cya3ay5Rcyb3ay5Rcyb3ay5Rcyb3ay5Rcyb3ay5Rcyb3ay5Rcyb3ay5Rcyb3ay5Rcyb3ay5Rcyb3ay5Rcyb3ay5RcybvbJzq6qcOnVKoqKiyryfIUVY1apVxc3NTY4cOeK0/siRIxIREVHs/l5eXuLl5eW0Ljg4uDIjSmBgoKmeUJcza3az5hYxb3az5hYxb3az5hYxb3az5hYxb3az5hYxb3az5hYxb3az5hYxb3az5hYxb3az5hYxb3az5hYxb3az5hYxb/bKzB0UFHTF+xgyWb6np6fExcXJ0qVLHeuKiopk6dKlTqdKAgAAAAAAABXFsFMjR48eLYMHD5ZWrVpJ69at5Y033pC8vDx54IEHjIoEAAAAAACA65hhRdjf/vY3OXbsmDz77LOSlZUlN954oyxatEjCw8ONiiQiF0/DHD9+fLFTMc3ArNnNmlvEvNnNmlvEvNnNmlvEvNnNmlvEvNnNmlvEvNnNmlvEvNnNmlvEvNnNmlvEvNnNmlvEvNnNmlvEvNnNmlvEvNldJbchV40EAAAAAAAArjVD5ggDAAAAAAAArjWKMAAAAAAAAFgCRRgAAAAAAAAsgSIMAAAAAAAAlkARBgAAAAAAAEtwNzoA/pxDhw6Jt7e3VK1aVUREfvzxR5k+fbocOHBAatWqJcnJydKmTRuDU17ZyZMnZd68eY7c/fv3l6CgIKNjXVe++OILSUpKEl9fX6OjWN4HH3wgffv25Tl+DU2YMEGSk5Md75WuKD09XeLi4oyOARjq/PnzkpmZKTVr1jQ6ClzAhQsXZP/+/RITEyN2u13y8/Plq6++kqKiIunUqZOEh4cbHfGqmHk7d+fOnY7c9erVMzoOUGEuXLggbm5ujtvr16+XoqIiadGihXh5eRmY7PqVlZUl69atk6ysLBERiYiIkPj4eImIiDAulKJMx48f11mzZhkdo5jWrVvrwoULVVV1wYIFarfbtVevXjpmzBjt27evenh4OMZdSd++fXXevHmqqrp161atWrWqVqtWTePj4zU8PFwjIiL0t99+Mzhl2c6fP+90e+3atbpy5UotKCgwKFHZbDabBgYG6tChQ3Xt2rVGx6lQp0+f1pUrVxod46p5eHi4/PNb9eJzfPfu3XrhwgVVVT137pzOnTtXP/30U83KyjI4XclycnKKLSdPnlQPDw9dt26dY50rstlsWrduXX3xxRf1P//5j9Fxys2Mz5fS3H///ab8f3C5wsJC3b9/v9Exyi0jI0PtdrvRMa6osLBQf/jhB/33v/+tixcvLrZN4GoyMjL0/fff1927d6vqxW2v4cOH67Bhw3TRokUGpyvZpk2bNDIyUu12uzZp0kQPHDigTZo0UT8/P/X399cqVaro+vXrjY5ZIrNu506aNEmXLFmiqhf3fbp06aI2m01tNpva7Xbt1q2bnjhxwtiQ5TRz5kw9efKk0THKNG3aNO3SpYv279/f8fu/5NixY1q7dm2Dkv05RUVFLv2euG/fPo2Li1M3Nzft1q2b5uTkaEJCguO5XqdOHd2xY4fRMUt15MgRXbp0qeN5nZWVpS+99JKmpqbq5s2bDU5XstOnT+uAAQPUzc1N3d3dNSwsTMPCwtTd3V3d3Nx04MCBmpeXZ0g2irArcNUNMz8/P92zZ4+qqsbHx+vkyZOdxqdOnaotWrQwIlqZqlSpotu2bVNV1aSkJL333ns1Pz9fVVULCgp0yJAh2rVrVyMjliozM1PbtWunbm5ueuutt+rx48e1R48ejjfPBg0aaGZmptExi7HZbDpx4kRt0aKF2mw2veGGG/T111/XP/74w+hof5mrvj6rVKlS4mKz2TQoKMhx2xWZdQfEbreXuFzaiL/0X1dks9l06NChjg2DHj166Pz58116Y/ISsz5fNm3aVOLi4eGh8+fPd9w2I1d9X7wSV809YsQIxweLBw8e1NjYWHVzc9Pw8HB1c3PTpk2b6qFDhwxOWbIvvvhC3dzcNDQ0VP39/XXx4sUaHBysCQkJmpiYqG5ubvrJJ58YHbOYxMREvfPOO3XLli362GOPaaNGjbR///5aUFCghYWFOnDgQE1ISDA6ZonMup1bo0YN3bhxo6qqPvTQQ9qiRQvduHGjnj17VjMyMvTmm2/WIUOGGJyyfFz9w8c333xTfX19NTk5WQcOHKienp46adIkx3hWVpZLvieqXvxA4JlnntFbb71Vn332WVVVnTJlivr6+qqnp6cOGjTI8bx3Jf369dMOHTrowoUL9a677tJ27dppx44d9dChQ5qZmamJiYnap08fo2OWaPny5ern56c2m00jIiI0IyNDa9SoofXr19eGDRuql5eXfv/990bHLGbIkCFav359XbRokdN27fnz5/X777/XBg0a6EMPPWRINssXYSUdRXD58uOPP7rkm1BQUJBjIz0sLKzYBvuuXbvU19fXiGhl8vHx0V27dqmqamRkpOOP7iU7duzQoKAgA5Jd2X333adt27bVr7/+Wv/2t79p27Zt9ZZbbtFDhw7p/v37tV27dpqcnGx0zGJsNpseOXJEVVU3bNigw4cP1+DgYPXy8tL+/fvrDz/8YHDCP89Vd5z8/f21R48e+sEHHziWmTNnqpubm7744ouOda7IrDsg1atX1x49euiyZct0xYoVumLFCl2+fLm6ubnpzJkzHetc0aXXaGFhoX7++efavXt3x472U0895dKfTpr1+XJ5Qfrfi6sXp1fiqu+LLVq0KHOJjY11ydzh4eG6ZcsWVVW96667NCEhQY8dO6aqqtnZ2Xr77bfrnXfeaWTEUrVs2VJfeOEFVVX99NNPNTg4WCdOnOgYf+WVV/TGG280Kl6pqlSp4igwzpw5o25ubrpu3TrH+NatWzU0NNSoeGUy63aul5eX7tu3T1VVY2Jiih1tv2HDBo2MjDQi2hWZ9cPHxo0bOxXRP/30k1arVk3HjRunqq5dhI0dO1bDw8N19OjR2rhxY33kkUc0OjpaP/74Y501a5ZWr15dX3rpJaNjFlOtWjX95ZdfVFX15MmTarPZ9Mcff3SMp6ena3h4uEHpyta+fXtNTk7WU6dO6csvv6zVq1d32u984okntG3btgYmLFlwcLD+9NNPpY6vXr1ag4ODr2Gi/2P5IuzSxu6VjiZwNb169dKnn35aVS/uiLz55ptO4++9957Wr1/fiGhlio+P13fffVdVL24Uz58/32n8hx9+0IiICAOSXVlkZKSmpaWp6sWNX5vN5nQY89KlS7VOnTpGxSvV5UXYJWfPntUPP/xQO3bsqHa7XWNiYgxKV7bSNm4uLYGBgS75+ty5c6fedNNNOmjQID116pRjvbu7u/76668GJrsys+6AZGdna58+fbRTp05OR2eY4Xde0mv00KFDOnHiRK1Tp47a7Xa95ZZbDEpXNrM+X5o3b649evTQbdu26b59+3Tfvn26d+9edXd318WLFzvWuSKzFkpeXl46ePBgfe6550pchg0b5pK5vb29HUfg16hRw+n5raq6ZcsWrVq1qhHRrsjPz0/37t2rqhdPWfLw8HA6fWb37t3q7+9vULrSBQcH6++//66qF4+icnNz0/T0dMf4tm3bXLLYUDXvdm6DBg30m2++UVXV2rVrF9tx/eWXXzQwMNCIaFdk1g8ffXx8HK/PS7Zs2aLh4eH69NNPu3QRVqdOHceRsjt37lS73a5z5sxxjM+dO1ebNGliVLxSBQQEON7PL1y4oO7u7pqRkeEY37lzpwYEBBgVr0yBgYGOkr2wsFDd3d0dpZ6q6u+//+6SJXtgYKD+/PPPpY6vX7/esPcWy0+WHxAQIM8884zEx8eXOL5z504ZNmzYNU51ZZMnT5ZbbrlFMjMzpX379vLMM8/Izz//LI0aNZIdO3bI3LlzZfr06UbHLGbcuHEyaNAg8fDwkEcffVRGjRol2dnZjtzjx4+X++67z+iYJTpx4oRUr15dRERCQkLE19dXatWq5RivV6+eHD582Kh4pbLZbMXWeXt7y3333Sf33Xef7Nq1S2bOnGlAsivLz8+X4cOHS9OmTUsc379/v0yYMOEap7qyevXqyZo1a+SZZ56RG2+8UWbNmiXt2rUzOtZVUVVxd7/4p+G//ysi4ubmJkVFRYZkK0tISIjMnz9f3nnnHWndurW88sorcs899xgd66qU9BqtXr26jBs3TsaNGydLly6VGTNmGJDsysz6fFm/fr089dRT0q9fP/n444+lRYsWjrGoqCin93ZX89tvv8ndd98ttWvXLnH88OHD8vvvv1/jVFfWpEkTiY+Pl+HDh5c4npGRIe+99941TnVlDRo0kPXr10vt2rUlICBAcnNzncZPnTrlks9xkYvbuNnZ2RITEyMnT56U8+fPS3Z2tmM8Oztb/P39DUxYsri4OHnppZdkwoQJ8v7770vt2rXl7bffdrwPTp06VZo0aWJwypKZdTt36NCh8uSTT0rDhg1lxIgR8sQTT8hHH30kdevWlb1798qoUaOka9euRscs0S+//CL33nuvLFu2TKZNm+Z4Tg8dOlT69OkjjRs3NjhhyapWrSoHDx6UmJgYx7omTZrIsmXLpHPnzpKZmWlcuCvIzMyU5s2bi8jFbV5PT0/HbRGRm266Sfbv329UvFLdcMMNMmPGDHn++edl1qxZEhoaKnPmzHFk//TTT6VBgwYGpyyZp6ennDt3TkRECgoKpKioyHFbROTs2bPi4eFhVLxS3X777fLwww/L+++/77StJXLxtTt8+HDp2bOnMeEMqd9cSMeOHcs8dDMjI0NtNts1THT1du3apXfffbcGBAQ4Tunw8PDQtm3bFvsEypV8/vnnWqNGjWKnpXh7e+vjjz/usvPi1KxZ0+mT4DFjxmh2drbjdkZGhkt+KlzS0SZm0bZtW33jjTdKHXfVU4Aut3TpUq1Zs6ampKSoh4eHyx+d1KVLFx0yZIgeOnRIJ0yYoPXq1dMHHnjAMf73v//dZY9OuuTXX3/V5s2b6z333GPaI8LMwuzPl//93//VGjVq6KRJkxyfDrv68yUuLk7/+c9/ljr+yy+/uOT74qOPPqqPPfZYqeO7du3Sjh07XrtAV2nmzJlao0YNXb58uX744YfaqFEjXbJkif7nP//RZcuWadOmTQ2b3+RKBg4cqPHx8frxxx9rz549NTExUW+++Wbdtm2bbt++XTt06OCSp3WuX79eQ0ND1W63a7Vq1XTr1q0aHx+vERERGhUVpT4+PsUmFnclZt3OHTlypHp4eGhsbKx6e3ur3W5XT09Ptdvt2qpVKz18+LDREUtVWFioTz31lNatW1dXr16tqq5/RPg999yjjz/+eIljW7du1WrVqrnke7nqxVPGLz+6tG3btk5H42/bts0ljyBctGiRent7q6enp3p7e+vKlSu1QYMG2rp1a7355pvVzc1N586da3TMEvXu3Vtvv/12Xb16tT788MPaqlUr7dGjh54+fVrz8vL0zjvv1G7duhkds5jjx49rt27d1GazaUhIiMbGxmpsbKyGhISo3W7XpKQkwy7EYfki7N133y12WuHlsrKy9LnnnruGicqvqKhIs7KyNDMz02WvXPjfzp8/r+vXr9c5c+bo7Nmzdfny5Zqbm2t0rDL16tWrzFLm7bff1s6dO1/DRFdn3759jqu5Xa6oqMiANOXz4osvlvn6O3DggN5///3XMNGf88cff2jfvn01ODhYt2/fbnScMpl9B+SS/Px8HTVqlN54442Ow+Bd1YoVK7SwsNDoGH/K9fB8ycrK0qSkJL3llltcfsdJ1byFkpm9+uqr6uvrqz4+Po5i4NLSp08fp1PgXUlWVpbedttt6u/vr4mJiXry5EkdMWKEY9qP+vXrO061cTWnT5/WDRs2OH63Z8+e1X//+986depUl/87qnpxO3fdunWm2s5VVf3tt990ypQp+sgjj+jDDz+s48eP1x9++MEU24yq5vrwcdOmTTpjxoxSx7ds2eKy+6CdOnUq83TTzz77TOPi4q5hoqu3d+9e/fzzzx2npWZlZem4ceP0H//4hy5btszYcGX4/ffftX79+mqz2bRRo0Z66NAh7dWrl7q7u6u7u7tWq1bN6RRyV7Nt2zadMWOGTpo0SSdNmqQzZsxwXFjEKDZVVWOORQOuL+vXrxdfX1+XPVz/v3l6esqmTZukUaNGRkeBi8nLy5Pt27dLw4YNxd/fX86dOyeffPKJnD17Vm677TZp2LCh0RHhQq6X58tbb70ly5cvl6lTp0qNGjWMjgMXc/LkSVm8eLHs2bNHioqKJDIyUtq1ayf169c3Olq57dmzR86cOSOxsbFOpzID14Ps7GwZOnSoLF++XNauXWuav0Fm8vvvv4uHh0epp+jPnj1b3N3d5a677rrGya5/2dnZEhoa6ri9dOlSOXv2rLRp08ZpPa6MIsykNm7cKFWqVHG8AX300Ucyffp0OXDggNSqVUtGjBghd999t8Epy+/EiROycOFCGTRokNFRrhujR48ucf2bb74pAwcOdLxpvvbaa9cylqWcP39eli9fLgcOHJCYmBjp2LGjuLm5GR3LEjp37iwzZ8506TmfREQ2bdok6enp0rFjR6lTp478+uuvMm3aNCkqKpK+fftKYmKi0RGBCrd3717ZtWuXREZGmuZDJFwbqir79u2T6OhocXd3l4KCApk/f77k5+dL9+7dpWrVqkZHLFVBQYEsWLBA0tLSJCsrS0REIiIipG3bttK7d2/x9PQ0OGHp8vLyJD09XQ4fPix2u13q1KkjLVu2LHEuS/x1R48ela1bt0pcXJwEBQXJkSNHZNasWVJUVCQ9evQodY5c/DVZWVmybt06p9dnfHy8REREGJzs+vPqq6/KnXfe6ZLb4RRhcnFyuU8//VRWr17t9Mbfp08f6dKli9HxStS8eXN59dVXJSEhQf7973/Lo48+KkOHDnVMxvnvf/9b3nzzTXnwwQeNjloumzZtkpYtW8qFCxeMjlJMfn6+2O12x0SEu3fvlhkzZjjKxyFDhpT6yYiR7Ha7NG/eXIKDg53Wr1y5Ulq1aiV+fn5is9lk2bJlxgS8AjMWBCNHjpTExES5/fbb5dChQ3LbbbfJzp07pWrVqvLHH39I48aN5bvvvnNcfMGVfPHFF5KUlCS+vr5GRymXr7/+usT1d9xxh7z55psSHR0tIiK9evW6lrGuypdffil33XWXBAcHS35+vsyfP1/69+8vrVq1Ejc3N1myZIl8+OGHcu+99xodtURm3mFdtmyZ09/+unXrSs+ePU15lM8ll3Zkb731VqOjOPn73/8uU6ZMEX9/fzl79qzcd999Mn/+fFFVsdls0qFDB/n6669dcvJ2EZGioiKx2+0lrj906JDUrFnTgFR/zZEjR+Rf//qXPPvss0ZHcbJjxw5JTEyUgwcPSp06deSHH36Q/v37y/bt20VVxdfXV9asWeOSr9Ndu3ZJYmKiZGZmSnx8vISHh4vIxd/1unXrpEaNGvLdd99JvXr1DE7qrKioSJ5++ml5++23JT8/X0QuvreLiNSsWVOmTp1q3ITW16kVK1bI7bffLmfOnJHw8HBZtGiR3H777eLj4yN2u1327dsnX3/9tctepEDEfIVSXl6eDBs2TObMmSM2m01CQkJEROT48eOiqnLPPffIv/71L5fdBjbjPpHdbhe73S6dOnWShx56SPr27es6HwYYc0am69i5c6fWqlVLw8LCNDo6Wm02m/bo0UPj4+PVzc1N+/fv75Jzt/j4+Dgu7d6iRQvHpZov+eSTT7Rx48ZGRCtTTk5OmcuPP/7oshNDdujQQefNm6eqqqtXr1YvLy9t1qyZ/u1vf9MWLVqor6+vrlmzxuCUxaWmpmrt2rV16dKlTuvNMBfOF198oW5ubhoaGqr+/v66ePFiDQ4O1oSEBE1MTFQ3Nzf95JNPjI5ZTHh4uG7ZskVVVe+66y5NSEjQY8eOqapqdna23n777S45QbHqxYnbAwMDdejQobp27Vqj41y1S3PeXD4x8X8vrvre0rJlS33hhRdUVfXTTz/V4OBgnThxomP8lVde0RtvvNGoeGXavn271qpVS+12u9arV0/37NmjcXFx6ufnp76+vlq1alX9/fffjY5ZzJEjR7R169Zqt9vV3d1d7Xa7xsXFaUREhLq5uemTTz5pdMQ/zVUvImK32x0XhUhJSdEaNWrosmXLNC8vT1evXq1169bVp59+2uCUxeXk5Gj//v3V29tbw8LCdNy4cU6TnWdlZbnk7/tquOpzpXfv3tqrVy/dvHmzPv7449qoUSPt3bu3FhQU6Llz57Rnz546cOBAo2OWKCEhQXv37q05OTnFxnJycrR3797atWtXA5KVbcyYMdqoUSNduHChLl68WG+99VZ96aWXdNu2bTpu3Dj18vLS77//3uiYJSooKNAnn3xS69atqzfddJO+//77TuOu+hpt3769Jicn66lTp/Tll1/W6tWra3JysmP8iSee0LZt2xqYsHSnT5/WAQMGqJubm7q7u2tYWJiGhYWpu7u7urm56cCBAzUvL8/omMUMGTJE69evr4sWLXJ6Hz9//rx+//332qBBA5e9+IlZ94lsNpvOnDlTe/furR4eHhoaGqqPPfaYYz/JSJYvwpKSknTYsGGOSSAnT56sSUlJqnpxUrqYmBgdP368gQlLFhoaqhs2bFBV1bCwMM3IyHAa37Vrl/r4+BgRrUyXdkZLW1x5ZzUwMNCxQ9ehQwcdNWqU0/jYsWO1Xbt2RkS7ovXr12uDBg30H//4h+OCCmYowsxaEHh7ezsmaK9Ro4bT1UZVL06A6opXGFW9+BqdOHGitmjRQm02m95www36+uuv6x9//GF0tDJ169ZNe/ToUezqi2Z4nvv5+TkmbS0qKlIPDw+nqzHt3r1b/f39DUpXNrPusP7tb3/TPn36aE5Ojp47d05HjBihgwYNUtWLky2HhoaWeXEUV+aq5cblV0dt0qSJzp4922n8q6++0gYNGhgRrUyPPvqoNmjQQOfNm6fvvfee1qpVS3v06KH5+fmqenEn21WvLr5p06Yyl7lz57rkc6VatWr6yy+/qOrFHW6bzaY//vijY/ynn37SmjVrGpSubD4+PmXu4G3evNklt88jIyN11apVjtuHDh1Sf39/PXfunKqqTpw4Udu0aWNUvDKNHz9ew8PD9eWXX9ZnnnlGg4KC9OGHH3aMu+prNDAw0HGxisLCQnV3d3c871Uv7ocGBQUZE+4KzFooBQcH608//VTq+OrVqzU4OPgaJrp6Zt0nuvxv/5EjR/Sll17S2NhYtdvtetNNN+m7775r2IVELF+E+fr6On1anZ+frx4eHo6dvgULFmhMTIxR8Uo1cOBAHTJkiKqq9u/fX8eOHes0PmnSJG3atKkR0coUGBioL730kq5YsaLE5b333nPJjTLVizurl65uER4eXmL56Ko7q6qqp06d0kGDBmmzZs10y5YtLn81HVXzFgTNmjXTOXPmqKpqo0aNdPHixU7ja9as0ZCQECOiXdHlf7A2bNigw4cP1+DgYPXy8tL+/fvrDz/8YHDC0r322msaHR2tCxcudKwzQxEWERHh+GDj+PHjarPZdPny5Y7x9evXa0REhEHpymbWHdbAwEDdunWr4/bp06fVw8PDcRTHRx99pA0bNjQqXpmqVKlS5hIYGOiSf0dtNpsePXpUVVWrVq3q9PtXvXiFY1csCGrWrOn0ejx27Ji2bt1au3btqufOnXPZo01Uyz5S1pU/fPTx8dH9+/c7bvv7+ztd3fLAgQPq5eVlRLQrioyMdPob9N++/vprjYyMvIaJrk5AQIDu3r3bcfvChQvq7u6uhw8fVlXVX3/9VX19fY2KV6Z69eo5/c537typ9erV0/vvv1+Liopc9jV6+ftgXl6e2u12TUtLc4xv2rTJZT80NWuhFBgYqD///HOp4+vXr9fAwMBrmOjqmXWf6PL9isutWrVKBw8erH5+furn52dAMlXLXyomODhYTp065bh95swZOX/+vOPc1WbNmsnhw4eNileql156Sdq1aycdOnSQVq1ayauvviorVqxwzBG2du1amT9/vtExi2nZsqWIiHTo0KHE8eDgYMecBK4mPj5eFi5cKLGxsVK3bl3ZtGmTNG/e3DGekZHhONfcFfn7+8usWbNkzpw5kpCQ4JLzsP23gIAAyc7OlpiYGDl58qScP39esrOzHePZ2dkuOZ/MqFGj5IknnpDw8HBJSUmRRx99VKZOnep4fT722GNyxx13GB3ziuLi4iQuLk5ee+01mTdvnsyYMUO6desmNWvWlL179xodr5hRo0ZJp06dZMCAAbJw4UJ5/fXXjY50VRISEiQ5OVlGjhwpc+fOla5du0pKSorMnDlTbDabPPnkk9K+fXujY5bo9OnTjvc9Pz8/8fPzk8jISMd4dHS0HDlyxKh4pfLy8nKa/Nlut8uFCxfk/PnzIiLStm1b2bdvn0Hpypafny/Dhw8vdRLl/fv3y4QJE65xqqszbtw48fX1FbvdLpmZmXLDDTc4xrKzs8XPz8/AdCU7duyY0yS/VatWlSVLlkhiYqJ0795d/v3vfxuYrmwhISEyZcqUUue7/fXXX11y3qeoqCg5cOCAY961KVOmSFhYmGP82LFjUqVKFaPilemhhx6SQYMGybhx46RLly5Oc4QtXbpUXnjhBRk5cqTBKYtr2rSpfPrpp/LMM8+IiMhnn30m/v7+jrmeioqKxMvLy8iIpfrPf/7jdLGNevXqyYoVK6Rz585y3333yZQpUwxMV7p27drJ008/LU8//bR8+OGH0rJlS3nhhRdk7ty5YrPZ5Pnnn5dWrVoZHbNERUVFZc7z5OnpKUVFRdcw0dW5/fbb5eGHH5b3339fWrRo4TT2yy+/yPDhw13yPVHEvPtEpV1o45ZbbpFbbrlF3nrrLZk7d+41TvX/GVK/uZDBgwdrhw4ddNu2bbpnzx7HfE+XrFixQqOjow1MWLoTJ07omDFjtHHjxurt7a2enp5aq1Ytvffee8tsu4307rvv6ptvvlnqeFZWlj733HPXMNHVW7NmjQYFBen48eN16tSpWrVqVR07dqx+8skn+uyzz2pwcLC+9NJLRse8KgcPHtQFCxbo6dOnjY5SpoEDB2p8fLx+/PHH2rNnT01MTNSbb75Zt23bptu3b9cOHTq47Fxbr776qvr6+qqPj496eno6nQLcp08fPXXqlNERS3T5PD4l2blzp/7P//zPNUxUfmfOnNFhw4Zp/fr11c3NzeWPCMvKytLbbrtN/f39NTExUU+ePKkjRoxwHK1Rv359p6MhXEndunWdjgD75z//6XSIe3p6uksezda3b1/t16+fnj59WgsKCvTxxx/XevXqOcbXrl3rkrlVVdu2bVvmaZuuempkhw4dtGPHjo7lvffecxp//vnntUOHDsaEK0PDhg3122+/Lbb+1KlT2qZNG23evLlL/r5VVbt27arPP/98qeMZGRkuecrYsGHDij0/Lpeamqrdu3e/honKZ/LkyRoZGek0HYjNZtPIyEiX3U5csmSJenl5aevWrfXWW29Vd3d3ff311x3jL7/8snbu3Nm4gGWoXbu2LlmypNj6//znP9qgQQO97bbbXPI1+vvvv2v9+vXVZrNpo0aN9NChQ9qrVy91d3dXd3d3rVatmqanpxsds0T33nuvtmjRQjdu3FhsbOPGjRoXF6cDBgwwIFnZjh8/rt26dVObzaYhISEaGxursbGxGhISona7XZOSkvTEiRNGxyyRWfeJSjsizBVY/qqRR48eld69e8u6devEZrNJdHS0zJ8/39ESf/7553L48GGX/PQG115aWpqMHj1a1q1b57Q+KipKnnzySXnssccMSnZ9OnLkiNx3332SlpYm7dq1k7lz58rYsWNl2rRpYrPZpG7duvLdd99J3bp1jY5aopMnT8rixYtlz549UlRUJJGRkdKuXTuXvNLVJXa7XbKyspw+fTerr7/+WpYuXSrPPPOMKX+ePXv2yJkzZyQ2Nlbc3V3zAO5HHnlEWrVqJQ899FCJ45MnT5Yff/xRvv3222ucrGx79uyRrl27yv79+8Vms4mfn5/MmzdPEhISRETkgw8+kB07dkhqaqrBSYubNGmSFBYWyvjx40scP3jwoDz77LMyc+bMa5zsz9H/f9XIPXv2iKenp9SoUcPoSE5GjhwpWVlZMm/evGJjp06dkttuu01+/vlnlzzKev78+ZKXlycDBw4scfzEiRPy9ddfy+DBg69xsr9m79694u3t7XT0qSvau3ev09X0XPHK4pfbtGmTfPbZZ5Kfny+JiYly2223GR3pqjz00EOiqvL+++8XG/vPf/4jHTt2lD179rjka1Tk4pE8oaGhjttLly6Vs2fPSps2bZzWu5ITJ07IvffeK99//71UqVLFsY119OhROXnypCQmJsrs2bOLXbHeVWzbtk3Wrl3r9Pps06aNxMbGGpysdGbfJ3JFli/CLtm5c6fk5+e79A4HXMexY8ecyo2YmBijI1mKGQoCs9q/f7/UrFmz1EOZzcbT01M2bdokjRo1MjqKJbnyDuuZM2fkp59+kvz8fLn55pulatWqRkeyJFd/jZ44caLYaZyXO3XqlGzcuLHUKR9gPYcPH5Z33nlHVq9eLYcPHxa73S516tSRPn36yP333y9ubm5GR7yu7N+/X7Zv3y6JiYkljmdmZsrixYtNV/iawfbt2yUtLc1UhdL1hn2iP48i7AoOHjwo48ePlxkzZhgd5bpx9uxZSU9Pl5CQEGncuLHT2Llz5+Szzz6TQYMGGZSubJc+QWjbtq00bNhQtm/fLm+++abk5+fLwIEDpXPnzkZHvK6MHDlS7rrrLrnllluMjvKnFBUVid1uL3H9oUOHHPOf4K8bPXp0ievffPNNGThwoONT1ddee+1axrpqZn5fBK6GWV+jZv87VBZX3sY163vihg0bJCEhQerVqyc+Pj6SlpYm9957rxQUFMj3338vjRs3lkWLFklAQIDRUYtRVdm3b59ER0eLu7u7FBQUyPz58yU/P1+6d+/OhwUVLD8/X+x2u3h4eIiIyO7du2XGjBly4MABqVWrlgwZMsTljyI0o02bNkl6erp07NhR6tSpI7/++qtMmzZNioqKpG/fvqUWqvjz3n77bVm/fr10795d7r77bvnoo48kNTVVioqK5I477pCJEycaU+IZdlKmSbjqXBtmtWPHDq1Vq5Zj3oRbb71VMzMzHeOuemUXVdXvvvtOPT09NSQkRL29vfW7777TatWqaUJCgnbu3Fnd3Nx06dKlRse8rlw+R9LkyZMdVy9ydTk5Odq/f3/19vbWsLAwHTdunNPlpV35ea56cY6t999/Xx944AHt1q2bdu/eXUeMGFHiHByuwmaz6Y033ug0B1HHjh3VZrPpTTfdpB07dtROnToZHbNEZn5fPHjwoB47dsxxe9WqVXrvvfdq+/btdcCAAbpmzRoD0/15WVlZOmHCBKNjXJWioiJdtmyZvvvuu7pw4UItKCgwOlKJzPoaNevfoavhqtu4Zn5PbNeundNctx999JHGx8er6sX5iW688UZ99NFHjYpXqu3btzt+5/Xq1dM9e/ZoXFyc+vn5qa+vr1atWlV///13o2OW6o8//tBly5Zpdna2ql68uuvkyZN1woQJ+ttvvxmcrmQdOnTQefPmqerFqyx6eXlps2bNHPNV+/r6mu5vaO3atV36efLFF1+om5ubhoaGqr+/vy5evFiDg4M1ISFBExMT1c3NTT/55BOjY5Zq4cKFOm7cOF29erWqqi5dulSTkpI0MTFR//WvfxmcrmTPP/+8BgQEaL9+/TQiIkInT56soaGh+sILL+ikSZO0WrVq+uyzzxqSzfJF2FdffVXm8vrrr7vsH1sz6tOnj/bo0UOPHTumO3fu1B49emjt2rUdl8l25Y2bNm3a6DPPPKOqqp9++qlWqVLFadLwp59+Wm+77Taj4l2XbDabLlmyRB977DGtWrWqenh4aK9evXThwoV64cIFo+OV6tFHH9UGDRrovHnz9L333tNatWppjx49ND8/X1UvPs9dcYJi1YuT4deqVUvDwsI0OjpabTab9ujRQ+Pj49XNzU379++vhYWFRscsJjU1VWvXrl2sjHZ3d3f5yfLN/L7YunVrx2XrFyxYoHa7XXv16qVjxozRvn37qoeHh9Nl7c3CVQsCVdWkpCQ9efKkqqpmZ2drfHy82mw2rVatmtrtdo2NjdWjR48anLI4s75Gzfp3SNW827hmfk/08fHR3bt3O25fuHBBPTw8NCsrS1VVf/jhB42KijIqXql69+6tvXr10s2bN+vjjz+ujRo10t69e2tBQYGeO3dOe/bsqQMHDjQ6ZonWrVunQUFBarPZtEqVKrphwwatXbu21q9fX+vWras+Pj4uOel8YGCgozTq0KGDjho1yml87Nix2q5dOyOiXdGbb75Z4uLm5qYpKSmO266mZcuW+sILL6jqxX254OBgnThxomP8lVde0RtvvNGoeGWaPn26uru7a1xcnAYGBupHH32kAQEB+tBDD+mwYcPUx8enzAvpGKVu3br6xRdfqOrFbSs3Nzf9+OOPHeNffvml08WKriXLF2GXPm2y2WylLq76x9aMwsLCdPPmzY7bRUVF+sgjj2jNmjV19+7dLr1xExgYqDt37lTVixs27u7uTldL2bJli4aHhxsV77p0+ZVGCgoKdO7cuY5PbKKiovR//ud/HP9PXEnNmjV1+fLljtvHjh3T1q1ba9euXfXcuXMu/TxPSkrSYcOGaVFRkapevPpVUlKSql68wlFMTIyOHz/ewISlW79+vTZo0ED/8Y9/OI6KcfWdbFVzvy/6+fnpnj17VFU1Pj5eJ0+e7DQ+depUpysxu4pNmzaVucydO9dlf+eXvy8OHz5cGzdu7Ph/cPDgQY2Li9NHHnnEyIilMuNr1Kx/h1TNu41r5vfEWrVqOY7WUFXNzMxUm82mZ86cUVXVvXv3qre3t1HxSlWtWjX95ZdfVFX19OnTarPZnK4I/NNPP2nNmjUNSle2hIQEfeihhzQ3N1dffvllrVGjhj700EOO8QceeED79OljYMKS+fn56bZt21RVNTw8XDMyMpzGd+3apf7+/kZEuyKbzaY1atTQmJgYp8Vms2n16tU1JiZGa9eubXTMYvz8/HTv3r2qevF9xcPDw+m9Zvfu3S77O2/cuLG+++67qqq6bNky9fb21mnTpjnGZ86cqY0aNTIqXql8fHwcH2Koqnp4eOjWrVsdt/ft26e+vr5GRKMIi4qK0gULFpQ6/ssvv7jsH1szCggIKPEQ5eTkZK1Ro4auWrXKZX/fgYGBumvXLsdtf39/p0/99u3b55IbN2ZW2iV39+/fr+PHj9datWq55PPFx8fHsWN6SW5urrZp00Y7d+6se/bsccncqqq+vr5Oh7Xn5+erh4eH/vHHH6p68aifmJgYo+Jd0alTp3TQoEHarFkz3bJli3p4eLj0Traqud8Xg4KCdNOmTap6cef10r8v2bVrl2EbOGUpqyC4tN5Vf+eXvy82bNhQv/rqK6fxJUuWuOQOyCVme42a9e+Qqnm3cc38nvjYY49pkyZN9LvvvtNly5Zpp06dtGPHjo7xRYsWad26dQ1MWLL/3ln19/d32uY9cOCAenl5GRHtiqpUqeJ4vhQUFKjdbtd169Y5xtPT07V69epGxStV586ddcqUKaqq2rZtW501a5bT+Oeff+6y5eOwYcP0xhtvLPY6dfUPNiIiInTDhg2qevFUZZvN5vTB9fr16zUiIsKgdGUrqVDasmWL4/bevXtdcnurdu3a+t1336nqxQ/U7Xa7fvbZZ47xb7/91rD9CstfWiAuLk7S09Old+/eJY7bbDZRridQYWJjY2XDhg3Frg719ttvi4hIr169jIh1VWJiYmTnzp2Oy9KmpaU5TXZ+4MABl7wy2vWoZs2a8txzz8n48eNlyZIlRscppmbNmrJt2zanSU4DAgLkhx9+kK5du0rfvn0NTFe24OBgOXXqlOP2mTNn5Pz58+Lp6SkiIs2aNZPDhw8bFe+K/P39ZdasWTJnzhxJSEhw2culX87M74sdOnSQTz/9VJo1ayYtWrSQFStWSLNmzRzjy5cvl+rVqxuYsGQhISEyZcoU6dKlS4njv/76q/Ts2fMap7p6l67qeuLEiWKXSq9Xr55kZmYaEeuqmPE1WhJX/zskYt5tXDO/J77wwgty+PBh6dmzp1y4cEHatGkjH3/8sWPcZrNJamqqgQlLFhUVJQcOHHBs106ZMkXCwsIc48eOHZMqVaoYFa9MBQUF4uPjIyIiHh4e4uvr6zSxf9WqVSU7O9uoeKV64YUXJCkpSfLy8uSee+6Rf/zjH7Jz505p1KiR7NixQ9566y1JSUkxOmaJpk+fLvPnz5fExER56qmnZMSIEUZHuioJCQmSnJwsI0eOlLlz50rXrl0lJSVFZs6cKTabTZ588klp37690TFLFBoa6riye2Zmppw/f14OHDggTZo0EZGLV08NCQkxOGVxAwYMkEGDBknv3r1l6dKl8tRTT8kTTzwh2dnZYrPZ5MUXX5Q777zTmHCG1G8uZNWqVY6WsiSnT5/WFStWXMNE17dJkyY5TrMqyfDhw1127qR33nlHv/nmm1LHU1JSdMiQIdcw0fUvJibGcSSSmYwcOVLvvPPOEsdyc3M1Pj7eZT/NHjx4sHbo0EG3bdume/bscUzaesmKFSs0OjrawIRX7+DBg7pgwQI9ffq00VHKZOb3xd9++01DQ0N10KBB+vzzz6u/v78OHDhQX3zxRR00aJB6eXnpzJkzjY5ZTNeuXfX5558vdTwjI8Nlf+c2m027d++uffv21SpVqhSbg23t2rWmOU3fDK9Rs/4dUjXvNq6Z3xMvOXv2rJ46dcroGFdt2LBh+t5775U6npqaqt27d7+Gia5ebGys09yD33zzjeNUVNWL74k1atQwItoVrVmzRm+++eZiRyZXr17dJed7+m+HDh3Szp07a7du3fTw4cMuf0RYVlaW3nbbberv76+JiYl68uRJHTFihNNFUS4/EtKVJCcna/369fWFF17Q1q1b6+DBgzU2Nla/++47XbRokTZt2lQffPBBo2MWc+HCBX3xxRf19ttv10mTJmlRUZF++umnGh0draGhoXr//fcbtg1gU3XBj4IAwMROnDghmZmZcsMNN5Q4furUKdm4caN06NDhGie7sqNHj0rv3r1l3bp1YrPZJDo6WubPny8tWrQQEZHPP/9cDh8+LCNHjjQ4KVzF7t27ZezYsfLtt9/K6dOnRUTE3d1dbrrpJnnyySelT58+xgYswfz58yUvL08GDhxY4viJEyfk66+/lsGDB1/jZFf2wAMPON1OSkqSu+66y3H7qaeeks2bN8uiRYuudTQA16m9e/eKt7e3S575MGHCBGnYsKHcfffdJY4/88wzsn37dvniiy+ucbKrd+zYMdmzZ48UFRVJRESE0xkFrk5VZfLkyfLWW2/JsWPHZPPmzdK4cWOjY5XLnj175MyZMxIbGyvu7q55wlxeXp6MGjVK0tLSpG3btjJ16lR566235JlnnpHCwkLp0KGDzJ071+lITpSNIgwAUMzOnTslPz/fpTcK4FpUVY4ePSpFRUVStWpV8fDwMDqSJeXl5Ymbm5t4e3sbHQUADHfmzBlxc3MTLy8vo6NcFU9PT9m0aVOxU4NdXXp6uqxevVoGDRrksqfRXo/OnTsnhYWFEhAQYHQU07EbHQAArkdnz56V1atXy2+//VZs7Ny5c/Lhhx8akOrq1a9fX5o0aVKsBDt48KA8+OCDBqWCK7PZbBIeHi6RkZGOEsyszxez5hYROX78uPz97383OgYAkzH7dktpsrOzZfjw4UbHKGb06NElLhcuXJDJkyc7bptFXFycPPbYY1KlShWX/ht6vT3Pvb29JSAgwKV/566KI8IAoIL9/vvv0rVrVzlw4IDYbDZp3769zJkzx3FKwZEjRyQqKsqUk0Rv2rRJWrZsacrsuPbM+nwxa24Rc2cHYAy2W649u90uzZs3l+DgYKf1K1eulFatWomfn5/YbDZZtmyZMQH/Alf9nfM8x+U43wUAKtiYMWOkSZMmsmHDBjl58qQ8/vjj0q5dO1mxYoXTlUZd0ddff13m+J49e65REpiBWZ8vZs0tYu7sAFwT2y3X3qRJk+Tdd9+VV199VTp37uxY7+HhIR988IFLz7Nl1t85z3NcjiPCAKCChYeHy5IlS6Rp06YicnHupL///e/yv//7v7J8+XLx8/Nz2U+c7Ha72Gw2KetPg81mc8nsuPbM+nwxa24Rc2cH4JrYbjHGzz//LAMHDpSePXtKamqqeHh4iIeHh2zatMmlizCz/s55nuNyzBEGABXs7NmzTnNr2Ww2eeedd6Rnz57SoUMH+f333w1MV7bIyEj58ssvpaioqMRl48aNRkeECzHr88WsuUXMnR2Aa2K7xRg33XSTpKeny7Fjx6RVq1aydetWsdlsRse6IrP+znme43IUYQBQwWJjY2XDhg3F1r/99tvSu3dv6dWrlwGprk5cXJykp6eXOn6lT6NgLWZ9vpg1t4i5swNwTWy3GMff319mzZolKSkpkpCQYIojesz6O+d5jssxRxgAVLC+ffvKp59+Kvfdd1+xsbfffluKiopk+vTpBiS7sieffFLy8vJKHa9Xr54sX778GiaCKzPr88WsuUXMnR2Aa2K7xXh33323tG/fXtLT06VWrVpGxymTWX/nPM9xOeYIAwAAAAAAgCVwaiQAAAAAAAAsgSIMAAAAAAAAlkARBgAAAAAAAEugCAMAAAAAAIAlUIQBAAAAAADAEijCAAAAAAAAYAkUYQAAAAAAALAEijAAAAAAAABYwv8Dgr9QdEd7vGIAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "story_counts = train_df[\"p\"].cat.codes.value_counts(sort=True)\n",
    "story_counts[:25].plot(kind=\"bar\", figsize=(15,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1790/3421603498.py:1: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  story_counts[-25:-1].plot(kind=\"bar\", figsize=(15,5))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "story_counts[-25:-1].plot(kind=\"bar\", figsize=(15,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABMEAAAGsCAYAAADUhrAuAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAArj0lEQVR4nO3dfZBV9X0/8M8CyyKRRZEKrIIYk5psVGxh2dKHFBMEiaNBY2uibTYmJW1yscZtk0CnCrad6piJZdrcie00PkxbM1Yn6lRaE0I0tA2RVYakZisTHHxIcNengZWlLsvu+f3R4f66ywK7l+VezndfrxkG7jnn3vO5937u997z5jzUZFmWBQAAAAAkbFy1CwAAAACAE00IBgAAAEDyhGAAAAAAJE8IBgAAAEDyhGAAAAAAJE8IBgAAAEDyhGAAAAAAJG9CtQsYqf7+/ti9e3dMmTIlampqql0OAAAAAFWUZVm8/fbb0dDQEOPGHXl/r9yFYLt3747Zs2dXuwwAAAAATiKvvPJKnH322Uecn7sQbMqUKRHxv0+svr6+ytWMXG9vb3znO9+JpUuXRm1tbbXL4SSgJxhMTzAUfcFgeoKh6AsG0xMMRV8wWN57oqurK2bPnl3KjI4kNyFYsViMYrEYfX19ERFRX1+f2xBs8uTJUV9fn8vGYvTpCQbTEwxFXzCYnmAo+oLB9ARD0RcMlkpPHOu0Wbk5MX6hUIj29vZoa2urdikAAAAA5ExuQjAAAAAAKJcQDAAAAIDkCcEAAAAASJ4QDAAAAIDkCcEAAAAASJ4QDAAAAIDkCcEAAAAASJ4QDAAAAIDkCcEAAAAASJ4QDAAAAIDkCcEAAAAASJ4QDAAAAIDkCcEAAAAASJ4QDAAAAIDkTah2AXAymbt6Q9n3ffGOy0exEgAAAGA02RMMAAAAgOQJwQAAAABIXm5CsGKxGI2NjdHU1FTtUgAAAADImdyEYIVCIdrb26Otra3apQAAAACQM7kJwQAAAACgXEIwAAAAAJInBAMAAAAgeUIwAAAAAJInBAMAAAAgeUIwAAAAAJInBAMAAAAgeUIwAAAAAJInBAMAAAAgeUIwAAAAAJInBAMAAAAgeUIwAAAAAJI3odoFkC9zV28o634v3nH5KFcCAAAAMHz2BAMAAAAgeUIwAAAAAJInBAMAAAAgeUIwAAAAAJInBAMAAAAgeUIwAAAAAJInBAMAAAAgeUIwAAAAAJInBAMAAAAgeUIwAAAAAJInBAMAAAAgeRMqvcI9e/bEkiVL4uDBg3Hw4MG46aabYuXKlZUug8TNXb2h2iUAAAAAJ5GKh2BTpkyJzZs3x+TJk6O7uzsuuOCCuPrqq+OMM86odCkAAAAAjBEVPxxy/PjxMXny5IiI6OnpiSzLIsuySpcBAAAAwBgy4hBs8+bNccUVV0RDQ0PU1NTEo48+etgyxWIx5s6dG5MmTYrm5ubYunXrgPl79uyJefPmxdlnnx1f/OIXY/r06WU/AQAAAAA4lhEfDtnd3R3z5s2LT3/603H11VcfNv/BBx+M1tbWuPvuu6O5uTnWr18fy5Ytix07dsSZZ54ZERGnnXZa/OhHP4rOzs64+uqr45prrokZM2YMub6enp7o6ekp3e7q6oqIiN7e3ujt7R1p+VV3qOY81h4RUTe+vL32Kv18y63zeJT7HPPeE4w+PcFQ9AWD6QmGoi8YTE8wFH3BYHnvieHWXZMdx7GINTU18cgjj8SKFStK05qbm6OpqSm+9rWvRUREf39/zJ49O2688cZYvXr1YY/x+c9/Pj70oQ/FNddcM+Q61q1bF7fddtth0x944IHSYZUAAAAAjE379++P6667Lvbu3Rv19fVHXG5UT4x/4MCBePbZZ2PNmjWlaePGjYslS5bEli1bIiKis7MzJk+eHFOmTIm9e/fG5s2b43Of+9wRH3PNmjXR2tpaut3V1RWzZ8+OpUuXHvWJnax6e3tj48aNcemll0ZtbW21yxmxC9Z9u6Lre27dsrLuV+k6I8qvNe89wejTEwxFXzCYnmAo+oLB9ARD0RcMlveeOHTU4LGMagj2xhtvRF9f32GHNs6YMSOef/75iIh46aWX4rOf/WzphPg33nhjXHjhhUd8zLq6uqirqztsem1tbS7fmEPyWn9PX01F11fua1TpOiPKr/X/3j+PPcGJoycYir5gMD3BUPQFg+kJhqIvGCyvPTHcmkc1BBuOhQsXxvbt2yu9WgAAAADGsBFfHfJopk+fHuPHj4/Ozs4B0zs7O2PmzJmjuSoAAAAAGLZRDcEmTpwY8+fPj02bNpWm9ff3x6ZNm2LRokXH9djFYjEaGxujqanpeMsEAAAAYIwZ8eGQ+/bti507d5Zu79q1K7Zv3x7Tpk2LOXPmRGtra7S0tMSCBQti4cKFsX79+uju7o4bbrjhuAotFApRKBSiq6srpk6delyPBQAAAMDYMuIQ7JlnnolLLrmkdPvQlRtbWlrivvvui2uvvTZef/31uPXWW6OjoyMuvvjieOKJJw47WT4AAAAAVMqIQ7DFixdHlmVHXWbVqlWxatWqsosCAAAAgNE0qucEAwAAAICTkRAMAAAAgOTlJgRzdUgAAAAAypWbEKxQKER7e3u0tbVVuxQAAAAAciY3IRgAAAAAlEsIBgAAAEDyhGAAAAAAJE8IBgAAAEDychOCuTokAAAAAOXKTQjm6pAAAAAAlCs3IRgAAAAAlEsIBgAAAEDyhGAAAAAAJE8IBgAAAEDyhGAAAAAAJC83IVixWIzGxsZoamqqdikAAAAA5ExuQrBCoRDt7e3R1tZW7VIAAAAAyJnchGAAAAAAUC4hGAAAAADJE4IBAAAAkDwhGAAAAADJm1DtAuBo5q7eUO0SAAAAgATYEwwAAACA5OUmBCsWi9HY2BhNTU3VLgUAAACAnMlNCFYoFKK9vT3a2tqqXQoAAAAAOZObEAwAAAAAyiUEAwAAACB5QjAAAAAAkicEAwAAACB5QjAAAAAAkicEAwAAACB5QjAAAAAAkicEAwAAACB5uQnBisViNDY2RlNTU7VLAQAAACBnchOCFQqFaG9vj7a2tmqXAgAAAEDO5CYEAwAAAIByCcEAAAAASJ4QDAAAAIDkCcEAAAAASJ4QDAAAAIDkCcEAAAAASJ4QDAAAAIDkCcEAAAAASJ4QDAAAAIDkCcEAAAAASJ4QDAAAAIDk5SYEKxaL0djYGE1NTdUuBQAAAICcyU0IVigUor29Pdra2qpdCgAAAAA5k5sQDAAAAADKJQQDAAAAIHlCMAAAAACSJwQDAAAAIHlCMAAAAACSJwQDAAAAIHlCMAAAAACSJwQDAAAAIHlCMAAAAACSJwQDAAAAIHlCMAAAAACSJwQDAAAAIHlCMAAAAACSJwQDAAAAIHlCMAAAAACSJwQDAAAAIHlCMAAAAACSl5sQrFgsRmNjYzQ1NVW7FAAAAAByJjchWKFQiPb29mhra6t2KQAAAADkTG5CMAAAAAAolxAMAAAAgOQJwQAAAABInhAMAAAAgOQJwQAAAABInhAMAAAAgOQJwQAAAABInhAMAAAAgOQJwQAAAABInhAMAAAAgOQJwQAAAABInhAMAAAAgOQJwQAAAABInhAMAAAAgOQJwQAAAABInhAMAAAAgOQJwQAAAABInhAMAAAAgOQJwQAAAABInhAMAAAAgOQJwQAAAABInhAMAAAAgOQJwQAAAABInhAMAAAAgORVPAR75ZVXYvHixdHY2BgXXXRRPPTQQ5UuAQAAAIAxZkLFVzhhQqxfvz4uvvji6OjoiPnz58dHPvKReNe73lXpUgAAAAAYIyoegs2aNStmzZoVEREzZ86M6dOnx1tvvSUEAwAAAOCEGfHhkJs3b44rrrgiGhoaoqamJh599NHDlikWizF37tyYNGlSNDc3x9atW4d8rGeffTb6+vpi9uzZIy4cAAAAAIZrxCFYd3d3zJs3L4rF4pDzH3zwwWhtbY21a9fGtm3bYt68ebFs2bJ47bXXBiz31ltvxSc/+cn4u7/7u/IqBwAAAIBhGvHhkMuXL4/ly5cfcf5dd90VK1eujBtuuCEiIu6+++7YsGFD3HPPPbF69eqIiOjp6YkVK1bE6tWr41d/9VePur6enp7o6ekp3e7q6oqIiN7e3ujt7R1p+VV3qOY81h4RUTc+q3YJJ61y39O89wSjT08wFH3BYHqCoegLBtMTDEVfMFjee2K4dddkWVZ2qlFTUxOPPPJIrFixIiIiDhw4EJMnT46HH364NC0ioqWlJfbs2ROPPfZYZFkW1113XZx//vmxbt26Y65j3bp1cdtttx02/YEHHojJkyeXWzoAAAAACdi/f39cd911sXfv3qivrz/icqN6Yvw33ngj+vr6YsaMGQOmz5gxI55//vmIiPjP//zPePDBB+Oiiy4qnU/sH/7hH+LCCy8c8jHXrFkTra2tpdtdXV0xe/bsWLp06VGf2Mmqt7c3Nm7cGJdeemnU1tZWu5wRu2Ddt6tdwknruXXLyrpf3nuC0acnGIq+YDA9wVD0BYPpCYaiLxgs7z1x6KjBY6n41SF//dd/Pfr7+4e9fF1dXdTV1R02vba2NpdvzCF5rb+nr6baJZy0jvf9zGtPcOLoCYaiLxhMTzAUfcFgeoKh6AsGy2tPDLfmEZ8Y/2imT58e48ePj87OzgHTOzs7Y+bMmaO5KgAAAAAYtlENwSZOnBjz58+PTZs2lab19/fHpk2bYtGiRcf12MViMRobG6Opqel4ywQAAABgjBnx4ZD79u2LnTt3lm7v2rUrtm/fHtOmTYs5c+ZEa2trtLS0xIIFC2LhwoWxfv366O7uLl0tslyFQiEKhUJ0dXXF1KlTj+uxAAAAABhbRhyCPfPMM3HJJZeUbh86aX1LS0vcd999ce2118brr78et956a3R0dMTFF18cTzzxxGEnywcAAACAShlxCLZ48eLIsuyoy6xatSpWrVpVdlEAAAAAMJpG9ZxgAAAAAHAyEoIBAAAAkLzchGCuDgkAAABAuXITghUKhWhvb4+2trZqlwIAAABAzuQmBAMAAACAcgnBAAAAAEieEAwAAACA5AnBAAAAAEjehGoXMFzFYjGKxWL09fVVuxQYVRes+3bcufB//+7pqxn2/V684/ITWBUAAACkJTd7grk6JAAAAADlyk0IBgAAAADlEoIBAAAAkDwhGAAAAADJE4IBAAAAkDwhGAAAAADJy00IViwWo7GxMZqamqpdCgAAAAA5k5sQrFAoRHt7e7S1tVW7FAAAAAByJjchGAAAAACUSwgGAAAAQPKEYAAAAAAkTwgGAAAAQPImVLsAqmPu6g3VLgEAAACgYuwJBgAAAEDychOCFYvFaGxsjKampmqXAgAAAEDO5CYEKxQK0d7eHm1tbdUuBQAAAICccU4wGCXlnmetbvwoFwIAAAAcJjd7ggEAAABAuYRgAAAAACRPCAYAAABA8oRgAAAAACRPCAYAAABA8oRgAAAAACRPCAYAAABA8iZUu4DhKhaLUSwWo6+vr9qlnBBzV28o634v3nH5KFcCAAAAkJ7c7AlWKBSivb092traql0KAAAAADmTmxAMAAAAAMolBAMAAAAgeUIwAAAAAJInBAMAAAAgebm5OiQwkCuKAgAAwPDZEwwAAACA5AnBAAAAAEiewyFzrtxD4gAAAADGEnuCAQAAAJA8IRgAAAAAyROCAQAAAJA8IRgAAAAAyctNCFYsFqOxsTGampqqXQoAAAAAOZObEKxQKER7e3u0tbVVuxQAAAAAciY3IRgAAAAAlEsIBgAAAEDyhGAAAAAAJE8IBgAAAEDyhGAAAAAAJE8IBgAAAEDyhGAAAAAAJE8IBgAAAEDyhGAAAAAAJE8IBgAAAEDyhGAAAAAAJE8IBgAAAEDyhGAAAAAAJE8IBgAAAEDyhGAAAAAAJE8IBgAAAEDychOCFYvFaGxsjKampmqXAgAAAEDO5CYEKxQK0d7eHm1tbdUuBQAAAICcyU0IBgAAAADlEoIBAAAAkDwhGAAAAADJE4IBAAAAkDwhGAAAAADJE4IBAAAAkDwhGAAAAADJE4IBAAAAkDwhGAAAAADJE4IBAAAAkDwhGAAAAADJE4IBAAAAkDwhGAAAAADJE4IBAAAAkDwhGAAAAADJE4IBAAAAkDwhGAAAAADJE4IBAAAAkDwhGAAAAADJE4IBAAAAkDwhGAAAAADJE4IBAAAAkDwhGAAAAADJE4IBAAAAkLyqhGBXXXVVnH766XHNNddUY/UAAAAAjDETqrHSm266KT796U/H/fffX43VA2WYu3pDWfd78Y7LR7kSAAAAGLmq7Am2ePHimDJlSjVWDQAAAMAYNOIQbPPmzXHFFVdEQ0ND1NTUxKOPPnrYMsViMebOnRuTJk2K5ubm2Lp162jUCgAAAABlGXEI1t3dHfPmzYtisTjk/AcffDBaW1tj7dq1sW3btpg3b14sW7YsXnvtteMuFgAAAADKMeJzgi1fvjyWL19+xPl33XVXrFy5Mm644YaIiLj77rtjw4YNcc8998Tq1atHXGBPT0/09PSUbnd1dUVERG9vb/T29o748artUM2Da68bn1WjHE4CdeOyAX+faOV+bsrt0Tx+TqvtSOMEY5u+YDA9wVD0BYPpCYaiLxgs7z0x3Lprsiwre8u7pqYmHnnkkVixYkVERBw4cCAmT54cDz/8cGlaRERLS0vs2bMnHnvssdK0p556Kr72ta/Fww8/fNR1rFu3Lm677bbDpj/wwAMxefLkcksHAAAAIAH79++P6667Lvbu3Rv19fVHXG5Urw75xhtvRF9fX8yYMWPA9BkzZsTzzz9fur1kyZL40Y9+FN3d3XH22WfHQw89FIsWLRryMdesWROtra2l211dXTF79uxYunTpUZ/Yyaq3tzc2btwYl156adTW1pamX7Du21WsimqqG5fFny/oj1ueGRc9/TUnfH3PrVtW1v3K7dFy1zeWHWmcYGzTFwymJxiKvmAwPcFQ9AWD5b0nDh01eCyjGoIN13e/+91hL1tXVxd1dXWHTa+trc3lG3PI4Pp7+k58+MHJrae/piJ9UO7nptza8vw5rba8j3OcGPqCwfQEQ9EXDKYnGIq+YLC89sRwax7xifGPZvr06TF+/Pjo7OwcML2zszNmzpw5mqsCAAAAgGEb1T3BJk6cGPPnz49NmzaVzgnW398fmzZtilWrVh3XYxeLxSgWi9HX1zcKlQInu7mrN5R1vxfvuHyUKwEAACAFIw7B9u3bFzt37izd3rVrV2zfvj2mTZsWc+bMidbW1mhpaYkFCxbEwoULY/369dHd3V26WmS5CoVCFAqF6OrqiqlTpx7XYwEAAAAwtow4BHvmmWfikksuKd0+dNL6lpaWuO++++Laa6+N119/PW699dbo6OiIiy++OJ544onDTpYPAAAAAJUy4hBs8eLFkWXZUZdZtWrVcR/+CAAAAACjZVRPjA8AAAAAJyMhGAAAAADJG9WrQ55Irg4Jo6Pcqy4CAABAnuVmT7BCoRDt7e3R1tZW7VIAAAAAyJnchGAAAAAAUC4hGAAAAADJE4IBAAAAkDwhGAAAAADJy00IViwWo7GxMZqamqpdCgAAAAA5k5sQzNUhAQAAAChXbkIwAAAAACiXEAwAAACA5AnBAAAAAEieEAwAAACA5AnBAAAAAEhebkKwYrEYjY2N0dTUVO1SAAAAAMiZ3IRghUIh2tvbo62trdqlAAAAAJAzuQnBAAAAAKBcQjAAAAAAkicEAwAAACB5QjAAAAAAkicEAwAAACB5QjAAAAAAkpebEKxYLEZjY2M0NTVVuxQAAAAAciY3IVihUIj29vZoa2urdikAAAAA5ExuQjAAAAAAKJcQDAAAAIDkCcEAAAAASJ4QDAAAAIDkCcEAAAAASJ4QDAAAAIDkCcEAAAAASJ4QDAAAAIDkTah2AcNVLBajWCxGX19ftUsBRmDu6g3VLgEAAADysydYoVCI9vb2aGtrq3YpAAAAAORMbkIwAAAAACiXEAwAAACA5AnBAAAAAEieEAwAAACA5AnBAAAAAEieEAwAAACA5AnBAAAAAEieEAwAAACA5AnBAAAAAEieEAwAAACA5AnBAAAAAEieEAwAAACA5E2odgHDVSwWo1gsRl9fX7VLAQBOgLmrN5R1vxfvuHyUKwEAIEW52ROsUChEe3t7tLW1VbsUAAAAAHImNyEYAAAAAJRLCAYAAABA8oRgAAAAACRPCAYAAABA8oRgAAAAACRPCAYAAABA8oRgAAAAACRPCAYAAABA8oRgAAAAACRPCAYAAABA8oRgAAAAACRPCAYAAABA8oRgAAAAACRPCAYAAABA8oRgAAAAACRPCAYAAABA8iZUu4DhKhaLUSwWo6+vr9qlAOTS3NUbyrrfi3dcPsqVHF1e6syLcl/PCK/pyeJI72Hd+CzuXBhxwbpvR09fzWHzvX8AAAPlZk+wQqEQ7e3t0dbWVu1SAAAAAMiZ3IRgAAAAAFAuIRgAAAAAyROCAQAAAJA8IRgAAAAAyROCAQAAAJA8IRgAAAAAyROCAQAAAJA8IRgAAAAAyROCAQAAAJA8IRgAAAAAyROCAQAAAJA8IRgAAAAAyROCAQAAAJA8IRgAAAAAyROCAQAAAJA8IRgAAAAAyROCAQAAAJA8IRgAAAAAyROCAQAAAJA8IRgAAAAAyROCAQAAAJA8IRgAAAAAyROCAQAAAJA8IRgAAAAAyatKCPb444/H+eefH+9973vj7//+76tRAgAAAABjyIRKr/DgwYPR2toaTz75ZEydOjXmz58fV111VZxxxhmVLgUAAACAMaLie4Jt3bo1PvCBD8RZZ50Vp556aixfvjy+853vVLoMAAAAAMaQEYdgmzdvjiuuuCIaGhqipqYmHn300cOWKRaLMXfu3Jg0aVI0NzfH1q1bS/N2794dZ511Vun2WWedFT//+c/Lqx4AAAAAhmHEIVh3d3fMmzcvisXikPMffPDBaG1tjbVr18a2bdti3rx5sWzZsnjttdeOu1gAAAAAKMeIzwm2fPnyWL58+RHn33XXXbFy5cq44YYbIiLi7rvvjg0bNsQ999wTq1evjoaGhgF7fv385z+PhQsXHvHxenp6oqenp3S7q6srIiJ6e3ujt7d3pOVX3aGaB9deNz6rRjmcBOrGZQP+5vjkcVwY7EjjxPEqd5yp9Gualzorrdy+OJ7vF+/9yeFIr8uxvj9Sf10Y2on6DiG/9ARD0RcMlveeGG7dNVmWlf3ruKamJh555JFYsWJFREQcOHAgJk+eHA8//HBpWkRES0tL7NmzJx577LE4ePBgvP/974+nnnqqdGL8H/zgB0c8Mf66devitttuO2z6Aw88EJMnTy63dAAAAAASsH///rjuuuti7969UV9ff8TlRvXqkG+88Ub09fXFjBkzBkyfMWNGPP/88/+7wgkT4qtf/Wpccskl0d/fH1/60peOemXINWvWRGtra+l2V1dXzJ49O5YuXXrUJ3ay6u3tjY0bN8all14atbW1pekXrPt2FauimurGZfHnC/rjlmfGRU9/TbXLGbOeW7esrPuV+9k92vqONE4c7zpTdzK9hyfCsfriSI6nXyr9mpar0u9FuUb7dTnW90deXpfjkZfPbyWVO1aQruH0hM/S2GOsSMdofX7z3hOHjho8llENwYbryiuvjCuvvHJYy9bV1UVdXd1h02tra3P5xhwyuP6ePuHHWNfTX6MPqqjc8aTc92w46zvSOKdPhnYyvocnwki//46nXyr9mpYrL78HTtTrcqTvj7y8Lscjb5/fSsr7b2VG39F6wmdp7DJW5N9of37z2hPDrXnEJ8Y/munTp8f48eOjs7NzwPTOzs6YOXPmaK4KAAAAAIZtVEOwiRMnxvz582PTpk2laf39/bFp06ZYtGjRaK4KAAAAAIZtxIdD7tu3L3bu3Fm6vWvXrti+fXtMmzYt5syZE62trdHS0hILFiyIhQsXxvr166O7u7t0tchyFYvFKBaL0dfXd1yPAwAAAMDYM+IQ7JlnnolLLrmkdPvQSetbWlrivvvui2uvvTZef/31uPXWW6OjoyMuvvjieOKJJw47Wf5IFQqFKBQK0dXVFVOnTj2uxwIAAABgbBlxCLZ48eLIsuyoy6xatSpWrVpVdlEAAAAAMJpG9ZxgAAAAAHAyEoIBAAAAkLzchGDFYjEaGxujqamp2qUAAAAAkDO5CcEKhUK0t7dHW1tbtUsBAAAAIGdyE4IBAAAAQLmEYAAAAAAkTwgGAAAAQPKEYAAAAAAkb0K1CxiuYrEYxWIxDh48GBERXV1dVa6oPL29vbF///7o6uqK2tra0vT+nv1VrIpq6hufxf79fdHXMz76+2qqXc6YVe6YUu5n92jrO9I4cbzrTN3J9B6eCMfqiyM5nn6p9Gtarrz8Jhjt1+VY3x95eV2OR14+v5VU7lhBuobTEz5LY4+xIh2j9fnNe08cej5Zlh11uZrsWEucZH72s5/F7Nmzq10GAAAAACeRV155Jc4+++wjzs9dCNbf3x+7d++OKVOmRE1N/vaa6erqitmzZ8crr7wS9fX11S6Hk4CeYDA9wVD0BYPpCYaiLxhMTzAUfcFgee+JLMvi7bffjoaGhhg37shn/srN4ZCHjBs37qipXl7U19fnsrE4cfQEg+kJhqIvGExPMBR9wWB6gqHoCwbLc09MnTr1mMs4MT4AAAAAyROCAQAAAJA8IViF1dXVxdq1a6Ourq7apXCS0BMMpicYir5gMD3BUPQFg+kJhqIvGGys9ETuTowPAAAAACNlTzAAAAAAkicEAwAAACB5QjAAAAAAkicEAwAAACB5QjAAAAAAkicEq6BisRhz586NSZMmRXNzc2zdurXaJVEht99+ezQ1NcWUKVPizDPPjBUrVsSOHTsGLLN48eKoqakZ8OcP/uAPqlQxlbBu3brD3vP3ve99pfnvvPNOFAqFOOOMM+LUU0+Nj33sY9HZ2VnFijnR5s6de1hP1NTURKFQiAjjxFixefPmuOKKK6KhoSFqamri0UcfHTA/y7K49dZbY9asWXHKKafEkiVL4qc//emAZd566624/vrro76+Pk477bT4zGc+E/v27avgs2A0Ha0nent748tf/nJceOGF8a53vSsaGhrik5/8ZOzevXvAYww1vtxxxx0VfiaMpmONFZ/61KcOe88vu+yyAcsYK9JyrJ4Y6jdGTU1NfOUrXyktY6xIy3C2Q4ezzfHyyy/H5ZdfHpMnT44zzzwzvvjFL8bBgwcr+VRGjRCsQh588MFobW2NtWvXxrZt22LevHmxbNmyeO2116pdGhXw/e9/PwqFQvzwhz+MjRs3Rm9vbyxdujS6u7sHLLdy5cp49dVXS3/uvPPOKlVMpXzgAx8Y8J7/x3/8R2nezTffHP/yL/8SDz30UHz/+9+P3bt3x9VXX13FajnR2traBvTDxo0bIyLit37rt0rLGCfS193dHfPmzYtisTjk/DvvvDP++q//Ou6+++54+umn413velcsW7Ys3nnnndIy119/ffzkJz+JjRs3xuOPPx6bN2+Oz372s5V6Coyyo/XE/v37Y9u2bXHLLbfEtm3b4lvf+lbs2LEjrrzyysOW/bM/+7MB48eNN95YifI5QY41VkREXHbZZQPe829+85sD5hsr0nKsnvi/vfDqq6/GPffcEzU1NfGxj31swHLGinQMZzv0WNscfX19cfnll8eBAwfiBz/4Qdx///1x3333xa233lqNp3T8Mipi4cKFWaFQKN3u6+vLGhoasttvv72KVVEtr732WhYR2fe///3StN/8zd/MbrrppuoVRcWtXbs2mzdv3pDz9uzZk9XW1mYPPfRQadp///d/ZxGRbdmypUIVUm033XRTdt5552X9/f1ZlhknxqKIyB555JHS7f7+/mzmzJnZV77yldK0PXv2ZHV1ddk3v/nNLMuyrL29PYuIrK2trbTMv/3bv2U1NTXZz3/+84rVzokxuCeGsnXr1iwispdeeqk07Zxzzsn+6q/+6sQWR9UM1RctLS3ZRz/60SPex1iRtuGMFR/96EezD33oQwOmGSvSNng7dDjbHP/6r/+ajRs3Luvo6Cgt8/Wvfz2rr6/Penp6KvsERoE9wSrgwIED8eyzz8aSJUtK08aNGxdLliyJLVu2VLEyqmXv3r0RETFt2rQB0//pn/4ppk+fHhdccEGsWbMm9u/fX43yqKCf/vSn0dDQEO9+97vj+uuvj5dffjkiIp599tno7e0dMG68733vizlz5hg3xogDBw7EP/7jP8anP/3pqKmpKU03Toxtu3btio6OjgFjw9SpU6O5ubk0NmzZsiVOO+20WLBgQWmZJUuWxLhx4+Lpp5+ueM1U3t69e6OmpiZOO+20AdPvuOOOOOOMM+KXfumX4itf+UpuD2Vh+J566qk488wz4/zzz4/Pfe5z8eabb5bmGSvGts7OztiwYUN85jOfOWyesSJdg7dDh7PNsWXLlrjwwgtjxowZpWWWLVsWXV1d8ZOf/KSC1Y+OCdUuYCx44403oq+vb0DTRETMmDEjnn/++SpVRbX09/fHF77whfi1X/u1uOCCC0rTr7vuujjnnHOioaEhfvzjH8eXv/zl2LFjR3zrW9+qYrWcSM3NzXHffffF+eefH6+++mrcdttt8Ru/8Rvx3HPPRUdHR0ycOPGwDZgZM2ZER0dHdQqmoh599NHYs2dPfOpTnypNM05w6PM/1G+KQ/M6OjrizDPPHDB/woQJMW3aNOPHGPDOO+/El7/85fjEJz4R9fX1pel/+Id/GL/8y78c06ZNix/84AexZs2aePXVV+Ouu+6qYrWcSJdddllcffXVce6558YLL7wQf/InfxLLly+PLVu2xPjx440VY9z9998fU6ZMOexUG8aKdA21HTqcbY6Ojo4hf3ccmpc3QjCosEKhEM8999yAcz9FxIDzL1x44YUxa9as+PCHPxwvvPBCnHfeeZUukwpYvnx56d8XXXRRNDc3xznnnBP//M//HKecckoVK+Nk8I1vfCOWL18eDQ0NpWnGCeBoent747d/+7cjy7L4+te/PmBea2tr6d8XXXRRTJw4MX7/938/br/99qirq6t0qVTAxz/+8dK/L7zwwrjooovivPPOi6eeeio+/OEPV7EyTgb33HNPXH/99TFp0qQB040V6TrSduhY43DICpg+fXqMHz/+sCssdHZ2xsyZM6tUFdWwatWqePzxx+PJJ5+Ms88++6jLNjc3R0TEzp07K1EaJ4HTTjstfvEXfzF27twZM2fOjAMHDsSePXsGLGPcGBteeuml+O53vxu/93u/d9TljBNjz6HP/9F+U8ycOfOwC+8cPHgw3nrrLeNHwg4FYC+99FJs3LhxwF5gQ2lubo6DBw/Giy++WJkCqbp3v/vdMX369NJ3hrFi7Pr3f//32LFjxzF/Z0QYK1JxpO3Q4WxzzJw5c8jfHYfm5Y0QrAImTpwY8+fPj02bNpWm9ff3x6ZNm2LRokVVrIxKybIsVq1aFY888kh873vfi3PPPfeY99m+fXtERMyaNesEV8fJYt++ffHCCy/ErFmzYv78+VFbWztg3NixY0e8/PLLxo0x4N57740zzzwzLr/88qMuZ5wYe84999yYOXPmgLGhq6srnn766dLYsGjRotizZ088++yzpWW+973vRX9/fyk4JS2HArCf/vSn8d3vfjfOOOOMY95n+/btMW7cuMMOhyNdP/vZz+LNN98sfWcYK8aub3zjGzF//vyYN2/eMZc1VuTbsbZDh7PNsWjRoviv//qvAaH5of9saWxsrMwTGUUOh6yQ1tbWaGlpiQULFsTChQtj/fr10d3dHTfccEO1S6MCCoVCPPDAA/HYY4/FlClTSsdOT506NU455ZR44YUX4oEHHoiPfOQjccYZZ8SPf/zjuPnmm+ODH/xgXHTRRVWunhPlj//4j+OKK66Ic845J3bv3h1r166N8ePHxyc+8YmYOnVqfOYzn4nW1taYNm1a1NfXx4033hiLFi2KX/mVX6l26ZxA/f39ce+990ZLS0tMmPD/v6aNE2PHvn37Buzdt2vXrti+fXtMmzYt5syZE1/4whfiL/7iL+K9731vnHvuuXHLLbdEQ0NDrFixIiIi3v/+98dll10WK1eujLvvvjt6e3tj1apV8fGPf3zA4bXkx9F6YtasWXHNNdfEtm3b4vHHH4++vr7S74xp06bFxIkTY8uWLfH000/HJZdcElOmTIktW7bEzTffHL/zO78Tp59+erWeFsfpaH0xbdq0uO222+JjH/tYzJw5M1544YX40pe+FO95z3ti2bJlEWGsSNGxvj8i/vc/Th566KH46le/etj9jRXpOdZ26HC2OZYuXRqNjY3xu7/7u3HnnXdGR0dH/Omf/mkUCoV8HiJb5atTjil/8zd/k82ZMyebOHFitnDhwuyHP/xhtUuiQiJiyD/33ntvlmVZ9vLLL2cf/OAHs2nTpmV1dXXZe97znuyLX/xitnfv3uoWzgl17bXXZrNmzcomTpyYnXXWWdm1116b7dy5szT/f/7nf7LPf/7z2emnn55Nnjw5u+qqq7JXX321ihVTCd/+9reziMh27NgxYLpxYux48sknh/zOaGlpybIsy/r7+7NbbrklmzFjRlZXV5d9+MMfPqxf3nzzzewTn/hEduqpp2b19fXZDTfckL399ttVeDaMhqP1xK5du474O+PJJ5/MsizLnn322ay5uTmbOnVqNmnSpOz9739/9pd/+ZfZO++8U90nxnE5Wl/s378/W7p0afYLv/ALWW1tbXbOOedkK1euzDo6OgY8hrEiLcf6/siyLPvbv/3b7JRTTsn27Nlz2P2NFek51nZolg1vm+PFF1/Mli9fnp1yyinZ9OnTsz/6oz/Kent7K/xsRkdNlmXZCczYAAAAAKDqnBMMAAAAgOQJwQAAAABInhAMAAAAgOQJwQAAAABInhAMAAAAgOQJwQAAAABInhAMAAAAgOQJwQAAAABInhAMAAAAgOQJwQAAAABInhAMAAAAgOT9P4JW6+Hgyy7fAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "story_counts.hist(log=True,bins=75,figsize=(15,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Validation-Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-25 16:18:07.797042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-25 16:18:08.201441: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/anaconda3/pkgs/cudatoolkit-11.2.2-hbe64b41_10/lib/libcudart.so.11.0\n",
      "2022-12-25 16:18:08.201479: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-25 16:18:09.343313: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/anaconda3/pkgs/cudatoolkit-11.2.2-hbe64b41_10/lib/libcudart.so.11.0\n",
      "2022-12-25 16:18:09.344286: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvrtc.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/anaconda3/pkgs/cudatoolkit-11.2.2-hbe64b41_10/lib/libcudart.so.11.0\n",
      "2022-12-25 16:18:09.344295: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from typing import List, Dict, Callable\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_data(model: keras.Model,\n",
    "                x: np.ndarray,\n",
    "                prediction_info: Dict):\n",
    "    \"\"\"\n",
    "    Inference routine of a given input set of examples\n",
    "\n",
    "    :param model: Keras built and possibly trained model\n",
    "    :param x: input set of examples in np.ndarray format\n",
    "    :param prediction_info: dictionary storing model predict() argument information\n",
    "\n",
    "    :return\n",
    "        predictions: predicted labels in np.ndarray format\n",
    "    \"\"\"\n",
    "    print(f'Starting prediction: \\n{prediction_info}')\n",
    "    print(f'Predicting on {x.shape[0]} samples')\n",
    "    predictions = model.predict(x, **prediction_info)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_f1(model: keras.Model, \n",
    "             x: np.ndarray, \n",
    "             y: np.ndarray):\n",
    "    \"\"\"\n",
    "    Compute F1_score on the given data with corresponding labels\n",
    "\n",
    "    :param model: Keras built and possibly trained model\n",
    "    :param x: data in np.ndarray format\n",
    "    :param y: ground-truth labels in np.ndarray format\n",
    "\n",
    "    :return\n",
    "        score: f1_macro_score\n",
    "    \"\"\"\n",
    "    #predictions on the x set\n",
    "    prediction_info = {\n",
    "        'batch_size': 64,\n",
    "        'verbose': 1\n",
    "    }\n",
    "    y_pred = predict_data(model=model, x=x, prediction_info=prediction_info)\n",
    "\n",
    "    #compute argmax to take the best class for each sample\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    #compute the f1_macro\n",
    "    score = f1_score(y, y_pred, average ='macro')\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_reproducibility(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp/lib/python3.7/site-packages/tensorflow_addons/utils/ensure_tf_install.py:67: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.8.0 and strictly below 2.11.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.11.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  UserWarning,\n",
      "2022-12-25 16:18:26.657379: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-25 16:18:26.657678: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/anaconda3/pkgs/cudatoolkit-11.2.2-hbe64b41_10/lib/libcudart.so.11.0\n",
      "2022-12-25 16:18:26.657760: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/anaconda3/pkgs/cudatoolkit-11.2.2-hbe64b41_10/lib/libcudart.so.11.0\n",
      "2022-12-25 16:18:26.657836: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/anaconda3/pkgs/cudatoolkit-11.2.2-hbe64b41_10/lib/libcudart.so.11.0\n",
      "2022-12-25 16:18:26.657918: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/anaconda3/pkgs/cudatoolkit-11.2.2-hbe64b41_10/lib/libcudart.so.11.0\n",
      "2022-12-25 16:18:26.657994: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/anaconda3/pkgs/cudatoolkit-11.2.2-hbe64b41_10/lib/libcudart.so.11.0\n",
      "2022-12-25 16:18:26.658048: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/anaconda3/pkgs/cudatoolkit-11.2.2-hbe64b41_10/lib/libcudart.so.11.0\n",
      "2022-12-25 16:18:26.658100: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/anaconda3/pkgs/cudatoolkit-11.2.2-hbe64b41_10/lib/libcudart.so.11.0\n",
      "2022-12-25 16:18:26.658742: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tqdm import tqdm\n",
    "from transformers import TFAutoModel, AutoTokenizer\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question generation $f_\\theta(P, Q)$ with text passage $P$ and question $Q$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seq2Seq LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTrainer(object):\n",
    "    \"\"\"\n",
    "    Simple wrapper class\n",
    "\n",
    "    train_op -> uses tf.GradientTape to compute the loss\n",
    "    batch_fit -> receives a batch and performs forward-backward passes (gradient included)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, encoder, decoder, max_length):\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.max_length = max_length\n",
    "        self.ce = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=1e-03)\n",
    "\n",
    "    @tf.function\n",
    "    def compute_loss(self, logits, target):\n",
    "        loss = self.ce(y_true=target, y_pred=logits)\n",
    "        mask = tf.logical_not(tf.math.equal(target, 0))\n",
    "        mask = tf.cast(mask, dtype=loss.dtype)\n",
    "        loss *= mask\n",
    "        return tf.reduce_mean(loss)\n",
    "\n",
    "    @tf.function\n",
    "    def train_op(self, inputs):\n",
    "        with tf.GradientTape() as tape:\n",
    "            encoder_output, encoder_h, encoder_s = self.encoder({'input_ids': inputs['encoder_input_ids'],\n",
    "                                                                 'hidden_state': inputs['encoder_state']})\n",
    "\n",
    "            decoder_input = inputs['decoder_target'][:, :-1]  # ignore <end>\n",
    "            real_target = inputs['decoder_target'][:, 1:]  # ignore <start>\n",
    "\n",
    "            decoder.attention.setup_memory(encoder_output)\n",
    "\n",
    "            decoder_initial_state = self.decoder.build_initial_state(decoder.batch_size, [encoder_h, encoder_s])\n",
    "            predicted = self.decoder({'input_ids': decoder_input,\n",
    "                                      'initial_state': decoder_initial_state}).rnn_output\n",
    "\n",
    "            loss = self.compute_loss(logits=predicted, target=real_target)\n",
    "\n",
    "        grads = tape.gradient(loss, self.encoder.trainable_variables + self.decoder.trainable_variables)\n",
    "        return loss, grads\n",
    "\n",
    "    @tf.function\n",
    "    def batch_fit(self, inputs):\n",
    "        loss, grads = self.train_op(inputs=inputs)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.encoder.trainable_variables + self.decoder.trainable_variables))\n",
    "        return loss\n",
    "\n",
    "    @tf.function\n",
    "    def generate(self, input_ids):\n",
    "        batch_size = input_ids.shape[0]\n",
    "        encoder_initial_state = [tf.zeros((batch_size, self.encoder.encoder_units)),\n",
    "                                 tf.zeros((batch_size, self.encoder.encoder_units))]\n",
    "        encoder_output, encoder_h, encoder_s = self.encoder({\n",
    "            'input_ids': input_ids,\n",
    "            'hidden_state': encoder_initial_state\n",
    "        })\n",
    "\n",
    "        start_tokens = tf.fill([batch_size], tokenizer.word_index['<start>'])\n",
    "        end_token = tokenizer.word_index['<end>']\n",
    "\n",
    "        greedy_sampler = tfa.seq2seq.GreedyEmbeddingSampler()\n",
    "        decoder_instance = tfa.seq2seq.BasicDecoder(cell=self.decoder.wrapped_decoder_cell,\n",
    "                                                    sampler=greedy_sampler,\n",
    "                                                    output_layer=self.decoder.generation_dense,\n",
    "                                                    maximum_iterations=self.max_length)\n",
    "        self.decoder.attention.setup_memory(encoder_output)\n",
    "\n",
    "        decoder_initial_state = self.decoder.build_initial_state(batch_size, [encoder_h, encoder_s])\n",
    "        decoder_embedding_matrix = self.decoder.embedding.variables[0]\n",
    "        outputs, _, _ = decoder_instance(decoder_embedding_matrix,\n",
    "                                         start_tokens=start_tokens,\n",
    "                                         end_token=end_token,\n",
    "                                         initial_state=decoder_initial_state)\n",
    "        return outputs\n",
    "\n",
    "    def translate(self, generated):\n",
    "        return tokenizer.sequences_to_texts(generated.sample_id.numpy())\n",
    "\n",
    "\n",
    "class Encoder(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, encoder_units):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.encoder_units = encoder_units\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(input_dim=vocab_size,\n",
    "                                                   output_dim=embedding_dim)\n",
    "        self.encoder_lstm = tf.keras.layers.LSTM(self.encoder_units,\n",
    "                                                 return_sequences=True,\n",
    "                                                 return_state=True)\n",
    "\n",
    "    def call(self, inputs, training=False, **kwargs):\n",
    "        input_ids = inputs['input_ids']\n",
    "        input_emb = self.embedding(input_ids)\n",
    "        encoder_output, lstm_hidden, lstm_states = self.encoder_lstm(input_emb, initial_state=inputs['hidden_state'])\n",
    "        return encoder_output, lstm_hidden, lstm_states\n",
    "\n",
    "    def initialize(self, batch_size):\n",
    "        return [tf.zeros((batch_size, self.encoder_units)), tf.zeros((batch_size, self.encoder_units))]\n",
    "\n",
    "\n",
    "class Decoder(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, vocab_size, max_sequence_length, embedding_dim, decoder_units, batch_size):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.max_sequence_length = max_sequence_length\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.decoder_units = decoder_units\n",
    "        self.embedding = tf.keras.layers.Embedding(input_dim=vocab_size,\n",
    "                                                   output_dim=embedding_dim)\n",
    "        self.decoder_lstm_cell = tf.keras.layers.LSTMCell(self.decoder_units)\n",
    "\n",
    "        self.attention = tfa.seq2seq.BahdanauAttention(units=self.decoder_units,\n",
    "                                                       memory=None,\n",
    "                                                       memory_sequence_length=self.batch_size * [max_sequence_length])\n",
    "\n",
    "        self.wrapped_decoder_cell = tfa.seq2seq.AttentionWrapper(self.decoder_lstm_cell,\n",
    "                                                                 self.attention,\n",
    "                                                                 attention_layer_size=self.decoder_units)\n",
    "\n",
    "        self.generation_dense = tf.keras.layers.Dense(vocab_size)\n",
    "        self.sampler = tfa.seq2seq.sampler.TrainingSampler()\n",
    "        self.decoder = tfa.seq2seq.BasicDecoder(self.wrapped_decoder_cell,\n",
    "                                                sampler=self.sampler,\n",
    "                                                output_layer=self.generation_dense)\n",
    "\n",
    "    def build_initial_state(self, batch_size, encoder_state):\n",
    "        initial_state = self.wrapped_decoder_cell.get_initial_state(batch_size=batch_size, dtype=tf.float32)\n",
    "        initial_state = initial_state.clone(cell_state=encoder_state)\n",
    "        return initial_state\n",
    "\n",
    "    def call(self, inputs, training=False, **kwargs):\n",
    "        input_ids = inputs['input_ids']\n",
    "        input_emb = self.embedding(input_ids)\n",
    "        decoder_output, _, _ = self.decoder(input_emb,\n",
    "                                            initial_state=inputs['initial_state'],\n",
    "                                            sequence_length=self.batch_size * [self.max_sequence_length - 1])\n",
    "        return decoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-14 00:08:14.456810: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 6, 16) -- (2, 16) -- (2, 16)\n",
      "(2, 5, 16)\n"
     ]
    }
   ],
   "source": [
    "# Sample\n",
    "input_sample = [\n",
    "    \"hello there how is it going\",\n",
    "    \"this assignment is hellish\"\n",
    "]\n",
    "output_sample = [\n",
    "    \"<start> it is going well <end>\",\n",
    "    \"<start> I agree <end>\"\n",
    "]\n",
    "\n",
    "batch_size = len(input_sample)\n",
    "\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='', oov_token='<UNK>')\n",
    "tokenizer.fit_on_texts(input_sample + output_sample)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "encoded_input_sample = tokenizer.texts_to_sequences(input_sample)\n",
    "max_input_length = max([len(item) for item in encoded_input_sample])\n",
    "\n",
    "encoded_output_sample = tokenizer.texts_to_sequences(output_sample)\n",
    "max_output_length = max([len(item) for item in encoded_output_sample])\n",
    "\n",
    "max_sequence_length = max(max_input_length, max_output_length)\n",
    "\n",
    "encoded_input_sample = tf.keras.preprocessing.sequence.pad_sequences(encoded_input_sample,\n",
    "                                                                        padding='post',\n",
    "                                                                        maxlen=max_sequence_length)\n",
    "encoded_output_sample = tf.keras.preprocessing.sequence.pad_sequences(encoded_output_sample,\n",
    "                                                                        padding='post',\n",
    "                                                                        maxlen=max_sequence_length)\n",
    "\n",
    "# Test encoder\n",
    "encoder = Encoder(vocab_size=vocab_size,\n",
    "                    embedding_dim=50,\n",
    "                    encoder_units=16)\n",
    "\n",
    "sample_hidden = encoder.initialize(batch_size=batch_size)\n",
    "encoder_sample_batch = {\n",
    "    'input_ids': tf.convert_to_tensor(encoded_input_sample, dtype=tf.int32),\n",
    "    'hidden_state': sample_hidden\n",
    "}\n",
    "\n",
    "sample_output, sample_h, sample_c = encoder(inputs=encoder_sample_batch)\n",
    "print(f'{sample_output.shape} -- {sample_h.shape} -- {sample_c.shape}')\n",
    "\n",
    "# Test decoder\n",
    "decoder = Decoder(vocab_size=vocab_size,\n",
    "                    embedding_dim=50,\n",
    "                    decoder_units=16,\n",
    "                    batch_size=batch_size,\n",
    "                    max_sequence_length=max_sequence_length)\n",
    "decoder.attention.setup_memory(sample_output)\n",
    "initial_state = decoder.build_initial_state(batch_size, [sample_h, sample_c])\n",
    "\n",
    "decoder_sample_batch = {\n",
    "    'input_ids': tf.convert_to_tensor(encoded_output_sample, tf.int32),\n",
    "    'initial_state': initial_state\n",
    "}\n",
    "sample_decoder_outputs = decoder(decoder_sample_batch).rnn_output\n",
    "print(f'{sample_decoder_outputs.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "trainer = MyTrainer(encoder=encoder,\n",
    "                    decoder=decoder,\n",
    "                    max_length=max_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:05<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [24], line 9\u001b[0m\n\u001b[1;32m      3\u001b[0m encoder_hidden_state \u001b[39m=\u001b[39m encoder\u001b[39m.\u001b[39minitialize(batch_size\u001b[39m=\u001b[39mbatch_size)\n\u001b[1;32m      4\u001b[0m batch \u001b[39m=\u001b[39m {\n\u001b[1;32m      5\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mencoder_input_ids\u001b[39m\u001b[39m'\u001b[39m: encoded_input_sample,\n\u001b[1;32m      6\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mencoder_state\u001b[39m\u001b[39m'\u001b[39m: encoder_hidden_state,\n\u001b[1;32m      7\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mdecoder_target\u001b[39m\u001b[39m'\u001b[39m: encoded_output_sample\n\u001b[1;32m      8\u001b[0m }\n\u001b[0;32m----> 9\u001b[0m loss \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39;49mbatch_fit(batch)\n\u001b[1;32m     10\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mLoss - \u001b[39m\u001b[39m{\u001b[39;00mloss\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     12\u001b[0m generated \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39mgenerate(input_ids\u001b[39m=\u001b[39mencoded_input_sample)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:963\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    960\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    961\u001b[0m   \u001b[39m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[1;32m    962\u001b[0m   initializers \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 963\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_initialize(args, kwds, add_initializers_to\u001b[39m=\u001b[39;49minitializers)\n\u001b[1;32m    964\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    965\u001b[0m   \u001b[39m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[1;32m    966\u001b[0m   \u001b[39m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[1;32m    967\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:785\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    782\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lifted_initializer_graph \u001b[39m=\u001b[39m lifted_initializer_graph\n\u001b[1;32m    783\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_graph_deleter \u001b[39m=\u001b[39m FunctionDeleter(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lifted_initializer_graph)\n\u001b[1;32m    784\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_concrete_stateful_fn \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 785\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateful_fn\u001b[39m.\u001b[39;49m_get_concrete_function_internal_garbage_collected(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    786\u001b[0m         \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds))\n\u001b[1;32m    788\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minvalid_creator_scope\u001b[39m(\u001b[39m*\u001b[39munused_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39munused_kwds):\n\u001b[1;32m    789\u001b[0m   \u001b[39m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2523\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2521\u001b[0m   args, kwargs \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   2522\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m-> 2523\u001b[0m   graph_function, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_function(args, kwargs)\n\u001b[1;32m   2524\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2760\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2758\u001b[0m   \u001b[39m# Only get placeholders for arguments, not captures\u001b[39;00m\n\u001b[1;32m   2759\u001b[0m   args, kwargs \u001b[39m=\u001b[39m placeholder_dict[\u001b[39m\"\u001b[39m\u001b[39margs\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m-> 2760\u001b[0m graph_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_graph_function(args, kwargs)\n\u001b[1;32m   2762\u001b[0m graph_capture_container \u001b[39m=\u001b[39m graph_function\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39m_capture_func_lib  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   2763\u001b[0m \u001b[39m# Maintain the list of all captures\u001b[39;00m\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2670\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2665\u001b[0m missing_arg_names \u001b[39m=\u001b[39m [\n\u001b[1;32m   2666\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (arg, i) \u001b[39mfor\u001b[39;00m i, arg \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(missing_arg_names)\n\u001b[1;32m   2667\u001b[0m ]\n\u001b[1;32m   2668\u001b[0m arg_names \u001b[39m=\u001b[39m base_arg_names \u001b[39m+\u001b[39m missing_arg_names\n\u001b[1;32m   2669\u001b[0m graph_function \u001b[39m=\u001b[39m ConcreteFunction(\n\u001b[0;32m-> 2670\u001b[0m     func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[1;32m   2671\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name,\n\u001b[1;32m   2672\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_function,\n\u001b[1;32m   2673\u001b[0m         args,\n\u001b[1;32m   2674\u001b[0m         kwargs,\n\u001b[1;32m   2675\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_signature,\n\u001b[1;32m   2676\u001b[0m         autograph\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph,\n\u001b[1;32m   2677\u001b[0m         autograph_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph_options,\n\u001b[1;32m   2678\u001b[0m         arg_names\u001b[39m=\u001b[39;49marg_names,\n\u001b[1;32m   2679\u001b[0m         capture_by_value\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_capture_by_value),\n\u001b[1;32m   2680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_attributes,\n\u001b[1;32m   2681\u001b[0m     spec\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_spec,\n\u001b[1;32m   2682\u001b[0m     \u001b[39m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m   2683\u001b[0m     \u001b[39m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m   2684\u001b[0m     \u001b[39m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m   2685\u001b[0m     \u001b[39m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m   2686\u001b[0m     shared_func_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   2687\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:1247\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1244\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1245\u001b[0m   _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1247\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39;49mfunc_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfunc_kwargs)\n\u001b[1;32m   1249\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1250\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1251\u001b[0m func_outputs \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mmap_structure(\n\u001b[1;32m   1252\u001b[0m     convert, func_outputs, expand_composites\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:677\u001b[0m, in \u001b[0;36mFunction._defun_with_scope.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[39mwith\u001b[39;00m default_graph\u001b[39m.\u001b[39m_variable_creator_scope(scope, priority\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m):  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    674\u001b[0m   \u001b[39m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[1;32m    675\u001b[0m   \u001b[39m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[1;32m    676\u001b[0m   \u001b[39mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[0;32m--> 677\u001b[0m     out \u001b[39m=\u001b[39m weak_wrapped_fn()\u001b[39m.\u001b[39;49m__wrapped__(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    678\u001b[0m   \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3317\u001b[0m, in \u001b[0;36mclass_method_to_instance_method.<locals>.bound_method_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   3312\u001b[0m   \u001b[39mreturn\u001b[39;00m wrapped_fn(weak_instance(), \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   3314\u001b[0m \u001b[39m# If __wrapped__ was replaced, then it is always an unbound function.\u001b[39;00m\n\u001b[1;32m   3315\u001b[0m \u001b[39m# However, the replacer is still responsible for attaching self properly.\u001b[39;00m\n\u001b[1;32m   3316\u001b[0m \u001b[39m# TODO(mdan): Is it possible to do it here instead?\u001b[39;00m\n\u001b[0;32m-> 3317\u001b[0m \u001b[39mreturn\u001b[39;00m wrapped_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:1222\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1220\u001b[0m \u001b[39m# TODO(mdan): Push this block higher in tf.function's call stack.\u001b[39;00m\n\u001b[1;32m   1221\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1222\u001b[0m   \u001b[39mreturn\u001b[39;00m autograph\u001b[39m.\u001b[39;49mconverted_call(\n\u001b[1;32m   1223\u001b[0m       original_func,\n\u001b[1;32m   1224\u001b[0m       args,\n\u001b[1;32m   1225\u001b[0m       kwargs,\n\u001b[1;32m   1226\u001b[0m       options\u001b[39m=\u001b[39;49mautograph\u001b[39m.\u001b[39;49mConversionOptions(\n\u001b[1;32m   1227\u001b[0m           recursive\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1228\u001b[0m           optional_features\u001b[39m=\u001b[39;49mautograph_options,\n\u001b[1;32m   1229\u001b[0m           user_requested\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1230\u001b[0m       ))\n\u001b[1;32m   1231\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m   1232\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39;49meffective_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filel6dm7ocs.py:10\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__batch_fit\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m      8\u001b[0m do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m      9\u001b[0m retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mUndefinedReturnValue()\n\u001b[0;32m---> 10\u001b[0m (loss, grads) \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mtrain_op, (), \u001b[39mdict\u001b[39;49m(inputs\u001b[39m=\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(inputs)), fscope)\n\u001b[1;32m     11\u001b[0m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mapply_gradients, (ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mzip\u001b[39m), (ag__\u001b[39m.\u001b[39mld(grads), ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mencoder\u001b[39m.\u001b[39mtrainable_variables \u001b[39m+\u001b[39m ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mdecoder\u001b[39m.\u001b[39mtrainable_variables), \u001b[39mNone\u001b[39;00m, fscope),), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     12\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    374\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    376\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39muser_requested \u001b[39mand\u001b[39;00m conversion\u001b[39m.\u001b[39mis_allowlisted(f):\n\u001b[0;32m--> 377\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    379\u001b[0m \u001b[39m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[39m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[39m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[39m# things like builtins.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:458\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    455\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    457\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 458\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    459\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:963\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    960\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    961\u001b[0m   \u001b[39m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[1;32m    962\u001b[0m   initializers \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 963\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_initialize(args, kwds, add_initializers_to\u001b[39m=\u001b[39;49minitializers)\n\u001b[1;32m    964\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    965\u001b[0m   \u001b[39m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[1;32m    966\u001b[0m   \u001b[39m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[1;32m    967\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:785\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    782\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lifted_initializer_graph \u001b[39m=\u001b[39m lifted_initializer_graph\n\u001b[1;32m    783\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_graph_deleter \u001b[39m=\u001b[39m FunctionDeleter(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lifted_initializer_graph)\n\u001b[1;32m    784\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_concrete_stateful_fn \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 785\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateful_fn\u001b[39m.\u001b[39;49m_get_concrete_function_internal_garbage_collected(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    786\u001b[0m         \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds))\n\u001b[1;32m    788\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minvalid_creator_scope\u001b[39m(\u001b[39m*\u001b[39munused_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39munused_kwds):\n\u001b[1;32m    789\u001b[0m   \u001b[39m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2523\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2521\u001b[0m   args, kwargs \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   2522\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m-> 2523\u001b[0m   graph_function, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_function(args, kwargs)\n\u001b[1;32m   2524\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2760\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2758\u001b[0m   \u001b[39m# Only get placeholders for arguments, not captures\u001b[39;00m\n\u001b[1;32m   2759\u001b[0m   args, kwargs \u001b[39m=\u001b[39m placeholder_dict[\u001b[39m\"\u001b[39m\u001b[39margs\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m-> 2760\u001b[0m graph_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_graph_function(args, kwargs)\n\u001b[1;32m   2762\u001b[0m graph_capture_container \u001b[39m=\u001b[39m graph_function\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39m_capture_func_lib  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   2763\u001b[0m \u001b[39m# Maintain the list of all captures\u001b[39;00m\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2670\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2665\u001b[0m missing_arg_names \u001b[39m=\u001b[39m [\n\u001b[1;32m   2666\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (arg, i) \u001b[39mfor\u001b[39;00m i, arg \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(missing_arg_names)\n\u001b[1;32m   2667\u001b[0m ]\n\u001b[1;32m   2668\u001b[0m arg_names \u001b[39m=\u001b[39m base_arg_names \u001b[39m+\u001b[39m missing_arg_names\n\u001b[1;32m   2669\u001b[0m graph_function \u001b[39m=\u001b[39m ConcreteFunction(\n\u001b[0;32m-> 2670\u001b[0m     func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[1;32m   2671\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name,\n\u001b[1;32m   2672\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_function,\n\u001b[1;32m   2673\u001b[0m         args,\n\u001b[1;32m   2674\u001b[0m         kwargs,\n\u001b[1;32m   2675\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_signature,\n\u001b[1;32m   2676\u001b[0m         autograph\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph,\n\u001b[1;32m   2677\u001b[0m         autograph_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph_options,\n\u001b[1;32m   2678\u001b[0m         arg_names\u001b[39m=\u001b[39;49marg_names,\n\u001b[1;32m   2679\u001b[0m         capture_by_value\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_capture_by_value),\n\u001b[1;32m   2680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_attributes,\n\u001b[1;32m   2681\u001b[0m     spec\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_spec,\n\u001b[1;32m   2682\u001b[0m     \u001b[39m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m   2683\u001b[0m     \u001b[39m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m   2684\u001b[0m     \u001b[39m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m   2685\u001b[0m     \u001b[39m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m   2686\u001b[0m     shared_func_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   2687\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:1247\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1244\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1245\u001b[0m   _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1247\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39;49mfunc_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfunc_kwargs)\n\u001b[1;32m   1249\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1250\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1251\u001b[0m func_outputs \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mmap_structure(\n\u001b[1;32m   1252\u001b[0m     convert, func_outputs, expand_composites\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:677\u001b[0m, in \u001b[0;36mFunction._defun_with_scope.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[39mwith\u001b[39;00m default_graph\u001b[39m.\u001b[39m_variable_creator_scope(scope, priority\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m):  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    674\u001b[0m   \u001b[39m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[1;32m    675\u001b[0m   \u001b[39m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[1;32m    676\u001b[0m   \u001b[39mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[0;32m--> 677\u001b[0m     out \u001b[39m=\u001b[39m weak_wrapped_fn()\u001b[39m.\u001b[39;49m__wrapped__(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    678\u001b[0m   \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3317\u001b[0m, in \u001b[0;36mclass_method_to_instance_method.<locals>.bound_method_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   3312\u001b[0m   \u001b[39mreturn\u001b[39;00m wrapped_fn(weak_instance(), \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   3314\u001b[0m \u001b[39m# If __wrapped__ was replaced, then it is always an unbound function.\u001b[39;00m\n\u001b[1;32m   3315\u001b[0m \u001b[39m# However, the replacer is still responsible for attaching self properly.\u001b[39;00m\n\u001b[1;32m   3316\u001b[0m \u001b[39m# TODO(mdan): Is it possible to do it here instead?\u001b[39;00m\n\u001b[0;32m-> 3317\u001b[0m \u001b[39mreturn\u001b[39;00m wrapped_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:1222\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1220\u001b[0m \u001b[39m# TODO(mdan): Push this block higher in tf.function's call stack.\u001b[39;00m\n\u001b[1;32m   1221\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1222\u001b[0m   \u001b[39mreturn\u001b[39;00m autograph\u001b[39m.\u001b[39;49mconverted_call(\n\u001b[1;32m   1223\u001b[0m       original_func,\n\u001b[1;32m   1224\u001b[0m       args,\n\u001b[1;32m   1225\u001b[0m       kwargs,\n\u001b[1;32m   1226\u001b[0m       options\u001b[39m=\u001b[39;49mautograph\u001b[39m.\u001b[39;49mConversionOptions(\n\u001b[1;32m   1227\u001b[0m           recursive\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1228\u001b[0m           optional_features\u001b[39m=\u001b[39;49mautograph_options,\n\u001b[1;32m   1229\u001b[0m           user_requested\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1230\u001b[0m       ))\n\u001b[1;32m   1231\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m   1232\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39;49meffective_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filekh3lyw76.py:16\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_op\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     14\u001b[0m     ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(decoder)\u001b[39m.\u001b[39mattention\u001b[39m.\u001b[39msetup_memory, (ag__\u001b[39m.\u001b[39mld(encoder_output),), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     15\u001b[0m     decoder_initial_state \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mdecoder\u001b[39m.\u001b[39mbuild_initial_state, (ag__\u001b[39m.\u001b[39mld(decoder)\u001b[39m.\u001b[39mbatch_size, [ag__\u001b[39m.\u001b[39mld(encoder_h), ag__\u001b[39m.\u001b[39mld(encoder_s)]), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m---> 16\u001b[0m     predicted \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mdecoder, ({\u001b[39m'\u001b[39;49m\u001b[39minput_ids\u001b[39;49m\u001b[39m'\u001b[39;49m: ag__\u001b[39m.\u001b[39;49mld(decoder_input), \u001b[39m'\u001b[39;49m\u001b[39minitial_state\u001b[39;49m\u001b[39m'\u001b[39;49m: ag__\u001b[39m.\u001b[39;49mld(decoder_initial_state)},), \u001b[39mNone\u001b[39;49;00m, fscope)\u001b[39m.\u001b[39mrnn_output\n\u001b[1;32m     17\u001b[0m     loss \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mcompute_loss, (), \u001b[39mdict\u001b[39m(logits\u001b[39m=\u001b[39mag__\u001b[39m.\u001b[39mld(predicted), target\u001b[39m=\u001b[39mag__\u001b[39m.\u001b[39mld(real_target)), fscope)\n\u001b[1;32m     18\u001b[0m grads \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tape)\u001b[39m.\u001b[39mgradient, (ag__\u001b[39m.\u001b[39mld(loss), ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mencoder\u001b[39m.\u001b[39mtrainable_variables \u001b[39m+\u001b[39m ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mdecoder\u001b[39m.\u001b[39mtrainable_variables), \u001b[39mNone\u001b[39;00m, fscope)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    374\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    376\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39muser_requested \u001b[39mand\u001b[39;00m conversion\u001b[39m.\u001b[39mis_allowlisted(f):\n\u001b[0;32m--> 377\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    379\u001b[0m \u001b[39m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[39m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[39m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[39m# things like builtins.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    458\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py:557\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(inputs, \u001b[39m*\u001b[39mcopied_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcopied_kwargs)\n\u001b[1;32m    555\u001b[0m     layout_map_lib\u001b[39m.\u001b[39m_map_subclass_model_variable(\u001b[39mself\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_layout_map)\n\u001b[0;32m--> 557\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/base_layer.py:1097\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1092\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[1;32m   1094\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object\n\u001b[1;32m   1096\u001b[0m ):\n\u001b[0;32m-> 1097\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1099\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[1;32m   1100\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    688\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 689\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[1;32m    690\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    691\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39;49meffective_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_fileazakgrur.py:12\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[0;34m(self, inputs, training, **kwargs)\u001b[0m\n\u001b[1;32m     10\u001b[0m input_ids \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mld(inputs)[\u001b[39m'\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     11\u001b[0m input_emb \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39membedding, (ag__\u001b[39m.\u001b[39mld(input_ids),), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m---> 12\u001b[0m (decoder_output, _, _) \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mdecoder, (ag__\u001b[39m.\u001b[39;49mld(input_emb),), \u001b[39mdict\u001b[39;49m(initial_state\u001b[39m=\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(inputs)[\u001b[39m'\u001b[39;49m\u001b[39minitial_state\u001b[39;49m\u001b[39m'\u001b[39;49m], sequence_length\u001b[39m=\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mbatch_size \u001b[39m*\u001b[39;49m [ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mmax_sequence_length \u001b[39m-\u001b[39;49m \u001b[39m1\u001b[39;49m]), fscope)\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    374\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    376\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39muser_requested \u001b[39mand\u001b[39;00m conversion\u001b[39m.\u001b[39mis_allowlisted(f):\n\u001b[0;32m--> 377\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    379\u001b[0m \u001b[39m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[39m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[39m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[39m# things like builtins.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:458\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    455\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    457\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 458\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    459\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/base_layer.py:1097\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1092\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[1;32m   1094\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object\n\u001b[1;32m   1096\u001b[0m ):\n\u001b[0;32m-> 1097\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1099\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[1;32m   1100\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    688\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 689\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[1;32m    690\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    691\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39;49meffective_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filemsorkd_q.py:14\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[0;34m(self, inputs, initial_state, training, **kwargs)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     13\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(dynamic_decode), (ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m),), \u001b[39mdict\u001b[39;49m(output_time_major\u001b[39m=\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49moutput_time_major, impute_finished\u001b[39m=\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mimpute_finished, maximum_iterations\u001b[39m=\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mmaximum_iterations, parallel_iterations\u001b[39m=\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mparallel_iterations, swap_memory\u001b[39m=\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mswap_memory, training\u001b[39m=\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(training), decoder_init_input\u001b[39m=\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(inputs), decoder_init_kwargs\u001b[39m=\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(init_kwargs)), fscope)\n\u001b[1;32m     15\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     16\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39;49meffective_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filegr21x5o1.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m memo \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(_CallMemo), (ag__\u001b[39m.\u001b[39mld(python_func), ag__\u001b[39m.\u001b[39mld(_localns)), \u001b[39mdict\u001b[39m(args\u001b[39m=\u001b[39mag__\u001b[39m.\u001b[39mld(args), kwargs\u001b[39m=\u001b[39mag__\u001b[39m.\u001b[39mld(kwargs)), fscope)\n\u001b[1;32m     14\u001b[0m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(check_argument_types), (ag__\u001b[39m.\u001b[39mld(memo),), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m---> 15\u001b[0m retval \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(func), \u001b[39mtuple\u001b[39;49m(ag__\u001b[39m.\u001b[39;49mld(args)), \u001b[39mdict\u001b[39;49m(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(kwargs)), fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(check_return_type), (ag__\u001b[39m.\u001b[39mld(retval), ag__\u001b[39m.\u001b[39mld(memo)), \u001b[39mNone\u001b[39;00m, fscope)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39;49meffective_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file9kvgam8p.py:473\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__dynamic_decode\u001b[0;34m(decoder, output_time_major, impute_finished, maximum_iterations, parallel_iterations, swap_memory, training, scope, enable_tflite_convertible, **kwargs)\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[39mraise\u001b[39;00m\n\u001b[1;32m    472\u001b[0m         \u001b[39mreturn\u001b[39;00m fscope_4\u001b[39m.\u001b[39mret(retval__4, do_return_4)\n\u001b[0;32m--> 473\u001b[0m res \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(tf)\u001b[39m.\u001b[39;49mwhile_loop, (ag__\u001b[39m.\u001b[39;49mld(condition), ag__\u001b[39m.\u001b[39;49mld(body)), \u001b[39mdict\u001b[39;49m(loop_vars\u001b[39m=\u001b[39;49m(ag__\u001b[39m.\u001b[39;49mld(initial_time), ag__\u001b[39m.\u001b[39;49mld(initial_outputs_ta), ag__\u001b[39m.\u001b[39;49mld(initial_state), ag__\u001b[39m.\u001b[39;49mld(initial_inputs), ag__\u001b[39m.\u001b[39;49mld(initial_finished), ag__\u001b[39m.\u001b[39;49mld(initial_sequence_lengths)), parallel_iterations\u001b[39m=\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(parallel_iterations), maximum_iterations\u001b[39m=\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(maximum_iterations), swap_memory\u001b[39m=\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(swap_memory)), fscope)\n\u001b[1;32m    474\u001b[0m final_outputs_ta \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mld(res)[\u001b[39m1\u001b[39m]\n\u001b[1;32m    475\u001b[0m final_state \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mld(res)[\u001b[39m2\u001b[39m]\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    374\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    376\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39muser_requested \u001b[39mand\u001b[39;00m conversion\u001b[39m.\u001b[39mis_allowlisted(f):\n\u001b[0;32m--> 377\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    379\u001b[0m \u001b[39m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[39m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[39m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[39m# things like builtins.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:458\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    455\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    457\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 458\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    459\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/util/deprecation.py:629\u001b[0m, in \u001b[0;36mdeprecated_arg_values.<locals>.deprecated_wrapper.<locals>.new_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    622\u001b[0m           _PRINTED_WARNING[(func, arg_name)] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    623\u001b[0m         logging\u001b[39m.\u001b[39mwarning(\n\u001b[1;32m    624\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mFrom \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: calling \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m (from \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m) with \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m=\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is deprecated and \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    625\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mwill be removed \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mInstructions for updating:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m,\n\u001b[1;32m    626\u001b[0m             _call_location(), decorator_utils\u001b[39m.\u001b[39mget_qualified_name(func),\n\u001b[1;32m    627\u001b[0m             func\u001b[39m.\u001b[39m\u001b[39m__module__\u001b[39m, arg_name, arg_value, \u001b[39m'\u001b[39m\u001b[39min a future version\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    628\u001b[0m             \u001b[39mif\u001b[39;00m date \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mafter \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m date), instructions)\n\u001b[0;32m--> 629\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/ops/control_flow_ops.py:2513\u001b[0m, in \u001b[0;36mwhile_loop_v2\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, maximum_iterations, name)\u001b[0m\n\u001b[1;32m   2337\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mwhile_loop\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[])\n\u001b[1;32m   2338\u001b[0m \u001b[39m@deprecation\u001b[39m\u001b[39m.\u001b[39mdeprecated_arg_values(\n\u001b[1;32m   2339\u001b[0m     \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2354\u001b[0m                   maximum_iterations\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   2355\u001b[0m                   name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   2356\u001b[0m   \u001b[39m\"\"\"Repeat `body` while the condition `cond` is true.\u001b[39;00m\n\u001b[1;32m   2357\u001b[0m \n\u001b[1;32m   2358\u001b[0m \u001b[39m  `cond` is a callable returning a boolean scalar tensor. `body` is a callable\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2511\u001b[0m \n\u001b[1;32m   2512\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2513\u001b[0m   \u001b[39mreturn\u001b[39;00m while_loop(\n\u001b[1;32m   2514\u001b[0m       cond\u001b[39m=\u001b[39;49mcond,\n\u001b[1;32m   2515\u001b[0m       body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m   2516\u001b[0m       loop_vars\u001b[39m=\u001b[39;49mloop_vars,\n\u001b[1;32m   2517\u001b[0m       shape_invariants\u001b[39m=\u001b[39;49mshape_invariants,\n\u001b[1;32m   2518\u001b[0m       parallel_iterations\u001b[39m=\u001b[39;49mparallel_iterations,\n\u001b[1;32m   2519\u001b[0m       back_prop\u001b[39m=\u001b[39;49mback_prop,\n\u001b[1;32m   2520\u001b[0m       swap_memory\u001b[39m=\u001b[39;49mswap_memory,\n\u001b[1;32m   2521\u001b[0m       name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m   2522\u001b[0m       maximum_iterations\u001b[39m=\u001b[39;49mmaximum_iterations,\n\u001b[1;32m   2523\u001b[0m       return_same_structure\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/ops/control_flow_ops.py:2713\u001b[0m, in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   2710\u001b[0m executing_eagerly \u001b[39m=\u001b[39m context\u001b[39m.\u001b[39mexecuting_eagerly()\n\u001b[1;32m   2711\u001b[0m \u001b[39mif\u001b[39;00m (util\u001b[39m.\u001b[39mEnableControlFlowV2(ops\u001b[39m.\u001b[39mget_default_graph()) \u001b[39mand\u001b[39;00m\n\u001b[1;32m   2712\u001b[0m     \u001b[39mnot\u001b[39;00m executing_eagerly):\n\u001b[0;32m-> 2713\u001b[0m   \u001b[39mreturn\u001b[39;00m while_v2\u001b[39m.\u001b[39;49mwhile_loop(\n\u001b[1;32m   2714\u001b[0m       cond,\n\u001b[1;32m   2715\u001b[0m       body,\n\u001b[1;32m   2716\u001b[0m       loop_vars,\n\u001b[1;32m   2717\u001b[0m       shape_invariants\u001b[39m=\u001b[39;49mshape_invariants,\n\u001b[1;32m   2718\u001b[0m       parallel_iterations\u001b[39m=\u001b[39;49mparallel_iterations,\n\u001b[1;32m   2719\u001b[0m       maximum_iterations\u001b[39m=\u001b[39;49mmaximum_iterations,\n\u001b[1;32m   2720\u001b[0m       name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m   2721\u001b[0m       return_same_structure\u001b[39m=\u001b[39;49mreturn_same_structure,\n\u001b[1;32m   2722\u001b[0m       back_prop\u001b[39m=\u001b[39;49mback_prop)\n\u001b[1;32m   2724\u001b[0m \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mname_scope(name, \u001b[39m\"\u001b[39m\u001b[39mwhile\u001b[39m\u001b[39m\"\u001b[39m, loop_vars):\n\u001b[1;32m   2725\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m loop_vars:\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/ops/while_v2.py:222\u001b[0m, in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, maximum_iterations, name, return_same_structure, back_prop)\u001b[0m\n\u001b[1;32m    218\u001b[0m   \u001b[39m# TODO(srbs): Update lowering code to create _Enter nodes with\u001b[39;00m\n\u001b[1;32m    219\u001b[0m   \u001b[39m# is_constant=True for inputs that are directly passed to outputs.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m   \u001b[39mreturn\u001b[39;00m [loop_counter \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, maximum_iterations_arg] \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(outputs)\n\u001b[0;32m--> 222\u001b[0m body_graph \u001b[39m=\u001b[39m func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[1;32m    223\u001b[0m     body_name,\n\u001b[1;32m    224\u001b[0m     wrapped_body,\n\u001b[1;32m    225\u001b[0m     [],  \u001b[39m# We provide signature instead of args.\u001b[39;49;00m\n\u001b[1;32m    226\u001b[0m     {},\n\u001b[1;32m    227\u001b[0m     signature\u001b[39m=\u001b[39;49mfunc_graph_signature,\n\u001b[1;32m    228\u001b[0m     func_graph\u001b[39m=\u001b[39;49mutil\u001b[39m.\u001b[39;49mWhileBodyFuncGraph(\n\u001b[1;32m    229\u001b[0m         body_name, collections\u001b[39m=\u001b[39;49mops\u001b[39m.\u001b[39;49mget_default_graph()\u001b[39m.\u001b[39;49m_collections),  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    230\u001b[0m     add_control_dependencies\u001b[39m=\u001b[39;49madd_control_dependencies,\n\u001b[1;32m    231\u001b[0m     acd_record_initial_resource_uses\u001b[39m=\u001b[39;49mstateful_parallelism)\n\u001b[1;32m    232\u001b[0m \u001b[39m# Add external captures of body to the list of loop vars.\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[39m# Note that external tensors will be treated as loop invariants, i.e.,\u001b[39;00m\n\u001b[1;32m    234\u001b[0m \u001b[39m# the value of that tensor in each iteration is the same as it was at the\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[39m# beginning of the loop execution.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m deferred_external_captures \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mflatten(\n\u001b[1;32m    237\u001b[0m     [c() \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m body_graph\u001b[39m.\u001b[39mdeferred_external_captures],\n\u001b[1;32m    238\u001b[0m     expand_composites\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:1247\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1244\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1245\u001b[0m   _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1247\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39;49mfunc_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfunc_kwargs)\n\u001b[1;32m   1249\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1250\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1251\u001b[0m func_outputs \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mmap_structure(\n\u001b[1;32m   1252\u001b[0m     convert, func_outputs, expand_composites\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/ops/while_v2.py:200\u001b[0m, in \u001b[0;36mwhile_loop.<locals>.wrapped_body\u001b[0;34m(loop_counter, maximum_iterations_arg, *args)\u001b[0m\n\u001b[1;32m    193\u001b[0m   ops\u001b[39m.\u001b[39mget_default_graph()\u001b[39m.\u001b[39mcapture(t)\n\u001b[1;32m    195\u001b[0m \u001b[39m# Convert the flow variables in `args` to TensorArrays. `args` should\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[39m# already have the same structure as `orig_loop_vars` but currently there\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[39m# is no nest.zip so we call `_pack_sequence_as` which flattens `args`,\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# converts flows in `args` to TensorArrays and packs it into the\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# structure of `loop_vars_signature`.\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m outputs \u001b[39m=\u001b[39m body(\n\u001b[1;32m    201\u001b[0m     \u001b[39m*\u001b[39;49m_pack_sequence_as(loop_vars_signature, flat_orig_loop_vars, args))\n\u001b[1;32m    202\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m nest\u001b[39m.\u001b[39mis_nested(outputs):\n\u001b[1;32m    203\u001b[0m   outputs \u001b[39m=\u001b[39m [outputs]\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file9kvgam8p.py:268\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__dynamic_decode.<locals>.body\u001b[0;34m(time, outputs_ta, state, inputs, finished, sequence_lengths)\u001b[0m\n\u001b[1;32m    266\u001b[0m do_return_4 \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    267\u001b[0m retval__4 \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mUndefinedReturnValue()\n\u001b[0;32m--> 268\u001b[0m (next_outputs, decoder_state, next_inputs, decoder_finished) \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(decoder)\u001b[39m.\u001b[39;49mstep, (ag__\u001b[39m.\u001b[39;49mld(time), ag__\u001b[39m.\u001b[39;49mld(inputs), ag__\u001b[39m.\u001b[39;49mld(state), ag__\u001b[39m.\u001b[39;49mld(training)), \u001b[39mNone\u001b[39;49;00m, fscope_4)\n\u001b[1;32m    269\u001b[0m decoder_state_sequence_lengths \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_state_10\u001b[39m():\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:441\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39;49meffective_args)\n\u001b[1;32m    442\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    443\u001b[0m   _attach_error_metadata(e, converted_f)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filev4zv8ykv.py:21\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__step\u001b[0;34m(self, time, inputs, state, training)\u001b[0m\n\u001b[1;32m     19\u001b[0m do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     20\u001b[0m retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mUndefinedReturnValue()\n\u001b[0;32m---> 21\u001b[0m (cell_outputs, cell_state) \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mcell, (ag__\u001b[39m.\u001b[39;49mld(inputs), ag__\u001b[39m.\u001b[39;49mld(state)), \u001b[39mdict\u001b[39;49m(training\u001b[39m=\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(training)), fscope)\n\u001b[1;32m     22\u001b[0m cell_state \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mpack_sequence_as, (ag__\u001b[39m.\u001b[39mld(state), ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten, (ag__\u001b[39m.\u001b[39mld(cell_state),), \u001b[39mNone\u001b[39;00m, fscope)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     24\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_state\u001b[39m():\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    374\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    376\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39muser_requested \u001b[39mand\u001b[39;00m conversion\u001b[39m.\u001b[39mis_allowlisted(f):\n\u001b[0;32m--> 377\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    379\u001b[0m \u001b[39m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[39m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[39m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[39m# things like builtins.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:458\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    455\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    457\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 458\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    459\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/base_layer.py:1097\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1092\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[1;32m   1094\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object\n\u001b[1;32m   1096\u001b[0m ):\n\u001b[0;32m-> 1097\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1099\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[1;32m   1100\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    688\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 689\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[1;32m    690\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    691\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:427\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    426\u001b[0m   program_ctx \u001b[39m=\u001b[39m converter\u001b[39m.\u001b[39mProgramContext(options\u001b[39m=\u001b[39moptions)\n\u001b[0;32m--> 427\u001b[0m   converted_f \u001b[39m=\u001b[39m _convert_actual(target_entity, program_ctx)\n\u001b[1;32m    428\u001b[0m   \u001b[39mif\u001b[39;00m logging\u001b[39m.\u001b[39mhas_verbosity(\u001b[39m2\u001b[39m):\n\u001b[1;32m    429\u001b[0m     _log_callargs(converted_f, effective_args, kwargs)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:269\u001b[0m, in \u001b[0;36m_convert_actual\u001b[0;34m(entity, program_ctx)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(entity, \u001b[39m'\u001b[39m\u001b[39m__code__\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    265\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mCannot apply autograph to a function that doesn\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39mt \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    266\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39mexpose a __code__ object. If this is a @tf.function,\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    267\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39m try passing f.python_function instead.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 269\u001b[0m transformed, module, source_map \u001b[39m=\u001b[39m _TRANSPILER\u001b[39m.\u001b[39;49mtransform(entity, program_ctx)\n\u001b[1;32m    271\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(transformed, \u001b[39m'\u001b[39m\u001b[39mag_module\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    272\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(transformed, \u001b[39m'\u001b[39m\u001b[39mag_source_map\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/transpiler.py:282\u001b[0m, in \u001b[0;36mGenericTranspiler.transform\u001b[0;34m(self, obj, user_context)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[39m\"\"\"Transforms a Python object.\u001b[39;00m\n\u001b[1;32m    268\u001b[0m \n\u001b[1;32m    269\u001b[0m \u001b[39mUsers typically call this method.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[39m  NotImplementedError: if the type of obj is not handled.\u001b[39;00m\n\u001b[1;32m    280\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    281\u001b[0m \u001b[39mif\u001b[39;00m inspect\u001b[39m.\u001b[39misfunction(obj) \u001b[39mor\u001b[39;00m inspect\u001b[39m.\u001b[39mismethod(obj):\n\u001b[0;32m--> 282\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform_function(obj, user_context)\n\u001b[1;32m    284\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mNon-function: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mtype\u001b[39m(obj)))\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/transpiler.py:466\u001b[0m, in \u001b[0;36mPyToPy.transform_function\u001b[0;34m(self, fn, user_context)\u001b[0m\n\u001b[1;32m    464\u001b[0m logging\u001b[39m.\u001b[39mlog(\u001b[39m1\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is not cached for subkey \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m, fn, cache_subkey)\n\u001b[1;32m    465\u001b[0m \u001b[39m# TODO(mdan): Confusing overloading pattern. Fix.\u001b[39;00m\n\u001b[0;32m--> 466\u001b[0m nodes, ctx \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m(PyToPy, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mtransform_function(fn, user_context)\n\u001b[1;32m    468\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(nodes, gast\u001b[39m.\u001b[39mLambda):\n\u001b[1;32m    469\u001b[0m   nodes \u001b[39m=\u001b[39m gast\u001b[39m.\u001b[39mAssign(\n\u001b[1;32m    470\u001b[0m       targets\u001b[39m=\u001b[39m[\n\u001b[1;32m    471\u001b[0m           gast\u001b[39m.\u001b[39mName(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    476\u001b[0m       ],\n\u001b[1;32m    477\u001b[0m       value\u001b[39m=\u001b[39mnodes)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/transpiler.py:359\u001b[0m, in \u001b[0;36mGenericTranspiler.transform_function\u001b[0;34m(self, fn, user_context)\u001b[0m\n\u001b[1;32m    356\u001b[0m context \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mContext(entity_info, namer, user_context)\n\u001b[1;32m    358\u001b[0m node \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_erase_arg_defaults(node)\n\u001b[0;32m--> 359\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform_ast(node, context)\n\u001b[1;32m    361\u001b[0m \u001b[39mreturn\u001b[39;00m result, context\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:252\u001b[0m, in \u001b[0;36mPyToTF.transform_ast\u001b[0;34m(self, node, ctx)\u001b[0m\n\u001b[1;32m    250\u001b[0m   node \u001b[39m=\u001b[39m lists\u001b[39m.\u001b[39mtransform(node, ctx)\n\u001b[1;32m    251\u001b[0m   node \u001b[39m=\u001b[39m slices\u001b[39m.\u001b[39mtransform(node, ctx)\n\u001b[0;32m--> 252\u001b[0m node \u001b[39m=\u001b[39m call_trees\u001b[39m.\u001b[39;49mtransform(node, ctx)\n\u001b[1;32m    253\u001b[0m node \u001b[39m=\u001b[39m control_flow\u001b[39m.\u001b[39mtransform(node, ctx)\n\u001b[1;32m    254\u001b[0m node \u001b[39m=\u001b[39m conditional_expressions\u001b[39m.\u001b[39mtransform(node, ctx)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/converters/call_trees.py:220\u001b[0m, in \u001b[0;36mtransform\u001b[0;34m(node, ctx)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[39m\"\"\"Transform function call to the compiled counterparts.\u001b[39;00m\n\u001b[1;32m    209\u001b[0m \n\u001b[1;32m    210\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[39m      new_names: set(string), containing any newly-generated names\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    218\u001b[0m node \u001b[39m=\u001b[39m qual_names\u001b[39m.\u001b[39mresolve(node)\n\u001b[0;32m--> 220\u001b[0m node \u001b[39m=\u001b[39m CallTreeTransformer(ctx)\u001b[39m.\u001b[39;49mvisit(node)\n\u001b[1;32m    221\u001b[0m \u001b[39mreturn\u001b[39;00m node\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/core/converter.py:314\u001b[0m, in \u001b[0;36mBase.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ast_depth \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    313\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 314\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(Base, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mvisit(node)\n\u001b[1;32m    315\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    316\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ast_depth \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/transformer.py:441\u001b[0m, in \u001b[0;36mBase.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[39mif\u001b[39;00m processing_expr_node:\n\u001b[1;32m    439\u001b[0m   entry_expr_value \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39mvalue\n\u001b[0;32m--> 441\u001b[0m result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m(Base, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mvisit(node)\n\u001b[1;32m    443\u001b[0m \u001b[39m# Adjust for consistency: replacing the value of an Expr with\u001b[39;00m\n\u001b[1;32m    444\u001b[0m \u001b[39m# an Assign node removes the need for the Expr node.\u001b[39;00m\n\u001b[1;32m    445\u001b[0m \u001b[39mif\u001b[39;00m (processing_expr_node \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(result, gast\u001b[39m.\u001b[39mExpr) \u001b[39mand\u001b[39;00m\n\u001b[1;32m    446\u001b[0m     (result\u001b[39m.\u001b[39mvalue \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m entry_expr_value)):\n\u001b[1;32m    447\u001b[0m   \u001b[39m# When the replacement is a list, it is assumed that the list came\u001b[39;00m\n\u001b[1;32m    448\u001b[0m   \u001b[39m# from a template that contained a number of statements, which\u001b[39;00m\n\u001b[1;32m    449\u001b[0m   \u001b[39m# themselves are standalone and don't require an enclosing Expr.\u001b[39;00m\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/ast.py:407\u001b[0m, in \u001b[0;36mNodeVisitor.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    405\u001b[0m method \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mvisit_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m node\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[1;32m    406\u001b[0m visitor \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, method, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgeneric_visit)\n\u001b[0;32m--> 407\u001b[0m \u001b[39mreturn\u001b[39;00m visitor(node)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/converters/call_trees.py:117\u001b[0m, in \u001b[0;36mCallTreeTransformer.visit_FunctionDef\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[39massert\u001b[39;00m anno\u001b[39m.\u001b[39mhasanno(node, \u001b[39m'\u001b[39m\u001b[39mfunction_context_name\u001b[39m\u001b[39m'\u001b[39m), (\n\u001b[1;32m    115\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mThe function_scopes converter always creates a scope for functions.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    116\u001b[0m fn_scope\u001b[39m.\u001b[39mcontext_name \u001b[39m=\u001b[39m anno\u001b[39m.\u001b[39mgetanno(node, \u001b[39m'\u001b[39m\u001b[39mfunction_context_name\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 117\u001b[0m node\u001b[39m.\u001b[39mbody \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit_block(node\u001b[39m.\u001b[39;49mbody)\n\u001b[1;32m    118\u001b[0m \u001b[39mif\u001b[39;00m node\u001b[39m.\u001b[39mreturns:\n\u001b[1;32m    119\u001b[0m   node\u001b[39m.\u001b[39mreturns \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvisit(node\u001b[39m.\u001b[39mreturns)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/transformer.py:336\u001b[0m, in \u001b[0;36mNodeStateTracker.visit_block\u001b[0;34m(self, nodes, before_visit, after_visit)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[39mif\u001b[39;00m before_visit:\n\u001b[1;32m    333\u001b[0m   \u001b[39m# TODO(mdan): We can modify node here too, if ever needed.\u001b[39;00m\n\u001b[1;32m    334\u001b[0m   before_visit()\n\u001b[0;32m--> 336\u001b[0m replacement \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit(node)\n\u001b[1;32m    338\u001b[0m \u001b[39mif\u001b[39;00m after_visit \u001b[39mand\u001b[39;00m replacement:\n\u001b[1;32m    339\u001b[0m   replacement, new_destination \u001b[39m=\u001b[39m after_visit(replacement)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/core/converter.py:314\u001b[0m, in \u001b[0;36mBase.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ast_depth \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    313\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 314\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(Base, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mvisit(node)\n\u001b[1;32m    315\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    316\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ast_depth \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/transformer.py:441\u001b[0m, in \u001b[0;36mBase.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[39mif\u001b[39;00m processing_expr_node:\n\u001b[1;32m    439\u001b[0m   entry_expr_value \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39mvalue\n\u001b[0;32m--> 441\u001b[0m result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m(Base, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mvisit(node)\n\u001b[1;32m    443\u001b[0m \u001b[39m# Adjust for consistency: replacing the value of an Expr with\u001b[39;00m\n\u001b[1;32m    444\u001b[0m \u001b[39m# an Assign node removes the need for the Expr node.\u001b[39;00m\n\u001b[1;32m    445\u001b[0m \u001b[39mif\u001b[39;00m (processing_expr_node \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(result, gast\u001b[39m.\u001b[39mExpr) \u001b[39mand\u001b[39;00m\n\u001b[1;32m    446\u001b[0m     (result\u001b[39m.\u001b[39mvalue \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m entry_expr_value)):\n\u001b[1;32m    447\u001b[0m   \u001b[39m# When the replacement is a list, it is assumed that the list came\u001b[39;00m\n\u001b[1;32m    448\u001b[0m   \u001b[39m# from a template that contained a number of statements, which\u001b[39;00m\n\u001b[1;32m    449\u001b[0m   \u001b[39m# themselves are standalone and don't require an enclosing Expr.\u001b[39;00m\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/ast.py:407\u001b[0m, in \u001b[0;36mNodeVisitor.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    405\u001b[0m method \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mvisit_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m node\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[1;32m    406\u001b[0m visitor \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, method, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgeneric_visit)\n\u001b[0;32m--> 407\u001b[0m \u001b[39mreturn\u001b[39;00m visitor(node)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/converters/call_trees.py:124\u001b[0m, in \u001b[0;36mCallTreeTransformer.visit_With\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvisit_With\u001b[39m(\u001b[39mself\u001b[39m, node):\n\u001b[1;32m    123\u001b[0m   \u001b[39m# Context manager calls (in node.items) are not converted.\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m   node\u001b[39m.\u001b[39mbody \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit_block(node\u001b[39m.\u001b[39;49mbody)\n\u001b[1;32m    125\u001b[0m   \u001b[39mreturn\u001b[39;00m node\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/transformer.py:336\u001b[0m, in \u001b[0;36mNodeStateTracker.visit_block\u001b[0;34m(self, nodes, before_visit, after_visit)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[39mif\u001b[39;00m before_visit:\n\u001b[1;32m    333\u001b[0m   \u001b[39m# TODO(mdan): We can modify node here too, if ever needed.\u001b[39;00m\n\u001b[1;32m    334\u001b[0m   before_visit()\n\u001b[0;32m--> 336\u001b[0m replacement \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit(node)\n\u001b[1;32m    338\u001b[0m \u001b[39mif\u001b[39;00m after_visit \u001b[39mand\u001b[39;00m replacement:\n\u001b[1;32m    339\u001b[0m   replacement, new_destination \u001b[39m=\u001b[39m after_visit(replacement)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/core/converter.py:314\u001b[0m, in \u001b[0;36mBase.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ast_depth \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    313\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 314\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(Base, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mvisit(node)\n\u001b[1;32m    315\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    316\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ast_depth \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/transformer.py:441\u001b[0m, in \u001b[0;36mBase.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[39mif\u001b[39;00m processing_expr_node:\n\u001b[1;32m    439\u001b[0m   entry_expr_value \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39mvalue\n\u001b[0;32m--> 441\u001b[0m result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m(Base, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mvisit(node)\n\u001b[1;32m    443\u001b[0m \u001b[39m# Adjust for consistency: replacing the value of an Expr with\u001b[39;00m\n\u001b[1;32m    444\u001b[0m \u001b[39m# an Assign node removes the need for the Expr node.\u001b[39;00m\n\u001b[1;32m    445\u001b[0m \u001b[39mif\u001b[39;00m (processing_expr_node \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(result, gast\u001b[39m.\u001b[39mExpr) \u001b[39mand\u001b[39;00m\n\u001b[1;32m    446\u001b[0m     (result\u001b[39m.\u001b[39mvalue \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m entry_expr_value)):\n\u001b[1;32m    447\u001b[0m   \u001b[39m# When the replacement is a list, it is assumed that the list came\u001b[39;00m\n\u001b[1;32m    448\u001b[0m   \u001b[39m# from a template that contained a number of statements, which\u001b[39;00m\n\u001b[1;32m    449\u001b[0m   \u001b[39m# themselves are standalone and don't require an enclosing Expr.\u001b[39;00m\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/ast.py:407\u001b[0m, in \u001b[0;36mNodeVisitor.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    405\u001b[0m method \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mvisit_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m node\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[1;32m    406\u001b[0m visitor \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, method, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgeneric_visit)\n\u001b[0;32m--> 407\u001b[0m \u001b[39mreturn\u001b[39;00m visitor(node)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/ast.py:483\u001b[0m, in \u001b[0;36mNodeTransformer.generic_visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[39mfor\u001b[39;00m value \u001b[39min\u001b[39;00m old_value:\n\u001b[1;32m    482\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, AST):\n\u001b[0;32m--> 483\u001b[0m         value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit(value)\n\u001b[1;32m    484\u001b[0m         \u001b[39mif\u001b[39;00m value \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    485\u001b[0m             \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/core/converter.py:314\u001b[0m, in \u001b[0;36mBase.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ast_depth \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    313\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 314\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(Base, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mvisit(node)\n\u001b[1;32m    315\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    316\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ast_depth \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/transformer.py:441\u001b[0m, in \u001b[0;36mBase.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[39mif\u001b[39;00m processing_expr_node:\n\u001b[1;32m    439\u001b[0m   entry_expr_value \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39mvalue\n\u001b[0;32m--> 441\u001b[0m result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m(Base, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mvisit(node)\n\u001b[1;32m    443\u001b[0m \u001b[39m# Adjust for consistency: replacing the value of an Expr with\u001b[39;00m\n\u001b[1;32m    444\u001b[0m \u001b[39m# an Assign node removes the need for the Expr node.\u001b[39;00m\n\u001b[1;32m    445\u001b[0m \u001b[39mif\u001b[39;00m (processing_expr_node \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(result, gast\u001b[39m.\u001b[39mExpr) \u001b[39mand\u001b[39;00m\n\u001b[1;32m    446\u001b[0m     (result\u001b[39m.\u001b[39mvalue \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m entry_expr_value)):\n\u001b[1;32m    447\u001b[0m   \u001b[39m# When the replacement is a list, it is assumed that the list came\u001b[39;00m\n\u001b[1;32m    448\u001b[0m   \u001b[39m# from a template that contained a number of statements, which\u001b[39;00m\n\u001b[1;32m    449\u001b[0m   \u001b[39m# themselves are standalone and don't require an enclosing Expr.\u001b[39;00m\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/ast.py:407\u001b[0m, in \u001b[0;36mNodeVisitor.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    405\u001b[0m method \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mvisit_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m node\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[1;32m    406\u001b[0m visitor \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, method, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgeneric_visit)\n\u001b[0;32m--> 407\u001b[0m \u001b[39mreturn\u001b[39;00m visitor(node)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/ast.py:492\u001b[0m, in \u001b[0;36mNodeTransformer.generic_visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    490\u001b[0m     old_value[:] \u001b[39m=\u001b[39m new_values\n\u001b[1;32m    491\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(old_value, AST):\n\u001b[0;32m--> 492\u001b[0m     new_node \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit(old_value)\n\u001b[1;32m    493\u001b[0m     \u001b[39mif\u001b[39;00m new_node \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    494\u001b[0m         \u001b[39mdelattr\u001b[39m(node, field)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/core/converter.py:314\u001b[0m, in \u001b[0;36mBase.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ast_depth \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    313\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 314\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(Base, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mvisit(node)\n\u001b[1;32m    315\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    316\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ast_depth \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/transformer.py:441\u001b[0m, in \u001b[0;36mBase.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[39mif\u001b[39;00m processing_expr_node:\n\u001b[1;32m    439\u001b[0m   entry_expr_value \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39mvalue\n\u001b[0;32m--> 441\u001b[0m result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m(Base, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mvisit(node)\n\u001b[1;32m    443\u001b[0m \u001b[39m# Adjust for consistency: replacing the value of an Expr with\u001b[39;00m\n\u001b[1;32m    444\u001b[0m \u001b[39m# an Assign node removes the need for the Expr node.\u001b[39;00m\n\u001b[1;32m    445\u001b[0m \u001b[39mif\u001b[39;00m (processing_expr_node \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(result, gast\u001b[39m.\u001b[39mExpr) \u001b[39mand\u001b[39;00m\n\u001b[1;32m    446\u001b[0m     (result\u001b[39m.\u001b[39mvalue \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m entry_expr_value)):\n\u001b[1;32m    447\u001b[0m   \u001b[39m# When the replacement is a list, it is assumed that the list came\u001b[39;00m\n\u001b[1;32m    448\u001b[0m   \u001b[39m# from a template that contained a number of statements, which\u001b[39;00m\n\u001b[1;32m    449\u001b[0m   \u001b[39m# themselves are standalone and don't require an enclosing Expr.\u001b[39;00m\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/ast.py:407\u001b[0m, in \u001b[0;36mNodeVisitor.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    405\u001b[0m method \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mvisit_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m node\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[1;32m    406\u001b[0m visitor \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, method, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgeneric_visit)\n\u001b[0;32m--> 407\u001b[0m \u001b[39mreturn\u001b[39;00m visitor(node)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/converters/call_trees.py:197\u001b[0m, in \u001b[0;36mCallTreeTransformer.visit_Call\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    192\u001b[0m   \u001b[39mreturn\u001b[39;00m node\n\u001b[1;32m    194\u001b[0m template \u001b[39m=\u001b[39m \u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m    195\u001b[0m \u001b[39m  ag__.converted_call(func, args, kwargs, function_ctx)\u001b[39m\n\u001b[1;32m    196\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39m\n\u001b[0;32m--> 197\u001b[0m new_call \u001b[39m=\u001b[39m templates\u001b[39m.\u001b[39;49mreplace_as_expression(\n\u001b[1;32m    198\u001b[0m     template,\n\u001b[1;32m    199\u001b[0m     func\u001b[39m=\u001b[39;49mnode\u001b[39m.\u001b[39;49mfunc,\n\u001b[1;32m    200\u001b[0m     args\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_args_to_tuple(node),\n\u001b[1;32m    201\u001b[0m     kwargs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_kwargs_to_dict(node),\n\u001b[1;32m    202\u001b[0m     function_ctx\u001b[39m=\u001b[39;49mfunction_context_name)\n\u001b[1;32m    204\u001b[0m \u001b[39mreturn\u001b[39;00m new_call\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/templates.py:277\u001b[0m, in \u001b[0;36mreplace_as_expression\u001b[0;34m(template, **replacements)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreplace_as_expression\u001b[39m(template, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mreplacements):\n\u001b[1;32m    276\u001b[0m   \u001b[39m\"\"\"Variant of replace that generates expressions, instead of code blocks.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 277\u001b[0m   replacement \u001b[39m=\u001b[39m replace(template, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mreplacements)\n\u001b[1;32m    278\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(replacement) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    279\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    280\u001b[0m         \u001b[39m'\u001b[39m\u001b[39msingle expression expected; for more general templates use replace\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/templates.py:266\u001b[0m, in \u001b[0;36mreplace\u001b[0;34m(template, **replacements)\u001b[0m\n\u001b[1;32m    264\u001b[0m results \u001b[39m=\u001b[39m []\n\u001b[1;32m    265\u001b[0m \u001b[39mfor\u001b[39;00m node \u001b[39min\u001b[39;00m nodes:\n\u001b[0;32m--> 266\u001b[0m   node \u001b[39m=\u001b[39m ReplaceTransformer(replacements)\u001b[39m.\u001b[39;49mvisit(node)\n\u001b[1;32m    267\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(node, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)):\n\u001b[1;32m    268\u001b[0m     results\u001b[39m.\u001b[39mextend(node)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/ast.py:407\u001b[0m, in \u001b[0;36mNodeVisitor.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    405\u001b[0m method \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mvisit_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m node\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[1;32m    406\u001b[0m visitor \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, method, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgeneric_visit)\n\u001b[0;32m--> 407\u001b[0m \u001b[39mreturn\u001b[39;00m visitor(node)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/templates.py:145\u001b[0m, in \u001b[0;36mReplaceTransformer.visit_Expr\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvisit_Expr\u001b[39m(\u001b[39mself\u001b[39m, node):\n\u001b[1;32m    143\u001b[0m   \u001b[39m# When replacing a placeholder with an entire statement, the replacement\u001b[39;00m\n\u001b[1;32m    144\u001b[0m   \u001b[39m# must stand on its own and not be wrapped in an Expr.\u001b[39;00m\n\u001b[0;32m--> 145\u001b[0m   new_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit(node\u001b[39m.\u001b[39;49mvalue)\n\u001b[1;32m    146\u001b[0m   \u001b[39mif\u001b[39;00m new_value \u001b[39mis\u001b[39;00m node\u001b[39m.\u001b[39mvalue:\n\u001b[1;32m    147\u001b[0m     \u001b[39mreturn\u001b[39;00m node\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/ast.py:407\u001b[0m, in \u001b[0;36mNodeVisitor.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    405\u001b[0m method \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mvisit_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m node\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[1;32m    406\u001b[0m visitor \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, method, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgeneric_visit)\n\u001b[0;32m--> 407\u001b[0m \u001b[39mreturn\u001b[39;00m visitor(node)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/ast.py:483\u001b[0m, in \u001b[0;36mNodeTransformer.generic_visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[39mfor\u001b[39;00m value \u001b[39min\u001b[39;00m old_value:\n\u001b[1;32m    482\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, AST):\n\u001b[0;32m--> 483\u001b[0m         value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit(value)\n\u001b[1;32m    484\u001b[0m         \u001b[39mif\u001b[39;00m value \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    485\u001b[0m             \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/ast.py:407\u001b[0m, in \u001b[0;36mNodeVisitor.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    405\u001b[0m method \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mvisit_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m node\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[1;32m    406\u001b[0m visitor \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, method, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgeneric_visit)\n\u001b[0;32m--> 407\u001b[0m \u001b[39mreturn\u001b[39;00m visitor(node)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/templates.py:197\u001b[0m, in \u001b[0;36mReplaceTransformer.visit_Name\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39mif\u001b[39;00m node\u001b[39m.\u001b[39mid \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreplacements:\n\u001b[1;32m    195\u001b[0m   \u001b[39mreturn\u001b[39;00m node\n\u001b[0;32m--> 197\u001b[0m new_nodes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_prepare_replacement(node, node\u001b[39m.\u001b[39;49mid)\n\u001b[1;32m    199\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m new_nodes:\n\u001b[1;32m    200\u001b[0m   \u001b[39mreturn\u001b[39;00m new_nodes\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/templates.py:136\u001b[0m, in \u001b[0;36mReplaceTransformer._prepare_replacement\u001b[0;34m(self, replaced, key)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[39m\"\"\"Prepares a replacement AST that's safe to swap in for a node.\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \n\u001b[1;32m    128\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[39m  ast.AST, the replacement AST\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    134\u001b[0m repl \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreplacements[key]\n\u001b[0;32m--> 136\u001b[0m new_nodes \u001b[39m=\u001b[39m ast_util\u001b[39m.\u001b[39;49mcopy_clean(repl, preserve_annos\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpreserved_annos)\n\u001b[1;32m    137\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(new_nodes, gast\u001b[39m.\u001b[39mAST):\n\u001b[1;32m    138\u001b[0m   new_nodes \u001b[39m=\u001b[39m [new_nodes]\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/ast_util.py:72\u001b[0m, in \u001b[0;36mcopy_clean\u001b[0;34m(node, preserve_annos)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcopy_clean\u001b[39m(node, preserve_annos\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     60\u001b[0m   \u001b[39m\"\"\"Creates a deep copy of an AST.\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \n\u001b[1;32m     62\u001b[0m \u001b[39m  The copy will not include fields that are prefixed by '__', with the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[39m    ast.AST\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m   \u001b[39mreturn\u001b[39;00m CleanCopier(preserve_annos)\u001b[39m.\u001b[39;49mcopy(node)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/ast_util.py:55\u001b[0m, in \u001b[0;36mCleanCopier.copy\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreserve_annos:\n\u001b[1;32m     54\u001b[0m   \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreserve_annos:\n\u001b[0;32m---> 55\u001b[0m     anno\u001b[39m.\u001b[39;49mcopyanno(node, new_node, k)\n\u001b[1;32m     56\u001b[0m \u001b[39mreturn\u001b[39;00m new_node\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    encoder_hidden_state = encoder.initialize(batch_size=batch_size)\n",
    "    batch = {\n",
    "        'encoder_input_ids': encoded_input_sample,\n",
    "        'encoder_state': encoder_hidden_state,\n",
    "        'decoder_target': encoded_output_sample\n",
    "    }\n",
    "    loss = trainer.batch_fit(batch)\n",
    "    print(f'Loss - {loss}')\n",
    "\n",
    "    generated = trainer.generate(input_ids=encoded_input_sample)\n",
    "    translated = trainer.translate(generated)\n",
    "    print(f'Translated - {translated}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seq2Seq Bert-Tiny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTrainer(object):\n",
    "    \"\"\"\n",
    "    Simple wrapper class\n",
    "\n",
    "    train_op -> uses tf.GradientTape to compute the loss\n",
    "    batch_fit -> receives a batch and performs forward-backward passes (gradient included)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, encoder, decoder, max_length):\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.max_length = max_length\n",
    "        self.ce = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=1e-03)\n",
    "\n",
    "    @tf.function\n",
    "    def compute_loss(self, logits, target):\n",
    "        loss = self.ce(y_true=target, y_pred=logits)\n",
    "        mask = tf.logical_not(tf.math.equal(target, 0))\n",
    "        mask = tf.cast(mask, dtype=loss.dtype)\n",
    "        loss *= mask\n",
    "        return tf.reduce_mean(loss)\n",
    "\n",
    "    @tf.function\n",
    "    def train_op(self, inputs):\n",
    "        with tf.GradientTape() as tape:\n",
    "            encoder_output, encoder_h, encoder_s = self.encoder({'input_ids': inputs['encoder_input_ids'],\n",
    "                                                                 'attention_mask': inputs['encoder_attention_mask']})\n",
    "\n",
    "            decoder_input = inputs['decoder_target'][:, :-1]  # ignore <end>\n",
    "            real_target = inputs['decoder_target'][:, 1:]  # ignore <start>\n",
    "\n",
    "            decoder.attention.setup_memory(encoder_output)\n",
    "\n",
    "            decoder_initial_state = self.decoder.build_initial_state(decoder.batch_size, [encoder_h, encoder_s])\n",
    "            predicted = self.decoder({'input_ids': decoder_input,\n",
    "                                      'initial_state': decoder_initial_state}).rnn_output\n",
    "\n",
    "            loss = self.compute_loss(logits=predicted, target=real_target)\n",
    "\n",
    "        grads = tape.gradient(loss, self.encoder.trainable_variables + self.decoder.trainable_variables)\n",
    "        return loss, grads\n",
    "\n",
    "    @tf.function\n",
    "    def batch_fit(self, inputs):\n",
    "        loss, grads = self.train_op(inputs=inputs)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.encoder.trainable_variables + self.decoder.trainable_variables))\n",
    "        return loss\n",
    "\n",
    "    # @tf.function\n",
    "    def generate(self, input_ids, attention_mask=None):\n",
    "        batch_size = input_ids.shape[0]\n",
    "        encoder_output, encoder_h, encoder_s = self.encoder({\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask\n",
    "        })\n",
    "\n",
    "        start_tokens = tf.fill([batch_size], output_tokenizer.word_index['<start>'])\n",
    "        end_token = output_tokenizer.word_index['<end>']\n",
    "\n",
    "        greedy_sampler = tfa.seq2seq.GreedyEmbeddingSampler()\n",
    "        decoder_instance = tfa.seq2seq.BasicDecoder(cell=self.decoder.wrapped_decoder_cell,\n",
    "                                                    sampler=greedy_sampler,\n",
    "                                                    output_layer=self.decoder.generation_dense,\n",
    "                                                    maximum_iterations=self.max_length)\n",
    "        self.decoder.attention.setup_memory(encoder_output)\n",
    "\n",
    "        decoder_initial_state = self.decoder.build_initial_state(batch_size, [encoder_h, encoder_s])\n",
    "        decoder_embedding_matrix = self.decoder.embedding.variables[0]\n",
    "        outputs, _, _ = decoder_instance(decoder_embedding_matrix,\n",
    "                                         start_tokens=start_tokens,\n",
    "                                         end_token=end_token,\n",
    "                                         initial_state=decoder_initial_state)\n",
    "        return outputs\n",
    "\n",
    "    def translate(self, generated):\n",
    "        return output_tokenizer.sequences_to_texts(generated.sample_id.numpy())\n",
    "\n",
    "\n",
    "class Encoder(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, model_name, decoder_units):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.model = TFAutoModel.from_pretrained(model_name, from_pt=True)\n",
    "        self.reducer = tf.keras.layers.Dense(decoder_units)\n",
    "\n",
    "    def call(self, inputs, training=False, **kwargs):\n",
    "        model_output = self.model(inputs)\n",
    "        all_outputs = model_output[0]\n",
    "        pooled_output = model_output[1]\n",
    "        pooled_output = self.reducer(pooled_output)\n",
    "        return all_outputs, pooled_output, pooled_output\n",
    "\n",
    "\n",
    "class Decoder(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, vocab_size, max_sequence_length, embedding_dim, decoder_units, batch_size):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.max_sequence_length = max_sequence_length\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.decoder_units = decoder_units\n",
    "        self.embedding = tf.keras.layers.Embedding(input_dim=vocab_size,\n",
    "                                                   output_dim=embedding_dim)\n",
    "        self.decoder_lstm_cell = tf.keras.layers.LSTMCell(self.decoder_units)\n",
    "\n",
    "        self.attention = tfa.seq2seq.BahdanauAttention(units=self.decoder_units,\n",
    "                                                       memory=None,\n",
    "                                                       memory_sequence_length=self.batch_size * [max_sequence_length])\n",
    "\n",
    "        self.wrapped_decoder_cell = tfa.seq2seq.AttentionWrapper(self.decoder_lstm_cell,\n",
    "                                                                 self.attention,\n",
    "                                                                 attention_layer_size=self.decoder_units)\n",
    "\n",
    "        self.generation_dense = tf.keras.layers.Dense(vocab_size)\n",
    "        self.sampler = tfa.seq2seq.sampler.TrainingSampler()\n",
    "        self.decoder = tfa.seq2seq.BasicDecoder(self.wrapped_decoder_cell,\n",
    "                                                sampler=self.sampler,\n",
    "                                                output_layer=self.generation_dense)\n",
    "\n",
    "    def build_initial_state(self, batch_size, encoder_state):\n",
    "        initial_state = self.wrapped_decoder_cell.get_initial_state(batch_size=batch_size, dtype=tf.float32)\n",
    "        initial_state = initial_state.clone(cell_state=encoder_state)\n",
    "        return initial_state\n",
    "\n",
    "    def call(self, inputs, training=False, **kwargs):\n",
    "        input_ids = inputs['input_ids']\n",
    "        input_emb = self.embedding(input_ids)\n",
    "        decoder_output, _, _ = self.decoder(input_emb,\n",
    "                                            initial_state=inputs['initial_state'],\n",
    "                                            sequence_length=self.batch_size * [self.max_sequence_length - 1])\n",
    "        return decoder_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForQuestionAnswering, AutoTokenizer, AutoConfig\n",
    "\n",
    "model_name = 'prajjwal1/bert-tiny'\n",
    "\n",
    "#config = AutoConfig.from_pretrained(model_name)\n",
    "#model = BertForQuestionAnswering.from_pretrained(model_name, config=config)\n",
    "input_tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next block of code is an example of encoding of a question-context pair: in this case, the question is the first part of the encoding, and the context is the second part. There are two special tokens: [CLS] token at the start of the encoding, [SEP] token between the question and the context, and at the end of the encoding.\n",
    "\n",
    "In this case the context is the *span*, to provide a better example that explains the encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Was Lassiter impressed with the horse?\n",
      "When Jerd led out this slender, beautifully built horse Lassiter suddenly became all eyes.\n",
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "101\t[CLS]\n",
      "2001\twas\n",
      "27333\tlass\n",
      "21646\t##iter\n",
      "7622\timpressed\n",
      "2007\twith\n",
      "1996\tthe\n",
      "3586\thorse\n",
      "1029\t?\n",
      "102\t[SEP]\n",
      "2043\twhen\n",
      "15333\tje\n",
      "4103\t##rd\n",
      "2419\tled\n",
      "2041\tout\n",
      "2023\tthis\n",
      "10944\tslender\n",
      "1010\t,\n",
      "17950\tbeautifully\n",
      "2328\tbuilt\n",
      "3586\thorse\n",
      "27333\tlass\n",
      "21646\t##iter\n",
      "3402\tsuddenly\n",
      "2150\tbecame\n",
      "2035\tall\n",
      "2159\teyes\n",
      "1012\t.\n",
      "102\t[SEP]\n"
     ]
    }
   ],
   "source": [
    "line = 42\n",
    "\n",
    "encoded_question = input_tokenizer(train_df['q'][line], return_tensors='tf', padding=True)\n",
    "print(train_df['q'][line])\n",
    "\n",
    "encoded_span = input_tokenizer(train_df['span'][line], return_tensors='tf', padding=True)\n",
    "print(train_df['span'][line])\n",
    "\n",
    "encoded_qs = input_tokenizer(train_df['q'][line], train_df['span'][line], return_tensors='tf', padding=True)\n",
    "\n",
    "print('= '*40)\n",
    "for idx, tok in zip(encoded_qs.input_ids.numpy()[0], input_tokenizer.convert_ids_to_tokens(encoded_qs.input_ids[0])):\n",
    "    print(\"{}\\t{}\".format(idx, tok))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets encode a part of the dataset in sentences of: [CLS] question [SEP] passage [SEP]. Otherwise, the training would be very slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 512  # The maximum length of a feature (question and context)\n",
    "doc_stride = (\n",
    "    128  # The authorized overlap between two part of the context when splitting\n",
    ")\n",
    "sentences = 20\n",
    "sample = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "qs = train_df['q'][range(sentences)] # questions\n",
    "cs = train_df['p'][range(sentences)] # contexts\n",
    "\n",
    "batch_size = len(qs)\n",
    "\n",
    "encoded_inputs = input_tokenizer(\n",
    "    qs.values.tolist(),\n",
    "    cs.values.tolist(),\n",
    "    #train_df['q'].values.tolist(),\n",
    "    #train_df['p'].values.tolist(),\n",
    "    truncation=\"only_second\",\n",
    "    max_length=max_length,\n",
    "    stride=doc_stride,\n",
    "    return_overflowing_tokens=True,\n",
    "    return_offsets_mapping=True,\n",
    "    padding=\"max_length\",\n",
    "    return_tensors='tf'\n",
    ")\n",
    "\n",
    "input_ids, attention_mask = encoded_inputs.input_ids, encoded_inputs.attention_mask\n",
    "max_input_length = input_ids.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_input_length: 512\n",
      "encoded_inputs shape = (20, 512)\n"
     ]
    }
   ],
   "source": [
    "print(\"max_input_length:\", max_input_length)\n",
    "print(\"encoded_inputs shape =\", encoded_inputs['input_ids'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'token_type_ids' encodes wether the encoded id is part of the question (=0) or the context (=1). The Attention Mask indicates if the input is needed (=1) or it's padding (=0)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare also the expected outputs, for the training (this code follows the example given by the tutors, but I'm not convinced that this is the proper formatting for a QA Bert model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 30, 5, 31, 10, 5, 32, 33, 3]\n"
     ]
    }
   ],
   "source": [
    "# Output\n",
    "outputs = \"<start> \" + train_df['a'][range(sentences)] + \" <end>\"\n",
    "\n",
    "output_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='', oov_token='<UNK>')\n",
    "output_tokenizer.fit_on_texts(outputs)\n",
    "\n",
    "output_vocab_size = len(output_tokenizer.word_index) + 1\n",
    "\n",
    "encoded_output = output_tokenizer.texts_to_sequences(outputs)\n",
    "print(encoded_output[sample])\n",
    "max_output_length = max([len(item) for item in encoded_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_output_length: 11\n",
      "max_sequence_length: 512\n"
     ]
    }
   ],
   "source": [
    "max_sequence_length = max(max_input_length, max_output_length)\n",
    "\n",
    "print(\"max_output_length: {}\".format(max_output_length))\n",
    "print(\"max_sequence_length: {}\".format(max_sequence_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2 30  5 31 10  5 32 33  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "encoded_output = tf.keras.preprocessing.sequence.pad_sequences(encoded_output,\n",
    "                                                                        padding='post',\n",
    "                                                                        maxlen=max_sequence_length)\n",
    "print(encoded_output[sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'bert.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 512, 128) - (20, 16) - (20, 16)\n"
     ]
    }
   ],
   "source": [
    "# Test encoder\n",
    "encoder = Encoder(model_name=model_name,\n",
    "                    decoder_units=16)\n",
    "encoder_output, encoder_h, encoder_s = encoder({'input_ids': input_ids,\n",
    "                                                'attention_mask': attention_mask})\n",
    "print(f'{encoder_output.shape} - {encoder_h.shape} - {encoder_s.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 511, 63)\n"
     ]
    }
   ],
   "source": [
    "# Test decoder\n",
    "decoder = Decoder(vocab_size=output_vocab_size,\n",
    "                    embedding_dim=50,\n",
    "                    decoder_units=16,\n",
    "                    batch_size=batch_size,\n",
    "                    max_sequence_length=max_sequence_length)\n",
    "decoder.attention.setup_memory(encoder_output)\n",
    "initial_state = decoder.build_initial_state(batch_size, [encoder_h, encoder_s])\n",
    "\n",
    "decoder_batch = {\n",
    "    'input_ids': tf.convert_to_tensor(encoded_output, tf.int32),\n",
    "    'initial_state': initial_state\n",
    "}\n",
    "decoder_outputs = decoder(decoder_batch).rnn_output\n",
    "print(f'{decoder_outputs.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "trainer = MyTrainer(encoder=encoder,\n",
    "                    decoder=decoder,\n",
    "                    max_length=max_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/envs/nlp/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "Loss - 0.03715987503528595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:16<00:33, 16.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated - ['<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>']\n",
      "Loss - 0.035390060395002365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:20<00:09,  9.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated - ['<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>']\n",
      "Loss - 0.03438769653439522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:24<00:00,  8.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated - ['<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    batch = {\n",
    "        'encoder_input_ids': input_ids,\n",
    "        'encoder_attention_mask': attention_mask,\n",
    "        'decoder_target': encoded_output\n",
    "    }\n",
    "    loss = trainer.batch_fit(batch)\n",
    "    print(f'Loss - {loss}')\n",
    "\n",
    "    generated = trainer.generate(input_ids=input_ids,\n",
    "                                    attention_mask=attention_mask)\n",
    "    translated = trainer.translate(generated)\n",
    "    print(f'Translated - {translated}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of answered question by the pretrained (*original*) model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertForQuestionAnswering: ['bert.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFBertForQuestionAnswering from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForQuestionAnswering from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFBertForQuestionAnswering were not initialized from the PyTorch model and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForQuestionAnswering: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model outputs: {'score': 2.5019875465659425e-05, 'start': 387, 'end': 438, 'answer': '1.1 million printed books, which include some 8,500'}\n",
      "\n",
      "official results are (from train.json):\n",
      "span_start: 151\n",
      "span_end: 179\n",
      "span_text: Formally established in 1475\n",
      "input_text: It was formally established in 1475\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFBertForQuestionAnswering, pipeline\n",
    "\n",
    "model = TFBertForQuestionAnswering.from_pretrained(model_name, from_pt=True)\n",
    "\n",
    "question_answerer = pipeline(\"question-answering\", model=model_name)\n",
    "\n",
    "outputs = question_answerer(question=train_df['q'][0], context=train_df['p'][0])\n",
    "\n",
    "print(\"model outputs:\", outputs)\n",
    "print()\n",
    "print(\"official results are (from train.json):\") \n",
    "print(\"span_start: 151\")\n",
    "print(\"span_end: 179\")\n",
    "print(\"span_text: Formally established in 1475\")\n",
    "print(\"input_text: It was formally established in 1475\")\n",
    "#print(\"start scores: {}\".format(start_scores))\n",
    "#print(\"end scores: {}\".format(end_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question generation $f_\\theta(P, Q, H)$ with text passage $P$, question $Q$ and dialogue history $H$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evaluate $f_\\theta(P, Q)$ and $f_\\theta(P, Q, H)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e405b0a43b05ed5b511dac57849ab560497f023fc2f8f0bfd2781bf41b5f416c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
