{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/Danysan1/ai-unibo-nlp-project/blob/main/a2/execution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: pandas in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (1.5.0)\n",
      "Requirement already satisfied: numpy in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (1.23.3)\n",
      "Requirement already satisfied: matplotlib in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (3.5.3)\n",
      "Requirement already satisfied: transformers in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (4.25.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from pandas) (2022.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from matplotlib) (9.2.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from matplotlib) (4.37.1)\n",
      "Requirement already satisfied: requests in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: filelock in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from transformers) (3.8.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from transformers) (0.11.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from requests->transformers) (2022.6.15.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from requests->transformers) (1.26.12)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas numpy matplotlib transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "from tqdm import tqdm\n",
    "\n",
    "class DownloadProgressBar(tqdm):\n",
    "    def update_to(self, b=1, bsize=1, tsize=None):\n",
    "        if tsize is not None:\n",
    "            self.total = tsize\n",
    "        self.update(b * bsize - self.n)\n",
    "        \n",
    "def download_url(url, output_path):\n",
    "    with DownloadProgressBar(unit='B', unit_scale=True,\n",
    "                             miniters=1, desc=url.split('/')[-1]) as t:\n",
    "        urllib.request.urlretrieve(url, filename=output_path, reporthook=t.update_to)\n",
    "\n",
    "def download_data(data_path, url_path, suffix):    \n",
    "    if not os.path.exists(data_path):\n",
    "        os.makedirs(data_path)\n",
    "        \n",
    "    data_path = os.path.join(data_path, f'{suffix}.json')\n",
    "    if not os.path.exists(data_path):\n",
    "        print(f\"Downloading CoQA {suffix} data split... (it may take a while)\")\n",
    "        download_url(url=url_path, output_path=data_path)\n",
    "        print(\"Download completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'Dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data\n",
    "train_url = \"https://nlp.stanford.edu/data/coqa/coqa-train-v1.0.json\"\n",
    "download_data(data_path=data_folder, url_path=train_url, suffix='train')\n",
    "\n",
    "# Test data\n",
    "test_url = \"https://nlp.stanford.edu/data/coqa/coqa-dev-v1.0.json\"\n",
    "download_data(data_path=data_folder, url_path=test_url, suffix='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataset(filename):\n",
    "    with open(path.join(data_folder, filename)) as file_obj:\n",
    "        df = json.load(file_obj)[\"data\"]\n",
    "    print(f'{len(df)} rows / {len(df[0][\"questions\"])} questions in the first row')\n",
    "\n",
    "    df = np.array([\n",
    "        [\n",
    "            story[\"story\"],\n",
    "            story[\"questions\"][question_index][\"input_text\"],\n",
    "            story[\"answers\"][question_index][\"input_text\"],\n",
    "            story[\"answers\"][question_index][\"span_text\"],\n",
    "            #story_index,\n",
    "            #question_index,\n",
    "        ]\n",
    "        for story_index, story in enumerate(df)\n",
    "        for question_index in range(len(story[\"questions\"]))\n",
    "    ])\n",
    "    print(f'{df.shape} unfiltered question-answer pairs x columns')\n",
    "    \n",
    "    # https://marcobonzanini.com/2021/09/15/tips-for-saving-memory-with-pandas/\n",
    "    # https://pandas.pydata.org/docs/user_guide/categorical.html\n",
    "    df = pd.DataFrame({\n",
    "        \"p\": pd.Series(df[:,0], dtype='category'),\n",
    "        \"q\": df[:,1],\n",
    "        \"a\": df[:,2],\n",
    "        \"span\": df[:,3],\n",
    "        #\"p_index\": df[:,4],\n",
    "        #\"q_index\": df[:,5],\n",
    "    })\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7199 rows / 20 questions in the first row\n",
      "(108647, 4) unfiltered question-answer pairs x columns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "p       108647\n",
       "q       108647\n",
       "a       108647\n",
       "span    108647\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = loadDataset(\"train.json\")\n",
    "train_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_df = loadDataset(\"test.json\")\n",
    "#test_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p</th>\n",
       "      <th>q</th>\n",
       "      <th>a</th>\n",
       "      <th>span</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
       "      <td>When was the Vat formally opened?</td>\n",
       "      <td>It was formally established in 1475</td>\n",
       "      <td>Formally established in 1475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
       "      <td>what is the library for?</td>\n",
       "      <td>research</td>\n",
       "      <td>he Vatican Library is a research library</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
       "      <td>for what subjects?</td>\n",
       "      <td>history, and law</td>\n",
       "      <td>Vatican Library is a research library for hist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
       "      <td>and?</td>\n",
       "      <td>philosophy, science and theology</td>\n",
       "      <td>Vatican Library is a research library for hist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
       "      <td>what was started in 2014?</td>\n",
       "      <td>a  project</td>\n",
       "      <td>March 2014, the Vatican Library began an initi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   p  \\\n",
       "0  The Vatican Apostolic Library (), more commonl...   \n",
       "1  The Vatican Apostolic Library (), more commonl...   \n",
       "2  The Vatican Apostolic Library (), more commonl...   \n",
       "3  The Vatican Apostolic Library (), more commonl...   \n",
       "4  The Vatican Apostolic Library (), more commonl...   \n",
       "\n",
       "                                   q                                    a  \\\n",
       "0  When was the Vat formally opened?  It was formally established in 1475   \n",
       "1           what is the library for?                             research   \n",
       "2                 for what subjects?                     history, and law   \n",
       "3                               and?     philosophy, science and theology   \n",
       "4          what was started in 2014?                           a  project   \n",
       "\n",
       "                                                span  \n",
       "0                       Formally established in 1475  \n",
       "1           he Vatican Library is a research library  \n",
       "2  Vatican Library is a research library for hist...  \n",
       "3  Vatican Library is a research library for hist...  \n",
       "4  March 2014, the Vatican Library began an initi...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index         128\n",
       "p        14243943\n",
       "q         9227996\n",
       "a         7802303\n",
       "span     12037273\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.memory_usage(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check unanswerable questions in the Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1371"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = (train_df.a == 'unknown')\n",
    "unanswerable = train_df[idx]\n",
    "unanswerable.q.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13         what must be requested to view?\n",
       "349    Were they the relatives of the kid?\n",
       "352            Where did he go afterwards?\n",
       "354                        Who found them?\n",
       "356              Did he have any siblings?\n",
       "Name: q, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unanswerable.q.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 1371 unanswerable questions in the Train Dataset, the next step is to remove those rows from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "p       107276\n",
       "q       107276\n",
       "a       107276\n",
       "span    107276\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_df[~idx]\n",
    "train_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p</th>\n",
       "      <th>q</th>\n",
       "      <th>a</th>\n",
       "      <th>span</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
       "      <td>When was the Vat formally opened?</td>\n",
       "      <td>It was formally established in 1475</td>\n",
       "      <td>Formally established in 1475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
       "      <td>what is the library for?</td>\n",
       "      <td>research</td>\n",
       "      <td>he Vatican Library is a research library</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
       "      <td>for what subjects?</td>\n",
       "      <td>history, and law</td>\n",
       "      <td>Vatican Library is a research library for hist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
       "      <td>and?</td>\n",
       "      <td>philosophy, science and theology</td>\n",
       "      <td>Vatican Library is a research library for hist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
       "      <td>what was started in 2014?</td>\n",
       "      <td>a  project</td>\n",
       "      <td>March 2014, the Vatican Library began an initi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   p  \\\n",
       "0  The Vatican Apostolic Library (), more commonl...   \n",
       "1  The Vatican Apostolic Library (), more commonl...   \n",
       "2  The Vatican Apostolic Library (), more commonl...   \n",
       "3  The Vatican Apostolic Library (), more commonl...   \n",
       "4  The Vatican Apostolic Library (), more commonl...   \n",
       "\n",
       "                                   q                                    a  \\\n",
       "0  When was the Vat formally opened?  It was formally established in 1475   \n",
       "1           what is the library for?                             research   \n",
       "2                 for what subjects?                     history, and law   \n",
       "3                               and?     philosophy, science and theology   \n",
       "4          what was started in 2014?                           a  project   \n",
       "\n",
       "                                                span  \n",
       "0                       Formally established in 1475  \n",
       "1           he Vatican Library is a research library  \n",
       "2  Vatican Library is a research library for hist...  \n",
       "3  Vatican Library is a research library for hist...  \n",
       "4  March 2014, the Vatican Library began an initi...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Validation-Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-14 00:08:06.404605: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-14 00:08:07.577286: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-14 00:08:07.577329: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-14 00:08:07.681771: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-12-14 00:08:09.917268: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-14 00:08:09.917572: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-14 00:08:09.917583: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from typing import List, Dict, Callable\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_data(model: keras.Model,\n",
    "                x: np.ndarray,\n",
    "                prediction_info: Dict):\n",
    "    \"\"\"\n",
    "    Inference routine of a given input set of examples\n",
    "\n",
    "    :param model: Keras built and possibly trained model\n",
    "    :param x: input set of examples in np.ndarray format\n",
    "    :param prediction_info: dictionary storing model predict() argument information\n",
    "\n",
    "    :return\n",
    "        predictions: predicted labels in np.ndarray format\n",
    "    \"\"\"\n",
    "    print(f'Starting prediction: \\n{prediction_info}')\n",
    "    print(f'Predicting on {x.shape[0]} samples')\n",
    "    predictions = model.predict(x, **prediction_info)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_f1(model: keras.Model, \n",
    "             x: np.ndarray, \n",
    "             y: np.ndarray):\n",
    "    \"\"\"\n",
    "    Compute F1_score on the given data with corresponding labels\n",
    "\n",
    "    :param model: Keras built and possibly trained model\n",
    "    :param x: data in np.ndarray format\n",
    "    :param y: ground-truth labels in np.ndarray format\n",
    "\n",
    "    :return\n",
    "        score: f1_macro_score\n",
    "    \"\"\"\n",
    "    #predictions on the x set\n",
    "    prediction_info = {\n",
    "        'batch_size': 64,\n",
    "        'verbose': 1\n",
    "    }\n",
    "    y_pred = predict_data(model=model, x=x, prediction_info=prediction_info)\n",
    "\n",
    "    #compute argmax to take the best class for each sample\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    #compute the f1_macro\n",
    "    score = f1_score(y, y_pred, average ='macro')\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_reproducibility(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-14 00:08:14.221229: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-12-14 00:08:14.221431: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-14 00:08:14.221669: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-14 00:08:14.222421: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-14 00:08:14.276762: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-14 00:08:14.277014: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-14 00:08:14.277150: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-12-14 00:08:14.277166: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tqdm import tqdm\n",
    "from transformers import TFAutoModel, AutoTokenizer\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question generation $f_\\theta(P, Q)$ with text passage $P$ and question $Q$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTrainer(object):\n",
    "    \"\"\"\n",
    "    Simple wrapper class\n",
    "\n",
    "    train_op -> uses tf.GradientTape to compute the loss\n",
    "    batch_fit -> receives a batch and performs forward-backward passes (gradient included)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, encoder, decoder, max_length):\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.max_length = max_length\n",
    "        self.ce = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=1e-03)\n",
    "\n",
    "    @tf.function\n",
    "    def compute_loss(self, logits, target):\n",
    "        loss = self.ce(y_true=target, y_pred=logits)\n",
    "        mask = tf.logical_not(tf.math.equal(target, 0))\n",
    "        mask = tf.cast(mask, dtype=loss.dtype)\n",
    "        loss *= mask\n",
    "        return tf.reduce_mean(loss)\n",
    "\n",
    "    @tf.function\n",
    "    def train_op(self, inputs):\n",
    "        with tf.GradientTape() as tape:\n",
    "            encoder_output, encoder_h, encoder_s = self.encoder({'input_ids': inputs['encoder_input_ids'],\n",
    "                                                                 'hidden_state': inputs['encoder_state']})\n",
    "\n",
    "            decoder_input = inputs['decoder_target'][:, :-1]  # ignore <end>\n",
    "            real_target = inputs['decoder_target'][:, 1:]  # ignore <start>\n",
    "\n",
    "            decoder.attention.setup_memory(encoder_output)\n",
    "\n",
    "            decoder_initial_state = self.decoder.build_initial_state(decoder.batch_size, [encoder_h, encoder_s])\n",
    "            predicted = self.decoder({'input_ids': decoder_input,\n",
    "                                      'initial_state': decoder_initial_state}).rnn_output\n",
    "\n",
    "            loss = self.compute_loss(logits=predicted, target=real_target)\n",
    "\n",
    "        grads = tape.gradient(loss, self.encoder.trainable_variables + self.decoder.trainable_variables)\n",
    "        return loss, grads\n",
    "\n",
    "    @tf.function\n",
    "    def batch_fit(self, inputs):\n",
    "        loss, grads = self.train_op(inputs=inputs)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.encoder.trainable_variables + self.decoder.trainable_variables))\n",
    "        return loss\n",
    "\n",
    "    @tf.function\n",
    "    def generate(self, input_ids):\n",
    "        batch_size = input_ids.shape[0]\n",
    "        encoder_initial_state = [tf.zeros((batch_size, self.encoder.encoder_units)),\n",
    "                                 tf.zeros((batch_size, self.encoder.encoder_units))]\n",
    "        encoder_output, encoder_h, encoder_s = self.encoder({\n",
    "            'input_ids': input_ids,\n",
    "            'hidden_state': encoder_initial_state\n",
    "        })\n",
    "\n",
    "        start_tokens = tf.fill([batch_size], tokenizer.word_index['<start>'])\n",
    "        end_token = tokenizer.word_index['<end>']\n",
    "\n",
    "        greedy_sampler = tfa.seq2seq.GreedyEmbeddingSampler()\n",
    "        decoder_instance = tfa.seq2seq.BasicDecoder(cell=self.decoder.wrapped_decoder_cell,\n",
    "                                                    sampler=greedy_sampler,\n",
    "                                                    output_layer=self.decoder.generation_dense,\n",
    "                                                    maximum_iterations=self.max_length)\n",
    "        self.decoder.attention.setup_memory(encoder_output)\n",
    "\n",
    "        decoder_initial_state = self.decoder.build_initial_state(batch_size, [encoder_h, encoder_s])\n",
    "        decoder_embedding_matrix = self.decoder.embedding.variables[0]\n",
    "        outputs, _, _ = decoder_instance(decoder_embedding_matrix,\n",
    "                                         start_tokens=start_tokens,\n",
    "                                         end_token=end_token,\n",
    "                                         initial_state=decoder_initial_state)\n",
    "        return outputs\n",
    "\n",
    "    def translate(self, generated):\n",
    "        return tokenizer.sequences_to_texts(generated.sample_id.numpy())\n",
    "\n",
    "\n",
    "class Encoder(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, encoder_units):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.encoder_units = encoder_units\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(input_dim=vocab_size,\n",
    "                                                   output_dim=embedding_dim)\n",
    "        self.encoder_lstm = tf.keras.layers.LSTM(self.encoder_units,\n",
    "                                                 return_sequences=True,\n",
    "                                                 return_state=True)\n",
    "\n",
    "    def call(self, inputs, training=False, **kwargs):\n",
    "        input_ids = inputs['input_ids']\n",
    "        input_emb = self.embedding(input_ids)\n",
    "        encoder_output, lstm_hidden, lstm_states = self.encoder_lstm(input_emb, initial_state=inputs['hidden_state'])\n",
    "        return encoder_output, lstm_hidden, lstm_states\n",
    "\n",
    "    def initialize(self, batch_size):\n",
    "        return [tf.zeros((batch_size, self.encoder_units)), tf.zeros((batch_size, self.encoder_units))]\n",
    "\n",
    "\n",
    "class Decoder(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, vocab_size, max_sequence_length, embedding_dim, decoder_units, batch_size):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.max_sequence_length = max_sequence_length\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.decoder_units = decoder_units\n",
    "        self.embedding = tf.keras.layers.Embedding(input_dim=vocab_size,\n",
    "                                                   output_dim=embedding_dim)\n",
    "        self.decoder_lstm_cell = tf.keras.layers.LSTMCell(self.decoder_units)\n",
    "\n",
    "        self.attention = tfa.seq2seq.BahdanauAttention(units=self.decoder_units,\n",
    "                                                       memory=None,\n",
    "                                                       memory_sequence_length=self.batch_size * [max_sequence_length])\n",
    "\n",
    "        self.wrapped_decoder_cell = tfa.seq2seq.AttentionWrapper(self.decoder_lstm_cell,\n",
    "                                                                 self.attention,\n",
    "                                                                 attention_layer_size=self.decoder_units)\n",
    "\n",
    "        self.generation_dense = tf.keras.layers.Dense(vocab_size)\n",
    "        self.sampler = tfa.seq2seq.sampler.TrainingSampler()\n",
    "        self.decoder = tfa.seq2seq.BasicDecoder(self.wrapped_decoder_cell,\n",
    "                                                sampler=self.sampler,\n",
    "                                                output_layer=self.generation_dense)\n",
    "\n",
    "    def build_initial_state(self, batch_size, encoder_state):\n",
    "        initial_state = self.wrapped_decoder_cell.get_initial_state(batch_size=batch_size, dtype=tf.float32)\n",
    "        initial_state = initial_state.clone(cell_state=encoder_state)\n",
    "        return initial_state\n",
    "\n",
    "    def call(self, inputs, training=False, **kwargs):\n",
    "        input_ids = inputs['input_ids']\n",
    "        input_emb = self.embedding(input_ids)\n",
    "        decoder_output, _, _ = self.decoder(input_emb,\n",
    "                                            initial_state=inputs['initial_state'],\n",
    "                                            sequence_length=self.batch_size * [self.max_sequence_length - 1])\n",
    "        return decoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-14 00:08:14.456810: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 6, 16) -- (2, 16) -- (2, 16)\n",
      "(2, 5, 16)\n"
     ]
    }
   ],
   "source": [
    "# Sample\n",
    "input_sample = [\n",
    "    \"hello there how is it going\",\n",
    "    \"this assignment is hellish\"\n",
    "]\n",
    "output_sample = [\n",
    "    \"<start> it is going well <end>\",\n",
    "    \"<start> I agree <end>\"\n",
    "]\n",
    "\n",
    "batch_size = len(input_sample)\n",
    "\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='', oov_token='<UNK>')\n",
    "tokenizer.fit_on_texts(input_sample + output_sample)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "encoded_input_sample = tokenizer.texts_to_sequences(input_sample)\n",
    "max_input_length = max([len(item) for item in encoded_input_sample])\n",
    "\n",
    "encoded_output_sample = tokenizer.texts_to_sequences(output_sample)\n",
    "max_output_length = max([len(item) for item in encoded_output_sample])\n",
    "\n",
    "max_sequence_length = max(max_input_length, max_output_length)\n",
    "\n",
    "encoded_input_sample = tf.keras.preprocessing.sequence.pad_sequences(encoded_input_sample,\n",
    "                                                                        padding='post',\n",
    "                                                                        maxlen=max_sequence_length)\n",
    "encoded_output_sample = tf.keras.preprocessing.sequence.pad_sequences(encoded_output_sample,\n",
    "                                                                        padding='post',\n",
    "                                                                        maxlen=max_sequence_length)\n",
    "\n",
    "# Test encoder\n",
    "encoder = Encoder(vocab_size=vocab_size,\n",
    "                    embedding_dim=50,\n",
    "                    encoder_units=16)\n",
    "\n",
    "sample_hidden = encoder.initialize(batch_size=batch_size)\n",
    "encoder_sample_batch = {\n",
    "    'input_ids': tf.convert_to_tensor(encoded_input_sample, dtype=tf.int32),\n",
    "    'hidden_state': sample_hidden\n",
    "}\n",
    "\n",
    "sample_output, sample_h, sample_c = encoder(inputs=encoder_sample_batch)\n",
    "print(f'{sample_output.shape} -- {sample_h.shape} -- {sample_c.shape}')\n",
    "\n",
    "# Test decoder\n",
    "decoder = Decoder(vocab_size=vocab_size,\n",
    "                    embedding_dim=50,\n",
    "                    decoder_units=16,\n",
    "                    batch_size=batch_size,\n",
    "                    max_sequence_length=max_sequence_length)\n",
    "decoder.attention.setup_memory(sample_output)\n",
    "initial_state = decoder.build_initial_state(batch_size, [sample_h, sample_c])\n",
    "\n",
    "decoder_sample_batch = {\n",
    "    'input_ids': tf.convert_to_tensor(encoded_output_sample, tf.int32),\n",
    "    'initial_state': initial_state\n",
    "}\n",
    "sample_decoder_outputs = decoder(decoder_sample_batch).rnn_output\n",
    "print(f'{sample_decoder_outputs.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "trainer = MyTrainer(encoder=encoder,\n",
    "                    decoder=decoder,\n",
    "                    max_length=max_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:05<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [24], line 9\u001b[0m\n\u001b[1;32m      3\u001b[0m encoder_hidden_state \u001b[39m=\u001b[39m encoder\u001b[39m.\u001b[39minitialize(batch_size\u001b[39m=\u001b[39mbatch_size)\n\u001b[1;32m      4\u001b[0m batch \u001b[39m=\u001b[39m {\n\u001b[1;32m      5\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mencoder_input_ids\u001b[39m\u001b[39m'\u001b[39m: encoded_input_sample,\n\u001b[1;32m      6\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mencoder_state\u001b[39m\u001b[39m'\u001b[39m: encoder_hidden_state,\n\u001b[1;32m      7\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mdecoder_target\u001b[39m\u001b[39m'\u001b[39m: encoded_output_sample\n\u001b[1;32m      8\u001b[0m }\n\u001b[0;32m----> 9\u001b[0m loss \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39;49mbatch_fit(batch)\n\u001b[1;32m     10\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mLoss - \u001b[39m\u001b[39m{\u001b[39;00mloss\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     12\u001b[0m generated \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39mgenerate(input_ids\u001b[39m=\u001b[39mencoded_input_sample)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:963\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    960\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    961\u001b[0m   \u001b[39m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[1;32m    962\u001b[0m   initializers \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 963\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_initialize(args, kwds, add_initializers_to\u001b[39m=\u001b[39;49minitializers)\n\u001b[1;32m    964\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    965\u001b[0m   \u001b[39m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[1;32m    966\u001b[0m   \u001b[39m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[1;32m    967\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:785\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    782\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lifted_initializer_graph \u001b[39m=\u001b[39m lifted_initializer_graph\n\u001b[1;32m    783\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_graph_deleter \u001b[39m=\u001b[39m FunctionDeleter(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lifted_initializer_graph)\n\u001b[1;32m    784\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_concrete_stateful_fn \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 785\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateful_fn\u001b[39m.\u001b[39;49m_get_concrete_function_internal_garbage_collected(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    786\u001b[0m         \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds))\n\u001b[1;32m    788\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minvalid_creator_scope\u001b[39m(\u001b[39m*\u001b[39munused_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39munused_kwds):\n\u001b[1;32m    789\u001b[0m   \u001b[39m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2523\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2521\u001b[0m   args, kwargs \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   2522\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m-> 2523\u001b[0m   graph_function, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_function(args, kwargs)\n\u001b[1;32m   2524\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2760\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2758\u001b[0m   \u001b[39m# Only get placeholders for arguments, not captures\u001b[39;00m\n\u001b[1;32m   2759\u001b[0m   args, kwargs \u001b[39m=\u001b[39m placeholder_dict[\u001b[39m\"\u001b[39m\u001b[39margs\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m-> 2760\u001b[0m graph_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_graph_function(args, kwargs)\n\u001b[1;32m   2762\u001b[0m graph_capture_container \u001b[39m=\u001b[39m graph_function\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39m_capture_func_lib  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   2763\u001b[0m \u001b[39m# Maintain the list of all captures\u001b[39;00m\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2670\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2665\u001b[0m missing_arg_names \u001b[39m=\u001b[39m [\n\u001b[1;32m   2666\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (arg, i) \u001b[39mfor\u001b[39;00m i, arg \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(missing_arg_names)\n\u001b[1;32m   2667\u001b[0m ]\n\u001b[1;32m   2668\u001b[0m arg_names \u001b[39m=\u001b[39m base_arg_names \u001b[39m+\u001b[39m missing_arg_names\n\u001b[1;32m   2669\u001b[0m graph_function \u001b[39m=\u001b[39m ConcreteFunction(\n\u001b[0;32m-> 2670\u001b[0m     func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[1;32m   2671\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name,\n\u001b[1;32m   2672\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_function,\n\u001b[1;32m   2673\u001b[0m         args,\n\u001b[1;32m   2674\u001b[0m         kwargs,\n\u001b[1;32m   2675\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_signature,\n\u001b[1;32m   2676\u001b[0m         autograph\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph,\n\u001b[1;32m   2677\u001b[0m         autograph_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph_options,\n\u001b[1;32m   2678\u001b[0m         arg_names\u001b[39m=\u001b[39;49marg_names,\n\u001b[1;32m   2679\u001b[0m         capture_by_value\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_capture_by_value),\n\u001b[1;32m   2680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_attributes,\n\u001b[1;32m   2681\u001b[0m     spec\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_spec,\n\u001b[1;32m   2682\u001b[0m     \u001b[39m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m   2683\u001b[0m     \u001b[39m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m   2684\u001b[0m     \u001b[39m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m   2685\u001b[0m     \u001b[39m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m   2686\u001b[0m     shared_func_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   2687\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:1247\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1244\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1245\u001b[0m   _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1247\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39;49mfunc_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfunc_kwargs)\n\u001b[1;32m   1249\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1250\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1251\u001b[0m func_outputs \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mmap_structure(\n\u001b[1;32m   1252\u001b[0m     convert, func_outputs, expand_composites\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:677\u001b[0m, in \u001b[0;36mFunction._defun_with_scope.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[39mwith\u001b[39;00m default_graph\u001b[39m.\u001b[39m_variable_creator_scope(scope, priority\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m):  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    674\u001b[0m   \u001b[39m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[1;32m    675\u001b[0m   \u001b[39m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[1;32m    676\u001b[0m   \u001b[39mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[0;32m--> 677\u001b[0m     out \u001b[39m=\u001b[39m weak_wrapped_fn()\u001b[39m.\u001b[39;49m__wrapped__(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    678\u001b[0m   \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3317\u001b[0m, in \u001b[0;36mclass_method_to_instance_method.<locals>.bound_method_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   3312\u001b[0m   \u001b[39mreturn\u001b[39;00m wrapped_fn(weak_instance(), \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   3314\u001b[0m \u001b[39m# If __wrapped__ was replaced, then it is always an unbound function.\u001b[39;00m\n\u001b[1;32m   3315\u001b[0m \u001b[39m# However, the replacer is still responsible for attaching self properly.\u001b[39;00m\n\u001b[1;32m   3316\u001b[0m \u001b[39m# TODO(mdan): Is it possible to do it here instead?\u001b[39;00m\n\u001b[0;32m-> 3317\u001b[0m \u001b[39mreturn\u001b[39;00m wrapped_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:1222\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1220\u001b[0m \u001b[39m# TODO(mdan): Push this block higher in tf.function's call stack.\u001b[39;00m\n\u001b[1;32m   1221\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1222\u001b[0m   \u001b[39mreturn\u001b[39;00m autograph\u001b[39m.\u001b[39;49mconverted_call(\n\u001b[1;32m   1223\u001b[0m       original_func,\n\u001b[1;32m   1224\u001b[0m       args,\n\u001b[1;32m   1225\u001b[0m       kwargs,\n\u001b[1;32m   1226\u001b[0m       options\u001b[39m=\u001b[39;49mautograph\u001b[39m.\u001b[39;49mConversionOptions(\n\u001b[1;32m   1227\u001b[0m           recursive\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1228\u001b[0m           optional_features\u001b[39m=\u001b[39;49mautograph_options,\n\u001b[1;32m   1229\u001b[0m           user_requested\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1230\u001b[0m       ))\n\u001b[1;32m   1231\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m   1232\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39;49meffective_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filel6dm7ocs.py:10\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__batch_fit\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m      8\u001b[0m do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m      9\u001b[0m retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mUndefinedReturnValue()\n\u001b[0;32m---> 10\u001b[0m (loss, grads) \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mtrain_op, (), \u001b[39mdict\u001b[39;49m(inputs\u001b[39m=\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(inputs)), fscope)\n\u001b[1;32m     11\u001b[0m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mapply_gradients, (ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mzip\u001b[39m), (ag__\u001b[39m.\u001b[39mld(grads), ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mencoder\u001b[39m.\u001b[39mtrainable_variables \u001b[39m+\u001b[39m ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mdecoder\u001b[39m.\u001b[39mtrainable_variables), \u001b[39mNone\u001b[39;00m, fscope),), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     12\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    374\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    376\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39muser_requested \u001b[39mand\u001b[39;00m conversion\u001b[39m.\u001b[39mis_allowlisted(f):\n\u001b[0;32m--> 377\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    379\u001b[0m \u001b[39m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[39m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[39m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[39m# things like builtins.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:458\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    455\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    457\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 458\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    459\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:963\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    960\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    961\u001b[0m   \u001b[39m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[1;32m    962\u001b[0m   initializers \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 963\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_initialize(args, kwds, add_initializers_to\u001b[39m=\u001b[39;49minitializers)\n\u001b[1;32m    964\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    965\u001b[0m   \u001b[39m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[1;32m    966\u001b[0m   \u001b[39m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[1;32m    967\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:785\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    782\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lifted_initializer_graph \u001b[39m=\u001b[39m lifted_initializer_graph\n\u001b[1;32m    783\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_graph_deleter \u001b[39m=\u001b[39m FunctionDeleter(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lifted_initializer_graph)\n\u001b[1;32m    784\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_concrete_stateful_fn \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 785\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateful_fn\u001b[39m.\u001b[39;49m_get_concrete_function_internal_garbage_collected(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    786\u001b[0m         \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds))\n\u001b[1;32m    788\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minvalid_creator_scope\u001b[39m(\u001b[39m*\u001b[39munused_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39munused_kwds):\n\u001b[1;32m    789\u001b[0m   \u001b[39m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2523\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2521\u001b[0m   args, kwargs \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   2522\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m-> 2523\u001b[0m   graph_function, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_function(args, kwargs)\n\u001b[1;32m   2524\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2760\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2758\u001b[0m   \u001b[39m# Only get placeholders for arguments, not captures\u001b[39;00m\n\u001b[1;32m   2759\u001b[0m   args, kwargs \u001b[39m=\u001b[39m placeholder_dict[\u001b[39m\"\u001b[39m\u001b[39margs\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m-> 2760\u001b[0m graph_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_graph_function(args, kwargs)\n\u001b[1;32m   2762\u001b[0m graph_capture_container \u001b[39m=\u001b[39m graph_function\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39m_capture_func_lib  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   2763\u001b[0m \u001b[39m# Maintain the list of all captures\u001b[39;00m\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2670\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2665\u001b[0m missing_arg_names \u001b[39m=\u001b[39m [\n\u001b[1;32m   2666\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (arg, i) \u001b[39mfor\u001b[39;00m i, arg \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(missing_arg_names)\n\u001b[1;32m   2667\u001b[0m ]\n\u001b[1;32m   2668\u001b[0m arg_names \u001b[39m=\u001b[39m base_arg_names \u001b[39m+\u001b[39m missing_arg_names\n\u001b[1;32m   2669\u001b[0m graph_function \u001b[39m=\u001b[39m ConcreteFunction(\n\u001b[0;32m-> 2670\u001b[0m     func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[1;32m   2671\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name,\n\u001b[1;32m   2672\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_function,\n\u001b[1;32m   2673\u001b[0m         args,\n\u001b[1;32m   2674\u001b[0m         kwargs,\n\u001b[1;32m   2675\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_signature,\n\u001b[1;32m   2676\u001b[0m         autograph\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph,\n\u001b[1;32m   2677\u001b[0m         autograph_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph_options,\n\u001b[1;32m   2678\u001b[0m         arg_names\u001b[39m=\u001b[39;49marg_names,\n\u001b[1;32m   2679\u001b[0m         capture_by_value\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_capture_by_value),\n\u001b[1;32m   2680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_attributes,\n\u001b[1;32m   2681\u001b[0m     spec\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_spec,\n\u001b[1;32m   2682\u001b[0m     \u001b[39m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m   2683\u001b[0m     \u001b[39m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m   2684\u001b[0m     \u001b[39m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m   2685\u001b[0m     \u001b[39m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m   2686\u001b[0m     shared_func_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   2687\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:1247\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1244\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1245\u001b[0m   _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1247\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39;49mfunc_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfunc_kwargs)\n\u001b[1;32m   1249\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1250\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1251\u001b[0m func_outputs \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mmap_structure(\n\u001b[1;32m   1252\u001b[0m     convert, func_outputs, expand_composites\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:677\u001b[0m, in \u001b[0;36mFunction._defun_with_scope.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[39mwith\u001b[39;00m default_graph\u001b[39m.\u001b[39m_variable_creator_scope(scope, priority\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m):  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    674\u001b[0m   \u001b[39m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[1;32m    675\u001b[0m   \u001b[39m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[1;32m    676\u001b[0m   \u001b[39mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[0;32m--> 677\u001b[0m     out \u001b[39m=\u001b[39m weak_wrapped_fn()\u001b[39m.\u001b[39;49m__wrapped__(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    678\u001b[0m   \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3317\u001b[0m, in \u001b[0;36mclass_method_to_instance_method.<locals>.bound_method_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   3312\u001b[0m   \u001b[39mreturn\u001b[39;00m wrapped_fn(weak_instance(), \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   3314\u001b[0m \u001b[39m# If __wrapped__ was replaced, then it is always an unbound function.\u001b[39;00m\n\u001b[1;32m   3315\u001b[0m \u001b[39m# However, the replacer is still responsible for attaching self properly.\u001b[39;00m\n\u001b[1;32m   3316\u001b[0m \u001b[39m# TODO(mdan): Is it possible to do it here instead?\u001b[39;00m\n\u001b[0;32m-> 3317\u001b[0m \u001b[39mreturn\u001b[39;00m wrapped_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:1222\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1220\u001b[0m \u001b[39m# TODO(mdan): Push this block higher in tf.function's call stack.\u001b[39;00m\n\u001b[1;32m   1221\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1222\u001b[0m   \u001b[39mreturn\u001b[39;00m autograph\u001b[39m.\u001b[39;49mconverted_call(\n\u001b[1;32m   1223\u001b[0m       original_func,\n\u001b[1;32m   1224\u001b[0m       args,\n\u001b[1;32m   1225\u001b[0m       kwargs,\n\u001b[1;32m   1226\u001b[0m       options\u001b[39m=\u001b[39;49mautograph\u001b[39m.\u001b[39;49mConversionOptions(\n\u001b[1;32m   1227\u001b[0m           recursive\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1228\u001b[0m           optional_features\u001b[39m=\u001b[39;49mautograph_options,\n\u001b[1;32m   1229\u001b[0m           user_requested\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1230\u001b[0m       ))\n\u001b[1;32m   1231\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m   1232\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39;49meffective_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filekh3lyw76.py:16\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_op\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     14\u001b[0m     ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(decoder)\u001b[39m.\u001b[39mattention\u001b[39m.\u001b[39msetup_memory, (ag__\u001b[39m.\u001b[39mld(encoder_output),), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     15\u001b[0m     decoder_initial_state \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mdecoder\u001b[39m.\u001b[39mbuild_initial_state, (ag__\u001b[39m.\u001b[39mld(decoder)\u001b[39m.\u001b[39mbatch_size, [ag__\u001b[39m.\u001b[39mld(encoder_h), ag__\u001b[39m.\u001b[39mld(encoder_s)]), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m---> 16\u001b[0m     predicted \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mdecoder, ({\u001b[39m'\u001b[39;49m\u001b[39minput_ids\u001b[39;49m\u001b[39m'\u001b[39;49m: ag__\u001b[39m.\u001b[39;49mld(decoder_input), \u001b[39m'\u001b[39;49m\u001b[39minitial_state\u001b[39;49m\u001b[39m'\u001b[39;49m: ag__\u001b[39m.\u001b[39;49mld(decoder_initial_state)},), \u001b[39mNone\u001b[39;49;00m, fscope)\u001b[39m.\u001b[39mrnn_output\n\u001b[1;32m     17\u001b[0m     loss \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mcompute_loss, (), \u001b[39mdict\u001b[39m(logits\u001b[39m=\u001b[39mag__\u001b[39m.\u001b[39mld(predicted), target\u001b[39m=\u001b[39mag__\u001b[39m.\u001b[39mld(real_target)), fscope)\n\u001b[1;32m     18\u001b[0m grads \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tape)\u001b[39m.\u001b[39mgradient, (ag__\u001b[39m.\u001b[39mld(loss), ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mencoder\u001b[39m.\u001b[39mtrainable_variables \u001b[39m+\u001b[39m ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mdecoder\u001b[39m.\u001b[39mtrainable_variables), \u001b[39mNone\u001b[39;00m, fscope)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    374\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    376\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39muser_requested \u001b[39mand\u001b[39;00m conversion\u001b[39m.\u001b[39mis_allowlisted(f):\n\u001b[0;32m--> 377\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    379\u001b[0m \u001b[39m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[39m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[39m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[39m# things like builtins.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    458\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py:557\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(inputs, \u001b[39m*\u001b[39mcopied_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcopied_kwargs)\n\u001b[1;32m    555\u001b[0m     layout_map_lib\u001b[39m.\u001b[39m_map_subclass_model_variable(\u001b[39mself\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_layout_map)\n\u001b[0;32m--> 557\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/base_layer.py:1097\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1092\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[1;32m   1094\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object\n\u001b[1;32m   1096\u001b[0m ):\n\u001b[0;32m-> 1097\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1099\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[1;32m   1100\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    688\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 689\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[1;32m    690\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    691\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39;49meffective_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_fileazakgrur.py:12\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[0;34m(self, inputs, training, **kwargs)\u001b[0m\n\u001b[1;32m     10\u001b[0m input_ids \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mld(inputs)[\u001b[39m'\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     11\u001b[0m input_emb \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39membedding, (ag__\u001b[39m.\u001b[39mld(input_ids),), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m---> 12\u001b[0m (decoder_output, _, _) \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mdecoder, (ag__\u001b[39m.\u001b[39;49mld(input_emb),), \u001b[39mdict\u001b[39;49m(initial_state\u001b[39m=\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(inputs)[\u001b[39m'\u001b[39;49m\u001b[39minitial_state\u001b[39;49m\u001b[39m'\u001b[39;49m], sequence_length\u001b[39m=\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mbatch_size \u001b[39m*\u001b[39;49m [ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mmax_sequence_length \u001b[39m-\u001b[39;49m \u001b[39m1\u001b[39;49m]), fscope)\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    374\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    376\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39muser_requested \u001b[39mand\u001b[39;00m conversion\u001b[39m.\u001b[39mis_allowlisted(f):\n\u001b[0;32m--> 377\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    379\u001b[0m \u001b[39m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[39m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[39m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[39m# things like builtins.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:458\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    455\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    457\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 458\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    459\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/base_layer.py:1097\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1092\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[1;32m   1094\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object\n\u001b[1;32m   1096\u001b[0m ):\n\u001b[0;32m-> 1097\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1099\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[1;32m   1100\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    688\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 689\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[1;32m    690\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    691\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39;49meffective_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filemsorkd_q.py:14\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[0;34m(self, inputs, initial_state, training, **kwargs)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     13\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(dynamic_decode), (ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m),), \u001b[39mdict\u001b[39;49m(output_time_major\u001b[39m=\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49moutput_time_major, impute_finished\u001b[39m=\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mimpute_finished, maximum_iterations\u001b[39m=\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mmaximum_iterations, parallel_iterations\u001b[39m=\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mparallel_iterations, swap_memory\u001b[39m=\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mswap_memory, training\u001b[39m=\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(training), decoder_init_input\u001b[39m=\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(inputs), decoder_init_kwargs\u001b[39m=\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(init_kwargs)), fscope)\n\u001b[1;32m     15\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     16\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39;49meffective_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filegr21x5o1.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m memo \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(_CallMemo), (ag__\u001b[39m.\u001b[39mld(python_func), ag__\u001b[39m.\u001b[39mld(_localns)), \u001b[39mdict\u001b[39m(args\u001b[39m=\u001b[39mag__\u001b[39m.\u001b[39mld(args), kwargs\u001b[39m=\u001b[39mag__\u001b[39m.\u001b[39mld(kwargs)), fscope)\n\u001b[1;32m     14\u001b[0m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(check_argument_types), (ag__\u001b[39m.\u001b[39mld(memo),), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m---> 15\u001b[0m retval \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(func), \u001b[39mtuple\u001b[39;49m(ag__\u001b[39m.\u001b[39;49mld(args)), \u001b[39mdict\u001b[39;49m(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(kwargs)), fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(check_return_type), (ag__\u001b[39m.\u001b[39mld(retval), ag__\u001b[39m.\u001b[39mld(memo)), \u001b[39mNone\u001b[39;00m, fscope)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39;49meffective_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file9kvgam8p.py:473\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__dynamic_decode\u001b[0;34m(decoder, output_time_major, impute_finished, maximum_iterations, parallel_iterations, swap_memory, training, scope, enable_tflite_convertible, **kwargs)\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[39mraise\u001b[39;00m\n\u001b[1;32m    472\u001b[0m         \u001b[39mreturn\u001b[39;00m fscope_4\u001b[39m.\u001b[39mret(retval__4, do_return_4)\n\u001b[0;32m--> 473\u001b[0m res \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(tf)\u001b[39m.\u001b[39;49mwhile_loop, (ag__\u001b[39m.\u001b[39;49mld(condition), ag__\u001b[39m.\u001b[39;49mld(body)), \u001b[39mdict\u001b[39;49m(loop_vars\u001b[39m=\u001b[39;49m(ag__\u001b[39m.\u001b[39;49mld(initial_time), ag__\u001b[39m.\u001b[39;49mld(initial_outputs_ta), ag__\u001b[39m.\u001b[39;49mld(initial_state), ag__\u001b[39m.\u001b[39;49mld(initial_inputs), ag__\u001b[39m.\u001b[39;49mld(initial_finished), ag__\u001b[39m.\u001b[39;49mld(initial_sequence_lengths)), parallel_iterations\u001b[39m=\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(parallel_iterations), maximum_iterations\u001b[39m=\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(maximum_iterations), swap_memory\u001b[39m=\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(swap_memory)), fscope)\n\u001b[1;32m    474\u001b[0m final_outputs_ta \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mld(res)[\u001b[39m1\u001b[39m]\n\u001b[1;32m    475\u001b[0m final_state \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mld(res)[\u001b[39m2\u001b[39m]\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    374\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    376\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39muser_requested \u001b[39mand\u001b[39;00m conversion\u001b[39m.\u001b[39mis_allowlisted(f):\n\u001b[0;32m--> 377\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    379\u001b[0m \u001b[39m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[39m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[39m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[39m# things like builtins.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:458\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    455\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    457\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 458\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    459\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/util/deprecation.py:629\u001b[0m, in \u001b[0;36mdeprecated_arg_values.<locals>.deprecated_wrapper.<locals>.new_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    622\u001b[0m           _PRINTED_WARNING[(func, arg_name)] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    623\u001b[0m         logging\u001b[39m.\u001b[39mwarning(\n\u001b[1;32m    624\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mFrom \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: calling \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m (from \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m) with \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m=\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is deprecated and \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    625\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mwill be removed \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mInstructions for updating:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m,\n\u001b[1;32m    626\u001b[0m             _call_location(), decorator_utils\u001b[39m.\u001b[39mget_qualified_name(func),\n\u001b[1;32m    627\u001b[0m             func\u001b[39m.\u001b[39m\u001b[39m__module__\u001b[39m, arg_name, arg_value, \u001b[39m'\u001b[39m\u001b[39min a future version\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    628\u001b[0m             \u001b[39mif\u001b[39;00m date \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mafter \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m date), instructions)\n\u001b[0;32m--> 629\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/ops/control_flow_ops.py:2513\u001b[0m, in \u001b[0;36mwhile_loop_v2\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, maximum_iterations, name)\u001b[0m\n\u001b[1;32m   2337\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mwhile_loop\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[])\n\u001b[1;32m   2338\u001b[0m \u001b[39m@deprecation\u001b[39m\u001b[39m.\u001b[39mdeprecated_arg_values(\n\u001b[1;32m   2339\u001b[0m     \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2354\u001b[0m                   maximum_iterations\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   2355\u001b[0m                   name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   2356\u001b[0m   \u001b[39m\"\"\"Repeat `body` while the condition `cond` is true.\u001b[39;00m\n\u001b[1;32m   2357\u001b[0m \n\u001b[1;32m   2358\u001b[0m \u001b[39m  `cond` is a callable returning a boolean scalar tensor. `body` is a callable\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2511\u001b[0m \n\u001b[1;32m   2512\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2513\u001b[0m   \u001b[39mreturn\u001b[39;00m while_loop(\n\u001b[1;32m   2514\u001b[0m       cond\u001b[39m=\u001b[39;49mcond,\n\u001b[1;32m   2515\u001b[0m       body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m   2516\u001b[0m       loop_vars\u001b[39m=\u001b[39;49mloop_vars,\n\u001b[1;32m   2517\u001b[0m       shape_invariants\u001b[39m=\u001b[39;49mshape_invariants,\n\u001b[1;32m   2518\u001b[0m       parallel_iterations\u001b[39m=\u001b[39;49mparallel_iterations,\n\u001b[1;32m   2519\u001b[0m       back_prop\u001b[39m=\u001b[39;49mback_prop,\n\u001b[1;32m   2520\u001b[0m       swap_memory\u001b[39m=\u001b[39;49mswap_memory,\n\u001b[1;32m   2521\u001b[0m       name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m   2522\u001b[0m       maximum_iterations\u001b[39m=\u001b[39;49mmaximum_iterations,\n\u001b[1;32m   2523\u001b[0m       return_same_structure\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/ops/control_flow_ops.py:2713\u001b[0m, in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   2710\u001b[0m executing_eagerly \u001b[39m=\u001b[39m context\u001b[39m.\u001b[39mexecuting_eagerly()\n\u001b[1;32m   2711\u001b[0m \u001b[39mif\u001b[39;00m (util\u001b[39m.\u001b[39mEnableControlFlowV2(ops\u001b[39m.\u001b[39mget_default_graph()) \u001b[39mand\u001b[39;00m\n\u001b[1;32m   2712\u001b[0m     \u001b[39mnot\u001b[39;00m executing_eagerly):\n\u001b[0;32m-> 2713\u001b[0m   \u001b[39mreturn\u001b[39;00m while_v2\u001b[39m.\u001b[39;49mwhile_loop(\n\u001b[1;32m   2714\u001b[0m       cond,\n\u001b[1;32m   2715\u001b[0m       body,\n\u001b[1;32m   2716\u001b[0m       loop_vars,\n\u001b[1;32m   2717\u001b[0m       shape_invariants\u001b[39m=\u001b[39;49mshape_invariants,\n\u001b[1;32m   2718\u001b[0m       parallel_iterations\u001b[39m=\u001b[39;49mparallel_iterations,\n\u001b[1;32m   2719\u001b[0m       maximum_iterations\u001b[39m=\u001b[39;49mmaximum_iterations,\n\u001b[1;32m   2720\u001b[0m       name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m   2721\u001b[0m       return_same_structure\u001b[39m=\u001b[39;49mreturn_same_structure,\n\u001b[1;32m   2722\u001b[0m       back_prop\u001b[39m=\u001b[39;49mback_prop)\n\u001b[1;32m   2724\u001b[0m \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mname_scope(name, \u001b[39m\"\u001b[39m\u001b[39mwhile\u001b[39m\u001b[39m\"\u001b[39m, loop_vars):\n\u001b[1;32m   2725\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m loop_vars:\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/ops/while_v2.py:222\u001b[0m, in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, maximum_iterations, name, return_same_structure, back_prop)\u001b[0m\n\u001b[1;32m    218\u001b[0m   \u001b[39m# TODO(srbs): Update lowering code to create _Enter nodes with\u001b[39;00m\n\u001b[1;32m    219\u001b[0m   \u001b[39m# is_constant=True for inputs that are directly passed to outputs.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m   \u001b[39mreturn\u001b[39;00m [loop_counter \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, maximum_iterations_arg] \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(outputs)\n\u001b[0;32m--> 222\u001b[0m body_graph \u001b[39m=\u001b[39m func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[1;32m    223\u001b[0m     body_name,\n\u001b[1;32m    224\u001b[0m     wrapped_body,\n\u001b[1;32m    225\u001b[0m     [],  \u001b[39m# We provide signature instead of args.\u001b[39;49;00m\n\u001b[1;32m    226\u001b[0m     {},\n\u001b[1;32m    227\u001b[0m     signature\u001b[39m=\u001b[39;49mfunc_graph_signature,\n\u001b[1;32m    228\u001b[0m     func_graph\u001b[39m=\u001b[39;49mutil\u001b[39m.\u001b[39;49mWhileBodyFuncGraph(\n\u001b[1;32m    229\u001b[0m         body_name, collections\u001b[39m=\u001b[39;49mops\u001b[39m.\u001b[39;49mget_default_graph()\u001b[39m.\u001b[39;49m_collections),  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    230\u001b[0m     add_control_dependencies\u001b[39m=\u001b[39;49madd_control_dependencies,\n\u001b[1;32m    231\u001b[0m     acd_record_initial_resource_uses\u001b[39m=\u001b[39;49mstateful_parallelism)\n\u001b[1;32m    232\u001b[0m \u001b[39m# Add external captures of body to the list of loop vars.\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[39m# Note that external tensors will be treated as loop invariants, i.e.,\u001b[39;00m\n\u001b[1;32m    234\u001b[0m \u001b[39m# the value of that tensor in each iteration is the same as it was at the\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[39m# beginning of the loop execution.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m deferred_external_captures \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mflatten(\n\u001b[1;32m    237\u001b[0m     [c() \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m body_graph\u001b[39m.\u001b[39mdeferred_external_captures],\n\u001b[1;32m    238\u001b[0m     expand_composites\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:1247\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1244\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1245\u001b[0m   _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1247\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39;49mfunc_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfunc_kwargs)\n\u001b[1;32m   1249\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1250\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1251\u001b[0m func_outputs \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mmap_structure(\n\u001b[1;32m   1252\u001b[0m     convert, func_outputs, expand_composites\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/ops/while_v2.py:200\u001b[0m, in \u001b[0;36mwhile_loop.<locals>.wrapped_body\u001b[0;34m(loop_counter, maximum_iterations_arg, *args)\u001b[0m\n\u001b[1;32m    193\u001b[0m   ops\u001b[39m.\u001b[39mget_default_graph()\u001b[39m.\u001b[39mcapture(t)\n\u001b[1;32m    195\u001b[0m \u001b[39m# Convert the flow variables in `args` to TensorArrays. `args` should\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[39m# already have the same structure as `orig_loop_vars` but currently there\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[39m# is no nest.zip so we call `_pack_sequence_as` which flattens `args`,\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# converts flows in `args` to TensorArrays and packs it into the\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# structure of `loop_vars_signature`.\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m outputs \u001b[39m=\u001b[39m body(\n\u001b[1;32m    201\u001b[0m     \u001b[39m*\u001b[39;49m_pack_sequence_as(loop_vars_signature, flat_orig_loop_vars, args))\n\u001b[1;32m    202\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m nest\u001b[39m.\u001b[39mis_nested(outputs):\n\u001b[1;32m    203\u001b[0m   outputs \u001b[39m=\u001b[39m [outputs]\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file9kvgam8p.py:268\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__dynamic_decode.<locals>.body\u001b[0;34m(time, outputs_ta, state, inputs, finished, sequence_lengths)\u001b[0m\n\u001b[1;32m    266\u001b[0m do_return_4 \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    267\u001b[0m retval__4 \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mUndefinedReturnValue()\n\u001b[0;32m--> 268\u001b[0m (next_outputs, decoder_state, next_inputs, decoder_finished) \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(decoder)\u001b[39m.\u001b[39;49mstep, (ag__\u001b[39m.\u001b[39;49mld(time), ag__\u001b[39m.\u001b[39;49mld(inputs), ag__\u001b[39m.\u001b[39;49mld(state), ag__\u001b[39m.\u001b[39;49mld(training)), \u001b[39mNone\u001b[39;49;00m, fscope_4)\n\u001b[1;32m    269\u001b[0m decoder_state_sequence_lengths \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_state_10\u001b[39m():\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:441\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39;49meffective_args)\n\u001b[1;32m    442\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    443\u001b[0m   _attach_error_metadata(e, converted_f)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filev4zv8ykv.py:21\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__step\u001b[0;34m(self, time, inputs, state, training)\u001b[0m\n\u001b[1;32m     19\u001b[0m do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     20\u001b[0m retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mUndefinedReturnValue()\n\u001b[0;32m---> 21\u001b[0m (cell_outputs, cell_state) \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mcell, (ag__\u001b[39m.\u001b[39;49mld(inputs), ag__\u001b[39m.\u001b[39;49mld(state)), \u001b[39mdict\u001b[39;49m(training\u001b[39m=\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(training)), fscope)\n\u001b[1;32m     22\u001b[0m cell_state \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mpack_sequence_as, (ag__\u001b[39m.\u001b[39mld(state), ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten, (ag__\u001b[39m.\u001b[39mld(cell_state),), \u001b[39mNone\u001b[39;00m, fscope)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     24\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_state\u001b[39m():\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    374\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    376\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39muser_requested \u001b[39mand\u001b[39;00m conversion\u001b[39m.\u001b[39mis_allowlisted(f):\n\u001b[0;32m--> 377\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    379\u001b[0m \u001b[39m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[39m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[39m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[39m# things like builtins.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:458\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    455\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    457\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 458\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    459\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/base_layer.py:1097\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1092\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[1;32m   1094\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object\n\u001b[1;32m   1096\u001b[0m ):\n\u001b[0;32m-> 1097\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1099\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[1;32m   1100\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    688\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 689\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[1;32m    690\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    691\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:427\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    426\u001b[0m   program_ctx \u001b[39m=\u001b[39m converter\u001b[39m.\u001b[39mProgramContext(options\u001b[39m=\u001b[39moptions)\n\u001b[0;32m--> 427\u001b[0m   converted_f \u001b[39m=\u001b[39m _convert_actual(target_entity, program_ctx)\n\u001b[1;32m    428\u001b[0m   \u001b[39mif\u001b[39;00m logging\u001b[39m.\u001b[39mhas_verbosity(\u001b[39m2\u001b[39m):\n\u001b[1;32m    429\u001b[0m     _log_callargs(converted_f, effective_args, kwargs)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:269\u001b[0m, in \u001b[0;36m_convert_actual\u001b[0;34m(entity, program_ctx)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(entity, \u001b[39m'\u001b[39m\u001b[39m__code__\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    265\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mCannot apply autograph to a function that doesn\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39mt \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    266\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39mexpose a __code__ object. If this is a @tf.function,\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    267\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39m try passing f.python_function instead.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 269\u001b[0m transformed, module, source_map \u001b[39m=\u001b[39m _TRANSPILER\u001b[39m.\u001b[39;49mtransform(entity, program_ctx)\n\u001b[1;32m    271\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(transformed, \u001b[39m'\u001b[39m\u001b[39mag_module\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    272\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(transformed, \u001b[39m'\u001b[39m\u001b[39mag_source_map\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/transpiler.py:282\u001b[0m, in \u001b[0;36mGenericTranspiler.transform\u001b[0;34m(self, obj, user_context)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[39m\"\"\"Transforms a Python object.\u001b[39;00m\n\u001b[1;32m    268\u001b[0m \n\u001b[1;32m    269\u001b[0m \u001b[39mUsers typically call this method.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[39m  NotImplementedError: if the type of obj is not handled.\u001b[39;00m\n\u001b[1;32m    280\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    281\u001b[0m \u001b[39mif\u001b[39;00m inspect\u001b[39m.\u001b[39misfunction(obj) \u001b[39mor\u001b[39;00m inspect\u001b[39m.\u001b[39mismethod(obj):\n\u001b[0;32m--> 282\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform_function(obj, user_context)\n\u001b[1;32m    284\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mNon-function: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mtype\u001b[39m(obj)))\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/transpiler.py:466\u001b[0m, in \u001b[0;36mPyToPy.transform_function\u001b[0;34m(self, fn, user_context)\u001b[0m\n\u001b[1;32m    464\u001b[0m logging\u001b[39m.\u001b[39mlog(\u001b[39m1\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is not cached for subkey \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m, fn, cache_subkey)\n\u001b[1;32m    465\u001b[0m \u001b[39m# TODO(mdan): Confusing overloading pattern. Fix.\u001b[39;00m\n\u001b[0;32m--> 466\u001b[0m nodes, ctx \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m(PyToPy, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mtransform_function(fn, user_context)\n\u001b[1;32m    468\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(nodes, gast\u001b[39m.\u001b[39mLambda):\n\u001b[1;32m    469\u001b[0m   nodes \u001b[39m=\u001b[39m gast\u001b[39m.\u001b[39mAssign(\n\u001b[1;32m    470\u001b[0m       targets\u001b[39m=\u001b[39m[\n\u001b[1;32m    471\u001b[0m           gast\u001b[39m.\u001b[39mName(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    476\u001b[0m       ],\n\u001b[1;32m    477\u001b[0m       value\u001b[39m=\u001b[39mnodes)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/transpiler.py:359\u001b[0m, in \u001b[0;36mGenericTranspiler.transform_function\u001b[0;34m(self, fn, user_context)\u001b[0m\n\u001b[1;32m    356\u001b[0m context \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mContext(entity_info, namer, user_context)\n\u001b[1;32m    358\u001b[0m node \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_erase_arg_defaults(node)\n\u001b[0;32m--> 359\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform_ast(node, context)\n\u001b[1;32m    361\u001b[0m \u001b[39mreturn\u001b[39;00m result, context\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:252\u001b[0m, in \u001b[0;36mPyToTF.transform_ast\u001b[0;34m(self, node, ctx)\u001b[0m\n\u001b[1;32m    250\u001b[0m   node \u001b[39m=\u001b[39m lists\u001b[39m.\u001b[39mtransform(node, ctx)\n\u001b[1;32m    251\u001b[0m   node \u001b[39m=\u001b[39m slices\u001b[39m.\u001b[39mtransform(node, ctx)\n\u001b[0;32m--> 252\u001b[0m node \u001b[39m=\u001b[39m call_trees\u001b[39m.\u001b[39;49mtransform(node, ctx)\n\u001b[1;32m    253\u001b[0m node \u001b[39m=\u001b[39m control_flow\u001b[39m.\u001b[39mtransform(node, ctx)\n\u001b[1;32m    254\u001b[0m node \u001b[39m=\u001b[39m conditional_expressions\u001b[39m.\u001b[39mtransform(node, ctx)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/converters/call_trees.py:220\u001b[0m, in \u001b[0;36mtransform\u001b[0;34m(node, ctx)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[39m\"\"\"Transform function call to the compiled counterparts.\u001b[39;00m\n\u001b[1;32m    209\u001b[0m \n\u001b[1;32m    210\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[39m      new_names: set(string), containing any newly-generated names\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    218\u001b[0m node \u001b[39m=\u001b[39m qual_names\u001b[39m.\u001b[39mresolve(node)\n\u001b[0;32m--> 220\u001b[0m node \u001b[39m=\u001b[39m CallTreeTransformer(ctx)\u001b[39m.\u001b[39;49mvisit(node)\n\u001b[1;32m    221\u001b[0m \u001b[39mreturn\u001b[39;00m node\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/core/converter.py:314\u001b[0m, in \u001b[0;36mBase.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ast_depth \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    313\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 314\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(Base, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mvisit(node)\n\u001b[1;32m    315\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    316\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ast_depth \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/transformer.py:441\u001b[0m, in \u001b[0;36mBase.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[39mif\u001b[39;00m processing_expr_node:\n\u001b[1;32m    439\u001b[0m   entry_expr_value \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39mvalue\n\u001b[0;32m--> 441\u001b[0m result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m(Base, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mvisit(node)\n\u001b[1;32m    443\u001b[0m \u001b[39m# Adjust for consistency: replacing the value of an Expr with\u001b[39;00m\n\u001b[1;32m    444\u001b[0m \u001b[39m# an Assign node removes the need for the Expr node.\u001b[39;00m\n\u001b[1;32m    445\u001b[0m \u001b[39mif\u001b[39;00m (processing_expr_node \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(result, gast\u001b[39m.\u001b[39mExpr) \u001b[39mand\u001b[39;00m\n\u001b[1;32m    446\u001b[0m     (result\u001b[39m.\u001b[39mvalue \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m entry_expr_value)):\n\u001b[1;32m    447\u001b[0m   \u001b[39m# When the replacement is a list, it is assumed that the list came\u001b[39;00m\n\u001b[1;32m    448\u001b[0m   \u001b[39m# from a template that contained a number of statements, which\u001b[39;00m\n\u001b[1;32m    449\u001b[0m   \u001b[39m# themselves are standalone and don't require an enclosing Expr.\u001b[39;00m\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/ast.py:407\u001b[0m, in \u001b[0;36mNodeVisitor.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    405\u001b[0m method \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mvisit_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m node\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[1;32m    406\u001b[0m visitor \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, method, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgeneric_visit)\n\u001b[0;32m--> 407\u001b[0m \u001b[39mreturn\u001b[39;00m visitor(node)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/converters/call_trees.py:117\u001b[0m, in \u001b[0;36mCallTreeTransformer.visit_FunctionDef\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[39massert\u001b[39;00m anno\u001b[39m.\u001b[39mhasanno(node, \u001b[39m'\u001b[39m\u001b[39mfunction_context_name\u001b[39m\u001b[39m'\u001b[39m), (\n\u001b[1;32m    115\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mThe function_scopes converter always creates a scope for functions.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    116\u001b[0m fn_scope\u001b[39m.\u001b[39mcontext_name \u001b[39m=\u001b[39m anno\u001b[39m.\u001b[39mgetanno(node, \u001b[39m'\u001b[39m\u001b[39mfunction_context_name\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 117\u001b[0m node\u001b[39m.\u001b[39mbody \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit_block(node\u001b[39m.\u001b[39;49mbody)\n\u001b[1;32m    118\u001b[0m \u001b[39mif\u001b[39;00m node\u001b[39m.\u001b[39mreturns:\n\u001b[1;32m    119\u001b[0m   node\u001b[39m.\u001b[39mreturns \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvisit(node\u001b[39m.\u001b[39mreturns)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/transformer.py:336\u001b[0m, in \u001b[0;36mNodeStateTracker.visit_block\u001b[0;34m(self, nodes, before_visit, after_visit)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[39mif\u001b[39;00m before_visit:\n\u001b[1;32m    333\u001b[0m   \u001b[39m# TODO(mdan): We can modify node here too, if ever needed.\u001b[39;00m\n\u001b[1;32m    334\u001b[0m   before_visit()\n\u001b[0;32m--> 336\u001b[0m replacement \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit(node)\n\u001b[1;32m    338\u001b[0m \u001b[39mif\u001b[39;00m after_visit \u001b[39mand\u001b[39;00m replacement:\n\u001b[1;32m    339\u001b[0m   replacement, new_destination \u001b[39m=\u001b[39m after_visit(replacement)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/core/converter.py:314\u001b[0m, in \u001b[0;36mBase.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ast_depth \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    313\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 314\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(Base, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mvisit(node)\n\u001b[1;32m    315\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    316\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ast_depth \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/transformer.py:441\u001b[0m, in \u001b[0;36mBase.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[39mif\u001b[39;00m processing_expr_node:\n\u001b[1;32m    439\u001b[0m   entry_expr_value \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39mvalue\n\u001b[0;32m--> 441\u001b[0m result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m(Base, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mvisit(node)\n\u001b[1;32m    443\u001b[0m \u001b[39m# Adjust for consistency: replacing the value of an Expr with\u001b[39;00m\n\u001b[1;32m    444\u001b[0m \u001b[39m# an Assign node removes the need for the Expr node.\u001b[39;00m\n\u001b[1;32m    445\u001b[0m \u001b[39mif\u001b[39;00m (processing_expr_node \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(result, gast\u001b[39m.\u001b[39mExpr) \u001b[39mand\u001b[39;00m\n\u001b[1;32m    446\u001b[0m     (result\u001b[39m.\u001b[39mvalue \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m entry_expr_value)):\n\u001b[1;32m    447\u001b[0m   \u001b[39m# When the replacement is a list, it is assumed that the list came\u001b[39;00m\n\u001b[1;32m    448\u001b[0m   \u001b[39m# from a template that contained a number of statements, which\u001b[39;00m\n\u001b[1;32m    449\u001b[0m   \u001b[39m# themselves are standalone and don't require an enclosing Expr.\u001b[39;00m\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/ast.py:407\u001b[0m, in \u001b[0;36mNodeVisitor.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    405\u001b[0m method \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mvisit_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m node\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[1;32m    406\u001b[0m visitor \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, method, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgeneric_visit)\n\u001b[0;32m--> 407\u001b[0m \u001b[39mreturn\u001b[39;00m visitor(node)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/converters/call_trees.py:124\u001b[0m, in \u001b[0;36mCallTreeTransformer.visit_With\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvisit_With\u001b[39m(\u001b[39mself\u001b[39m, node):\n\u001b[1;32m    123\u001b[0m   \u001b[39m# Context manager calls (in node.items) are not converted.\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m   node\u001b[39m.\u001b[39mbody \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit_block(node\u001b[39m.\u001b[39;49mbody)\n\u001b[1;32m    125\u001b[0m   \u001b[39mreturn\u001b[39;00m node\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/transformer.py:336\u001b[0m, in \u001b[0;36mNodeStateTracker.visit_block\u001b[0;34m(self, nodes, before_visit, after_visit)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[39mif\u001b[39;00m before_visit:\n\u001b[1;32m    333\u001b[0m   \u001b[39m# TODO(mdan): We can modify node here too, if ever needed.\u001b[39;00m\n\u001b[1;32m    334\u001b[0m   before_visit()\n\u001b[0;32m--> 336\u001b[0m replacement \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit(node)\n\u001b[1;32m    338\u001b[0m \u001b[39mif\u001b[39;00m after_visit \u001b[39mand\u001b[39;00m replacement:\n\u001b[1;32m    339\u001b[0m   replacement, new_destination \u001b[39m=\u001b[39m after_visit(replacement)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/core/converter.py:314\u001b[0m, in \u001b[0;36mBase.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ast_depth \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    313\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 314\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(Base, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mvisit(node)\n\u001b[1;32m    315\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    316\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ast_depth \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/transformer.py:441\u001b[0m, in \u001b[0;36mBase.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[39mif\u001b[39;00m processing_expr_node:\n\u001b[1;32m    439\u001b[0m   entry_expr_value \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39mvalue\n\u001b[0;32m--> 441\u001b[0m result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m(Base, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mvisit(node)\n\u001b[1;32m    443\u001b[0m \u001b[39m# Adjust for consistency: replacing the value of an Expr with\u001b[39;00m\n\u001b[1;32m    444\u001b[0m \u001b[39m# an Assign node removes the need for the Expr node.\u001b[39;00m\n\u001b[1;32m    445\u001b[0m \u001b[39mif\u001b[39;00m (processing_expr_node \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(result, gast\u001b[39m.\u001b[39mExpr) \u001b[39mand\u001b[39;00m\n\u001b[1;32m    446\u001b[0m     (result\u001b[39m.\u001b[39mvalue \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m entry_expr_value)):\n\u001b[1;32m    447\u001b[0m   \u001b[39m# When the replacement is a list, it is assumed that the list came\u001b[39;00m\n\u001b[1;32m    448\u001b[0m   \u001b[39m# from a template that contained a number of statements, which\u001b[39;00m\n\u001b[1;32m    449\u001b[0m   \u001b[39m# themselves are standalone and don't require an enclosing Expr.\u001b[39;00m\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/ast.py:407\u001b[0m, in \u001b[0;36mNodeVisitor.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    405\u001b[0m method \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mvisit_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m node\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[1;32m    406\u001b[0m visitor \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, method, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgeneric_visit)\n\u001b[0;32m--> 407\u001b[0m \u001b[39mreturn\u001b[39;00m visitor(node)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/ast.py:483\u001b[0m, in \u001b[0;36mNodeTransformer.generic_visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[39mfor\u001b[39;00m value \u001b[39min\u001b[39;00m old_value:\n\u001b[1;32m    482\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, AST):\n\u001b[0;32m--> 483\u001b[0m         value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit(value)\n\u001b[1;32m    484\u001b[0m         \u001b[39mif\u001b[39;00m value \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    485\u001b[0m             \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/core/converter.py:314\u001b[0m, in \u001b[0;36mBase.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ast_depth \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    313\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 314\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(Base, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mvisit(node)\n\u001b[1;32m    315\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    316\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ast_depth \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/transformer.py:441\u001b[0m, in \u001b[0;36mBase.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[39mif\u001b[39;00m processing_expr_node:\n\u001b[1;32m    439\u001b[0m   entry_expr_value \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39mvalue\n\u001b[0;32m--> 441\u001b[0m result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m(Base, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mvisit(node)\n\u001b[1;32m    443\u001b[0m \u001b[39m# Adjust for consistency: replacing the value of an Expr with\u001b[39;00m\n\u001b[1;32m    444\u001b[0m \u001b[39m# an Assign node removes the need for the Expr node.\u001b[39;00m\n\u001b[1;32m    445\u001b[0m \u001b[39mif\u001b[39;00m (processing_expr_node \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(result, gast\u001b[39m.\u001b[39mExpr) \u001b[39mand\u001b[39;00m\n\u001b[1;32m    446\u001b[0m     (result\u001b[39m.\u001b[39mvalue \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m entry_expr_value)):\n\u001b[1;32m    447\u001b[0m   \u001b[39m# When the replacement is a list, it is assumed that the list came\u001b[39;00m\n\u001b[1;32m    448\u001b[0m   \u001b[39m# from a template that contained a number of statements, which\u001b[39;00m\n\u001b[1;32m    449\u001b[0m   \u001b[39m# themselves are standalone and don't require an enclosing Expr.\u001b[39;00m\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/ast.py:407\u001b[0m, in \u001b[0;36mNodeVisitor.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    405\u001b[0m method \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mvisit_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m node\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[1;32m    406\u001b[0m visitor \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, method, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgeneric_visit)\n\u001b[0;32m--> 407\u001b[0m \u001b[39mreturn\u001b[39;00m visitor(node)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/ast.py:492\u001b[0m, in \u001b[0;36mNodeTransformer.generic_visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    490\u001b[0m     old_value[:] \u001b[39m=\u001b[39m new_values\n\u001b[1;32m    491\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(old_value, AST):\n\u001b[0;32m--> 492\u001b[0m     new_node \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit(old_value)\n\u001b[1;32m    493\u001b[0m     \u001b[39mif\u001b[39;00m new_node \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    494\u001b[0m         \u001b[39mdelattr\u001b[39m(node, field)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/core/converter.py:314\u001b[0m, in \u001b[0;36mBase.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ast_depth \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    313\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 314\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(Base, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mvisit(node)\n\u001b[1;32m    315\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    316\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ast_depth \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/transformer.py:441\u001b[0m, in \u001b[0;36mBase.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[39mif\u001b[39;00m processing_expr_node:\n\u001b[1;32m    439\u001b[0m   entry_expr_value \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39mvalue\n\u001b[0;32m--> 441\u001b[0m result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m(Base, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mvisit(node)\n\u001b[1;32m    443\u001b[0m \u001b[39m# Adjust for consistency: replacing the value of an Expr with\u001b[39;00m\n\u001b[1;32m    444\u001b[0m \u001b[39m# an Assign node removes the need for the Expr node.\u001b[39;00m\n\u001b[1;32m    445\u001b[0m \u001b[39mif\u001b[39;00m (processing_expr_node \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(result, gast\u001b[39m.\u001b[39mExpr) \u001b[39mand\u001b[39;00m\n\u001b[1;32m    446\u001b[0m     (result\u001b[39m.\u001b[39mvalue \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m entry_expr_value)):\n\u001b[1;32m    447\u001b[0m   \u001b[39m# When the replacement is a list, it is assumed that the list came\u001b[39;00m\n\u001b[1;32m    448\u001b[0m   \u001b[39m# from a template that contained a number of statements, which\u001b[39;00m\n\u001b[1;32m    449\u001b[0m   \u001b[39m# themselves are standalone and don't require an enclosing Expr.\u001b[39;00m\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/ast.py:407\u001b[0m, in \u001b[0;36mNodeVisitor.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    405\u001b[0m method \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mvisit_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m node\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[1;32m    406\u001b[0m visitor \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, method, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgeneric_visit)\n\u001b[0;32m--> 407\u001b[0m \u001b[39mreturn\u001b[39;00m visitor(node)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/converters/call_trees.py:197\u001b[0m, in \u001b[0;36mCallTreeTransformer.visit_Call\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    192\u001b[0m   \u001b[39mreturn\u001b[39;00m node\n\u001b[1;32m    194\u001b[0m template \u001b[39m=\u001b[39m \u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m    195\u001b[0m \u001b[39m  ag__.converted_call(func, args, kwargs, function_ctx)\u001b[39m\n\u001b[1;32m    196\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39m\n\u001b[0;32m--> 197\u001b[0m new_call \u001b[39m=\u001b[39m templates\u001b[39m.\u001b[39;49mreplace_as_expression(\n\u001b[1;32m    198\u001b[0m     template,\n\u001b[1;32m    199\u001b[0m     func\u001b[39m=\u001b[39;49mnode\u001b[39m.\u001b[39;49mfunc,\n\u001b[1;32m    200\u001b[0m     args\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_args_to_tuple(node),\n\u001b[1;32m    201\u001b[0m     kwargs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_kwargs_to_dict(node),\n\u001b[1;32m    202\u001b[0m     function_ctx\u001b[39m=\u001b[39;49mfunction_context_name)\n\u001b[1;32m    204\u001b[0m \u001b[39mreturn\u001b[39;00m new_call\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/templates.py:277\u001b[0m, in \u001b[0;36mreplace_as_expression\u001b[0;34m(template, **replacements)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreplace_as_expression\u001b[39m(template, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mreplacements):\n\u001b[1;32m    276\u001b[0m   \u001b[39m\"\"\"Variant of replace that generates expressions, instead of code blocks.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 277\u001b[0m   replacement \u001b[39m=\u001b[39m replace(template, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mreplacements)\n\u001b[1;32m    278\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(replacement) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    279\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    280\u001b[0m         \u001b[39m'\u001b[39m\u001b[39msingle expression expected; for more general templates use replace\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/templates.py:266\u001b[0m, in \u001b[0;36mreplace\u001b[0;34m(template, **replacements)\u001b[0m\n\u001b[1;32m    264\u001b[0m results \u001b[39m=\u001b[39m []\n\u001b[1;32m    265\u001b[0m \u001b[39mfor\u001b[39;00m node \u001b[39min\u001b[39;00m nodes:\n\u001b[0;32m--> 266\u001b[0m   node \u001b[39m=\u001b[39m ReplaceTransformer(replacements)\u001b[39m.\u001b[39;49mvisit(node)\n\u001b[1;32m    267\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(node, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)):\n\u001b[1;32m    268\u001b[0m     results\u001b[39m.\u001b[39mextend(node)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/ast.py:407\u001b[0m, in \u001b[0;36mNodeVisitor.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    405\u001b[0m method \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mvisit_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m node\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[1;32m    406\u001b[0m visitor \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, method, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgeneric_visit)\n\u001b[0;32m--> 407\u001b[0m \u001b[39mreturn\u001b[39;00m visitor(node)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/templates.py:145\u001b[0m, in \u001b[0;36mReplaceTransformer.visit_Expr\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvisit_Expr\u001b[39m(\u001b[39mself\u001b[39m, node):\n\u001b[1;32m    143\u001b[0m   \u001b[39m# When replacing a placeholder with an entire statement, the replacement\u001b[39;00m\n\u001b[1;32m    144\u001b[0m   \u001b[39m# must stand on its own and not be wrapped in an Expr.\u001b[39;00m\n\u001b[0;32m--> 145\u001b[0m   new_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit(node\u001b[39m.\u001b[39;49mvalue)\n\u001b[1;32m    146\u001b[0m   \u001b[39mif\u001b[39;00m new_value \u001b[39mis\u001b[39;00m node\u001b[39m.\u001b[39mvalue:\n\u001b[1;32m    147\u001b[0m     \u001b[39mreturn\u001b[39;00m node\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/ast.py:407\u001b[0m, in \u001b[0;36mNodeVisitor.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    405\u001b[0m method \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mvisit_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m node\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[1;32m    406\u001b[0m visitor \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, method, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgeneric_visit)\n\u001b[0;32m--> 407\u001b[0m \u001b[39mreturn\u001b[39;00m visitor(node)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/ast.py:483\u001b[0m, in \u001b[0;36mNodeTransformer.generic_visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[39mfor\u001b[39;00m value \u001b[39min\u001b[39;00m old_value:\n\u001b[1;32m    482\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, AST):\n\u001b[0;32m--> 483\u001b[0m         value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit(value)\n\u001b[1;32m    484\u001b[0m         \u001b[39mif\u001b[39;00m value \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    485\u001b[0m             \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/ast.py:407\u001b[0m, in \u001b[0;36mNodeVisitor.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    405\u001b[0m method \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mvisit_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m node\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[1;32m    406\u001b[0m visitor \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, method, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgeneric_visit)\n\u001b[0;32m--> 407\u001b[0m \u001b[39mreturn\u001b[39;00m visitor(node)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/templates.py:197\u001b[0m, in \u001b[0;36mReplaceTransformer.visit_Name\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39mif\u001b[39;00m node\u001b[39m.\u001b[39mid \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreplacements:\n\u001b[1;32m    195\u001b[0m   \u001b[39mreturn\u001b[39;00m node\n\u001b[0;32m--> 197\u001b[0m new_nodes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_prepare_replacement(node, node\u001b[39m.\u001b[39;49mid)\n\u001b[1;32m    199\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m new_nodes:\n\u001b[1;32m    200\u001b[0m   \u001b[39mreturn\u001b[39;00m new_nodes\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/templates.py:136\u001b[0m, in \u001b[0;36mReplaceTransformer._prepare_replacement\u001b[0;34m(self, replaced, key)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[39m\"\"\"Prepares a replacement AST that's safe to swap in for a node.\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \n\u001b[1;32m    128\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[39m  ast.AST, the replacement AST\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    134\u001b[0m repl \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreplacements[key]\n\u001b[0;32m--> 136\u001b[0m new_nodes \u001b[39m=\u001b[39m ast_util\u001b[39m.\u001b[39;49mcopy_clean(repl, preserve_annos\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpreserved_annos)\n\u001b[1;32m    137\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(new_nodes, gast\u001b[39m.\u001b[39mAST):\n\u001b[1;32m    138\u001b[0m   new_nodes \u001b[39m=\u001b[39m [new_nodes]\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/ast_util.py:72\u001b[0m, in \u001b[0;36mcopy_clean\u001b[0;34m(node, preserve_annos)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcopy_clean\u001b[39m(node, preserve_annos\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     60\u001b[0m   \u001b[39m\"\"\"Creates a deep copy of an AST.\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \n\u001b[1;32m     62\u001b[0m \u001b[39m  The copy will not include fields that are prefixed by '__', with the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[39m    ast.AST\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m   \u001b[39mreturn\u001b[39;00m CleanCopier(preserve_annos)\u001b[39m.\u001b[39;49mcopy(node)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/ast_util.py:55\u001b[0m, in \u001b[0;36mCleanCopier.copy\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreserve_annos:\n\u001b[1;32m     54\u001b[0m   \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreserve_annos:\n\u001b[0;32m---> 55\u001b[0m     anno\u001b[39m.\u001b[39;49mcopyanno(node, new_node, k)\n\u001b[1;32m     56\u001b[0m \u001b[39mreturn\u001b[39;00m new_node\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    encoder_hidden_state = encoder.initialize(batch_size=batch_size)\n",
    "    batch = {\n",
    "        'encoder_input_ids': encoded_input_sample,\n",
    "        'encoder_state': encoder_hidden_state,\n",
    "        'decoder_target': encoded_output_sample\n",
    "    }\n",
    "    loss = trainer.batch_fit(batch)\n",
    "    print(f'Loss - {loss}')\n",
    "\n",
    "    generated = trainer.generate(input_ids=encoded_input_sample)\n",
    "    translated = trainer.translate(generated)\n",
    "    print(f'Translated - {translated}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question generation $f_\\theta(P, Q, H)$ with text passage $P$, question $Q$ and dialogue history $H$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evaluate $f_\\theta(P, Q)$ and $f_\\theta(P, Q, H)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e405b0a43b05ed5b511dac57849ab560497f023fc2f8f0bfd2781bf41b5f416c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
