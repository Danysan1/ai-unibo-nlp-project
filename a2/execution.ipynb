{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAbMpqPm1mPC"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Danysan1/ai-unibo-nlp-project/blob/main/a2/execution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtlMx4kv1mPK"
      },
      "source": [
        "# Assignment 2 execution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "feevAAsT1mPL",
        "outputId": "e31fb0f5-f2eb-443a-a27b-917302d57276"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
            "Requirement already satisfied: pandas in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (1.5.0)\n",
            "Requirement already satisfied: numpy in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (1.23.3)\n",
            "Requirement already satisfied: matplotlib in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (3.5.3)\n",
            "Requirement already satisfied: transformers in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (4.25.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from pandas) (2022.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from matplotlib) (9.2.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from matplotlib) (4.37.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from matplotlib) (21.3)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: requests in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from transformers) (2.28.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: filelock in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from transformers) (3.8.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from transformers) (0.11.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from requests->transformers) (2022.6.15.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from requests->transformers) (1.26.12)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from requests->transformers) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from requests->transformers) (3.3)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install pandas numpy matplotlib transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJSsWQg_1mPO"
      },
      "source": [
        "## Data loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mXm1Fpq1mPP"
      },
      "source": [
        "### Dataset download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oOqlik_a1mPP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import urllib.request\n",
        "from tqdm import tqdm\n",
        "\n",
        "class DownloadProgressBar(tqdm):\n",
        "    def update_to(self, b=1, bsize=1, tsize=None):\n",
        "        if tsize is not None:\n",
        "            self.total = tsize\n",
        "        self.update(b * bsize - self.n)\n",
        "        \n",
        "def download_url(url, output_path):\n",
        "    with DownloadProgressBar(unit='B', unit_scale=True,\n",
        "                             miniters=1, desc=url.split('/')[-1]) as t:\n",
        "        urllib.request.urlretrieve(url, filename=output_path, reporthook=t.update_to)\n",
        "\n",
        "def download_data(data_path, url_path, suffix):    \n",
        "    if not os.path.exists(data_path):\n",
        "        os.makedirs(data_path)\n",
        "        \n",
        "    data_path = os.path.join(data_path, f'{suffix}.json')\n",
        "    if not os.path.exists(data_path):\n",
        "        print(f\"Downloading CoQA {suffix} data split... (it may take a while)\")\n",
        "        download_url(url=url_path, output_path=data_path)\n",
        "        print(\"Download completed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sskRUOtB1mPR"
      },
      "outputs": [],
      "source": [
        "data_folder = 'Dataset'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CzsJWqI61mPR"
      },
      "outputs": [],
      "source": [
        "# Train data\n",
        "train_url = \"https://nlp.stanford.edu/data/coqa/coqa-train-v1.0.json\"\n",
        "download_data(data_path=data_folder, url_path=train_url, suffix='train')\n",
        "\n",
        "# Test data\n",
        "test_url = \"https://nlp.stanford.edu/data/coqa/coqa-dev-v1.0.json\"\n",
        "download_data(data_path=data_folder, url_path=test_url, suffix='test')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsM9znVV1mPT"
      },
      "source": [
        "### Dataset loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VRsmY5Wn1mPV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "from os import path\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lI74kMng1mPW"
      },
      "outputs": [],
      "source": [
        "def loadDataset(filename):\n",
        "    with open(path.join(data_folder, filename)) as file_obj:\n",
        "        df = json.load(file_obj)[\"data\"]\n",
        "    print(f'{len(df)} stories / {len(df[0][\"questions\"])} questions in the first row')\n",
        "\n",
        "    storyDType = pd.CategoricalDtype(pd.unique([story[\"story\"] for story in df]))\n",
        "    sourceDType = pd.CategoricalDtype(pd.unique([story[\"source\"] for story in df]))\n",
        "    print(f\"Sources: {sourceDType.categories}\")\n",
        "\n",
        "    df = np.array([\n",
        "        [\n",
        "            sourceDType.categories.get_loc(story[\"source\"]), # Sources factorization\n",
        "            storyDType.categories.get_loc(story[\"story\"]), # Sources factorization\n",
        "            story[\"questions\"][question_index][\"input_text\"],\n",
        "            story[\"answers\"][question_index][\"input_text\"],\n",
        "            story[\"answers\"][question_index][\"span_text\"],\n",
        "        ]\n",
        "        for story in df\n",
        "        for question_index in range(len(story[\"questions\"]))\n",
        "        if story[\"answers\"][question_index][\"input_text\"] != 'unknown'\n",
        "    ])\n",
        "    print(f'{df.shape} question-answer pairs x columns')\n",
        "    print(f'First row: {df[0]}')\n",
        "    \n",
        "    # https://marcobonzanini.com/2021/09/15/tips-for-saving-memory-with-pandas/\n",
        "    # https://pandas.pydata.org/docs/user_guide/categorical.html\n",
        "    df = pd.DataFrame({\n",
        "        \"source\": pd.Series(pd.Categorical.from_codes(df[:,0].astype(np.int16), dtype=sourceDType)),\n",
        "        \"p\": pd.Series(pd.Categorical.from_codes(df[:,1].astype(np.int16), dtype=storyDType)),\n",
        "        \"q\": df[:,2],\n",
        "        \"a\": df[:,3],\n",
        "        \"span\": df[:,4],\n",
        "    })\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jsZrgF5d1mPX",
        "outputId": "0718a9f5-48de-4e9a-85b1-e25dbc87dcd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7199 stories / 20 questions in the first row\n",
            "Sources: Index(['wikipedia', 'cnn', 'gutenberg', 'race', 'mctest'], dtype='object')\n",
            "(107276, 5) question-answer pairs x columns\n",
            "First row: ['0' '0' 'When was the Vat formally opened?'\n",
            " 'It was formally established in 1475' 'Formally established in 1475']\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "source    107276\n",
              "p         107276\n",
              "q         107276\n",
              "a         107276\n",
              "span      107276\n",
              "dtype: int64"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df = loadDataset(\"train.json\")\n",
        "train_df.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lOQSe3Sc1mPY",
        "outputId": "594e0f7a-473b-4468-dad6-19cc2743c669"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "6605"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.unique(train_df[\"p\"]).size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJaLGY_p1mPZ",
        "outputId": "4f03c35e-65b2-4c98-d982-ed365899c17b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "99470"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.unique(train_df[\"span\"]).size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_ml0A1b1mPZ",
        "outputId": "dbfec6c6-e1da-4b8f-e359-29cfbfdf5a56"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.unique(train_df[\"source\"]).size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G9VjurfZ1mPZ",
        "outputId": "e4da073f-4818-4729-a2b0-585b173390f2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>p</th>\n",
              "      <th>q</th>\n",
              "      <th>a</th>\n",
              "      <th>span</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>wikipedia</td>\n",
              "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
              "      <td>When was the Vat formally opened?</td>\n",
              "      <td>It was formally established in 1475</td>\n",
              "      <td>Formally established in 1475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>wikipedia</td>\n",
              "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
              "      <td>what is the library for?</td>\n",
              "      <td>research</td>\n",
              "      <td>he Vatican Library is a research library</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>wikipedia</td>\n",
              "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
              "      <td>for what subjects?</td>\n",
              "      <td>history, and law</td>\n",
              "      <td>Vatican Library is a research library for hist...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>wikipedia</td>\n",
              "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
              "      <td>and?</td>\n",
              "      <td>philosophy, science and theology</td>\n",
              "      <td>Vatican Library is a research library for hist...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>wikipedia</td>\n",
              "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
              "      <td>what was started in 2014?</td>\n",
              "      <td>a  project</td>\n",
              "      <td>March 2014, the Vatican Library began an initi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      source                                                  p  \\\n",
              "0  wikipedia  The Vatican Apostolic Library (), more commonl...   \n",
              "1  wikipedia  The Vatican Apostolic Library (), more commonl...   \n",
              "2  wikipedia  The Vatican Apostolic Library (), more commonl...   \n",
              "3  wikipedia  The Vatican Apostolic Library (), more commonl...   \n",
              "4  wikipedia  The Vatican Apostolic Library (), more commonl...   \n",
              "\n",
              "                                   q                                    a  \\\n",
              "0  When was the Vat formally opened?  It was formally established in 1475   \n",
              "1           what is the library for?                             research   \n",
              "2                 for what subjects?                     history, and law   \n",
              "3                               and?     philosophy, science and theology   \n",
              "4          what was started in 2014?                           a  project   \n",
              "\n",
              "                                                span  \n",
              "0                       Formally established in 1475  \n",
              "1           he Vatican Library is a research library  \n",
              "2  Vatican Library is a research library for hist...  \n",
              "3  Vatican Library is a research library for hist...  \n",
              "4  March 2014, the Vatican Library began an initi...  "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nrRkHhES1mPa",
        "outputId": "95d808d1-dc88-4361-8c0a-eacf73026447"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index          128\n",
              "source      107764\n",
              "p         14241201\n",
              "q          9110271\n",
              "a          7714559\n",
              "span      12090637\n",
              "dtype: int64"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.memory_usage(deep=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v5aer1n41mPa"
      },
      "outputs": [],
      "source": [
        "#test_df = loadDataset(\"test.json\")\n",
        "#test_df.count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRs7YHKY1mPa"
      },
      "source": [
        "## Data Pre-Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0GmOXam1mPb"
      },
      "source": [
        "### Check unanswerable questions in the Train Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Aq524zd1mPb",
        "outputId": "36057809-1b0b-4f2d-8e8b-d55c4816e548"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "idx = (train_df.a == 'unknown')\n",
        "unanswerable = train_df[idx]\n",
        "unanswerable.q.count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTdjLFYI1mPb"
      },
      "source": [
        "All unanswerable questions in the Train Dataset have been already removed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maBslb2n1mPb"
      },
      "source": [
        "## Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VH5Ep77e1mPb",
        "outputId": "c9a6519d-d3e5-41bb-bfc0-6cc2e15656d1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'CHAPTER VII. THE DAUGHTER OF WITHERSTEEN \\n\\n\"Lassiter, will you be my rider?\" Jane had asked him. \\n\\n\"I reckon so,\" he had replied. \\n\\nFew as the words were, Jane knew how infinitely much they implied. She wanted him to take charge of her cattle and horse and ranges, and save them if that were possible. Yet, though she could not have spoken aloud all she meant, she was perfectly honest with herself. Whatever the price to be paid, she must keep Lassiter close to her; she must shield from him the man who had led Milly Erne to Cottonwoods. In her fear she so controlled her mind that she did not whisper this Mormon\\'s name to her own soul, she did not even think it. Besides, beyond this thing she regarded as a sacred obligation thrust upon her, was the need of a helper, of a friend, of a champion in this critical time. If she could rule this gun-man, as Venters had called him, if she could even keep him from shedding blood, what strategy to play his flame and his presence against the game of oppression her churchmen were waging against her? Never would she forget the effect on Tull and his men when Venters shouted Lassiter\\'s name. If she could not wholly control Lassiter, then what she could do might put off the fatal day. \\n\\nOne of her safe racers was a dark bay, and she called him Bells because of the way he struck his iron shoes on the stones. When Jerd led out this slender, beautifully built horse Lassiter suddenly became all eyes. A rider\\'s love of a thoroughbred shone in them. Round and round Bells he walked, plainly weakening all the time in his determination not to take one of Jane\\'s favorite racers. '"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df[\"p\"][42]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zYcgBVcG1mPc",
        "outputId": "115cf9e6-13a3-468a-bc66-21f245f9f7c0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Was Lassiter impressed with the horse?'"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df[\"q\"][42]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5zvn9Tv01mPc",
        "outputId": "e264d236-7ef6-4744-8ced-945594814543"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df[\"a\"][42]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NokHfoLm1mPc",
        "outputId": "f162825e-3535-48e4-f931-2fc8ec70e0b8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'When Jerd led out this slender, beautifully built horse Lassiter suddenly became all eyes.'"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df[\"span\"][42]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JskMPh-Y1mPc",
        "outputId": "3c776b60-b358-405e-ab0c-d3771926f3d8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'gutenberg'"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df[\"source\"][42]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8lIuR9RO1mPd"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mm2QCJbR1mPd"
      },
      "source": [
        "## Train-Validation-Test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lmr_hj9-1mPd"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SICbZ6vB1mPd"
      },
      "source": [
        "## Model definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wuh0_ic1mPd"
      },
      "source": [
        "### Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4pKuTsYt1mPd",
        "outputId": "a4f9be20-6653-4c4c-9983-6146c5ddb338"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-12-25 16:18:07.797042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-12-25 16:18:08.201441: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/anaconda3/pkgs/cudatoolkit-11.2.2-hbe64b41_10/lib/libcudart.so.11.0\n",
            "2022-12-25 16:18:08.201479: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "2022-12-25 16:18:09.343313: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/anaconda3/pkgs/cudatoolkit-11.2.2-hbe64b41_10/lib/libcudart.so.11.0\n",
            "2022-12-25 16:18:09.344286: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvrtc.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/anaconda3/pkgs/cudatoolkit-11.2.2-hbe64b41_10/lib/libcudart.so.11.0\n",
            "2022-12-25 16:18:09.344295: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from typing import List, Dict, Callable\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YutAeLih1mPe"
      },
      "outputs": [],
      "source": [
        "def predict_data(model: keras.Model,\n",
        "                x: np.ndarray,\n",
        "                prediction_info: Dict):\n",
        "    \"\"\"\n",
        "    Inference routine of a given input set of examples\n",
        "\n",
        "    :param model: Keras built and possibly trained model\n",
        "    :param x: input set of examples in np.ndarray format\n",
        "    :param prediction_info: dictionary storing model predict() argument information\n",
        "\n",
        "    :return\n",
        "        predictions: predicted labels in np.ndarray format\n",
        "    \"\"\"\n",
        "    print(f'Starting prediction: \\n{prediction_info}')\n",
        "    print(f'Predicting on {x.shape[0]} samples')\n",
        "    predictions = model.predict(x, **prediction_info)\n",
        "    return predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CS_dd2On1mPe"
      },
      "outputs": [],
      "source": [
        "def compute_f1(model: keras.Model, \n",
        "             x: np.ndarray, \n",
        "             y: np.ndarray):\n",
        "    \"\"\"\n",
        "    Compute F1_score on the given data with corresponding labels\n",
        "\n",
        "    :param model: Keras built and possibly trained model\n",
        "    :param x: data in np.ndarray format\n",
        "    :param y: ground-truth labels in np.ndarray format\n",
        "\n",
        "    :return\n",
        "        score: f1_macro_score\n",
        "    \"\"\"\n",
        "    #predictions on the x set\n",
        "    prediction_info = {\n",
        "        'batch_size': 64,\n",
        "        'verbose': 1\n",
        "    }\n",
        "    y_pred = predict_data(model=model, x=x, prediction_info=prediction_info)\n",
        "\n",
        "    #compute argmax to take the best class for each sample\n",
        "    y_pred = np.argmax(y_pred, axis=1)\n",
        "    #compute the f1_macro\n",
        "    score = f1_score(y, y_pred, average ='macro')\n",
        "    return score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-akLLJo1mPe"
      },
      "outputs": [],
      "source": [
        "def set_reproducibility(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    os.environ['TF_DETERMINISTIC_OPS'] = '1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61_GSxvB1mPe",
        "outputId": "fc90c31c-a958-4ffe-e327-819603014c10"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/nlp/lib/python3.7/site-packages/tensorflow_addons/utils/ensure_tf_install.py:67: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.8.0 and strictly below 2.11.0 (nightly versions are not supported). \n",
            " The versions of TensorFlow you are currently using is 2.11.0 and is not supported. \n",
            "Some things might work, some things might not.\n",
            "If you were to encounter a bug, do not file an issue.\n",
            "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
            "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
            "https://github.com/tensorflow/addons\n",
            "  UserWarning,\n",
            "2022-12-25 16:18:26.657379: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-12-25 16:18:26.657678: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/anaconda3/pkgs/cudatoolkit-11.2.2-hbe64b41_10/lib/libcudart.so.11.0\n",
            "2022-12-25 16:18:26.657760: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/anaconda3/pkgs/cudatoolkit-11.2.2-hbe64b41_10/lib/libcudart.so.11.0\n",
            "2022-12-25 16:18:26.657836: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/anaconda3/pkgs/cudatoolkit-11.2.2-hbe64b41_10/lib/libcudart.so.11.0\n",
            "2022-12-25 16:18:26.657918: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/anaconda3/pkgs/cudatoolkit-11.2.2-hbe64b41_10/lib/libcudart.so.11.0\n",
            "2022-12-25 16:18:26.657994: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/anaconda3/pkgs/cudatoolkit-11.2.2-hbe64b41_10/lib/libcudart.so.11.0\n",
            "2022-12-25 16:18:26.658048: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/anaconda3/pkgs/cudatoolkit-11.2.2-hbe64b41_10/lib/libcudart.so.11.0\n",
            "2022-12-25 16:18:26.658100: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/anaconda3/pkgs/cudatoolkit-11.2.2-hbe64b41_10/lib/libcudart.so.11.0\n",
            "2022-12-25 16:18:26.658742: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "from tqdm import tqdm\n",
        "from transformers import TFAutoModel, AutoTokenizer\n",
        "\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    except RuntimeError as e:\n",
        "        print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1aFTVbjH1mPf"
      },
      "source": [
        "### Question generation $f_\\theta(P, Q)$ with text passage $P$ and question $Q$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxoRFA2j1mPf"
      },
      "source": [
        "### Seq2Seq LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZecoZhu1mPf"
      },
      "outputs": [],
      "source": [
        "class MyTrainer(object):\n",
        "    \"\"\"\n",
        "    Simple wrapper class\n",
        "\n",
        "    train_op -> uses tf.GradientTape to compute the loss\n",
        "    batch_fit -> receives a batch and performs forward-backward passes (gradient included)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, encoder, decoder, max_length):\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.max_length = max_length\n",
        "        self.ce = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=1e-03)\n",
        "\n",
        "    @tf.function\n",
        "    def compute_loss(self, logits, target):\n",
        "        loss = self.ce(y_true=target, y_pred=logits)\n",
        "        mask = tf.logical_not(tf.math.equal(target, 0))\n",
        "        mask = tf.cast(mask, dtype=loss.dtype)\n",
        "        loss *= mask\n",
        "        return tf.reduce_mean(loss)\n",
        "\n",
        "    @tf.function\n",
        "    def train_op(self, inputs):\n",
        "        with tf.GradientTape() as tape:\n",
        "            encoder_output, encoder_h, encoder_s = self.encoder({'input_ids': inputs['encoder_input_ids'],\n",
        "                                                                 'hidden_state': inputs['encoder_state']})\n",
        "\n",
        "            decoder_input = inputs['decoder_target'][:, :-1]  # ignore <end>\n",
        "            real_target = inputs['decoder_target'][:, 1:]  # ignore <start>\n",
        "\n",
        "            decoder.attention.setup_memory(encoder_output)\n",
        "\n",
        "            decoder_initial_state = self.decoder.build_initial_state(decoder.batch_size, [encoder_h, encoder_s])\n",
        "            predicted = self.decoder({'input_ids': decoder_input,\n",
        "                                      'initial_state': decoder_initial_state}).rnn_output\n",
        "\n",
        "            loss = self.compute_loss(logits=predicted, target=real_target)\n",
        "\n",
        "        grads = tape.gradient(loss, self.encoder.trainable_variables + self.decoder.trainable_variables)\n",
        "        return loss, grads\n",
        "\n",
        "    @tf.function\n",
        "    def batch_fit(self, inputs):\n",
        "        loss, grads = self.train_op(inputs=inputs)\n",
        "        self.optimizer.apply_gradients(zip(grads, self.encoder.trainable_variables + self.decoder.trainable_variables))\n",
        "        return loss\n",
        "\n",
        "    @tf.function\n",
        "    def generate(self, input_ids):\n",
        "        batch_size = input_ids.shape[0]\n",
        "        encoder_initial_state = [tf.zeros((batch_size, self.encoder.encoder_units)),\n",
        "                                 tf.zeros((batch_size, self.encoder.encoder_units))]\n",
        "        encoder_output, encoder_h, encoder_s = self.encoder({\n",
        "            'input_ids': input_ids,\n",
        "            'hidden_state': encoder_initial_state\n",
        "        })\n",
        "\n",
        "        start_tokens = tf.fill([batch_size], tokenizer.word_index['<start>'])\n",
        "        end_token = tokenizer.word_index['<end>']\n",
        "\n",
        "        greedy_sampler = tfa.seq2seq.GreedyEmbeddingSampler()\n",
        "        decoder_instance = tfa.seq2seq.BasicDecoder(cell=self.decoder.wrapped_decoder_cell,\n",
        "                                                    sampler=greedy_sampler,\n",
        "                                                    output_layer=self.decoder.generation_dense,\n",
        "                                                    maximum_iterations=self.max_length)\n",
        "        self.decoder.attention.setup_memory(encoder_output)\n",
        "\n",
        "        decoder_initial_state = self.decoder.build_initial_state(batch_size, [encoder_h, encoder_s])\n",
        "        decoder_embedding_matrix = self.decoder.embedding.variables[0]\n",
        "        outputs, _, _ = decoder_instance(decoder_embedding_matrix,\n",
        "                                         start_tokens=start_tokens,\n",
        "                                         end_token=end_token,\n",
        "                                         initial_state=decoder_initial_state)\n",
        "        return outputs\n",
        "\n",
        "    def translate(self, generated):\n",
        "        return tokenizer.sequences_to_texts(generated.sample_id.numpy())\n",
        "\n",
        "\n",
        "class Encoder(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, vocab_size, embedding_dim, encoder_units):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.encoder_units = encoder_units\n",
        "\n",
        "        self.embedding = tf.keras.layers.Embedding(input_dim=vocab_size,\n",
        "                                                   output_dim=embedding_dim)\n",
        "        self.encoder_lstm = tf.keras.layers.LSTM(self.encoder_units,\n",
        "                                                 return_sequences=True,\n",
        "                                                 return_state=True)\n",
        "\n",
        "    def call(self, inputs, training=False, **kwargs):\n",
        "        input_ids = inputs['input_ids']\n",
        "        input_emb = self.embedding(input_ids)\n",
        "        encoder_output, lstm_hidden, lstm_states = self.encoder_lstm(input_emb, initial_state=inputs['hidden_state'])\n",
        "        return encoder_output, lstm_hidden, lstm_states\n",
        "\n",
        "    def initialize(self, batch_size):\n",
        "        return [tf.zeros((batch_size, self.encoder_units)), tf.zeros((batch_size, self.encoder_units))]\n",
        "\n",
        "\n",
        "class Decoder(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, vocab_size, max_sequence_length, embedding_dim, decoder_units, batch_size):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.max_sequence_length = max_sequence_length\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.decoder_units = decoder_units\n",
        "        self.embedding = tf.keras.layers.Embedding(input_dim=vocab_size,\n",
        "                                                   output_dim=embedding_dim)\n",
        "        self.decoder_lstm_cell = tf.keras.layers.LSTMCell(self.decoder_units)\n",
        "\n",
        "        self.attention = tfa.seq2seq.BahdanauAttention(units=self.decoder_units,\n",
        "                                                       memory=None,\n",
        "                                                       memory_sequence_length=self.batch_size * [max_sequence_length])\n",
        "\n",
        "        self.wrapped_decoder_cell = tfa.seq2seq.AttentionWrapper(self.decoder_lstm_cell,\n",
        "                                                                 self.attention,\n",
        "                                                                 attention_layer_size=self.decoder_units)\n",
        "\n",
        "        self.generation_dense = tf.keras.layers.Dense(vocab_size)\n",
        "        self.sampler = tfa.seq2seq.sampler.TrainingSampler()\n",
        "        self.decoder = tfa.seq2seq.BasicDecoder(self.wrapped_decoder_cell,\n",
        "                                                sampler=self.sampler,\n",
        "                                                output_layer=self.generation_dense)\n",
        "\n",
        "    def build_initial_state(self, batch_size, encoder_state):\n",
        "        initial_state = self.wrapped_decoder_cell.get_initial_state(batch_size=batch_size, dtype=tf.float32)\n",
        "        initial_state = initial_state.clone(cell_state=encoder_state)\n",
        "        return initial_state\n",
        "\n",
        "    def call(self, inputs, training=False, **kwargs):\n",
        "        input_ids = inputs['input_ids']\n",
        "        input_emb = self.embedding(input_ids)\n",
        "        decoder_output, _, _ = self.decoder(input_emb,\n",
        "                                            initial_state=inputs['initial_state'],\n",
        "                                            sequence_length=self.batch_size * [self.max_sequence_length - 1])\n",
        "        return decoder_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t29CV-S41mPg",
        "outputId": "b15fcf00-b73a-41ca-f7aa-954a058ad5d1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-12-14 00:08:14.456810: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2, 6, 16) -- (2, 16) -- (2, 16)\n",
            "(2, 5, 16)\n"
          ]
        }
      ],
      "source": [
        "# Sample\n",
        "input_sample = [\n",
        "    \"hello there how is it going\",\n",
        "    \"this assignment is hellish\"\n",
        "]\n",
        "output_sample = [\n",
        "    \"<start> it is going well <end>\",\n",
        "    \"<start> I agree <end>\"\n",
        "]\n",
        "\n",
        "batch_size = len(input_sample)\n",
        "\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='', oov_token='<UNK>')\n",
        "tokenizer.fit_on_texts(input_sample + output_sample)\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "encoded_input_sample = tokenizer.texts_to_sequences(input_sample)\n",
        "max_input_length = max([len(item) for item in encoded_input_sample])\n",
        "\n",
        "encoded_output_sample = tokenizer.texts_to_sequences(output_sample)\n",
        "max_output_length = max([len(item) for item in encoded_output_sample])\n",
        "\n",
        "max_sequence_length = max(max_input_length, max_output_length)\n",
        "\n",
        "encoded_input_sample = tf.keras.preprocessing.sequence.pad_sequences(encoded_input_sample,\n",
        "                                                                        padding='post',\n",
        "                                                                        maxlen=max_sequence_length)\n",
        "encoded_output_sample = tf.keras.preprocessing.sequence.pad_sequences(encoded_output_sample,\n",
        "                                                                        padding='post',\n",
        "                                                                        maxlen=max_sequence_length)\n",
        "\n",
        "# Test encoder\n",
        "encoder = Encoder(vocab_size=vocab_size,\n",
        "                    embedding_dim=50,\n",
        "                    encoder_units=16)\n",
        "\n",
        "sample_hidden = encoder.initialize(batch_size=batch_size)\n",
        "encoder_sample_batch = {\n",
        "    'input_ids': tf.convert_to_tensor(encoded_input_sample, dtype=tf.int32),\n",
        "    'hidden_state': sample_hidden\n",
        "}\n",
        "\n",
        "sample_output, sample_h, sample_c = encoder(inputs=encoder_sample_batch)\n",
        "print(f'{sample_output.shape} -- {sample_h.shape} -- {sample_c.shape}')\n",
        "\n",
        "# Test decoder\n",
        "decoder = Decoder(vocab_size=vocab_size,\n",
        "                    embedding_dim=50,\n",
        "                    decoder_units=16,\n",
        "                    batch_size=batch_size,\n",
        "                    max_sequence_length=max_sequence_length)\n",
        "decoder.attention.setup_memory(sample_output)\n",
        "initial_state = decoder.build_initial_state(batch_size, [sample_h, sample_c])\n",
        "\n",
        "decoder_sample_batch = {\n",
        "    'input_ids': tf.convert_to_tensor(encoded_output_sample, tf.int32),\n",
        "    'initial_state': initial_state\n",
        "}\n",
        "sample_decoder_outputs = decoder(decoder_sample_batch).rnn_output\n",
        "print(f'{sample_decoder_outputs.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZhSq6V41mPg"
      },
      "outputs": [],
      "source": [
        "# Training\n",
        "trainer = MyTrainer(encoder=encoder,\n",
        "                    decoder=decoder,\n",
        "                    max_length=max_sequence_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d5lLS5pc1mPg",
        "outputId": "d8da62b6-89fe-47fe-ef85-061c004f53c7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/100 [00:05<?, ?it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [24], line 9\u001b[0m\n\u001b[1;32m      3\u001b[0m encoder_hidden_state \u001b[39m=\u001b[39m encoder\u001b[39m.\u001b[39minitialize(batch_size\u001b[39m=\u001b[39mbatch_size)\n\u001b[1;32m      4\u001b[0m batch \u001b[39m=\u001b[39m {\n\u001b[1;32m      5\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mencoder_input_ids\u001b[39m\u001b[39m'\u001b[39m: encoded_input_sample,\n\u001b[1;32m      6\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mencoder_state\u001b[39m\u001b[39m'\u001b[39m: encoder_hidden_state,\n\u001b[1;32m      7\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mdecoder_target\u001b[39m\u001b[39m'\u001b[39m: encoded_output_sample\n\u001b[1;32m      8\u001b[0m }\n\u001b[0;32m----> 9\u001b[0m loss \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39;49mbatch_fit(batch)\n\u001b[1;32m     10\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mLoss - \u001b[39m\u001b[39m{\u001b[39;00mloss\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     12\u001b[0m generated \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39mgenerate(input_ids\u001b[39m=\u001b[39mencoded_input_sample)\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:963\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    960\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    961\u001b[0m   \u001b[39m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[1;32m    962\u001b[0m   initializers \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 963\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_initialize(args, kwds, add_initializers_to\u001b[39m=\u001b[39;49minitializers)\n\u001b[1;32m    964\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    965\u001b[0m   \u001b[39m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[1;32m    966\u001b[0m   \u001b[39m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[1;32m    967\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:785\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    782\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lifted_initializer_graph \u001b[39m=\u001b[39m lifted_initializer_graph\n\u001b[1;32m    783\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_graph_deleter \u001b[39m=\u001b[39m FunctionDeleter(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lifted_initializer_graph)\n\u001b[1;32m    784\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_concrete_stateful_fn \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 785\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateful_fn\u001b[39m.\u001b[39;49m_get_concrete_function_internal_garbage_collected(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    786\u001b[0m         \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds))\n\u001b[1;32m    788\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minvalid_creator_scope\u001b[39m(\u001b[39m*\u001b[39munused_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39munused_kwds):\n\u001b[1;32m    789\u001b[0m   \u001b[39m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2523\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2521\u001b[0m   args, kwargs \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   2522\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m-> 2523\u001b[0m   graph_function, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_function(args, kwargs)\n\u001b[1;32m   2524\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2760\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2758\u001b[0m   \u001b[39m# Only get placeholders for arguments, not captures\u001b[39;00m\n\u001b[1;32m   2759\u001b[0m   args, kwargs \u001b[39m=\u001b[39m placeholder_dict[\u001b[39m\"\u001b[39m\u001b[39margs\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m-> 2760\u001b[0m graph_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_graph_function(args, kwargs)\n\u001b[1;32m   2762\u001b[0m graph_capture_container \u001b[39m=\u001b[39m graph_function\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39m_capture_func_lib  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   2763\u001b[0m \u001b[39m# Maintain the list of all captures\u001b[39;00m\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2670\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2665\u001b[0m missing_arg_names \u001b[39m=\u001b[39m [\n\u001b[1;32m   2666\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (arg, i) \u001b[39mfor\u001b[39;00m i, arg \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(missing_arg_names)\n\u001b[1;32m   2667\u001b[0m ]\n\u001b[1;32m   2668\u001b[0m arg_names \u001b[39m=\u001b[39m base_arg_names \u001b[39m+\u001b[39m missing_arg_names\n\u001b[1;32m   2669\u001b[0m graph_function \u001b[39m=\u001b[39m ConcreteFunction(\n\u001b[0;32m-> 2670\u001b[0m     func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[1;32m   2671\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name,\n\u001b[1;32m   2672\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_function,\n\u001b[1;32m   2673\u001b[0m         args,\n\u001b[1;32m   2674\u001b[0m         kwargs,\n\u001b[1;32m   2675\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_signature,\n\u001b[1;32m   2676\u001b[0m         autograph\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph,\n\u001b[1;32m   2677\u001b[0m         autograph_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph_options,\n\u001b[1;32m   2678\u001b[0m         arg_names\u001b[39m=\u001b[39;49marg_names,\n\u001b[1;32m   2679\u001b[0m         capture_by_value\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_capture_by_value),\n\u001b[1;32m   2680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_attributes,\n\u001b[1;32m   2681\u001b[0m     spec\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_spec,\n\u001b[1;32m   2682\u001b[0m     \u001b[39m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m   2683\u001b[0m     \u001b[39m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m   2684\u001b[0m     \u001b[39m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m   2685\u001b[0m     \u001b[39m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m   2686\u001b[0m     shared_func_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   2687\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:1247\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1244\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1245\u001b[0m   _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1247\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39;49mfunc_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfunc_kwargs)\n\u001b[1;32m   1249\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1250\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1251\u001b[0m func_outputs \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mmap_structure(\n\u001b[1;32m   1252\u001b[0m     convert, func_outputs, expand_composites\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:677\u001b[0m, in \u001b[0;36mFunction._defun_with_scope.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[39mwith\u001b[39;00m default_graph\u001b[39m.\u001b[39m_variable_creator_scope(scope, priority\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m):  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    674\u001b[0m   \u001b[39m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[1;32m    675\u001b[0m   \u001b[39m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[1;32m    676\u001b[0m   \u001b[39mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[0;32m--> 677\u001b[0m     out \u001b[39m=\u001b[39m weak_wrapped_fn()\u001b[39m.\u001b[39;49m__wrapped__(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    678\u001b[0m   \u001b[39mreturn\u001b[39;00m out\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3317\u001b[0m, in \u001b[0;36mclass_method_to_instance_method.<locals>.bound_method_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   3312\u001b[0m   \u001b[39mreturn\u001b[39;00m wrapped_fn(weak_instance(), \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   3314\u001b[0m \u001b[39m# If __wrapped__ was replaced, then it is always an unbound function.\u001b[39;00m\n\u001b[1;32m   3315\u001b[0m \u001b[39m# However, the replacer is still responsible for attaching self properly.\u001b[39;00m\n\u001b[1;32m   3316\u001b[0m \u001b[39m# TODO(mdan): Is it possible to do it here instead?\u001b[39;00m\n\u001b[0;32m-> 3317\u001b[0m \u001b[39mreturn\u001b[39;00m wrapped_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:1222\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1220\u001b[0m \u001b[39m# TODO(mdan): Push this block higher in tf.function's call stack.\u001b[39;00m\n\u001b[1;32m   1221\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1222\u001b[0m   \u001b[39mreturn\u001b[39;00m autograph\u001b[39m.\u001b[39;49mconverted_call(\n\u001b[1;32m   1223\u001b[0m       original_func,\n\u001b[1;32m   1224\u001b[0m       args,\n\u001b[1;32m   1225\u001b[0m       kwargs,\n\u001b[1;32m   1226\u001b[0m       options\u001b[39m=\u001b[39;49mautograph\u001b[39m.\u001b[39;49mConversionOptions(\n\u001b[1;32m   1227\u001b[0m           recursive\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1228\u001b[0m           optional_features\u001b[39m=\u001b[39;49mautograph_options,\n\u001b[1;32m   1229\u001b[0m           user_requested\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1230\u001b[0m       ))\n\u001b[1;32m   1231\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m   1232\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39;49meffective_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
            "File \u001b[0;32m/tmp/__autograph_generated_filel6dm7ocs.py:10\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__batch_fit\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m      8\u001b[0m do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m      9\u001b[0m retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mUndefinedReturnValue()\n\u001b[0;32m---> 10\u001b[0m (loss, grads) \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mtrain_op, (), \u001b[39mdict\u001b[39;49m(inputs\u001b[39m=\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(inputs)), fscope)\n\u001b[1;32m     11\u001b[0m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mapply_gradients, (ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mzip\u001b[39m), (ag__\u001b[39m.\u001b[39mld(grads), ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mencoder\u001b[39m.\u001b[39mtrainable_variables \u001b[39m+\u001b[39m ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mdecoder\u001b[39m.\u001b[39mtrainable_variables), \u001b[39mNone\u001b[39;00m, fscope),), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     12\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    374\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    376\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39muser_requested \u001b[39mand\u001b[39;00m conversion\u001b[39m.\u001b[39mis_allowlisted(f):\n\u001b[0;32m--> 377\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    379\u001b[0m \u001b[39m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[39m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[39m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[39m# things like builtins.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39minternal_convert_user_code:\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:458\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    455\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    457\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 458\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    459\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:963\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    960\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    961\u001b[0m   \u001b[39m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[1;32m    962\u001b[0m   initializers \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 963\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_initialize(args, kwds, add_initializers_to\u001b[39m=\u001b[39;49minitializers)\n\u001b[1;32m    964\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    965\u001b[0m   \u001b[39m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[1;32m    966\u001b[0m   \u001b[39m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[1;32m    967\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:785\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    782\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lifted_initializer_graph \u001b[39m=\u001b[39m lifted_initializer_graph\n\u001b[1;32m    783\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_graph_deleter \u001b[39m=\u001b[39m FunctionDeleter(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lifted_initializer_graph)\n\u001b[1;32m    784\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_concrete_stateful_fn \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 785\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateful_fn\u001b[39m.\u001b[39;49m_get_concrete_function_internal_garbage_collected(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    786\u001b[0m         \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds))\n\u001b[1;32m    788\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minvalid_creator_scope\u001b[39m(\u001b[39m*\u001b[39munused_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39munused_kwds):\n\u001b[1;32m    789\u001b[0m   \u001b[39m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2523\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2521\u001b[0m   args, kwargs \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   2522\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m-> 2523\u001b[0m   graph_function, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_function(args, kwargs)\n\u001b[1;32m   2524\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2760\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2758\u001b[0m   \u001b[39m# Only get placeholders for arguments, not captures\u001b[39;00m\n\u001b[1;32m   2759\u001b[0m   args, kwargs \u001b[39m=\u001b[39m placeholder_dict[\u001b[39m\"\u001b[39m\u001b[39margs\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m-> 2760\u001b[0m graph_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_graph_function(args, kwargs)\n\u001b[1;32m   2762\u001b[0m graph_capture_container \u001b[39m=\u001b[39m graph_function\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39m_capture_func_lib  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   2763\u001b[0m \u001b[39m# Maintain the list of all captures\u001b[39;00m\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2670\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2665\u001b[0m missing_arg_names \u001b[39m=\u001b[39m [\n\u001b[1;32m   2666\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (arg, i) \u001b[39mfor\u001b[39;00m i, arg \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(missing_arg_names)\n\u001b[1;32m   2667\u001b[0m ]\n\u001b[1;32m   2668\u001b[0m arg_names \u001b[39m=\u001b[39m base_arg_names \u001b[39m+\u001b[39m missing_arg_names\n\u001b[1;32m   2669\u001b[0m graph_function \u001b[39m=\u001b[39m ConcreteFunction(\n\u001b[0;32m-> 2670\u001b[0m     func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[1;32m   2671\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name,\n\u001b[1;32m   2672\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_function,\n\u001b[1;32m   2673\u001b[0m         args,\n\u001b[1;32m   2674\u001b[0m         kwargs,\n\u001b[1;32m   2675\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_signature,\n\u001b[1;32m   2676\u001b[0m         autograph\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph,\n\u001b[1;32m   2677\u001b[0m         autograph_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph_options,\n\u001b[1;32m   2678\u001b[0m         arg_names\u001b[39m=\u001b[39;49marg_names,\n\u001b[1;32m   2679\u001b[0m         capture_by_value\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_capture_by_value),\n\u001b[1;32m   2680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_attributes,\n\u001b[1;32m   2681\u001b[0m     spec\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_spec,\n\u001b[1;32m   2682\u001b[0m     \u001b[39m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m   2683\u001b[0m     \u001b[39m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m   2684\u001b[0m     \u001b[39m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m   2685\u001b[0m     \u001b[39m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m   2686\u001b[0m     shared_func_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   2687\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:1247\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1244\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1245\u001b[0m   _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1247\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39;49mfunc_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfunc_kwargs)\n\u001b[1;32m   1249\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1250\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1251\u001b[0m func_outputs \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mmap_structure(\n\u001b[1;32m   1252\u001b[0m     convert, func_outputs, expand_composites\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:677\u001b[0m, in \u001b[0;36mFunction._defun_with_scope.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[39mwith\u001b[39;00m default_graph\u001b[39m.\u001b[39m_variable_creator_scope(scope, priority\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m):  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    674\u001b[0m   \u001b[39m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[1;32m    675\u001b[0m   \u001b[39m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[1;32m    676\u001b[0m   \u001b[39mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[0;32m--> 677\u001b[0m     out \u001b[39m=\u001b[39m weak_wrapped_fn()\u001b[39m.\u001b[39;49m__wrapped__(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    678\u001b[0m   \u001b[39mreturn\u001b[39;00m out\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3317\u001b[0m, in \u001b[0;36mclass_method_to_instance_method.<locals>.bound_method_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   3312\u001b[0m   \u001b[39mreturn\u001b[39;00m wrapped_fn(weak_instance(), \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   3314\u001b[0m \u001b[39m# If __wrapped__ was replaced, then it is always an unbound function.\u001b[39;00m\n\u001b[1;32m   3315\u001b[0m \u001b[39m# However, the replacer is still responsible for attaching self properly.\u001b[39;00m\n\u001b[1;32m   3316\u001b[0m \u001b[39m# TODO(mdan): Is it possible to do it here instead?\u001b[39;00m\n\u001b[0;32m-> 3317\u001b[0m \u001b[39mreturn\u001b[39;00m wrapped_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:1222\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1220\u001b[0m \u001b[39m# TODO(mdan): Push this block higher in tf.function's call stack.\u001b[39;00m\n\u001b[1;32m   1221\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1222\u001b[0m   \u001b[39mreturn\u001b[39;00m autograph\u001b[39m.\u001b[39;49mconverted_call(\n\u001b[1;32m   1223\u001b[0m       original_func,\n\u001b[1;32m   1224\u001b[0m       args,\n\u001b[1;32m   1225\u001b[0m       kwargs,\n\u001b[1;32m   1226\u001b[0m       options\u001b[39m=\u001b[39;49mautograph\u001b[39m.\u001b[39;49mConversionOptions(\n\u001b[1;32m   1227\u001b[0m           recursive\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1228\u001b[0m           optional_features\u001b[39m=\u001b[39;49mautograph_options,\n\u001b[1;32m   1229\u001b[0m           user_requested\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1230\u001b[0m       ))\n\u001b[1;32m   1231\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m   1232\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39;49meffective_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
            "File \u001b[0;32m/tmp/__autograph_generated_filekh3lyw76.py:16\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_op\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     14\u001b[0m     ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(decoder)\u001b[39m.\u001b[39mattention\u001b[39m.\u001b[39msetup_memory, (ag__\u001b[39m.\u001b[39mld(encoder_output),), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     15\u001b[0m     decoder_initial_state \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mdecoder\u001b[39m.\u001b[39mbuild_initial_state, (ag__\u001b[39m.\u001b[39mld(decoder)\u001b[39m.\u001b[39mbatch_size, [ag__\u001b[39m.\u001b[39mld(encoder_h), ag__\u001b[39m.\u001b[39mld(encoder_s)]), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m---> 16\u001b[0m     predicted \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mdecoder, ({\u001b[39m'\u001b[39;49m\u001b[39minput_ids\u001b[39;49m\u001b[39m'\u001b[39;49m: ag__\u001b[39m.\u001b[39;49mld(decoder_input), \u001b[39m'\u001b[39;49m\u001b[39minitial_state\u001b[39;49m\u001b[39m'\u001b[39;49m: ag__\u001b[39m.\u001b[39;49mld(decoder_initial_state)},), \u001b[39mNone\u001b[39;49;00m, fscope)\u001b[39m.\u001b[39mrnn_output\n\u001b[1;32m     17\u001b[0m     loss \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mcompute_loss, (), \u001b[39mdict\u001b[39m(logits\u001b[39m=\u001b[39mag__\u001b[39m.\u001b[39mld(predicted), target\u001b[39m=\u001b[39mag__\u001b[39m.\u001b[39mld(real_target)), fscope)\n\u001b[1;32m     18\u001b[0m grads \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tape)\u001b[39m.\u001b[39mgradient, (ag__\u001b[39m.\u001b[39mld(loss), ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mencoder\u001b[39m.\u001b[39mtrainable_variables \u001b[39m+\u001b[39m ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mdecoder\u001b[39m.\u001b[39mtrainable_variables), \u001b[39mNone\u001b[39;00m, fscope)\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    374\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    376\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39muser_requested \u001b[39mand\u001b[39;00m conversion\u001b[39m.\u001b[39mis_allowlisted(f):\n\u001b[0;32m--> 377\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    379\u001b[0m \u001b[39m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[39m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[39m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[39m# things like builtins.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39minternal_convert_user_code:\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    458\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs)\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py:557\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(inputs, \u001b[39m*\u001b[39mcopied_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcopied_kwargs)\n\u001b[1;32m    555\u001b[0m     layout_map_lib\u001b[39m.\u001b[39m_map_subclass_model_variable(\u001b[39mself\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_layout_map)\n\u001b[0;32m--> 557\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/base_layer.py:1097\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1092\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[1;32m   1094\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object\n\u001b[1;32m   1096\u001b[0m ):\n\u001b[0;32m-> 1097\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1099\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[1;32m   1100\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    688\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 689\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[1;32m    690\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    691\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39;49meffective_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
            "File \u001b[0;32m/tmp/__autograph_generated_fileazakgrur.py:12\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[0;34m(self, inputs, training, **kwargs)\u001b[0m\n\u001b[1;32m     10\u001b[0m input_ids \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mld(inputs)[\u001b[39m'\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     11\u001b[0m input_emb \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39membedding, (ag__\u001b[39m.\u001b[39mld(input_ids),), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m---> 12\u001b[0m (decoder_output, _, _) \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mdecoder, (ag__\u001b[39m.\u001b[39;49mld(input_emb),), \u001b[39mdict\u001b[39;49m(initial_state\u001b[39m=\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(inputs)[\u001b[39m'\u001b[39;49m\u001b[39minitial_state\u001b[39;49m\u001b[39m'\u001b[39;49m], sequence_length\u001b[39m=\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mbatch_size \u001b[39m*\u001b[39;49m [ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mmax_sequence_length \u001b[39m-\u001b[39;49m \u001b[39m1\u001b[39;49m]), fscope)\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    374\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    376\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39muser_requested \u001b[39mand\u001b[39;00m conversion\u001b[39m.\u001b[39mis_allowlisted(f):\n\u001b[0;32m--> 377\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    379\u001b[0m \u001b[39m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[39m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[39m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[39m# things like builtins.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39minternal_convert_user_code:\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:458\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    455\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    457\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 458\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    459\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/base_layer.py:1097\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1092\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[1;32m   1094\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object\n\u001b[1;32m   1096\u001b[0m ):\n\u001b[0;32m-> 1097\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1099\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[1;32m   1100\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    688\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 689\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[1;32m    690\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    691\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39;49meffective_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
            "File \u001b[0;32m/tmp/__autograph_generated_filemsorkd_q.py:14\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[0;34m(self, inputs, initial_state, training, **kwargs)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     13\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(dynamic_decode), (ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m),), \u001b[39mdict\u001b[39;49m(output_time_major\u001b[39m=\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49moutput_time_major, impute_finished\u001b[39m=\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mimpute_finished, maximum_iterations\u001b[39m=\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mmaximum_iterations, parallel_iterations\u001b[39m=\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mparallel_iterations, swap_memory\u001b[39m=\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mswap_memory, training\u001b[39m=\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(training), decoder_init_input\u001b[39m=\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(inputs), decoder_init_kwargs\u001b[39m=\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(init_kwargs)), fscope)\n\u001b[1;32m     15\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     16\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39;49meffective_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
            "File \u001b[0;32m/tmp/__autograph_generated_filegr21x5o1.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m memo \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(_CallMemo), (ag__\u001b[39m.\u001b[39mld(python_func), ag__\u001b[39m.\u001b[39mld(_localns)), \u001b[39mdict\u001b[39m(args\u001b[39m=\u001b[39mag__\u001b[39m.\u001b[39mld(args), kwargs\u001b[39m=\u001b[39mag__\u001b[39m.\u001b[39mld(kwargs)), fscope)\n\u001b[1;32m     14\u001b[0m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(check_argument_types), (ag__\u001b[39m.\u001b[39mld(memo),), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m---> 15\u001b[0m retval \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(func), \u001b[39mtuple\u001b[39;49m(ag__\u001b[39m.\u001b[39;49mld(args)), \u001b[39mdict\u001b[39;49m(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(kwargs)), fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(check_return_type), (ag__\u001b[39m.\u001b[39mld(retval), ag__\u001b[39m.\u001b[39mld(memo)), \u001b[39mNone\u001b[39;00m, fscope)\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39;49meffective_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
            "File \u001b[0;32m/tmp/__autograph_generated_file9kvgam8p.py:473\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__dynamic_decode\u001b[0;34m(decoder, output_time_major, impute_finished, maximum_iterations, parallel_iterations, swap_memory, training, scope, enable_tflite_convertible, **kwargs)\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[39mraise\u001b[39;00m\n\u001b[1;32m    472\u001b[0m         \u001b[39mreturn\u001b[39;00m fscope_4\u001b[39m.\u001b[39mret(retval__4, do_return_4)\n\u001b[0;32m--> 473\u001b[0m res \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(tf)\u001b[39m.\u001b[39;49mwhile_loop, (ag__\u001b[39m.\u001b[39;49mld(condition), ag__\u001b[39m.\u001b[39;49mld(body)), \u001b[39mdict\u001b[39;49m(loop_vars\u001b[39m=\u001b[39;49m(ag__\u001b[39m.\u001b[39;49mld(initial_time), ag__\u001b[39m.\u001b[39;49mld(initial_outputs_ta), ag__\u001b[39m.\u001b[39;49mld(initial_state), ag__\u001b[39m.\u001b[39;49mld(initial_inputs), ag__\u001b[39m.\u001b[39;49mld(initial_finished), ag__\u001b[39m.\u001b[39;49mld(initial_sequence_lengths)), parallel_iterations\u001b[39m=\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(parallel_iterations), maximum_iterations\u001b[39m=\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(maximum_iterations), swap_memory\u001b[39m=\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(swap_memory)), fscope)\n\u001b[1;32m    474\u001b[0m final_outputs_ta \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mld(res)[\u001b[39m1\u001b[39m]\n\u001b[1;32m    475\u001b[0m final_state \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mld(res)[\u001b[39m2\u001b[39m]\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    374\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    376\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39muser_requested \u001b[39mand\u001b[39;00m conversion\u001b[39m.\u001b[39mis_allowlisted(f):\n\u001b[0;32m--> 377\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    379\u001b[0m \u001b[39m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[39m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[39m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[39m# things like builtins.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39minternal_convert_user_code:\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:458\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    455\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    457\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 458\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    459\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/util/deprecation.py:629\u001b[0m, in \u001b[0;36mdeprecated_arg_values.<locals>.deprecated_wrapper.<locals>.new_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    622\u001b[0m           _PRINTED_WARNING[(func, arg_name)] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    623\u001b[0m         logging\u001b[39m.\u001b[39mwarning(\n\u001b[1;32m    624\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mFrom \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: calling \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m (from \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m) with \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m=\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is deprecated and \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    625\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mwill be removed \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mInstructions for updating:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m,\n\u001b[1;32m    626\u001b[0m             _call_location(), decorator_utils\u001b[39m.\u001b[39mget_qualified_name(func),\n\u001b[1;32m    627\u001b[0m             func\u001b[39m.\u001b[39m\u001b[39m__module__\u001b[39m, arg_name, arg_value, \u001b[39m'\u001b[39m\u001b[39min a future version\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    628\u001b[0m             \u001b[39mif\u001b[39;00m date \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mafter \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m date), instructions)\n\u001b[0;32m--> 629\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/ops/control_flow_ops.py:2513\u001b[0m, in \u001b[0;36mwhile_loop_v2\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, maximum_iterations, name)\u001b[0m\n\u001b[1;32m   2337\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mwhile_loop\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[])\n\u001b[1;32m   2338\u001b[0m \u001b[39m@deprecation\u001b[39m\u001b[39m.\u001b[39mdeprecated_arg_values(\n\u001b[1;32m   2339\u001b[0m     \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2354\u001b[0m                   maximum_iterations\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   2355\u001b[0m                   name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   2356\u001b[0m   \u001b[39m\"\"\"Repeat `body` while the condition `cond` is true.\u001b[39;00m\n\u001b[1;32m   2357\u001b[0m \n\u001b[1;32m   2358\u001b[0m \u001b[39m  `cond` is a callable returning a boolean scalar tensor. `body` is a callable\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2511\u001b[0m \n\u001b[1;32m   2512\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2513\u001b[0m   \u001b[39mreturn\u001b[39;00m while_loop(\n\u001b[1;32m   2514\u001b[0m       cond\u001b[39m=\u001b[39;49mcond,\n\u001b[1;32m   2515\u001b[0m       body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m   2516\u001b[0m       loop_vars\u001b[39m=\u001b[39;49mloop_vars,\n\u001b[1;32m   2517\u001b[0m       shape_invariants\u001b[39m=\u001b[39;49mshape_invariants,\n\u001b[1;32m   2518\u001b[0m       parallel_iterations\u001b[39m=\u001b[39;49mparallel_iterations,\n\u001b[1;32m   2519\u001b[0m       back_prop\u001b[39m=\u001b[39;49mback_prop,\n\u001b[1;32m   2520\u001b[0m       swap_memory\u001b[39m=\u001b[39;49mswap_memory,\n\u001b[1;32m   2521\u001b[0m       name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m   2522\u001b[0m       maximum_iterations\u001b[39m=\u001b[39;49mmaximum_iterations,\n\u001b[1;32m   2523\u001b[0m       return_same_structure\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/ops/control_flow_ops.py:2713\u001b[0m, in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   2710\u001b[0m executing_eagerly \u001b[39m=\u001b[39m context\u001b[39m.\u001b[39mexecuting_eagerly()\n\u001b[1;32m   2711\u001b[0m \u001b[39mif\u001b[39;00m (util\u001b[39m.\u001b[39mEnableControlFlowV2(ops\u001b[39m.\u001b[39mget_default_graph()) \u001b[39mand\u001b[39;00m\n\u001b[1;32m   2712\u001b[0m     \u001b[39mnot\u001b[39;00m executing_eagerly):\n\u001b[0;32m-> 2713\u001b[0m   \u001b[39mreturn\u001b[39;00m while_v2\u001b[39m.\u001b[39;49mwhile_loop(\n\u001b[1;32m   2714\u001b[0m       cond,\n\u001b[1;32m   2715\u001b[0m       body,\n\u001b[1;32m   2716\u001b[0m       loop_vars,\n\u001b[1;32m   2717\u001b[0m       shape_invariants\u001b[39m=\u001b[39;49mshape_invariants,\n\u001b[1;32m   2718\u001b[0m       parallel_iterations\u001b[39m=\u001b[39;49mparallel_iterations,\n\u001b[1;32m   2719\u001b[0m       maximum_iterations\u001b[39m=\u001b[39;49mmaximum_iterations,\n\u001b[1;32m   2720\u001b[0m       name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m   2721\u001b[0m       return_same_structure\u001b[39m=\u001b[39;49mreturn_same_structure,\n\u001b[1;32m   2722\u001b[0m       back_prop\u001b[39m=\u001b[39;49mback_prop)\n\u001b[1;32m   2724\u001b[0m \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mname_scope(name, \u001b[39m\"\u001b[39m\u001b[39mwhile\u001b[39m\u001b[39m\"\u001b[39m, loop_vars):\n\u001b[1;32m   2725\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m loop_vars:\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/ops/while_v2.py:222\u001b[0m, in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, maximum_iterations, name, return_same_structure, back_prop)\u001b[0m\n\u001b[1;32m    218\u001b[0m   \u001b[39m# TODO(srbs): Update lowering code to create _Enter nodes with\u001b[39;00m\n\u001b[1;32m    219\u001b[0m   \u001b[39m# is_constant=True for inputs that are directly passed to outputs.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m   \u001b[39mreturn\u001b[39;00m [loop_counter \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, maximum_iterations_arg] \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(outputs)\n\u001b[0;32m--> 222\u001b[0m body_graph \u001b[39m=\u001b[39m func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[1;32m    223\u001b[0m     body_name,\n\u001b[1;32m    224\u001b[0m     wrapped_body,\n\u001b[1;32m    225\u001b[0m     [],  \u001b[39m# We provide signature instead of args.\u001b[39;49;00m\n\u001b[1;32m    226\u001b[0m     {},\n\u001b[1;32m    227\u001b[0m     signature\u001b[39m=\u001b[39;49mfunc_graph_signature,\n\u001b[1;32m    228\u001b[0m     func_graph\u001b[39m=\u001b[39;49mutil\u001b[39m.\u001b[39;49mWhileBodyFuncGraph(\n\u001b[1;32m    229\u001b[0m         body_name, collections\u001b[39m=\u001b[39;49mops\u001b[39m.\u001b[39;49mget_default_graph()\u001b[39m.\u001b[39;49m_collections),  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    230\u001b[0m     add_control_dependencies\u001b[39m=\u001b[39;49madd_control_dependencies,\n\u001b[1;32m    231\u001b[0m     acd_record_initial_resource_uses\u001b[39m=\u001b[39;49mstateful_parallelism)\n\u001b[1;32m    232\u001b[0m \u001b[39m# Add external captures of body to the list of loop vars.\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[39m# Note that external tensors will be treated as loop invariants, i.e.,\u001b[39;00m\n\u001b[1;32m    234\u001b[0m \u001b[39m# the value of that tensor in each iteration is the same as it was at the\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[39m# beginning of the loop execution.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m deferred_external_captures \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mflatten(\n\u001b[1;32m    237\u001b[0m     [c() \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m body_graph\u001b[39m.\u001b[39mdeferred_external_captures],\n\u001b[1;32m    238\u001b[0m     expand_composites\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:1247\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1244\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1245\u001b[0m   _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1247\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39;49mfunc_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfunc_kwargs)\n\u001b[1;32m   1249\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1250\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1251\u001b[0m func_outputs \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mmap_structure(\n\u001b[1;32m   1252\u001b[0m     convert, func_outputs, expand_composites\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/ops/while_v2.py:200\u001b[0m, in \u001b[0;36mwhile_loop.<locals>.wrapped_body\u001b[0;34m(loop_counter, maximum_iterations_arg, *args)\u001b[0m\n\u001b[1;32m    193\u001b[0m   ops\u001b[39m.\u001b[39mget_default_graph()\u001b[39m.\u001b[39mcapture(t)\n\u001b[1;32m    195\u001b[0m \u001b[39m# Convert the flow variables in `args` to TensorArrays. `args` should\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[39m# already have the same structure as `orig_loop_vars` but currently there\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[39m# is no nest.zip so we call `_pack_sequence_as` which flattens `args`,\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# converts flows in `args` to TensorArrays and packs it into the\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# structure of `loop_vars_signature`.\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m outputs \u001b[39m=\u001b[39m body(\n\u001b[1;32m    201\u001b[0m     \u001b[39m*\u001b[39;49m_pack_sequence_as(loop_vars_signature, flat_orig_loop_vars, args))\n\u001b[1;32m    202\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m nest\u001b[39m.\u001b[39mis_nested(outputs):\n\u001b[1;32m    203\u001b[0m   outputs \u001b[39m=\u001b[39m [outputs]\n",
            "File \u001b[0;32m/tmp/__autograph_generated_file9kvgam8p.py:268\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__dynamic_decode.<locals>.body\u001b[0;34m(time, outputs_ta, state, inputs, finished, sequence_lengths)\u001b[0m\n\u001b[1;32m    266\u001b[0m do_return_4 \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    267\u001b[0m retval__4 \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mUndefinedReturnValue()\n\u001b[0;32m--> 268\u001b[0m (next_outputs, decoder_state, next_inputs, decoder_finished) \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(decoder)\u001b[39m.\u001b[39;49mstep, (ag__\u001b[39m.\u001b[39;49mld(time), ag__\u001b[39m.\u001b[39;49mld(inputs), ag__\u001b[39m.\u001b[39;49mld(state), ag__\u001b[39m.\u001b[39;49mld(training)), \u001b[39mNone\u001b[39;49;00m, fscope_4)\n\u001b[1;32m    269\u001b[0m decoder_state_sequence_lengths \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_state_10\u001b[39m():\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:441\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39;49meffective_args)\n\u001b[1;32m    442\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    443\u001b[0m   _attach_error_metadata(e, converted_f)\n",
            "File \u001b[0;32m/tmp/__autograph_generated_filev4zv8ykv.py:21\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__step\u001b[0;34m(self, time, inputs, state, training)\u001b[0m\n\u001b[1;32m     19\u001b[0m do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     20\u001b[0m retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mUndefinedReturnValue()\n\u001b[0;32m---> 21\u001b[0m (cell_outputs, cell_state) \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mcell, (ag__\u001b[39m.\u001b[39;49mld(inputs), ag__\u001b[39m.\u001b[39;49mld(state)), \u001b[39mdict\u001b[39;49m(training\u001b[39m=\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(training)), fscope)\n\u001b[1;32m     22\u001b[0m cell_state \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mpack_sequence_as, (ag__\u001b[39m.\u001b[39mld(state), ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten, (ag__\u001b[39m.\u001b[39mld(cell_state),), \u001b[39mNone\u001b[39;00m, fscope)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     24\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_state\u001b[39m():\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    374\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    376\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39muser_requested \u001b[39mand\u001b[39;00m conversion\u001b[39m.\u001b[39mis_allowlisted(f):\n\u001b[0;32m--> 377\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    379\u001b[0m \u001b[39m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[39m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[39m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[39m# things like builtins.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39minternal_convert_user_code:\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:458\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    455\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    457\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 458\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    459\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/base_layer.py:1097\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1092\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[1;32m   1094\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object\n\u001b[1;32m   1096\u001b[0m ):\n\u001b[0;32m-> 1097\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1099\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[1;32m   1100\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    688\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 689\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[1;32m    690\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    691\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:427\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    426\u001b[0m   program_ctx \u001b[39m=\u001b[39m converter\u001b[39m.\u001b[39mProgramContext(options\u001b[39m=\u001b[39moptions)\n\u001b[0;32m--> 427\u001b[0m   converted_f \u001b[39m=\u001b[39m _convert_actual(target_entity, program_ctx)\n\u001b[1;32m    428\u001b[0m   \u001b[39mif\u001b[39;00m logging\u001b[39m.\u001b[39mhas_verbosity(\u001b[39m2\u001b[39m):\n\u001b[1;32m    429\u001b[0m     _log_callargs(converted_f, effective_args, kwargs)\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:269\u001b[0m, in \u001b[0;36m_convert_actual\u001b[0;34m(entity, program_ctx)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(entity, \u001b[39m'\u001b[39m\u001b[39m__code__\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    265\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mCannot apply autograph to a function that doesn\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39mt \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    266\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39mexpose a __code__ object. If this is a @tf.function,\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    267\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39m try passing f.python_function instead.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 269\u001b[0m transformed, module, source_map \u001b[39m=\u001b[39m _TRANSPILER\u001b[39m.\u001b[39;49mtransform(entity, program_ctx)\n\u001b[1;32m    271\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(transformed, \u001b[39m'\u001b[39m\u001b[39mag_module\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    272\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(transformed, \u001b[39m'\u001b[39m\u001b[39mag_source_map\u001b[39m\u001b[39m'\u001b[39m)\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/transpiler.py:282\u001b[0m, in \u001b[0;36mGenericTranspiler.transform\u001b[0;34m(self, obj, user_context)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[39m\"\"\"Transforms a Python object.\u001b[39;00m\n\u001b[1;32m    268\u001b[0m \n\u001b[1;32m    269\u001b[0m \u001b[39mUsers typically call this method.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[39m  NotImplementedError: if the type of obj is not handled.\u001b[39;00m\n\u001b[1;32m    280\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    281\u001b[0m \u001b[39mif\u001b[39;00m inspect\u001b[39m.\u001b[39misfunction(obj) \u001b[39mor\u001b[39;00m inspect\u001b[39m.\u001b[39mismethod(obj):\n\u001b[0;32m--> 282\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform_function(obj, user_context)\n\u001b[1;32m    284\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mNon-function: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mtype\u001b[39m(obj)))\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/transpiler.py:466\u001b[0m, in \u001b[0;36mPyToPy.transform_function\u001b[0;34m(self, fn, user_context)\u001b[0m\n\u001b[1;32m    464\u001b[0m logging\u001b[39m.\u001b[39mlog(\u001b[39m1\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is not cached for subkey \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m, fn, cache_subkey)\n\u001b[1;32m    465\u001b[0m \u001b[39m# TODO(mdan): Confusing overloading pattern. Fix.\u001b[39;00m\n\u001b[0;32m--> 466\u001b[0m nodes, ctx \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m(PyToPy, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mtransform_function(fn, user_context)\n\u001b[1;32m    468\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(nodes, gast\u001b[39m.\u001b[39mLambda):\n\u001b[1;32m    469\u001b[0m   nodes \u001b[39m=\u001b[39m gast\u001b[39m.\u001b[39mAssign(\n\u001b[1;32m    470\u001b[0m       targets\u001b[39m=\u001b[39m[\n\u001b[1;32m    471\u001b[0m           gast\u001b[39m.\u001b[39mName(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    476\u001b[0m       ],\n\u001b[1;32m    477\u001b[0m       value\u001b[39m=\u001b[39mnodes)\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/transpiler.py:359\u001b[0m, in \u001b[0;36mGenericTranspiler.transform_function\u001b[0;34m(self, fn, user_context)\u001b[0m\n\u001b[1;32m    356\u001b[0m context \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mContext(entity_info, namer, user_context)\n\u001b[1;32m    358\u001b[0m node \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_erase_arg_defaults(node)\n\u001b[0;32m--> 359\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform_ast(node, context)\n\u001b[1;32m    361\u001b[0m \u001b[39mreturn\u001b[39;00m result, context\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:252\u001b[0m, in \u001b[0;36mPyToTF.transform_ast\u001b[0;34m(self, node, ctx)\u001b[0m\n\u001b[1;32m    250\u001b[0m   node \u001b[39m=\u001b[39m lists\u001b[39m.\u001b[39mtransform(node, ctx)\n\u001b[1;32m    251\u001b[0m   node \u001b[39m=\u001b[39m slices\u001b[39m.\u001b[39mtransform(node, ctx)\n\u001b[0;32m--> 252\u001b[0m node \u001b[39m=\u001b[39m call_trees\u001b[39m.\u001b[39;49mtransform(node, ctx)\n\u001b[1;32m    253\u001b[0m node \u001b[39m=\u001b[39m control_flow\u001b[39m.\u001b[39mtransform(node, ctx)\n\u001b[1;32m    254\u001b[0m node \u001b[39m=\u001b[39m conditional_expressions\u001b[39m.\u001b[39mtransform(node, ctx)\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/converters/call_trees.py:220\u001b[0m, in \u001b[0;36mtransform\u001b[0;34m(node, ctx)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[39m\"\"\"Transform function call to the compiled counterparts.\u001b[39;00m\n\u001b[1;32m    209\u001b[0m \n\u001b[1;32m    210\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[39m      new_names: set(string), containing any newly-generated names\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    218\u001b[0m node \u001b[39m=\u001b[39m qual_names\u001b[39m.\u001b[39mresolve(node)\n\u001b[0;32m--> 220\u001b[0m node \u001b[39m=\u001b[39m CallTreeTransformer(ctx)\u001b[39m.\u001b[39;49mvisit(node)\n\u001b[1;32m    221\u001b[0m \u001b[39mreturn\u001b[39;00m node\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/core/converter.py:314\u001b[0m, in \u001b[0;36mBase.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ast_depth \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    313\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 314\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(Base, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mvisit(node)\n\u001b[1;32m    315\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    316\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ast_depth \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/transformer.py:441\u001b[0m, in \u001b[0;36mBase.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[39mif\u001b[39;00m processing_expr_node:\n\u001b[1;32m    439\u001b[0m   entry_expr_value \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39mvalue\n\u001b[0;32m--> 441\u001b[0m result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m(Base, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mvisit(node)\n\u001b[1;32m    443\u001b[0m \u001b[39m# Adjust for consistency: replacing the value of an Expr with\u001b[39;00m\n\u001b[1;32m    444\u001b[0m \u001b[39m# an Assign node removes the need for the Expr node.\u001b[39;00m\n\u001b[1;32m    445\u001b[0m \u001b[39mif\u001b[39;00m (processing_expr_node \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(result, gast\u001b[39m.\u001b[39mExpr) \u001b[39mand\u001b[39;00m\n\u001b[1;32m    446\u001b[0m     (result\u001b[39m.\u001b[39mvalue \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m entry_expr_value)):\n\u001b[1;32m    447\u001b[0m   \u001b[39m# When the replacement is a list, it is assumed that the list came\u001b[39;00m\n\u001b[1;32m    448\u001b[0m   \u001b[39m# from a template that contained a number of statements, which\u001b[39;00m\n\u001b[1;32m    449\u001b[0m   \u001b[39m# themselves are standalone and don't require an enclosing Expr.\u001b[39;00m\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/ast.py:407\u001b[0m, in \u001b[0;36mNodeVisitor.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    405\u001b[0m method \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mvisit_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m node\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[1;32m    406\u001b[0m visitor \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, method, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgeneric_visit)\n\u001b[0;32m--> 407\u001b[0m \u001b[39mreturn\u001b[39;00m visitor(node)\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/converters/call_trees.py:117\u001b[0m, in \u001b[0;36mCallTreeTransformer.visit_FunctionDef\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[39massert\u001b[39;00m anno\u001b[39m.\u001b[39mhasanno(node, \u001b[39m'\u001b[39m\u001b[39mfunction_context_name\u001b[39m\u001b[39m'\u001b[39m), (\n\u001b[1;32m    115\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mThe function_scopes converter always creates a scope for functions.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    116\u001b[0m fn_scope\u001b[39m.\u001b[39mcontext_name \u001b[39m=\u001b[39m anno\u001b[39m.\u001b[39mgetanno(node, \u001b[39m'\u001b[39m\u001b[39mfunction_context_name\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 117\u001b[0m node\u001b[39m.\u001b[39mbody \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit_block(node\u001b[39m.\u001b[39;49mbody)\n\u001b[1;32m    118\u001b[0m \u001b[39mif\u001b[39;00m node\u001b[39m.\u001b[39mreturns:\n\u001b[1;32m    119\u001b[0m   node\u001b[39m.\u001b[39mreturns \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvisit(node\u001b[39m.\u001b[39mreturns)\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/transformer.py:336\u001b[0m, in \u001b[0;36mNodeStateTracker.visit_block\u001b[0;34m(self, nodes, before_visit, after_visit)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[39mif\u001b[39;00m before_visit:\n\u001b[1;32m    333\u001b[0m   \u001b[39m# TODO(mdan): We can modify node here too, if ever needed.\u001b[39;00m\n\u001b[1;32m    334\u001b[0m   before_visit()\n\u001b[0;32m--> 336\u001b[0m replacement \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit(node)\n\u001b[1;32m    338\u001b[0m \u001b[39mif\u001b[39;00m after_visit \u001b[39mand\u001b[39;00m replacement:\n\u001b[1;32m    339\u001b[0m   replacement, new_destination \u001b[39m=\u001b[39m after_visit(replacement)\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/core/converter.py:314\u001b[0m, in \u001b[0;36mBase.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ast_depth \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    313\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 314\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(Base, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mvisit(node)\n\u001b[1;32m    315\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    316\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ast_depth \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/transformer.py:441\u001b[0m, in \u001b[0;36mBase.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[39mif\u001b[39;00m processing_expr_node:\n\u001b[1;32m    439\u001b[0m   entry_expr_value \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39mvalue\n\u001b[0;32m--> 441\u001b[0m result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m(Base, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mvisit(node)\n\u001b[1;32m    443\u001b[0m \u001b[39m# Adjust for consistency: replacing the value of an Expr with\u001b[39;00m\n\u001b[1;32m    444\u001b[0m \u001b[39m# an Assign node removes the need for the Expr node.\u001b[39;00m\n\u001b[1;32m    445\u001b[0m \u001b[39mif\u001b[39;00m (processing_expr_node \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(result, gast\u001b[39m.\u001b[39mExpr) \u001b[39mand\u001b[39;00m\n\u001b[1;32m    446\u001b[0m     (result\u001b[39m.\u001b[39mvalue \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m entry_expr_value)):\n\u001b[1;32m    447\u001b[0m   \u001b[39m# When the replacement is a list, it is assumed that the list came\u001b[39;00m\n\u001b[1;32m    448\u001b[0m   \u001b[39m# from a template that contained a number of statements, which\u001b[39;00m\n\u001b[1;32m    449\u001b[0m   \u001b[39m# themselves are standalone and don't require an enclosing Expr.\u001b[39;00m\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/ast.py:407\u001b[0m, in \u001b[0;36mNodeVisitor.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    405\u001b[0m method \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mvisit_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m node\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[1;32m    406\u001b[0m visitor \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, method, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgeneric_visit)\n\u001b[0;32m--> 407\u001b[0m \u001b[39mreturn\u001b[39;00m visitor(node)\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/converters/call_trees.py:124\u001b[0m, in \u001b[0;36mCallTreeTransformer.visit_With\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvisit_With\u001b[39m(\u001b[39mself\u001b[39m, node):\n\u001b[1;32m    123\u001b[0m   \u001b[39m# Context manager calls (in node.items) are not converted.\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m   node\u001b[39m.\u001b[39mbody \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit_block(node\u001b[39m.\u001b[39;49mbody)\n\u001b[1;32m    125\u001b[0m   \u001b[39mreturn\u001b[39;00m node\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/transformer.py:336\u001b[0m, in \u001b[0;36mNodeStateTracker.visit_block\u001b[0;34m(self, nodes, before_visit, after_visit)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[39mif\u001b[39;00m before_visit:\n\u001b[1;32m    333\u001b[0m   \u001b[39m# TODO(mdan): We can modify node here too, if ever needed.\u001b[39;00m\n\u001b[1;32m    334\u001b[0m   before_visit()\n\u001b[0;32m--> 336\u001b[0m replacement \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit(node)\n\u001b[1;32m    338\u001b[0m \u001b[39mif\u001b[39;00m after_visit \u001b[39mand\u001b[39;00m replacement:\n\u001b[1;32m    339\u001b[0m   replacement, new_destination \u001b[39m=\u001b[39m after_visit(replacement)\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/core/converter.py:314\u001b[0m, in \u001b[0;36mBase.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ast_depth \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    313\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 314\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(Base, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mvisit(node)\n\u001b[1;32m    315\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    316\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ast_depth \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/transformer.py:441\u001b[0m, in \u001b[0;36mBase.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[39mif\u001b[39;00m processing_expr_node:\n\u001b[1;32m    439\u001b[0m   entry_expr_value \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39mvalue\n\u001b[0;32m--> 441\u001b[0m result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m(Base, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mvisit(node)\n\u001b[1;32m    443\u001b[0m \u001b[39m# Adjust for consistency: replacing the value of an Expr with\u001b[39;00m\n\u001b[1;32m    444\u001b[0m \u001b[39m# an Assign node removes the need for the Expr node.\u001b[39;00m\n\u001b[1;32m    445\u001b[0m \u001b[39mif\u001b[39;00m (processing_expr_node \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(result, gast\u001b[39m.\u001b[39mExpr) \u001b[39mand\u001b[39;00m\n\u001b[1;32m    446\u001b[0m     (result\u001b[39m.\u001b[39mvalue \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m entry_expr_value)):\n\u001b[1;32m    447\u001b[0m   \u001b[39m# When the replacement is a list, it is assumed that the list came\u001b[39;00m\n\u001b[1;32m    448\u001b[0m   \u001b[39m# from a template that contained a number of statements, which\u001b[39;00m\n\u001b[1;32m    449\u001b[0m   \u001b[39m# themselves are standalone and don't require an enclosing Expr.\u001b[39;00m\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/ast.py:407\u001b[0m, in \u001b[0;36mNodeVisitor.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    405\u001b[0m method \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mvisit_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m node\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[1;32m    406\u001b[0m visitor \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, method, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgeneric_visit)\n\u001b[0;32m--> 407\u001b[0m \u001b[39mreturn\u001b[39;00m visitor(node)\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/ast.py:483\u001b[0m, in \u001b[0;36mNodeTransformer.generic_visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[39mfor\u001b[39;00m value \u001b[39min\u001b[39;00m old_value:\n\u001b[1;32m    482\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, AST):\n\u001b[0;32m--> 483\u001b[0m         value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit(value)\n\u001b[1;32m    484\u001b[0m         \u001b[39mif\u001b[39;00m value \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    485\u001b[0m             \u001b[39mcontinue\u001b[39;00m\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/core/converter.py:314\u001b[0m, in \u001b[0;36mBase.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ast_depth \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    313\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 314\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(Base, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mvisit(node)\n\u001b[1;32m    315\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    316\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ast_depth \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/transformer.py:441\u001b[0m, in \u001b[0;36mBase.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[39mif\u001b[39;00m processing_expr_node:\n\u001b[1;32m    439\u001b[0m   entry_expr_value \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39mvalue\n\u001b[0;32m--> 441\u001b[0m result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m(Base, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mvisit(node)\n\u001b[1;32m    443\u001b[0m \u001b[39m# Adjust for consistency: replacing the value of an Expr with\u001b[39;00m\n\u001b[1;32m    444\u001b[0m \u001b[39m# an Assign node removes the need for the Expr node.\u001b[39;00m\n\u001b[1;32m    445\u001b[0m \u001b[39mif\u001b[39;00m (processing_expr_node \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(result, gast\u001b[39m.\u001b[39mExpr) \u001b[39mand\u001b[39;00m\n\u001b[1;32m    446\u001b[0m     (result\u001b[39m.\u001b[39mvalue \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m entry_expr_value)):\n\u001b[1;32m    447\u001b[0m   \u001b[39m# When the replacement is a list, it is assumed that the list came\u001b[39;00m\n\u001b[1;32m    448\u001b[0m   \u001b[39m# from a template that contained a number of statements, which\u001b[39;00m\n\u001b[1;32m    449\u001b[0m   \u001b[39m# themselves are standalone and don't require an enclosing Expr.\u001b[39;00m\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/ast.py:407\u001b[0m, in \u001b[0;36mNodeVisitor.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    405\u001b[0m method \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mvisit_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m node\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[1;32m    406\u001b[0m visitor \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, method, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgeneric_visit)\n\u001b[0;32m--> 407\u001b[0m \u001b[39mreturn\u001b[39;00m visitor(node)\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/ast.py:492\u001b[0m, in \u001b[0;36mNodeTransformer.generic_visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    490\u001b[0m     old_value[:] \u001b[39m=\u001b[39m new_values\n\u001b[1;32m    491\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(old_value, AST):\n\u001b[0;32m--> 492\u001b[0m     new_node \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit(old_value)\n\u001b[1;32m    493\u001b[0m     \u001b[39mif\u001b[39;00m new_node \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    494\u001b[0m         \u001b[39mdelattr\u001b[39m(node, field)\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/core/converter.py:314\u001b[0m, in \u001b[0;36mBase.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ast_depth \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    313\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 314\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(Base, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mvisit(node)\n\u001b[1;32m    315\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    316\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ast_depth \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/transformer.py:441\u001b[0m, in \u001b[0;36mBase.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[39mif\u001b[39;00m processing_expr_node:\n\u001b[1;32m    439\u001b[0m   entry_expr_value \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39mvalue\n\u001b[0;32m--> 441\u001b[0m result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m(Base, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mvisit(node)\n\u001b[1;32m    443\u001b[0m \u001b[39m# Adjust for consistency: replacing the value of an Expr with\u001b[39;00m\n\u001b[1;32m    444\u001b[0m \u001b[39m# an Assign node removes the need for the Expr node.\u001b[39;00m\n\u001b[1;32m    445\u001b[0m \u001b[39mif\u001b[39;00m (processing_expr_node \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(result, gast\u001b[39m.\u001b[39mExpr) \u001b[39mand\u001b[39;00m\n\u001b[1;32m    446\u001b[0m     (result\u001b[39m.\u001b[39mvalue \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m entry_expr_value)):\n\u001b[1;32m    447\u001b[0m   \u001b[39m# When the replacement is a list, it is assumed that the list came\u001b[39;00m\n\u001b[1;32m    448\u001b[0m   \u001b[39m# from a template that contained a number of statements, which\u001b[39;00m\n\u001b[1;32m    449\u001b[0m   \u001b[39m# themselves are standalone and don't require an enclosing Expr.\u001b[39;00m\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/ast.py:407\u001b[0m, in \u001b[0;36mNodeVisitor.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    405\u001b[0m method \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mvisit_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m node\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[1;32m    406\u001b[0m visitor \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, method, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgeneric_visit)\n\u001b[0;32m--> 407\u001b[0m \u001b[39mreturn\u001b[39;00m visitor(node)\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/converters/call_trees.py:197\u001b[0m, in \u001b[0;36mCallTreeTransformer.visit_Call\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    192\u001b[0m   \u001b[39mreturn\u001b[39;00m node\n\u001b[1;32m    194\u001b[0m template \u001b[39m=\u001b[39m \u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m    195\u001b[0m \u001b[39m  ag__.converted_call(func, args, kwargs, function_ctx)\u001b[39m\n\u001b[1;32m    196\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39m\n\u001b[0;32m--> 197\u001b[0m new_call \u001b[39m=\u001b[39m templates\u001b[39m.\u001b[39;49mreplace_as_expression(\n\u001b[1;32m    198\u001b[0m     template,\n\u001b[1;32m    199\u001b[0m     func\u001b[39m=\u001b[39;49mnode\u001b[39m.\u001b[39;49mfunc,\n\u001b[1;32m    200\u001b[0m     args\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_args_to_tuple(node),\n\u001b[1;32m    201\u001b[0m     kwargs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_kwargs_to_dict(node),\n\u001b[1;32m    202\u001b[0m     function_ctx\u001b[39m=\u001b[39;49mfunction_context_name)\n\u001b[1;32m    204\u001b[0m \u001b[39mreturn\u001b[39;00m new_call\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/templates.py:277\u001b[0m, in \u001b[0;36mreplace_as_expression\u001b[0;34m(template, **replacements)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreplace_as_expression\u001b[39m(template, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mreplacements):\n\u001b[1;32m    276\u001b[0m   \u001b[39m\"\"\"Variant of replace that generates expressions, instead of code blocks.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 277\u001b[0m   replacement \u001b[39m=\u001b[39m replace(template, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mreplacements)\n\u001b[1;32m    278\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(replacement) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    279\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    280\u001b[0m         \u001b[39m'\u001b[39m\u001b[39msingle expression expected; for more general templates use replace\u001b[39m\u001b[39m'\u001b[39m)\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/templates.py:266\u001b[0m, in \u001b[0;36mreplace\u001b[0;34m(template, **replacements)\u001b[0m\n\u001b[1;32m    264\u001b[0m results \u001b[39m=\u001b[39m []\n\u001b[1;32m    265\u001b[0m \u001b[39mfor\u001b[39;00m node \u001b[39min\u001b[39;00m nodes:\n\u001b[0;32m--> 266\u001b[0m   node \u001b[39m=\u001b[39m ReplaceTransformer(replacements)\u001b[39m.\u001b[39;49mvisit(node)\n\u001b[1;32m    267\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(node, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)):\n\u001b[1;32m    268\u001b[0m     results\u001b[39m.\u001b[39mextend(node)\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/ast.py:407\u001b[0m, in \u001b[0;36mNodeVisitor.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    405\u001b[0m method \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mvisit_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m node\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[1;32m    406\u001b[0m visitor \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, method, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgeneric_visit)\n\u001b[0;32m--> 407\u001b[0m \u001b[39mreturn\u001b[39;00m visitor(node)\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/templates.py:145\u001b[0m, in \u001b[0;36mReplaceTransformer.visit_Expr\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvisit_Expr\u001b[39m(\u001b[39mself\u001b[39m, node):\n\u001b[1;32m    143\u001b[0m   \u001b[39m# When replacing a placeholder with an entire statement, the replacement\u001b[39;00m\n\u001b[1;32m    144\u001b[0m   \u001b[39m# must stand on its own and not be wrapped in an Expr.\u001b[39;00m\n\u001b[0;32m--> 145\u001b[0m   new_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit(node\u001b[39m.\u001b[39;49mvalue)\n\u001b[1;32m    146\u001b[0m   \u001b[39mif\u001b[39;00m new_value \u001b[39mis\u001b[39;00m node\u001b[39m.\u001b[39mvalue:\n\u001b[1;32m    147\u001b[0m     \u001b[39mreturn\u001b[39;00m node\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/ast.py:407\u001b[0m, in \u001b[0;36mNodeVisitor.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    405\u001b[0m method \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mvisit_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m node\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[1;32m    406\u001b[0m visitor \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, method, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgeneric_visit)\n\u001b[0;32m--> 407\u001b[0m \u001b[39mreturn\u001b[39;00m visitor(node)\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/ast.py:483\u001b[0m, in \u001b[0;36mNodeTransformer.generic_visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[39mfor\u001b[39;00m value \u001b[39min\u001b[39;00m old_value:\n\u001b[1;32m    482\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, AST):\n\u001b[0;32m--> 483\u001b[0m         value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit(value)\n\u001b[1;32m    484\u001b[0m         \u001b[39mif\u001b[39;00m value \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    485\u001b[0m             \u001b[39mcontinue\u001b[39;00m\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/ast.py:407\u001b[0m, in \u001b[0;36mNodeVisitor.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    405\u001b[0m method \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mvisit_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m node\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[1;32m    406\u001b[0m visitor \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, method, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgeneric_visit)\n\u001b[0;32m--> 407\u001b[0m \u001b[39mreturn\u001b[39;00m visitor(node)\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/templates.py:197\u001b[0m, in \u001b[0;36mReplaceTransformer.visit_Name\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39mif\u001b[39;00m node\u001b[39m.\u001b[39mid \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreplacements:\n\u001b[1;32m    195\u001b[0m   \u001b[39mreturn\u001b[39;00m node\n\u001b[0;32m--> 197\u001b[0m new_nodes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_prepare_replacement(node, node\u001b[39m.\u001b[39;49mid)\n\u001b[1;32m    199\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m new_nodes:\n\u001b[1;32m    200\u001b[0m   \u001b[39mreturn\u001b[39;00m new_nodes\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/templates.py:136\u001b[0m, in \u001b[0;36mReplaceTransformer._prepare_replacement\u001b[0;34m(self, replaced, key)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[39m\"\"\"Prepares a replacement AST that's safe to swap in for a node.\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \n\u001b[1;32m    128\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[39m  ast.AST, the replacement AST\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    134\u001b[0m repl \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreplacements[key]\n\u001b[0;32m--> 136\u001b[0m new_nodes \u001b[39m=\u001b[39m ast_util\u001b[39m.\u001b[39;49mcopy_clean(repl, preserve_annos\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpreserved_annos)\n\u001b[1;32m    137\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(new_nodes, gast\u001b[39m.\u001b[39mAST):\n\u001b[1;32m    138\u001b[0m   new_nodes \u001b[39m=\u001b[39m [new_nodes]\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/ast_util.py:72\u001b[0m, in \u001b[0;36mcopy_clean\u001b[0;34m(node, preserve_annos)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcopy_clean\u001b[39m(node, preserve_annos\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     60\u001b[0m   \u001b[39m\"\"\"Creates a deep copy of an AST.\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \n\u001b[1;32m     62\u001b[0m \u001b[39m  The copy will not include fields that are prefixed by '__', with the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[39m    ast.AST\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m   \u001b[39mreturn\u001b[39;00m CleanCopier(preserve_annos)\u001b[39m.\u001b[39;49mcopy(node)\n",
            "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/ast_util.py:55\u001b[0m, in \u001b[0;36mCleanCopier.copy\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreserve_annos:\n\u001b[1;32m     54\u001b[0m   \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreserve_annos:\n\u001b[0;32m---> 55\u001b[0m     anno\u001b[39m.\u001b[39;49mcopyanno(node, new_node, k)\n\u001b[1;32m     56\u001b[0m \u001b[39mreturn\u001b[39;00m new_node\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "epochs = 100\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    encoder_hidden_state = encoder.initialize(batch_size=batch_size)\n",
        "    batch = {\n",
        "        'encoder_input_ids': encoded_input_sample,\n",
        "        'encoder_state': encoder_hidden_state,\n",
        "        'decoder_target': encoded_output_sample\n",
        "    }\n",
        "    loss = trainer.batch_fit(batch)\n",
        "    print(f'Loss - {loss}')\n",
        "\n",
        "    generated = trainer.generate(input_ids=encoded_input_sample)\n",
        "    translated = trainer.translate(generated)\n",
        "    print(f'Translated - {translated}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Akd5eb5N1mPh"
      },
      "outputs": [],
      "source": [
        "#TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ia7JgdiF1mPh"
      },
      "source": [
        "### Seq2Seq Bert-Tiny"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tIz7Z9QV1mPh"
      },
      "outputs": [],
      "source": [
        "class MyTrainer(object):\n",
        "    \"\"\"\n",
        "    Simple wrapper class\n",
        "\n",
        "    train_op -> uses tf.GradientTape to compute the loss\n",
        "    batch_fit -> receives a batch and performs forward-backward passes (gradient included)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, encoder, decoder, max_length):\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.max_length = max_length\n",
        "        self.ce = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=1e-03)\n",
        "\n",
        "    @tf.function\n",
        "    def compute_loss(self, logits, target):\n",
        "        loss = self.ce(y_true=target, y_pred=logits)\n",
        "        mask = tf.logical_not(tf.math.equal(target, 0))\n",
        "        mask = tf.cast(mask, dtype=loss.dtype)\n",
        "        loss *= mask\n",
        "        return tf.reduce_mean(loss)\n",
        "\n",
        "    @tf.function\n",
        "    def train_op(self, inputs):\n",
        "        with tf.GradientTape() as tape:\n",
        "            encoder_output, encoder_h, encoder_s = self.encoder({'input_ids': inputs['encoder_input_ids'],\n",
        "                                                                 'attention_mask': inputs['encoder_attention_mask']})\n",
        "\n",
        "            decoder_input = inputs['decoder_target'][:, :-1]  # ignore <end>\n",
        "            real_target = inputs['decoder_target'][:, 1:]  # ignore <start>\n",
        "\n",
        "            decoder.attention.setup_memory(encoder_output)\n",
        "\n",
        "            decoder_initial_state = self.decoder.build_initial_state(decoder.batch_size, [encoder_h, encoder_s])\n",
        "            predicted = self.decoder({'input_ids': decoder_input,\n",
        "                                      'initial_state': decoder_initial_state}).rnn_output\n",
        "\n",
        "            loss = self.compute_loss(logits=predicted, target=real_target)\n",
        "\n",
        "        grads = tape.gradient(loss, self.encoder.trainable_variables + self.decoder.trainable_variables)\n",
        "        return loss, grads\n",
        "\n",
        "    @tf.function\n",
        "    def batch_fit(self, inputs):\n",
        "        loss, grads = self.train_op(inputs=inputs)\n",
        "        self.optimizer.apply_gradients(zip(grads, self.encoder.trainable_variables + self.decoder.trainable_variables))\n",
        "        return loss\n",
        "\n",
        "    # @tf.function\n",
        "    def generate(self, input_ids, attention_mask=None):\n",
        "        batch_size = input_ids.shape[0]\n",
        "        encoder_output, encoder_h, encoder_s = self.encoder({\n",
        "            'input_ids': input_ids,\n",
        "            'attention_mask': attention_mask\n",
        "        })\n",
        "\n",
        "        start_tokens = tf.fill([batch_size], output_tokenizer.word_index['<start>'])\n",
        "        end_token = output_tokenizer.word_index['<end>']\n",
        "\n",
        "        greedy_sampler = tfa.seq2seq.GreedyEmbeddingSampler()\n",
        "        decoder_instance = tfa.seq2seq.BasicDecoder(cell=self.decoder.wrapped_decoder_cell,\n",
        "                                                    sampler=greedy_sampler,\n",
        "                                                    output_layer=self.decoder.generation_dense,\n",
        "                                                    maximum_iterations=self.max_length)\n",
        "        self.decoder.attention.setup_memory(encoder_output)\n",
        "\n",
        "        decoder_initial_state = self.decoder.build_initial_state(batch_size, [encoder_h, encoder_s])\n",
        "        decoder_embedding_matrix = self.decoder.embedding.variables[0]\n",
        "        outputs, _, _ = decoder_instance(decoder_embedding_matrix,\n",
        "                                         start_tokens=start_tokens,\n",
        "                                         end_token=end_token,\n",
        "                                         initial_state=decoder_initial_state)\n",
        "        return outputs\n",
        "\n",
        "    def translate(self, generated):\n",
        "        return output_tokenizer.sequences_to_texts(generated.sample_id.numpy())\n",
        "\n",
        "\n",
        "class Encoder(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, model_name, decoder_units):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.model = TFAutoModel.from_pretrained(model_name, from_pt=True)\n",
        "        self.reducer = tf.keras.layers.Dense(decoder_units)\n",
        "\n",
        "    def call(self, inputs, training=False, **kwargs):\n",
        "        model_output = self.model(inputs)\n",
        "        all_outputs = model_output[0]\n",
        "        pooled_output = model_output[1]\n",
        "        pooled_output = self.reducer(pooled_output)\n",
        "        return all_outputs, pooled_output, pooled_output\n",
        "\n",
        "\n",
        "class Decoder(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, vocab_size, max_sequence_length, embedding_dim, decoder_units, batch_size):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.max_sequence_length = max_sequence_length\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.decoder_units = decoder_units\n",
        "        self.embedding = tf.keras.layers.Embedding(input_dim=vocab_size,\n",
        "                                                   output_dim=embedding_dim)\n",
        "        self.decoder_lstm_cell = tf.keras.layers.LSTMCell(self.decoder_units)\n",
        "\n",
        "        self.attention = tfa.seq2seq.BahdanauAttention(units=self.decoder_units,\n",
        "                                                       memory=None,\n",
        "                                                       memory_sequence_length=self.batch_size * [max_sequence_length])\n",
        "\n",
        "        self.wrapped_decoder_cell = tfa.seq2seq.AttentionWrapper(self.decoder_lstm_cell,\n",
        "                                                                 self.attention,\n",
        "                                                                 attention_layer_size=self.decoder_units)\n",
        "\n",
        "        self.generation_dense = tf.keras.layers.Dense(vocab_size)\n",
        "        self.sampler = tfa.seq2seq.sampler.TrainingSampler()\n",
        "        self.decoder = tfa.seq2seq.BasicDecoder(self.wrapped_decoder_cell,\n",
        "                                                sampler=self.sampler,\n",
        "                                                output_layer=self.generation_dense)\n",
        "\n",
        "    def build_initial_state(self, batch_size, encoder_state):\n",
        "        initial_state = self.wrapped_decoder_cell.get_initial_state(batch_size=batch_size, dtype=tf.float32)\n",
        "        initial_state = initial_state.clone(cell_state=encoder_state)\n",
        "        return initial_state\n",
        "\n",
        "    def call(self, inputs, training=False, **kwargs):\n",
        "        input_ids = inputs['input_ids']\n",
        "        input_emb = self.embedding(input_ids)\n",
        "        decoder_output, _, _ = self.decoder(input_emb,\n",
        "                                            initial_state=inputs['initial_state'],\n",
        "                                            sequence_length=self.batch_size * [self.max_sequence_length - 1])\n",
        "        return decoder_output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vV1rlQqR1mPi"
      },
      "outputs": [],
      "source": [
        "from transformers import BertForQuestionAnswering, AutoTokenizer, AutoConfig\n",
        "\n",
        "model_name = 'prajjwal1/bert-tiny'\n",
        "\n",
        "#config = AutoConfig.from_pretrained(model_name)\n",
        "#model = BertForQuestionAnswering.from_pretrained(model_name, config=config)\n",
        "input_tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kswqcr_m1mPi"
      },
      "source": [
        "The next block of code is an example of encoding of a question-context pair: in this case, the question is the first part of the encoding, and the context is the second part. There are two special tokens: [CLS] token at the start of the encoding, [SEP] token between the question and the context, and at the end of the encoding.\n",
        "\n",
        "In this case the context is the *span*, to provide a better example that explains the encoding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxqLjPlL1mPi",
        "outputId": "8b7d0cea-e17f-44ac-abb6-290888dc468a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Was Lassiter impressed with the horse?\n",
            "When Jerd led out this slender, beautifully built horse Lassiter suddenly became all eyes.\n",
            "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
            "101\t[CLS]\n",
            "2001\twas\n",
            "27333\tlass\n",
            "21646\t##iter\n",
            "7622\timpressed\n",
            "2007\twith\n",
            "1996\tthe\n",
            "3586\thorse\n",
            "1029\t?\n",
            "102\t[SEP]\n",
            "2043\twhen\n",
            "15333\tje\n",
            "4103\t##rd\n",
            "2419\tled\n",
            "2041\tout\n",
            "2023\tthis\n",
            "10944\tslender\n",
            "1010\t,\n",
            "17950\tbeautifully\n",
            "2328\tbuilt\n",
            "3586\thorse\n",
            "27333\tlass\n",
            "21646\t##iter\n",
            "3402\tsuddenly\n",
            "2150\tbecame\n",
            "2035\tall\n",
            "2159\teyes\n",
            "1012\t.\n",
            "102\t[SEP]\n"
          ]
        }
      ],
      "source": [
        "line = 42\n",
        "\n",
        "encoded_question = input_tokenizer(train_df['q'][line], return_tensors='tf', padding=True)\n",
        "print(train_df['q'][line])\n",
        "\n",
        "encoded_span = input_tokenizer(train_df['span'][line], return_tensors='tf', padding=True)\n",
        "print(train_df['span'][line])\n",
        "\n",
        "encoded_qs = input_tokenizer(train_df['q'][line], train_df['span'][line], return_tensors='tf', padding=True)\n",
        "\n",
        "print('= '*40)\n",
        "for idx, tok in zip(encoded_qs.input_ids.numpy()[0], input_tokenizer.convert_ids_to_tokens(encoded_qs.input_ids[0])):\n",
        "    print(\"{}\\t{}\".format(idx, tok))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYZk4xQk1mPi"
      },
      "source": [
        "Lets encode a part of the dataset in sentences of: [CLS] question [SEP] passage [SEP]. Otherwise, the training would be very slow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xBycfrq51mPj"
      },
      "outputs": [],
      "source": [
        "max_length = 512  # The maximum length of a feature (question and context)\n",
        "doc_stride = (\n",
        "    128  # The authorized overlap between two part of the context when splitting\n",
        ")\n",
        "sentences = 20\n",
        "sample = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZhjywqdM1mPj"
      },
      "outputs": [],
      "source": [
        "# Input\n",
        "qs = train_df['q'][range(sentences)] # questions\n",
        "cs = train_df['p'][range(sentences)] # contexts\n",
        "\n",
        "batch_size = len(qs)\n",
        "\n",
        "encoded_inputs = input_tokenizer(\n",
        "    qs.values.tolist(),\n",
        "    cs.values.tolist(),\n",
        "    #train_df['q'].values.tolist(),\n",
        "    #train_df['p'].values.tolist(),\n",
        "    truncation=\"only_second\",\n",
        "    max_length=max_length,\n",
        "    stride=doc_stride,\n",
        "    return_overflowing_tokens=True,\n",
        "    return_offsets_mapping=True,\n",
        "    padding=\"max_length\",\n",
        "    return_tensors='tf'\n",
        ")\n",
        "\n",
        "input_ids, attention_mask = encoded_inputs.input_ids, encoded_inputs.attention_mask\n",
        "max_input_length = input_ids.shape[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "emIgycXc1mPk",
        "outputId": "c171e250-6167-456b-deb7-761b923cbcce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "max_input_length: 512\n",
            "encoded_inputs shape = (20, 512)\n"
          ]
        }
      ],
      "source": [
        "print(\"max_input_length:\", max_input_length)\n",
        "print(\"encoded_inputs shape =\", encoded_inputs['input_ids'].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cpxq9qK1mPl"
      },
      "source": [
        "The 'token_type_ids' encodes wether the encoded id is part of the question (=0) or the context (=1). The Attention Mask indicates if the input is needed (=1) or it's padding (=0)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIGwPsUg1mPm"
      },
      "source": [
        "Prepare also the expected outputs, for the training (this code follows the example given by the tutors, but I'm not convinced that this is the proper formatting for a QA Bert model)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "APmOG4gv1mPm",
        "outputId": "77cb34f3-579d-4a83-d2d7-065f8cb61331"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2, 30, 5, 31, 10, 5, 32, 33, 3]\n"
          ]
        }
      ],
      "source": [
        "# Output\n",
        "outputs = \"<start> \" + train_df['a'][range(sentences)] + \" <end>\"\n",
        "\n",
        "output_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='', oov_token='<UNK>')\n",
        "output_tokenizer.fit_on_texts(outputs)\n",
        "\n",
        "output_vocab_size = len(output_tokenizer.word_index) + 1\n",
        "\n",
        "encoded_output = output_tokenizer.texts_to_sequences(outputs)\n",
        "print(encoded_output[sample])\n",
        "max_output_length = max([len(item) for item in encoded_output])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4wdmkDs1mPn",
        "outputId": "17d82207-b850-4b54-f679-e886186ee5c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "max_output_length: 11\n",
            "max_sequence_length: 512\n"
          ]
        }
      ],
      "source": [
        "max_sequence_length = max(max_input_length, max_output_length)\n",
        "\n",
        "print(\"max_output_length: {}\".format(max_output_length))\n",
        "print(\"max_sequence_length: {}\".format(max_sequence_length))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cNunTdpj1mPn",
        "outputId": "341ad36a-a211-4744-818d-8c4785f05a5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 2 30  5 31 10  5 32 33  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0]\n"
          ]
        }
      ],
      "source": [
        "encoded_output = tf.keras.preprocessing.sequence.pad_sequences(encoded_output,\n",
        "                                                                        padding='post',\n",
        "                                                                        maxlen=max_sequence_length)\n",
        "print(encoded_output[sample])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-G1IKYO61mPo",
        "outputId": "51413bbc-b166-4320-8cbb-11d6ef001804"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'bert.embeddings.position_ids']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(20, 512, 128) - (20, 16) - (20, 16)\n"
          ]
        }
      ],
      "source": [
        "# Test encoder\n",
        "encoder = Encoder(model_name=model_name,\n",
        "                    decoder_units=16)\n",
        "encoder_output, encoder_h, encoder_s = encoder({'input_ids': input_ids,\n",
        "                                                'attention_mask': attention_mask})\n",
        "print(f'{encoder_output.shape} - {encoder_h.shape} - {encoder_s.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zkKbWjm11mPo",
        "outputId": "b0e3ad8e-c144-4efd-a827-7c97d69e1f85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(20, 511, 63)\n"
          ]
        }
      ],
      "source": [
        "# Test decoder\n",
        "decoder = Decoder(vocab_size=output_vocab_size,\n",
        "                    embedding_dim=50,\n",
        "                    decoder_units=16,\n",
        "                    batch_size=batch_size,\n",
        "                    max_sequence_length=max_sequence_length)\n",
        "decoder.attention.setup_memory(encoder_output)\n",
        "initial_state = decoder.build_initial_state(batch_size, [encoder_h, encoder_s])\n",
        "\n",
        "decoder_batch = {\n",
        "    'input_ids': tf.convert_to_tensor(encoded_output, tf.int32),\n",
        "    'initial_state': initial_state\n",
        "}\n",
        "decoder_outputs = decoder(decoder_batch).rnn_output\n",
        "print(f'{decoder_outputs.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RueCJjXO1mPp"
      },
      "outputs": [],
      "source": [
        "# Training\n",
        "trainer = MyTrainer(encoder=encoder,\n",
        "                    decoder=decoder,\n",
        "                    max_length=max_sequence_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l5H1c5ZN1mPp",
        "outputId": "d56bee8b-043a-4526-e4d9-efca762bd374"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/3 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /opt/anaconda3/envs/nlp/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
            "Loss - 0.03715987503528595\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 33%|      | 1/3 [00:16<00:33, 16.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Translated - ['<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>']\n",
            "Loss - 0.035390060395002365\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 67%|   | 2/3 [00:20<00:09,  9.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Translated - ['<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>']\n",
            "Loss - 0.03438769653439522\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 3/3 [00:24<00:00,  8.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Translated - ['<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "epochs = 3\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    batch = {\n",
        "        'encoder_input_ids': input_ids,\n",
        "        'encoder_attention_mask': attention_mask,\n",
        "        'decoder_target': encoded_output\n",
        "    }\n",
        "    loss = trainer.batch_fit(batch)\n",
        "    print(f'Loss - {loss}')\n",
        "\n",
        "    generated = trainer.generate(input_ids=input_ids,\n",
        "                                    attention_mask=attention_mask)\n",
        "    translated = trainer.translate(generated)\n",
        "    print(f'Translated - {translated}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3vOKrD11mPp"
      },
      "source": [
        "An example of answered question by the pretrained (*original*) model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "09T-nztL1mPp",
        "outputId": "a3e7b98e-9407-4984-f02a-b40253b9f6a0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertForQuestionAnswering: ['bert.embeddings.position_ids']\n",
            "- This IS expected if you are initializing TFBertForQuestionAnswering from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertForQuestionAnswering from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights or buffers of the TF 2.0 model TFBertForQuestionAnswering were not initialized from the PyTorch model and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForQuestionAnswering: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model outputs: {'score': 2.5019875465659425e-05, 'start': 387, 'end': 438, 'answer': '1.1 million printed books, which include some 8,500'}\n",
            "\n",
            "official results are (from train.json):\n",
            "span_start: 151\n",
            "span_end: 179\n",
            "span_text: Formally established in 1475\n",
            "input_text: It was formally established in 1475\n"
          ]
        }
      ],
      "source": [
        "from transformers import TFBertForQuestionAnswering, pipeline\n",
        "\n",
        "model = TFBertForQuestionAnswering.from_pretrained(model_name, from_pt=True)\n",
        "\n",
        "question_answerer = pipeline(\"question-answering\", model=model_name)\n",
        "\n",
        "outputs = question_answerer(question=train_df['q'][0], context=train_df['p'][0])\n",
        "\n",
        "print(\"model outputs:\", outputs)\n",
        "print()\n",
        "print(\"official results are (from train.json):\") \n",
        "print(\"span_start: 151\")\n",
        "print(\"span_end: 179\")\n",
        "print(\"span_text: Formally established in 1475\")\n",
        "print(\"input_text: It was formally established in 1475\")\n",
        "#print(\"start scores: {}\".format(start_scores))\n",
        "#print(\"end scores: {}\".format(end_scores))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scfOBhZf1mPp"
      },
      "source": [
        "### Question generation $f_\\theta(P, Q, H)$ with text passage $P$, question $Q$ and dialogue history $H$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9maQVnw61mPp"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpTttkRT1mPq"
      },
      "source": [
        "## Train and evaluate $f_\\theta(P, Q)$ and $f_\\theta(P, Q, H)$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j9Mb67HE1mPq"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmviMChy1mPq"
      },
      "source": [
        "## Conclusions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jDn-h3WL1mPq"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#BERT2BERT Pytorch version"
      ],
      "metadata": {
        "id": "-BnJYkp91si0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "contexts = list(train_df['p'])\n",
        "questions = list(train_df['q'])\n",
        "answers = list(train_df['a'])\n",
        "\n",
        "contexts = contexts[:65000]\n",
        "questions = questions[:65000]\n",
        "answers = answers[:65000]\n",
        "len(contexts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjo5CbruHgPC",
        "outputId": "8c15dfc7-c9f8-4472-b7e1-e6ac0ef1bbcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "65000"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import EncoderDecoderModel, AutoTokenizer\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "model_name = 'distilroberta-base'\n",
        "# tie_encoder_decoder to share weights and half the number of parameters\n",
        "model = EncoderDecoderModel.from_encoder_decoder_pretrained(model_name, model_name,\n",
        "                                                                        #encoder_from_pt=True,\n",
        "                                                                        #decoder_from_pt=True,\n",
        "                                                                        tie_encoder_decoder=True)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "\n",
        "model.config.decoder_start_token_id = tokenizer.cls_token_id\n",
        "model.config_eos_token_id = tokenizer.sep_token_id\n",
        "model.config.pad_token_id = tokenizer.pad_token_id\n",
        "model.config.vocab_size = model.config.encoder.vocab_size\n",
        "\n",
        "\n",
        "input_values = tokenizer(questions, contexts, add_special_tokens=False, \n",
        "                          padding=True,\n",
        "                          truncation=True,\n",
        "                          max_length = 512\n",
        "                          )\n",
        "input_ids, input_attention_mask = input_values['input_ids'], input_values['attention_mask']\n",
        "label_values = tokenizer(answers,\n",
        "                          padding=True,\n",
        "                          truncation=True,\n",
        "                          max_length = 200\n",
        "                          )\n",
        "labels, labels_mask = label_values['input_ids'], label_values['attention_mask']\n",
        "#Tokens with indices set to ``-100`` are ignored (masked) during training, the loss is only computed for the tokens with labels\n",
        "masked_labels = [[-100 if token == tokenizer.pad_token_id else token for token in labels] for labels in labels]\n",
        "\n",
        "print(f'input_ids shape: {np.shape(input_ids)}')\n",
        "print(f'decoder_input_ids shape: {np.shape(input_ids)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286,
          "referenced_widgets": [
            "7f219d584cef45c7a9d4c6fb119fb875",
            "57abad1c5304477390ad452b7e327cce",
            "5c5b683fef3d47d6ba764450fb51d222",
            "1eb08feeffa0454d8f4089936c4d8e6a",
            "ffe265d648044231af6593e7a0e34284",
            "a3db08d7869248f69bf6deb4aa373c10",
            "19cc50f1b97e419e971f1ff95818b1f0",
            "0c79fa3a300a4ef5917e7ca4697e9371",
            "d70a1236dac34e2e8f2fa2ec71eb4339",
            "964325358bdf49e8beeeb2de9c70a1a5",
            "4f8196af05424ebb9eba369cfb7ce97e",
            "0250cccffe58428ebdf624fed7b1607a",
            "91b3ee9b621843e3b5d2d1e074218fac",
            "3dfd85863ab841f2ac5f60f41f555464",
            "a2f217673e40426b8ddd4fe7290740f9",
            "a935658dccbe4777b4677f12749fb27e",
            "ffa55de0941142179f2fe7f5c27d2bbb",
            "f665cdb90ffb44d19f2443ef9d3501b2",
            "7d72596d97e1467088e674490a9f8dd2",
            "20a0e91c6ac24db0a5f180ceea08f930",
            "a9eaf654813f42278c72cc94b82de790",
            "9d04b06e888d4136bfcb8c4e73adc0cc",
            "7218f1d2564b4c3ea6eee8133d8df93e",
            "6491c27a5d0544bb9c1f33b87e1d345a",
            "8c8213dcae7345acac634f7f15747d06",
            "24eaa5293e8b4092962dc2c1ff062cb9",
            "30ef13a4498d49709b442d2e67ec720d",
            "1b45c89ede5541f49eedfc15148f3fb3",
            "dc34375957e349a1aeea0e7db63e4df0",
            "bbfa71d332a6491395500bc753802577",
            "11bdf46a2f7043bd98c0a56c1a75f187",
            "ecc2d09f76c54ddd896cf320287220a3",
            "823f02c3dd7e4343acee762e24e9447a",
            "9d961931befb4718abefa6a3d4a3b1e0",
            "794af08e2f894655b5ec913c4e5f2525",
            "d9ec5f97a6e04ef098965d1592a41286",
            "aad4c1d77c5c4e0eb9e417aede0c51c3",
            "1a60411526dd4db2821fcb57b439a7aa",
            "da522d756efa448b93019498cf3a0336",
            "87b6d4f8ae0e4088acb545b924240776",
            "e53d80b0723f444b99543edfa06d4b8e",
            "26ea9c71d4b1410bb938ff72061936bb",
            "76e1b793b9bd4cad94ee4d03770f5a7a",
            "e248682a7b10478a8e1a51b11a7bae87"
          ]
        },
        "id": "n3qnKLzpyuYv",
        "outputId": "523e09e1-f9c9-43f1-a49a-bbcbb4638450"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/331M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7f219d584cef45c7a9d4c6fb119fb875"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForCausalLM were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['roberta.encoder.layer.4.crossattention.output.dense.bias', 'roberta.encoder.layer.0.crossattention.self.key.weight', 'roberta.encoder.layer.4.crossattention.output.dense.weight', 'roberta.encoder.layer.5.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.5.crossattention.self.key.weight', 'roberta.encoder.layer.4.crossattention.self.value.bias', 'roberta.encoder.layer.0.crossattention.self.query.weight', 'roberta.encoder.layer.1.crossattention.self.query.bias', 'roberta.encoder.layer.4.crossattention.self.key.bias', 'roberta.encoder.layer.3.crossattention.self.query.weight', 'roberta.encoder.layer.2.crossattention.self.key.weight', 'roberta.encoder.layer.0.crossattention.self.value.weight', 'roberta.encoder.layer.2.crossattention.self.key.bias', 'roberta.encoder.layer.0.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.2.crossattention.self.query.weight', 'roberta.encoder.layer.5.crossattention.self.value.weight', 'roberta.encoder.layer.5.crossattention.self.query.weight', 'roberta.encoder.layer.0.crossattention.output.dense.weight', 'roberta.encoder.layer.3.crossattention.self.key.weight', 'roberta.encoder.layer.2.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.1.crossattention.output.dense.bias', 'roberta.encoder.layer.3.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.1.crossattention.self.value.weight', 'roberta.encoder.layer.4.crossattention.self.key.weight', 'roberta.encoder.layer.5.crossattention.self.key.bias', 'roberta.encoder.layer.4.crossattention.self.value.weight', 'roberta.encoder.layer.3.crossattention.self.key.bias', 'roberta.encoder.layer.3.crossattention.output.dense.bias', 'roberta.encoder.layer.2.crossattention.self.value.bias', 'roberta.encoder.layer.5.crossattention.self.value.bias', 'roberta.encoder.layer.3.crossattention.self.value.weight', 'roberta.encoder.layer.2.crossattention.output.dense.bias', 'roberta.encoder.layer.4.crossattention.self.query.weight', 'roberta.encoder.layer.1.crossattention.self.query.weight', 'roberta.encoder.layer.2.crossattention.output.dense.weight', 'roberta.encoder.layer.0.crossattention.self.value.bias', 'roberta.encoder.layer.0.crossattention.output.dense.bias', 'roberta.encoder.layer.3.crossattention.output.dense.weight', 'roberta.encoder.layer.0.crossattention.self.query.bias', 'roberta.encoder.layer.5.crossattention.self.query.bias', 'roberta.encoder.layer.1.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.3.crossattention.self.query.bias', 'roberta.encoder.layer.1.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.3.crossattention.self.value.bias', 'roberta.encoder.layer.5.crossattention.output.dense.bias', 'roberta.encoder.layer.5.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.2.crossattention.self.value.weight', 'roberta.encoder.layer.4.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.0.crossattention.self.key.bias', 'roberta.encoder.layer.5.crossattention.output.dense.weight', 'roberta.encoder.layer.2.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.1.crossattention.self.key.weight', 'roberta.encoder.layer.3.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.2.crossattention.self.query.bias', 'roberta.encoder.layer.1.crossattention.self.key.bias', 'roberta.encoder.layer.4.crossattention.self.query.bias', 'roberta.encoder.layer.1.crossattention.output.dense.weight', 'roberta.encoder.layer.1.crossattention.self.value.bias', 'roberta.encoder.layer.4.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.0.crossattention.output.LayerNorm.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "The following encoder weights were not tied to the decoder ['roberta/pooler']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0250cccffe58428ebdf624fed7b1607a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7218f1d2564b4c3ea6eee8133d8df93e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9d961931befb4718abefa6a3d4a3b1e0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of input_ids: (65000, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_values.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LePPZM5FRjX6",
        "outputId": "39a57afe-fdd9-4173-b3bf-ebca33ef2f4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'attention_mask'])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dictionary returned from the tokenizer will be used to build a dataset."
      ],
      "metadata": {
        "id": "Ko_uyAU1BN2o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encodings = input_values\n",
        "encodings.update({'decoder_input_ids': labels,\n",
        "                 'decoder_attention_mask': labels_mask,\n",
        "                 'labels': masked_labels\n",
        "                 })\n",
        "encodings.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z71ZL00bP9nD",
        "outputId": "467429d8-0145-46b6-ec9a-754c1380d4ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'attention_mask', 'decoder_input_ids', 'decoder_attention_mask', 'labels'])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "  Since the training will be done by using the Trainer API, which need as input a Pytorch dataset, the function defined below build a Pytorch Dataset object."
      ],
      "metadata": {
        "id": "ax_O8CegF5wv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings.input_ids)"
      ],
      "metadata": {
        "id": "dkWdaeb6AfHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CustomTextDataset(encodings)"
      ],
      "metadata": {
        "id": "psBNzKDTstsW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define some parameters of the model\n",
        "batch_size = 16\n",
        "learning_rate = 1e-4\n",
        "tot_epochs = 3.0 "
      ],
      "metadata": {
        "id": "kDGBVcNgHcJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The version in which the traning is done by the Trainer."
      ],
      "metadata": {
        "id": "oecDSCLH2c0u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training with the Trainer"
      ],
      "metadata": {
        "id": "ff2a-2Pl3Tx3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, DataCollatorWithPadding, TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments('output',per_device_train_batch_size = batch_size, num_train_epochs = tot_epochs)\n",
        "\n",
        "trainer = Trainer(\n",
        "    model,\n",
        "    training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    tokenizer=tokenizer)\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5e83030f-7fc1-4cd1-cf15-f53af0fb0364",
        "id": "TQCaPaG8NB5C"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 65000\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 8126\n",
            "  Number of trainable parameters = 96944217\n",
            "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='8126' max='8126' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [8126/8126 3:03:21, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.452800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.002600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.001400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.000400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.000100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.000300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.000300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>0.000300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>0.000100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>0.000100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to output/checkpoint-500\n",
            "Configuration saved in output/checkpoint-500/config.json\n",
            "Model weights saved in output/checkpoint-500/pytorch_model.bin\n",
            "tokenizer config file saved in output/checkpoint-500/tokenizer_config.json\n",
            "Special tokens file saved in output/checkpoint-500/special_tokens_map.json\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "Saving model checkpoint to output/checkpoint-1000\n",
            "Configuration saved in output/checkpoint-1000/config.json\n",
            "Model weights saved in output/checkpoint-1000/pytorch_model.bin\n",
            "tokenizer config file saved in output/checkpoint-1000/tokenizer_config.json\n",
            "Special tokens file saved in output/checkpoint-1000/special_tokens_map.json\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "Saving model checkpoint to output/checkpoint-1500\n",
            "Configuration saved in output/checkpoint-1500/config.json\n",
            "Model weights saved in output/checkpoint-1500/pytorch_model.bin\n",
            "tokenizer config file saved in output/checkpoint-1500/tokenizer_config.json\n",
            "Special tokens file saved in output/checkpoint-1500/special_tokens_map.json\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "Saving model checkpoint to output/checkpoint-2000\n",
            "Configuration saved in output/checkpoint-2000/config.json\n",
            "Model weights saved in output/checkpoint-2000/pytorch_model.bin\n",
            "tokenizer config file saved in output/checkpoint-2000/tokenizer_config.json\n",
            "Special tokens file saved in output/checkpoint-2000/special_tokens_map.json\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "Saving model checkpoint to output/checkpoint-2500\n",
            "Configuration saved in output/checkpoint-2500/config.json\n",
            "Model weights saved in output/checkpoint-2500/pytorch_model.bin\n",
            "tokenizer config file saved in output/checkpoint-2500/tokenizer_config.json\n",
            "Special tokens file saved in output/checkpoint-2500/special_tokens_map.json\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "Saving model checkpoint to output/checkpoint-3000\n",
            "Configuration saved in output/checkpoint-3000/config.json\n",
            "Model weights saved in output/checkpoint-3000/pytorch_model.bin\n",
            "tokenizer config file saved in output/checkpoint-3000/tokenizer_config.json\n",
            "Special tokens file saved in output/checkpoint-3000/special_tokens_map.json\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "Saving model checkpoint to output/checkpoint-3500\n",
            "Configuration saved in output/checkpoint-3500/config.json\n",
            "Model weights saved in output/checkpoint-3500/pytorch_model.bin\n",
            "tokenizer config file saved in output/checkpoint-3500/tokenizer_config.json\n",
            "Special tokens file saved in output/checkpoint-3500/special_tokens_map.json\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "Saving model checkpoint to output/checkpoint-4000\n",
            "Configuration saved in output/checkpoint-4000/config.json\n",
            "Model weights saved in output/checkpoint-4000/pytorch_model.bin\n",
            "tokenizer config file saved in output/checkpoint-4000/tokenizer_config.json\n",
            "Special tokens file saved in output/checkpoint-4000/special_tokens_map.json\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "Saving model checkpoint to output/checkpoint-4500\n",
            "Configuration saved in output/checkpoint-4500/config.json\n",
            "Model weights saved in output/checkpoint-4500/pytorch_model.bin\n",
            "tokenizer config file saved in output/checkpoint-4500/tokenizer_config.json\n",
            "Special tokens file saved in output/checkpoint-4500/special_tokens_map.json\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "Saving model checkpoint to output/checkpoint-5000\n",
            "Configuration saved in output/checkpoint-5000/config.json\n",
            "Model weights saved in output/checkpoint-5000/pytorch_model.bin\n",
            "tokenizer config file saved in output/checkpoint-5000/tokenizer_config.json\n",
            "Special tokens file saved in output/checkpoint-5000/special_tokens_map.json\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "Saving model checkpoint to output/checkpoint-5500\n",
            "Configuration saved in output/checkpoint-5500/config.json\n",
            "Model weights saved in output/checkpoint-5500/pytorch_model.bin\n",
            "tokenizer config file saved in output/checkpoint-5500/tokenizer_config.json\n",
            "Special tokens file saved in output/checkpoint-5500/special_tokens_map.json\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "Saving model checkpoint to output/checkpoint-6000\n",
            "Configuration saved in output/checkpoint-6000/config.json\n",
            "Model weights saved in output/checkpoint-6000/pytorch_model.bin\n",
            "tokenizer config file saved in output/checkpoint-6000/tokenizer_config.json\n",
            "Special tokens file saved in output/checkpoint-6000/special_tokens_map.json\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "Saving model checkpoint to output/checkpoint-6500\n",
            "Configuration saved in output/checkpoint-6500/config.json\n",
            "Model weights saved in output/checkpoint-6500/pytorch_model.bin\n",
            "tokenizer config file saved in output/checkpoint-6500/tokenizer_config.json\n",
            "Special tokens file saved in output/checkpoint-6500/special_tokens_map.json\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "Saving model checkpoint to output/checkpoint-7000\n",
            "Configuration saved in output/checkpoint-7000/config.json\n",
            "Model weights saved in output/checkpoint-7000/pytorch_model.bin\n",
            "tokenizer config file saved in output/checkpoint-7000/tokenizer_config.json\n",
            "Special tokens file saved in output/checkpoint-7000/special_tokens_map.json\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "Saving model checkpoint to output/checkpoint-7500\n",
            "Configuration saved in output/checkpoint-7500/config.json\n",
            "Model weights saved in output/checkpoint-7500/pytorch_model.bin\n",
            "tokenizer config file saved in output/checkpoint-7500/tokenizer_config.json\n",
            "Special tokens file saved in output/checkpoint-7500/special_tokens_map.json\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "Saving model checkpoint to output/checkpoint-8000\n",
            "Configuration saved in output/checkpoint-8000/config.json\n",
            "Model weights saved in output/checkpoint-8000/pytorch_model.bin\n",
            "tokenizer config file saved in output/checkpoint-8000/tokenizer_config.json\n",
            "Special tokens file saved in output/checkpoint-8000/special_tokens_map.json\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=8126, training_loss=0.028264920794979928, metrics={'train_runtime': 11005.5715, 'train_samples_per_second': 11.812, 'train_steps_per_second': 0.738, 'total_flos': 2.314098588672e+16, 'train_loss': 0.028264920794979928, 'epoch': 2.0})"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Custom training with Pytorch"
      ],
      "metadata": {
        "id": "5zyT3ZnN3CjE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, DataCollatorWithPadding, TrainingArguments\n",
        "from transformers import AdamW\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "train_ld = torch.utils.data.DataLoader(train_dataset,\n",
        "                                     batch_size=batch_size,\n",
        "                                     )\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model.to(device)\n",
        "model.train()\n",
        "optim = AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for epoch in range(tot_epochs):\n",
        "    loop = tqdm(train_ld)\n",
        "    for batch in loop:\n",
        "        optim.zero_grad()\n",
        "\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        decoder_input_ids = batch['decoder_input_ids'].to(device)\n",
        "        decoder_attention_mask = batch['decoder_attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        loss, outputs = model(input_ids,\n",
        "                              attention_mask=attention_mask,\n",
        "                              decoder_input_ids= decoder_input_ids,\n",
        "                              decoder_attention_mask= decoder_attention_mask,\n",
        "                              labels = labels\n",
        "                        )[:2]\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        loop.set_description(f'Epoch {epoch}')\n",
        "        loop.set_postfix(loss=loss.item())"
      ],
      "metadata": {
        "id": "cDNdl1mrNOhq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Testing the Trainer model "
      ],
      "metadata": {
        "id": "zS2JruSS4Lte"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = train_df.iloc[50000:50250]\n",
        "context_test = list(test['p'])\n",
        "question_test = list(test['q'])\n",
        "answer_test = list(test['a'])"
      ],
      "metadata": {
        "id": "qZW-Qs56RV4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_values = tokenizer(question_test,context_test, add_special_tokens=False, padding=True, truncation=True, max_length = 512)\n",
        "input_ids, input_attention_mask = input_values['input_ids'], input_values['attention_mask']"
      ],
      "metadata": {
        "id": "CtdO6Zx8Q8vI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#clean some GPU memory\n",
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "cIFMjpiIUroq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.model.cuda()\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "mylist = []\n",
        "for input in input_ids:\n",
        "  input = np.array(input)\n",
        "  input = np.expand_dims(input, axis=0)\n",
        "  #print(np.shape(input))\n",
        "  generated = trainer.model.generate(input_ids=torch.tensor(input).to(device),\n",
        "                                                 max_length=30,\n",
        "                                                 repetition_penalty=3.,\n",
        "                                                 min_length=1,\n",
        "                                                 no_repeat_ngram_size=2,\n",
        "                                                 early_stopping=True,\n",
        "                                                 num_beams=1\n",
        "                                                 )\n",
        "  generated = tokenizer.batch_decode(generated, skip_special_tokens=True)\n",
        "  mylist.append(generated)\n",
        "  #print(f'Generated: {generated}')"
      ],
      "metadata": {
        "id": "6BwlwGcjR9dA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import regex as re\n",
        "def clean_text(text):\n",
        "  text = re.sub(r'[-\\(\\)\\\"#\\/@;:<>\\{\\}\\-=~|\\.\\?,%*!\\']', '', text)\n",
        "  text = re.sub(r'[^a-zA-Z0-9 ]', '', text)\n",
        "  return text"
      ],
      "metadata": {
        "id": "sE9yeoroeMp3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = pd.DataFrame(mylist, columns = ['generated'])"
      ],
      "metadata": {
        "id": "YqC8s-Nff8i8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x['answers'] = answer_test\n",
        "x['generated'] = x['generated'].apply(clean_text)"
      ],
      "metadata": {
        "id": "sAe35G7NakrQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_rows', None)\n",
        "x.head(200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7v8Xd6xVHNIS",
        "outputId": "3d18cbc8-8b4f-4402-abd5-6873cca16309"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             generated  \\\n",
              "0                                                        \n",
              "1                                                        \n",
              "2        descDesc Desc desc unsc unc UncuncncencEnc...   \n",
              "3           464472471474477484494492476448449459457497   \n",
              "4    to to tootootomatomatemiem Siem Sem semSemTam ...   \n",
              "5                                                        \n",
              "6                                                   si   \n",
              "7                                                        \n",
              "8                                                        \n",
              "9                                                        \n",
              "10                        minsminsminminimim m ml mmmm   \n",
              "11   utory statutory statistical Statistical Statis...   \n",
              "12                                                       \n",
              "13                                                       \n",
              "14                                                       \n",
              "15                                                       \n",
              "16                                                       \n",
              "17       DescDiv Div div dec descdescescascASCNCncdcdk   \n",
              "18    un UnUnununitunits units Units Unit unitUnitI...   \n",
              "19                                     estyakyokyythyk   \n",
              "20    mon Mon MONMONMonmonemonemiemymmmm mm m ml mi...   \n",
              "21                                                       \n",
              "22                                                       \n",
              "23    to tootootoTOTo To TO OF FOR For Of OOowowkw ...   \n",
              "24    descDesc Desc desc dec Dec DEC REC REMREMMR M...   \n",
              "25     althoughAlthough although afterwards beforeh...   \n",
              "26                                                       \n",
              "27                                                       \n",
              "28                                                       \n",
              "29                                                       \n",
              "30                                                       \n",
              "31                                                       \n",
              "32               enserensedenseENSEensesendsendENDENen   \n",
              "33                                                       \n",
              "34                                                       \n",
              "35                                                       \n",
              "36                                                  NK   \n",
              "37                                                       \n",
              "38                                                       \n",
              "39   unicsictext text TextTextTEXTTIT TIT Tit tit h...   \n",
              "40                                                       \n",
              "41                                                       \n",
              "42                                                       \n",
              "43                                                       \n",
              "44    to too TooTooTo To TuTututurTur Tur tur bur B...   \n",
              "45                 signifies signify yea y YYYAyayahyk   \n",
              "46                                                       \n",
              "47                                                       \n",
              "48    to too only least most MostMostSinceBecauseWh...   \n",
              "49                                                       \n",
              "50                                                       \n",
              "51    un UnUnununtunitUnit Unit Units units unit un...   \n",
              "52                                                       \n",
              "53                                                       \n",
              "54                                                       \n",
              "55              un Un UNUNUnununitunits units Units...   \n",
              "56                                                       \n",
              "57                                                       \n",
              "58                                                       \n",
              "59                                                       \n",
              "60           l bbsbsrkrcrCr Cr cr CRCRRrrbrrrh rh RhRh   \n",
              "61                         AtATGTgtg g GGMGBG BG MG MP   \n",
              "62                                                  pt   \n",
              "63         signifies signify marry spouse spouses h...   \n",
              "64                                                       \n",
              "65    lldldLmLLM LM M m mlmlslnltlklnm nm mmmmmMMPmpmb   \n",
              "66                          em em Em Im im m mlmlmm mm   \n",
              "67                                                       \n",
              "68   PPsHPWPPPMPEPEp Ep ep apr epist apost Apost Ap...   \n",
              "69                                                       \n",
              "70      semic cryptoc coc CococrocloccolColCOL COL ...   \n",
              "71                                                       \n",
              "72                                                       \n",
              "73    un UnUnUNununitunits units Units Unit unitUni...   \n",
              "74                                                       \n",
              "75                                                       \n",
              "76                                                       \n",
              "77                                                       \n",
              "78                                                       \n",
              "79                                                       \n",
              "80     1010910980 980 970 960 950 9009001001000 100...   \n",
              "81    narr narrator narration narrated voiced voici...   \n",
              "82      un UnUnununionunityunitunits units Units Un...   \n",
              "83          wormsworm worms worm Worm Grim RamRamRAMAM   \n",
              "84                                                       \n",
              "85                                                       \n",
              "86                                                       \n",
              "87   to to tootooToo Too To TOTOToT T NNTNNsNMNNNTn...   \n",
              "88                                                       \n",
              "89                              teredtenteTE TE TeTeLe   \n",
              "90                                                       \n",
              "91   othy Timothy TimTimTony TonyonyONYAMYamyiemymo...   \n",
              "92      eqeqefdefDef Def DEF ADV Adv adv av AvAvavA...   \n",
              "93                    minsminsminminimimgmdmdldpdtgdmd   \n",
              "94                                                       \n",
              "95    urURBURBurbur Bur bur tur TurTurturthurfurmur...   \n",
              "96                                                       \n",
              "97                                                       \n",
              "98                                                       \n",
              "99   alphphaphophiphilibitableitabilityitablyblyrel...   \n",
              "100                                                      \n",
              "101                                                      \n",
              "102                                                      \n",
              "103                                                      \n",
              "104                                                      \n",
              "105                               k KKkikikkkkckackick   \n",
              "106                                   vernernernalerno   \n",
              "107                                                      \n",
              "108                                                      \n",
              "109    b B TBTBT T ttm m mmmmcm cm kmkmtmsmesmemail...   \n",
              "110                                         IREsrkrmrr   \n",
              "111                                                      \n",
              "112           o O Y yyiyayAYYAy Ay ay   Mi Mi mimimesm   \n",
              "113                                                      \n",
              "114                                                      \n",
              "115                                                      \n",
              "116  kishkikyk k KKPKNKKKKEYKYMY MY My mymyMyYour Y...   \n",
              "117                                        minsminsmin   \n",
              "118     onestandyandraandrerdd d t TTtttrett Brett ...   \n",
              "119                        b BBBCBSbsNSNDNBNBNbnnbnbmb   \n",
              "120  isoISOSONOnoNoYesYESyes yes YES Yes No NO SO S...   \n",
              "121   un Un UNUNUnunsunmonemonemanemenemiemiomomOMU...   \n",
              "122   to tootootoToTooSoNowNOWNONo No nonononnot no...   \n",
              "123                                                      \n",
              "124   minsminsminMINMERmermoreMOREMYmyMy My my MY B...   \n",
              "125                                                      \n",
              "126   to tootooTooTo To TOTONONoMoMO MO Mo Go GOGOG...   \n",
              "127                                                      \n",
              "128                                                      \n",
              "129                                                      \n",
              "130           circa approximately approximate appro...   \n",
              "131                                                      \n",
              "132                                                      \n",
              "133                                                      \n",
              "134                                                      \n",
              "135                                    binaries binary   \n",
              "136                                                      \n",
              "137                                                      \n",
              "138   to tootootoTo To TOTOToo Too Tw TWTWTwtw tw q...   \n",
              "139                                                      \n",
              "140                                                      \n",
              "141                                                      \n",
              "142                                                      \n",
              "143                                                      \n",
              "144                                                      \n",
              "145                                                      \n",
              "146                                                      \n",
              "147                                                      \n",
              "148                                                      \n",
              "149      br Br BRBRBrbrblablabiliblibIBABAb Ab ababbsb   \n",
              "150  alphphophaphraphroththithithshewskuslususulull...   \n",
              "151                                                      \n",
              "152                                                      \n",
              "153  oughtaililkil kil Kil KillKillkill kill destro...   \n",
              "154   heticalhesishesesheticallyheticheticslyslyily...   \n",
              "155                                mmmmmmmhhhhhhhhhogh   \n",
              "156                                                      \n",
              "157                                                      \n",
              "158                                                      \n",
              "159                                                      \n",
              "160   DescriptionIntroduction Introduction introduc...   \n",
              "161  toToByAboutBetweenInOn On on ONONononicicICRIC...   \n",
              "162                                                      \n",
              "163  to to tootooTooTo To TOTONOnoNo No no NO SO So...   \n",
              "164                              e E M m rrorcordorori   \n",
              "165           ki Ki NiNi ninienieliediesiesyeticall...   \n",
              "166                                                      \n",
              "167                    silSil Sil sil SIL SOSOso so So   \n",
              "168                                                      \n",
              "169                                                      \n",
              "170                                                      \n",
              "171  to to ToToTO TO TooTootoobecausefromFrom From ...   \n",
              "172   to ToTotoTO TO Too TTTTTC TC ST StStSTsttttty...   \n",
              "173                                                      \n",
              "174                                                      \n",
              "175                                                ung   \n",
              "176                                                      \n",
              "177   tal TalTaltalmal mal MalMalMALALal al lltlate...   \n",
              "178    minsminsmsm m ml mm cmcmmmtmsmesmgmdmmc mc M...   \n",
              "179    fifrietjitietietstiestytT T t unt UntUntTNNT...   \n",
              "180                                                      \n",
              "181                                                      \n",
              "182                                                      \n",
              "183                                                      \n",
              "184                                                      \n",
              "185    ppprPr Pr pr PRPRPMPHPhph ph Ph PH HY Hy H h...   \n",
              "186                                              j JJj   \n",
              "187                                                      \n",
              "188                                                      \n",
              "189                                                      \n",
              "190                     urURTERtertherth th ThThuthith   \n",
              "191   to tootooToo Too ToToTaTUnt Unt unt nont dest...   \n",
              "192     uppoppppppspperspperoperopersopsOPSOPopoopo...   \n",
              "193   to To TOToTOtotooTooTa Ta ta ti vi Vi SiSiTiV...   \n",
              "194                                                      \n",
              "195                                                      \n",
              "196     jugraglagagagsaggedaggingaggggrogrococogoggugg   \n",
              "197                                                      \n",
              "198                 mirMirMm m M mmmmmsmbmpsmSMSmMP MP   \n",
              "199                                                      \n",
              "\n",
              "                                               answers  \n",
              "0                                           27 million  \n",
              "1                                         15.7 million  \n",
              "2                                                   no  \n",
              "3    a loosely defined categorization which include...  \n",
              "4               east and south of present-day Cameroon  \n",
              "5                                                  yes  \n",
              "6                                                   no  \n",
              "7                                                Shona  \n",
              "8                                           Ethnologue  \n",
              "9                                         12.4 million  \n",
              "10                                                 yes  \n",
              "11                                                  no  \n",
              "12                                      southeast asia  \n",
              "13                                                 yes  \n",
              "14                                               India  \n",
              "15                                   Definitions vary,  \n",
              "16                                                 Yes  \n",
              "17              Association of Southeast Asian Nations  \n",
              "18                                                 yes  \n",
              "19                                          East Tinor  \n",
              "20                                                 Yes  \n",
              "21             Papua New Guinea, is sometimes included  \n",
              "22                                           sometimes  \n",
              "23                                                 yes  \n",
              "24            . Christmas Island and the Cocos islands  \n",
              "25                                  Sovereignty issues  \n",
              "26                                it might join ASEAN,  \n",
              "27                                        an observer.  \n",
              "28                                               China  \n",
              "29                               from 111 BC to AD 939  \n",
              "30                   the Socialist Republic of Vietnam  \n",
              "31                                       North Vietnam  \n",
              "32                                             in 1975  \n",
              "33                                          after 1954  \n",
              "34                             between North and South  \n",
              "35                                   in Southeast Asia  \n",
              "36              the world's 14th-most-populous country  \n",
              "37                             the ninth-most-populous  \n",
              "38                                                 939  \n",
              "39                             in the mid-19th century  \n",
              "40                                          the French  \n",
              "41                                        the Japanese  \n",
              "42                                                 six  \n",
              "43                                               eight  \n",
              "44                                        1965 to 1973  \n",
              "45                                                1975  \n",
              "46                                               Hanoi  \n",
              "47                                    Ho Chi Minh City  \n",
              "48                                    A group of frogs  \n",
              "49                                       Nick and Jack  \n",
              "50                                 All the other frogs  \n",
              "51                                       Nick and Jack  \n",
              "52                     Because of how deep the pit was  \n",
              "53                                                Nick  \n",
              "54                                                Jack  \n",
              "55                                           He's deaf  \n",
              "56                                  Encouraging things  \n",
              "57                                                 Yes  \n",
              "58                                       Kristin Davis  \n",
              "59                                             Tuesday  \n",
              "60                                            $100,000  \n",
              "61                                         September 5  \n",
              "62                                                  no  \n",
              "63                                                  no  \n",
              "64                                   2009 through 2011  \n",
              "65                             FBI cooperating witness  \n",
              "66                                       Andrew Miller  \n",
              "67                                                 yes  \n",
              "68                                                  38  \n",
              "69                                        Monday night  \n",
              "70                                  prescription drugs  \n",
              "71                                                 yes  \n",
              "72                         heroin and cocaine combined  \n",
              "73   four counts of distributing and possessing wit...  \n",
              "74                            20 years for each count,  \n",
              "75                          city comptroller candidate  \n",
              "76                        ecstasy, Adderall  and Xanax  \n",
              "77                                             Penquay  \n",
              "78                                          Mrs. Smith  \n",
              "79                                             Johnson  \n",
              "80                                      Friday evening  \n",
              "81                                         the weekend  \n",
              "82                                went straight to bed  \n",
              "83                                   he was very tired  \n",
              "84                                                  no  \n",
              "85                                                none  \n",
              "86                                           Catherine  \n",
              "87                                          her father  \n",
              "88                                             outside  \n",
              "89                He jumped up and ran out of the room  \n",
              "90                        It was the man in the photo.  \n",
              "91   Three years before he had gone out in his boat...  \n",
              "92                                           Catherine  \n",
              "93   Johnson noticed there were four places at the ...  \n",
              "94                                                 Yes  \n",
              "95                                        Robert Peary  \n",
              "96          he explored Greenland, mapping parts of it  \n",
              "97                                           some furs  \n",
              "98                                      Matthew Henson  \n",
              "99    African American mechanic, builder and navigator  \n",
              "100                                         the Arctic  \n",
              "101                                   Henson and Peary  \n",
              "102                             the land by dog sledge  \n",
              "103                                 Henson was injured  \n",
              "104                                  the native people  \n",
              "105                                            In 1895  \n",
              "106                     Greenland's northernmost point  \n",
              "107                                       Arctic Ocean  \n",
              "108                                   to cross the ice  \n",
              "109                                       Peary's feet  \n",
              "110                                   he lost his toes  \n",
              "111                        when Peary was 53 years old  \n",
              "112           across the sea ice from Ellesmere Island  \n",
              "113                                    north of Canada  \n",
              "114                                 51 degrees Celsius  \n",
              "115                                              HAMAD  \n",
              "116                                       1,000 meters  \n",
              "117                                     two miles long  \n",
              "118                                     \"H\" to the \"D\"  \n",
              "119                                  Al Futaisi Island  \n",
              "120                                          waterways  \n",
              "121                                           Google's  \n",
              "122                                        his workmen  \n",
              "123                                              weeks  \n",
              "124                                                 no  \n",
              "125                                     Rainbow Sheikh  \n",
              "126                                          Abu Dhabi  \n",
              "127                                                yes  \n",
              "128                                           200 cars  \n",
              "129                                  Mercedes 500 SELs  \n",
              "130                                 in a giant pyramid  \n",
              "131                                      largest truck  \n",
              "132                                      four bedrooms  \n",
              "133                                        giant globe  \n",
              "134                                            Morocco  \n",
              "135                                               wind  \n",
              "136                                   around the house  \n",
              "137                                          old woman  \n",
              "138                                                 no  \n",
              "139                                                 no  \n",
              "140                                           memories  \n",
              "141                                           her life  \n",
              "142                                being a little girl  \n",
              "143                                                yes  \n",
              "144                                              three  \n",
              "145                           dad, mom, younger sister  \n",
              "146                                                 no  \n",
              "147                                                yes  \n",
              "148                                             sister  \n",
              "149                                               wind  \n",
              "150                                                 no  \n",
              "151                                             sister  \n",
              "152                                                 no  \n",
              "153                                    \"What's wrong?\"  \n",
              "154                                               died  \n",
              "155               runs to a sports club to play sports  \n",
              "156                                                yes  \n",
              "157          she goes to school at 8:00 in the morning  \n",
              "158                   at four fifteen in the afternoon  \n",
              "159                      she does her homework at 5:00  \n",
              "160                  at three o'clock in the afternoon  \n",
              "161                         six o'clock in the morning  \n",
              "162                                                 no  \n",
              "163                            going to clothes stores  \n",
              "164                                                 no  \n",
              "165                                                 no  \n",
              "166                                  to a singing club  \n",
              "167                                                 no  \n",
              "168                                   the English club  \n",
              "169                                                 no  \n",
              "170                                                yes  \n",
              "171                                            the bus  \n",
              "172                                                 no  \n",
              "173                                           two kids  \n",
              "174                                                yes  \n",
              "175                                          the bell!  \n",
              "176                                             Robbie  \n",
              "177                                him to do something  \n",
              "178                                             Robbie  \n",
              "179                                                 no  \n",
              "180                                      turn the heat  \n",
              "181                         before the family got home  \n",
              "182                                              Helen  \n",
              "183                                     ten past eight  \n",
              "184                                              bread  \n",
              "185                                   the chicken soup  \n",
              "186                                   family came home  \n",
              "187                                                 no  \n",
              "188                                              robot  \n",
              "189                            he family a lot of work  \n",
              "190                                             Victor  \n",
              "191                                              Helen  \n",
              "192                                           tomatoes  \n",
              "193                                           cabbages  \n",
              "194                                             Robbie  \n",
              "195                                    get the big pot  \n",
              "196                          put some water in the pot  \n",
              "197                                            Johnson  \n",
              "198                                     Karnack, Texas  \n",
              "199                                          her nurse  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1f255db6-6373-4b4d-98cd-8b1e175674e0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>generated</th>\n",
              "      <th>answers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td></td>\n",
              "      <td>27 million</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td></td>\n",
              "      <td>15.7 million</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>descDesc Desc desc unsc unc UncuncncencEnc...</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>464472471474477484494492476448449459457497</td>\n",
              "      <td>a loosely defined categorization which include...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>to to tootootomatomatemiem Siem Sem semSemTam ...</td>\n",
              "      <td>east and south of present-day Cameroon</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td></td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>si</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td></td>\n",
              "      <td>Shona</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td></td>\n",
              "      <td>Ethnologue</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td></td>\n",
              "      <td>12.4 million</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>minsminsminminimim m ml mmmm</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>utory statutory statistical Statistical Statis...</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td></td>\n",
              "      <td>southeast asia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td></td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td></td>\n",
              "      <td>India</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td></td>\n",
              "      <td>Definitions vary,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td></td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>DescDiv Div div dec descdescescascASCNCncdcdk</td>\n",
              "      <td>Association of Southeast Asian Nations</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>un UnUnununitunits units Units Unit unitUnitI...</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>estyakyokyythyk</td>\n",
              "      <td>East Tinor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>mon Mon MONMONMonmonemonemiemymmmm mm m ml mi...</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td></td>\n",
              "      <td>Papua New Guinea, is sometimes included</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td></td>\n",
              "      <td>sometimes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>to tootootoTOTo To TO OF FOR For Of OOowowkw ...</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>descDesc Desc desc dec Dec DEC REC REMREMMR M...</td>\n",
              "      <td>. Christmas Island and the Cocos islands</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>althoughAlthough although afterwards beforeh...</td>\n",
              "      <td>Sovereignty issues</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td></td>\n",
              "      <td>it might join ASEAN,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td></td>\n",
              "      <td>an observer.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td></td>\n",
              "      <td>China</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td></td>\n",
              "      <td>from 111 BC to AD 939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td></td>\n",
              "      <td>the Socialist Republic of Vietnam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td></td>\n",
              "      <td>North Vietnam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>enserensedenseENSEensesendsendENDENen</td>\n",
              "      <td>in 1975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td></td>\n",
              "      <td>after 1954</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td></td>\n",
              "      <td>between North and South</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td></td>\n",
              "      <td>in Southeast Asia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>NK</td>\n",
              "      <td>the world's 14th-most-populous country</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td></td>\n",
              "      <td>the ninth-most-populous</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td></td>\n",
              "      <td>939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>unicsictext text TextTextTEXTTIT TIT Tit tit h...</td>\n",
              "      <td>in the mid-19th century</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td></td>\n",
              "      <td>the French</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td></td>\n",
              "      <td>the Japanese</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td></td>\n",
              "      <td>six</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td></td>\n",
              "      <td>eight</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>to too TooTooTo To TuTututurTur Tur tur bur B...</td>\n",
              "      <td>1965 to 1973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>signifies signify yea y YYYAyayahyk</td>\n",
              "      <td>1975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td></td>\n",
              "      <td>Hanoi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td></td>\n",
              "      <td>Ho Chi Minh City</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>to too only least most MostMostSinceBecauseWh...</td>\n",
              "      <td>A group of frogs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td></td>\n",
              "      <td>Nick and Jack</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td></td>\n",
              "      <td>All the other frogs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>un UnUnununtunitUnit Unit Units units unit un...</td>\n",
              "      <td>Nick and Jack</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td></td>\n",
              "      <td>Because of how deep the pit was</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td></td>\n",
              "      <td>Nick</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td></td>\n",
              "      <td>Jack</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>un Un UNUNUnununitunits units Units...</td>\n",
              "      <td>He's deaf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td></td>\n",
              "      <td>Encouraging things</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td></td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td></td>\n",
              "      <td>Kristin Davis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td></td>\n",
              "      <td>Tuesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>l bbsbsrkrcrCr Cr cr CRCRRrrbrrrh rh RhRh</td>\n",
              "      <td>$100,000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>AtATGTgtg g GGMGBG BG MG MP</td>\n",
              "      <td>September 5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>pt</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>signifies signify marry spouse spouses h...</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td></td>\n",
              "      <td>2009 through 2011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>lldldLmLLM LM M m mlmlslnltlklnm nm mmmmmMMPmpmb</td>\n",
              "      <td>FBI cooperating witness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>em em Em Im im m mlmlmm mm</td>\n",
              "      <td>Andrew Miller</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td></td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>PPsHPWPPPMPEPEp Ep ep apr epist apost Apost Ap...</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td></td>\n",
              "      <td>Monday night</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>semic cryptoc coc CococrocloccolColCOL COL ...</td>\n",
              "      <td>prescription drugs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td></td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td></td>\n",
              "      <td>heroin and cocaine combined</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>un UnUnUNununitunits units Units Unit unitUni...</td>\n",
              "      <td>four counts of distributing and possessing wit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td></td>\n",
              "      <td>20 years for each count,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td></td>\n",
              "      <td>city comptroller candidate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td></td>\n",
              "      <td>ecstasy, Adderall  and Xanax</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td></td>\n",
              "      <td>Penquay</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td></td>\n",
              "      <td>Mrs. Smith</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td></td>\n",
              "      <td>Johnson</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>1010910980 980 970 960 950 9009001001000 100...</td>\n",
              "      <td>Friday evening</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>narr narrator narration narrated voiced voici...</td>\n",
              "      <td>the weekend</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>un UnUnununionunityunitunits units Units Un...</td>\n",
              "      <td>went straight to bed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>wormsworm worms worm Worm Grim RamRamRAMAM</td>\n",
              "      <td>he was very tired</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td></td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td></td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td></td>\n",
              "      <td>Catherine</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>to to tootooToo Too To TOTOToT T NNTNNsNMNNNTn...</td>\n",
              "      <td>her father</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td></td>\n",
              "      <td>outside</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>teredtenteTE TE TeTeLe</td>\n",
              "      <td>He jumped up and ran out of the room</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td></td>\n",
              "      <td>It was the man in the photo.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>othy Timothy TimTimTony TonyonyONYAMYamyiemymo...</td>\n",
              "      <td>Three years before he had gone out in his boat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>eqeqefdefDef Def DEF ADV Adv adv av AvAvavA...</td>\n",
              "      <td>Catherine</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>minsminsminminimimgmdmdldpdtgdmd</td>\n",
              "      <td>Johnson noticed there were four places at the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td></td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>urURBURBurbur Bur bur tur TurTurturthurfurmur...</td>\n",
              "      <td>Robert Peary</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td></td>\n",
              "      <td>he explored Greenland, mapping parts of it</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td></td>\n",
              "      <td>some furs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td></td>\n",
              "      <td>Matthew Henson</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>alphphaphophiphilibitableitabilityitablyblyrel...</td>\n",
              "      <td>African American mechanic, builder and navigator</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td></td>\n",
              "      <td>the Arctic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td></td>\n",
              "      <td>Henson and Peary</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td></td>\n",
              "      <td>the land by dog sledge</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td></td>\n",
              "      <td>Henson was injured</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td></td>\n",
              "      <td>the native people</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105</th>\n",
              "      <td>k KKkikikkkkckackick</td>\n",
              "      <td>In 1895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>vernernernalerno</td>\n",
              "      <td>Greenland's northernmost point</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107</th>\n",
              "      <td></td>\n",
              "      <td>Arctic Ocean</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108</th>\n",
              "      <td></td>\n",
              "      <td>to cross the ice</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>b B TBTBT T ttm m mmmmcm cm kmkmtmsmesmemail...</td>\n",
              "      <td>Peary's feet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>IREsrkrmrr</td>\n",
              "      <td>he lost his toes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td></td>\n",
              "      <td>when Peary was 53 years old</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>o O Y yyiyayAYYAy Ay ay   Mi Mi mimimesm</td>\n",
              "      <td>across the sea ice from Ellesmere Island</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td></td>\n",
              "      <td>north of Canada</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114</th>\n",
              "      <td></td>\n",
              "      <td>51 degrees Celsius</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td></td>\n",
              "      <td>HAMAD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>kishkikyk k KKPKNKKKKEYKYMY MY My mymyMyYour Y...</td>\n",
              "      <td>1,000 meters</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>minsminsmin</td>\n",
              "      <td>two miles long</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118</th>\n",
              "      <td>onestandyandraandrerdd d t TTtttrett Brett ...</td>\n",
              "      <td>\"H\" to the \"D\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>b BBBCBSbsNSNDNBNBNbnnbnbmb</td>\n",
              "      <td>Al Futaisi Island</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>isoISOSONOnoNoYesYESyes yes YES Yes No NO SO S...</td>\n",
              "      <td>waterways</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121</th>\n",
              "      <td>un Un UNUNUnunsunmonemonemanemenemiemiomomOMU...</td>\n",
              "      <td>Google's</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122</th>\n",
              "      <td>to tootootoToTooSoNowNOWNONo No nonononnot no...</td>\n",
              "      <td>his workmen</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123</th>\n",
              "      <td></td>\n",
              "      <td>weeks</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>124</th>\n",
              "      <td>minsminsminMINMERmermoreMOREMYmyMy My my MY B...</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125</th>\n",
              "      <td></td>\n",
              "      <td>Rainbow Sheikh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126</th>\n",
              "      <td>to tootooTooTo To TOTONONoMoMO MO Mo Go GOGOG...</td>\n",
              "      <td>Abu Dhabi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127</th>\n",
              "      <td></td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td></td>\n",
              "      <td>200 cars</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129</th>\n",
              "      <td></td>\n",
              "      <td>Mercedes 500 SELs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130</th>\n",
              "      <td>circa approximately approximate appro...</td>\n",
              "      <td>in a giant pyramid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131</th>\n",
              "      <td></td>\n",
              "      <td>largest truck</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td></td>\n",
              "      <td>four bedrooms</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133</th>\n",
              "      <td></td>\n",
              "      <td>giant globe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>134</th>\n",
              "      <td></td>\n",
              "      <td>Morocco</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135</th>\n",
              "      <td>binaries binary</td>\n",
              "      <td>wind</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136</th>\n",
              "      <td></td>\n",
              "      <td>around the house</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137</th>\n",
              "      <td></td>\n",
              "      <td>old woman</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>138</th>\n",
              "      <td>to tootootoTo To TOTOToo Too Tw TWTWTwtw tw q...</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>139</th>\n",
              "      <td></td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140</th>\n",
              "      <td></td>\n",
              "      <td>memories</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141</th>\n",
              "      <td></td>\n",
              "      <td>her life</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142</th>\n",
              "      <td></td>\n",
              "      <td>being a little girl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143</th>\n",
              "      <td></td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>144</th>\n",
              "      <td></td>\n",
              "      <td>three</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td></td>\n",
              "      <td>dad, mom, younger sister</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td></td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td></td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td></td>\n",
              "      <td>sister</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>br Br BRBRBrbrblablabiliblibIBABAb Ab ababbsb</td>\n",
              "      <td>wind</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>alphphophaphraphroththithithshewskuslususulull...</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151</th>\n",
              "      <td></td>\n",
              "      <td>sister</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152</th>\n",
              "      <td></td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153</th>\n",
              "      <td>oughtaililkil kil Kil KillKillkill kill destro...</td>\n",
              "      <td>\"What's wrong?\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>154</th>\n",
              "      <td>heticalhesishesesheticallyheticheticslyslyily...</td>\n",
              "      <td>died</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>155</th>\n",
              "      <td>mmmmmmmhhhhhhhhhogh</td>\n",
              "      <td>runs to a sports club to play sports</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156</th>\n",
              "      <td></td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>157</th>\n",
              "      <td></td>\n",
              "      <td>she goes to school at 8:00 in the morning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>158</th>\n",
              "      <td></td>\n",
              "      <td>at four fifteen in the afternoon</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159</th>\n",
              "      <td></td>\n",
              "      <td>she does her homework at 5:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>160</th>\n",
              "      <td>DescriptionIntroduction Introduction introduc...</td>\n",
              "      <td>at three o'clock in the afternoon</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161</th>\n",
              "      <td>toToByAboutBetweenInOn On on ONONononicicICRIC...</td>\n",
              "      <td>six o'clock in the morning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>162</th>\n",
              "      <td></td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>163</th>\n",
              "      <td>to to tootooTooTo To TOTONOnoNo No no NO SO So...</td>\n",
              "      <td>going to clothes stores</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>164</th>\n",
              "      <td>e E M m rrorcordorori</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165</th>\n",
              "      <td>ki Ki NiNi ninienieliediesiesyeticall...</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>166</th>\n",
              "      <td></td>\n",
              "      <td>to a singing club</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167</th>\n",
              "      <td>silSil Sil sil SIL SOSOso so So</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>168</th>\n",
              "      <td></td>\n",
              "      <td>the English club</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>169</th>\n",
              "      <td></td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>170</th>\n",
              "      <td></td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>171</th>\n",
              "      <td>to to ToToTO TO TooTootoobecausefromFrom From ...</td>\n",
              "      <td>the bus</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172</th>\n",
              "      <td>to ToTotoTO TO Too TTTTTC TC ST StStSTsttttty...</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td></td>\n",
              "      <td>two kids</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td></td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>ung</td>\n",
              "      <td>the bell!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td></td>\n",
              "      <td>Robbie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>tal TalTaltalmal mal MalMalMALALal al lltlate...</td>\n",
              "      <td>him to do something</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178</th>\n",
              "      <td>minsminsmsm m ml mm cmcmmmtmsmesmgmdmmc mc M...</td>\n",
              "      <td>Robbie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>179</th>\n",
              "      <td>fifrietjitietietstiestytT T t unt UntUntTNNT...</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180</th>\n",
              "      <td></td>\n",
              "      <td>turn the heat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>181</th>\n",
              "      <td></td>\n",
              "      <td>before the family got home</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>182</th>\n",
              "      <td></td>\n",
              "      <td>Helen</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>183</th>\n",
              "      <td></td>\n",
              "      <td>ten past eight</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>184</th>\n",
              "      <td></td>\n",
              "      <td>bread</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>185</th>\n",
              "      <td>ppprPr Pr pr PRPRPMPHPhph ph Ph PH HY Hy H h...</td>\n",
              "      <td>the chicken soup</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>186</th>\n",
              "      <td>j JJj</td>\n",
              "      <td>family came home</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>187</th>\n",
              "      <td></td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188</th>\n",
              "      <td></td>\n",
              "      <td>robot</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189</th>\n",
              "      <td></td>\n",
              "      <td>he family a lot of work</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>190</th>\n",
              "      <td>urURTERtertherth th ThThuthith</td>\n",
              "      <td>Victor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>191</th>\n",
              "      <td>to tootooToo Too ToToTaTUnt Unt unt nont dest...</td>\n",
              "      <td>Helen</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>uppoppppppspperspperoperopersopsOPSOPopoopo...</td>\n",
              "      <td>tomatoes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>193</th>\n",
              "      <td>to To TOToTOtotooTooTa Ta ta ti vi Vi SiSiTiV...</td>\n",
              "      <td>cabbages</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>194</th>\n",
              "      <td></td>\n",
              "      <td>Robbie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td></td>\n",
              "      <td>get the big pot</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>jugraglagagagsaggedaggingaggggrogrococogoggugg</td>\n",
              "      <td>put some water in the pot</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td></td>\n",
              "      <td>Johnson</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>mirMirMm m M mmmmmsmbmpsmSMSmMP MP</td>\n",
              "      <td>Karnack, Texas</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td></td>\n",
              "      <td>her nurse</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1f255db6-6373-4b4d-98cd-8b1e175674e0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1f255db6-6373-4b4d-98cd-8b1e175674e0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1f255db6-6373-4b4d-98cd-8b1e175674e0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "nlp",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "0847cda728ef3e0f335e7e94b5a043d9a0fda1c620343fc6302f7013063303dc"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}