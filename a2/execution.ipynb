{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Assignment 2 execution","metadata":{"id":"qtlMx4kv1mPK"}},{"cell_type":"code","source":"%pip install pandas numpy matplotlib transformers==4.25.1  dataset tensorflow_addons","metadata":{"id":"feevAAsT1mPL","outputId":"e0f0f7c5-3f9e-4862-a741-838835dcd664","execution":{"iopub.status.busy":"2023-01-14T19:27:05.275678Z","iopub.execute_input":"2023-01-14T19:27:05.276062Z","iopub.status.idle":"2023-01-14T19:27:15.930750Z","shell.execute_reply.started":"2023-01-14T19:27:05.276030Z","shell.execute_reply":"2023-01-14T19:27:15.929368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data loading","metadata":{"id":"kJSsWQg_1mPO"}},{"cell_type":"markdown","source":"### Dataset download","metadata":{"id":"1mXm1Fpq1mPP"}},{"cell_type":"code","source":"import os\nimport urllib.request\nfrom tqdm import tqdm\n\nclass DownloadProgressBar(tqdm):\n    def update_to(self, b=1, bsize=1, tsize=None):\n        if tsize is not None:\n            self.total = tsize\n        self.update(b * bsize - self.n)\n        \ndef download_url(url, output_path):\n    with DownloadProgressBar(unit='B', unit_scale=True,\n                             miniters=1, desc=url.split('/')[-1]) as t:\n        urllib.request.urlretrieve(url, filename=output_path, reporthook=t.update_to)\n\ndef download_data(data_path, url_path, suffix):    \n    if not os.path.exists(data_path):\n        os.makedirs(data_path)\n        \n    data_path = os.path.join(data_path, f'{suffix}.json')\n    if not os.path.exists(data_path):\n        print(f\"Downloading CoQA {suffix} data split... (it may take a while)\")\n        download_url(url=url_path, output_path=data_path)\n        print(\"Download completed!\")","metadata":{"id":"oOqlik_a1mPP","execution":{"iopub.status.busy":"2023-01-14T19:27:15.933200Z","iopub.execute_input":"2023-01-14T19:27:15.933918Z","iopub.status.idle":"2023-01-14T19:27:15.943875Z","shell.execute_reply.started":"2023-01-14T19:27:15.933876Z","shell.execute_reply":"2023-01-14T19:27:15.943086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_folder = 'Dataset'","metadata":{"id":"sskRUOtB1mPR","execution":{"iopub.status.busy":"2023-01-14T19:27:15.946772Z","iopub.execute_input":"2023-01-14T19:27:15.947037Z","iopub.status.idle":"2023-01-14T19:27:15.955878Z","shell.execute_reply.started":"2023-01-14T19:27:15.947012Z","shell.execute_reply":"2023-01-14T19:27:15.954901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train & Validation data\ntrain_url = \"https://nlp.stanford.edu/data/coqa/coqa-train-v1.0.json\"\ndownload_data(data_path=data_folder, url_path=train_url, suffix='train')\n\n# Test data\ntest_url = \"https://nlp.stanford.edu/data/coqa/coqa-dev-v1.0.json\"\ndownload_data(data_path=data_folder, url_path=test_url, suffix='test')","metadata":{"id":"CzsJWqI61mPR","execution":{"iopub.status.busy":"2023-01-14T19:27:15.958711Z","iopub.execute_input":"2023-01-14T19:27:15.959226Z","iopub.status.idle":"2023-01-14T19:27:15.965990Z","shell.execute_reply.started":"2023-01-14T19:27:15.959169Z","shell.execute_reply":"2023-01-14T19:27:15.965021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Dataset loading","metadata":{"id":"GsM9znVV1mPT"}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport json\nfrom os import path\nfrom matplotlib import pyplot as plt","metadata":{"id":"VRsmY5Wn1mPV","execution":{"iopub.status.busy":"2023-01-14T19:27:15.967313Z","iopub.execute_input":"2023-01-14T19:27:15.968286Z","iopub.status.idle":"2023-01-14T19:27:15.977796Z","shell.execute_reply.started":"2023-01-14T19:27:15.968251Z","shell.execute_reply":"2023-01-14T19:27:15.976677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_coqa_dataset(filename:str) -> pd.DataFrame:\n    with open(path.join(data_folder, filename)) as file_obj:\n        data_arr = json.load(file_obj)[\"data\"]\n    print(f'{len(data_arr)} stories / {len(data_arr[0][\"questions\"])} questions in the first row')\n    \n    # Prepare the Categorical DTypes\n\n    storyDType = pd.CategoricalDtype(pd.unique([story[\"story\"] for story in data_arr]))\n    print(f\"{storyDType.categories.size} distinct stories\")\n\n    sourceDType = pd.CategoricalDtype(pd.unique([story[\"source\"] for story in data_arr]))\n    print(f\"{sourceDType.categories.size} distinct sources: {sourceDType.categories}\")\n    \n    # Transform into a numpy matrix (denormalization and categorical factorization)\n\n    data_arr = np.array([\n        [\n            sourceDType.categories.get_loc(story[\"source\"]), # Sources factorization\n            storyDType.categories.get_loc(story[\"story\"]), # Sources factorization\n            story[\"questions\"][question_index][\"input_text\"],\n            story[\"answers\"][question_index][\"input_text\"],\n            story[\"answers\"][question_index][\"span_text\"],\n            #story[\"questions\"][question_index][\"turn_id\"],\n        ]\n        for story in data_arr\n        for question_index in range(len(story[\"questions\"]))\n        if story[\"answers\"][question_index][\"input_text\"] != 'unknown'\n    ])\n    print(f'{data_arr.shape} question-answer pairs x columns')\n    print(f'First row: {data_arr[0]}')\n    \n    # Transform into a DataFrame\n    \n    # https://marcobonzanini.com/2021/09/15/tips-for-saving-memory-with-pandas/\n    # https://pandas.pydata.org/docs/user_guide/categorical.html\n    return pd.DataFrame({\n        \"source\": pd.Series(pd.Categorical.from_codes(data_arr[:,0].astype(np.int16), dtype=sourceDType)),\n        \"p\": pd.Series(pd.Categorical.from_codes(data_arr[:,1].astype(np.int16), dtype=storyDType)),\n        \"q\": data_arr[:,2],\n        \"a\": data_arr[:,3],\n        \"span\": data_arr[:,4],\n    })","metadata":{"id":"lI74kMng1mPW","execution":{"iopub.status.busy":"2023-01-14T19:27:15.979480Z","iopub.execute_input":"2023-01-14T19:27:15.979843Z","iopub.status.idle":"2023-01-14T19:27:15.993559Z","shell.execute_reply.started":"2023-01-14T19:27:15.979810Z","shell.execute_reply":"2023-01-14T19:27:15.992649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def append_shifted_question_to_coqa_dataset(df:pd.DataFrame, shift:int) -> (pd.DataFrame,int):\n    if shift <= 0:\n        raise Exception(\"shift must be grater than zero\")\n    history_mask = df[\"p\"] == df[\"p\"].shift(shift)\n    history_series = df[\"q\"].shift(shift).astype(str) + ' ' + df[\"a\"].shift(shift) + '. ' + df[\"history\"]\n    df[\"history\"] = np.where(history_mask, history_series, df[\"history\"])\n    return df, history_mask.sum()","metadata":{"execution":{"iopub.status.busy":"2023-01-14T19:27:15.994763Z","iopub.execute_input":"2023-01-14T19:27:15.995033Z","iopub.status.idle":"2023-01-14T19:27:16.004567Z","shell.execute_reply.started":"2023-01-14T19:27:15.994999Z","shell.execute_reply":"2023-01-14T19:27:16.003692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def transform_coqa_dataset_with_history(df:pd.DataFrame, max_history_depth:int=3) -> pd.DataFrame:\n    df[\"history\"] = \"\"\n    for i in range(1, max_history_depth+1):\n        df, count = append_shifted_question_to_coqa_dataset(df, i)\n        print(i, count)\n        if(count == 0):\n            break;\n    return df","metadata":{"execution":{"iopub.status.busy":"2023-01-14T19:27:16.007753Z","iopub.execute_input":"2023-01-14T19:27:16.008007Z","iopub.status.idle":"2023-01-14T19:27:16.018355Z","shell.execute_reply.started":"2023-01-14T19:27:16.007984Z","shell.execute_reply":"2023-01-14T19:27:16.017379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = load_coqa_dataset(\"train.json\")\ntrain_df.count()","metadata":{"id":"jsZrgF5d1mPX","outputId":"7d294195-2b7a-4754-c327-cef6550664b4","execution":{"iopub.status.busy":"2023-01-14T19:27:16.020981Z","iopub.execute_input":"2023-01-14T19:27:16.021753Z","iopub.status.idle":"2023-01-14T19:27:22.418630Z","shell.execute_reply.started":"2023-01-14T19:27:16.021727Z","shell.execute_reply":"2023-01-14T19:27:22.417721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2 = transform_coqa_dataset_with_history(train_df.head(50))\ndf2.to_csv(\"x.csv\")\ndf2","metadata":{"execution":{"iopub.status.busy":"2023-01-14T19:27:22.421497Z","iopub.execute_input":"2023-01-14T19:27:22.422340Z","iopub.status.idle":"2023-01-14T19:27:22.470558Z","shell.execute_reply.started":"2023-01-14T19:27:22.422307Z","shell.execute_reply":"2023-01-14T19:27:22.469594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.unique(train_df[\"p\"]).size","metadata":{"id":"lOQSe3Sc1mPY","outputId":"304485dc-ba35-42fa-e3ea-55fe7e3e9bde","execution":{"iopub.status.busy":"2023-01-14T18:01:58.421000Z","iopub.execute_input":"2023-01-14T18:01:58.421366Z","iopub.status.idle":"2023-01-14T18:01:58.429161Z","shell.execute_reply.started":"2023-01-14T18:01:58.421339Z","shell.execute_reply":"2023-01-14T18:01:58.428187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.unique(train_df[\"span\"]).size","metadata":{"id":"WJaLGY_p1mPZ","outputId":"24eabb58-d7c7-4b52-91b1-2f60e42c1bb4","execution":{"iopub.status.busy":"2023-01-14T18:01:58.430592Z","iopub.execute_input":"2023-01-14T18:01:58.431456Z","iopub.status.idle":"2023-01-14T18:01:58.467502Z","shell.execute_reply.started":"2023-01-14T18:01:58.431419Z","shell.execute_reply":"2023-01-14T18:01:58.466452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.unique(train_df[\"source\"]).size","metadata":{"id":"V_ml0A1b1mPZ","outputId":"871d6621-8a87-4838-94f7-dd66c0343e48","execution":{"iopub.status.busy":"2023-01-14T18:01:58.468805Z","iopub.execute_input":"2023-01-14T18:01:58.469191Z","iopub.status.idle":"2023-01-14T18:01:58.478021Z","shell.execute_reply.started":"2023-01-14T18:01:58.469139Z","shell.execute_reply":"2023-01-14T18:01:58.476843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"id":"G9VjurfZ1mPZ","outputId":"c6f1b913-ee94-42e4-b851-3beca4d70565","execution":{"iopub.status.busy":"2023-01-14T18:01:58.479825Z","iopub.execute_input":"2023-01-14T18:01:58.480486Z","iopub.status.idle":"2023-01-14T18:01:58.494445Z","shell.execute_reply.started":"2023-01-14T18:01:58.480450Z","shell.execute_reply":"2023-01-14T18:01:58.493448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.memory_usage(deep=True)","metadata":{"id":"nrRkHhES1mPa","outputId":"61821621-8bab-4aa8-c8c3-1046fbf6d0af","execution":{"iopub.status.busy":"2023-01-14T18:01:58.496105Z","iopub.execute_input":"2023-01-14T18:01:58.496470Z","iopub.status.idle":"2023-01-14T18:01:58.536943Z","shell.execute_reply.started":"2023-01-14T18:01:58.496437Z","shell.execute_reply":"2023-01-14T18:01:58.535854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = load_coqa_dataset(\"test.json\")\ntest_df.count()","metadata":{"id":"v5aer1n41mPa","outputId":"86f96ff7-3b2b-49e5-81f3-d97167146d20","execution":{"iopub.status.busy":"2023-01-14T18:01:58.538771Z","iopub.execute_input":"2023-01-14T18:01:58.539167Z","iopub.status.idle":"2023-01-14T18:01:59.219403Z","shell.execute_reply.started":"2023-01-14T18:01:58.539132Z","shell.execute_reply":"2023-01-14T18:01:59.218387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Pre-Processing","metadata":{"id":"XRs7YHKY1mPa"}},{"cell_type":"markdown","source":"### Check unanswerable questions in the Train Dataset","metadata":{"id":"k0GmOXam1mPb"}},{"cell_type":"code","source":"idx = (train_df.a == 'unknown')\nunanswerable = train_df[idx]\nunanswerable.q.count()","metadata":{"id":"6Aq524zd1mPb","outputId":"084d7a36-f516-43c0-fd94-576917191158","execution":{"iopub.status.busy":"2023-01-11T21:00:17.620618Z","iopub.execute_input":"2023-01-11T21:00:17.621703Z","iopub.status.idle":"2023-01-11T21:00:17.652117Z","shell.execute_reply.started":"2023-01-11T21:00:17.621664Z","shell.execute_reply":"2023-01-11T21:00:17.651119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"All unanswerable questions in the Train Dataset have been already removed.","metadata":{"id":"lTdjLFYI1mPb"}},{"cell_type":"markdown","source":"## Exploratory Data Analysis","metadata":{"id":"maBslb2n1mPb"}},{"cell_type":"code","source":"train_df[\"p\"][42]","metadata":{"id":"VH5Ep77e1mPb","outputId":"0975fa5c-13a7-4c27-b8bd-feb9ca5a502c","execution":{"iopub.status.busy":"2023-01-11T21:00:17.653755Z","iopub.execute_input":"2023-01-11T21:00:17.654426Z","iopub.status.idle":"2023-01-11T21:00:17.677739Z","shell.execute_reply.started":"2023-01-11T21:00:17.654387Z","shell.execute_reply":"2023-01-11T21:00:17.676457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[\"q\"][42]","metadata":{"id":"zYcgBVcG1mPc","outputId":"06e1a9cf-64db-48bf-b61f-e2f90390aeee","execution":{"iopub.status.busy":"2023-01-11T21:00:17.679295Z","iopub.execute_input":"2023-01-11T21:00:17.679818Z","iopub.status.idle":"2023-01-11T21:00:17.688873Z","shell.execute_reply.started":"2023-01-11T21:00:17.679783Z","shell.execute_reply":"2023-01-11T21:00:17.687694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[\"a\"][42]","metadata":{"id":"5zvn9Tv01mPc","outputId":"0fd3f762-55b0-4149-d739-7438aac60f03","execution":{"iopub.status.busy":"2023-01-11T21:00:17.690431Z","iopub.execute_input":"2023-01-11T21:00:17.690914Z","iopub.status.idle":"2023-01-11T21:00:17.705300Z","shell.execute_reply.started":"2023-01-11T21:00:17.690874Z","shell.execute_reply":"2023-01-11T21:00:17.704082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[\"span\"][42]","metadata":{"id":"NokHfoLm1mPc","outputId":"9126a685-5d14-4e32-ebd1-9e2c504b32b6","execution":{"iopub.status.busy":"2023-01-11T21:00:17.706787Z","iopub.execute_input":"2023-01-11T21:00:17.707264Z","iopub.status.idle":"2023-01-11T21:00:17.716884Z","shell.execute_reply.started":"2023-01-11T21:00:17.707231Z","shell.execute_reply":"2023-01-11T21:00:17.715553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[\"source\"][42]","metadata":{"id":"JskMPh-Y1mPc","outputId":"c50f699e-e12f-4126-b8be-118960bdb039","execution":{"iopub.status.busy":"2023-01-11T21:00:17.718439Z","iopub.execute_input":"2023-01-11T21:00:17.718915Z","iopub.status.idle":"2023-01-11T21:00:17.729939Z","shell.execute_reply.started":"2023-01-11T21:00:17.718881Z","shell.execute_reply":"2023-01-11T21:00:17.728732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Distribution statistics","metadata":{"id":"IhdF4AR7ef05"}},{"cell_type":"markdown","source":"Sources:","metadata":{"id":"ebBVUlveef05"}},{"cell_type":"code","source":"train_df[\"source\"].hist()","metadata":{"id":"8lIuR9RO1mPd","outputId":"0369e9c1-3f19-4637-95cc-5a2c8ef1319b","execution":{"iopub.status.busy":"2023-01-11T21:00:17.731526Z","iopub.execute_input":"2023-01-11T21:00:17.732007Z","iopub.status.idle":"2023-01-11T21:00:18.104916Z","shell.execute_reply.started":"2023-01-11T21:00:17.731972Z","shell.execute_reply":"2023-01-11T21:00:18.103960Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Occurrences of 25 most popular stories:","metadata":{"id":"Ax5uSP6Lef06"}},{"cell_type":"code","source":"story_counts = train_df[\"p\"].cat.codes.value_counts(sort=True)\nstory_counts[:25].plot(kind=\"bar\", figsize=(15,5))","metadata":{"id":"wUgsqg4Uef06","outputId":"cc65605d-ca1a-47c2-ab42-dddb83cfd83f","execution":{"iopub.status.busy":"2023-01-11T21:00:18.109193Z","iopub.execute_input":"2023-01-11T21:00:18.111545Z","iopub.status.idle":"2023-01-11T21:00:18.536732Z","shell.execute_reply.started":"2023-01-11T21:00:18.111490Z","shell.execute_reply":"2023-01-11T21:00:18.535711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Occurrences of 25 least popular stories:","metadata":{"id":"qL-m6SuVef06"}},{"cell_type":"code","source":"story_counts[-25:-1].plot(kind=\"bar\", figsize=(15,5))","metadata":{"id":"jkiwEygzef06","outputId":"7edfc225-8301-4365-af3c-591fb59887a1","execution":{"iopub.status.busy":"2023-01-11T21:00:18.541310Z","iopub.execute_input":"2023-01-11T21:00:18.543837Z","iopub.status.idle":"2023-01-11T21:00:18.982802Z","shell.execute_reply.started":"2023-01-11T21:00:18.543794Z","shell.execute_reply":"2023-01-11T21:00:18.981861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Histogram of story popularities:","metadata":{"id":"9-EVRQQVef06"}},{"cell_type":"code","source":"story_counts.hist(log=True,bins=75,figsize=(15,5))","metadata":{"id":"CJLPGCfcef07","outputId":"fa4f07bc-deb2-4806-c940-91b40663aca5","execution":{"iopub.status.busy":"2023-01-11T21:00:18.986932Z","iopub.execute_input":"2023-01-11T21:00:18.989144Z","iopub.status.idle":"2023-01-11T21:00:20.056265Z","shell.execute_reply.started":"2023-01-11T21:00:18.989105Z","shell.execute_reply":"2023-01-11T21:00:20.055343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Removing rows with outlier story lengths to save memory","metadata":{"id":"Xs4usWsveQN2"}},{"cell_type":"code","source":"train_df.count()","metadata":{"execution":{"iopub.status.busy":"2023-01-11T21:00:20.060502Z","iopub.execute_input":"2023-01-11T21:00:20.062774Z","iopub.status.idle":"2023-01-11T21:00:20.096428Z","shell.execute_reply.started":"2023-01-11T21:00:20.062736Z","shell.execute_reply":"2023-01-11T21:00:20.095341Z"},"id":"fF88Qa2DeQN2","outputId":"2c103f10-9c9d-4854-f1dc-4e1867563b64","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"LOGARITHMIC histogram of story length:","metadata":{"id":"xOq3OJo1eQN2"}},{"cell_type":"code","source":"story_lengths = train_df[\"p\"].str.len()\nstory_lengths.hist(log=True,bins=75,figsize=(15,5))","metadata":{"execution":{"iopub.status.busy":"2023-01-11T21:00:20.098032Z","iopub.execute_input":"2023-01-11T21:00:20.098354Z","iopub.status.idle":"2023-01-11T21:00:21.022634Z","shell.execute_reply.started":"2023-01-11T21:00:20.098322Z","shell.execute_reply":"2023-01-11T21:00:21.021710Z"},"id":"N9SpIueeeQN2","outputId":"2001c8cb-8339-4e32-f377-828390f12842","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"p_length_limit = story_lengths.quantile(0.999)\np_length_limit","metadata":{"execution":{"iopub.status.busy":"2023-01-11T21:00:21.023971Z","iopub.execute_input":"2023-01-11T21:00:21.024522Z","iopub.status.idle":"2023-01-11T21:00:21.036709Z","shell.execute_reply.started":"2023-01-11T21:00:21.024485Z","shell.execute_reply":"2023-01-11T21:00:21.035374Z"},"id":"55wmfOrseQN3","outputId":"f2acc89b-54c0-4ee9-f0b6-424b69be6758","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"p_length_mask = story_lengths < p_length_limit\np_length_mask.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-01-11T21:00:21.041357Z","iopub.execute_input":"2023-01-11T21:00:21.041755Z","iopub.status.idle":"2023-01-11T21:00:21.055317Z","shell.execute_reply.started":"2023-01-11T21:00:21.041715Z","shell.execute_reply":"2023-01-11T21:00:21.053819Z"},"id":"JdD1HKnqeQN3","outputId":"933f1245-eaa4-4dca-f8cf-7b9d8a12d87a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = train_df[p_length_mask]\ntrain_df.count()","metadata":{"execution":{"iopub.status.busy":"2023-01-11T21:00:21.066878Z","iopub.execute_input":"2023-01-11T21:00:21.068993Z","iopub.status.idle":"2023-01-11T21:00:21.116598Z","shell.execute_reply.started":"2023-01-11T21:00:21.068957Z","shell.execute_reply":"2023-01-11T21:00:21.115706Z"},"id":"8ZrtswVUeQN3","outputId":"31a0adf9-0b43-4c28-8590-ed0a995bbc6d","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Removing rows with outlier question/answer/span lengths to save memory","metadata":{"id":"CvuDNquieQN3"}},{"cell_type":"markdown","source":"LOGARITHMIC histogram of question length:","metadata":{"id":"XTnHoRoEeQN3"}},{"cell_type":"code","source":"question_lengths = train_df[\"q\"].str.len()\nquestion_lengths.hist(log=True,bins=75,figsize=(15,5))","metadata":{"id":"kFobL8Upef07","outputId":"5bec3346-d87a-48fd-dcc3-13ec411c23a2","execution":{"iopub.status.busy":"2023-01-11T21:00:21.121249Z","iopub.execute_input":"2023-01-11T21:00:21.124112Z","iopub.status.idle":"2023-01-11T21:00:21.898684Z","shell.execute_reply.started":"2023-01-11T21:00:21.124072Z","shell.execute_reply":"2023-01-11T21:00:21.897686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"q_length_limit = question_lengths.quantile(0.999)\nq_length_limit","metadata":{"execution":{"iopub.status.busy":"2023-01-11T21:00:21.903244Z","iopub.execute_input":"2023-01-11T21:00:21.906122Z","iopub.status.idle":"2023-01-11T21:00:21.920912Z","shell.execute_reply.started":"2023-01-11T21:00:21.906083Z","shell.execute_reply":"2023-01-11T21:00:21.919697Z"},"id":"Y5492ySpeQN4","outputId":"78a94bf1-267a-472c-b2f8-14e440219ea6","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"LOGARITHMIC histogram of answer length:","metadata":{"id":"yGTJLGsWeQN4"}},{"cell_type":"code","source":"answer_lengths = train_df[\"a\"].str.len()\nanswer_lengths.hist(log=True,bins=75,figsize=(15,5))","metadata":{"id":"_7phh51Nef07","outputId":"b333993b-a2c7-4078-b2d1-a4f5d6d448b6","execution":{"iopub.status.busy":"2023-01-11T21:00:21.923093Z","iopub.execute_input":"2023-01-11T21:00:21.923995Z","iopub.status.idle":"2023-01-11T21:00:22.662567Z","shell.execute_reply.started":"2023-01-11T21:00:21.923955Z","shell.execute_reply":"2023-01-11T21:00:22.661550Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a_length_limit = answer_lengths.quantile(0.999)\na_length_limit","metadata":{"execution":{"iopub.status.busy":"2023-01-11T21:00:22.664096Z","iopub.execute_input":"2023-01-11T21:00:22.664460Z","iopub.status.idle":"2023-01-11T21:00:22.675110Z","shell.execute_reply.started":"2023-01-11T21:00:22.664422Z","shell.execute_reply":"2023-01-11T21:00:22.673990Z"},"id":"B9Z5Ck7XeQN4","outputId":"56e030b9-70e8-487a-860d-c7298a41bc67","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"span_lengths = train_df[\"span\"].str.len()\nspan_lengths.hist(log=True,bins=75,figsize=(15,5))","metadata":{"execution":{"iopub.status.busy":"2023-01-11T21:00:22.676750Z","iopub.execute_input":"2023-01-11T21:00:22.677160Z","iopub.status.idle":"2023-01-11T21:00:23.561713Z","shell.execute_reply.started":"2023-01-11T21:00:22.677118Z","shell.execute_reply":"2023-01-11T21:00:23.560658Z"},"id":"KfwQxbu_eQN4","outputId":"36c69df9-ee25-4c99-c9e5-fae92edccae1","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"span_length_limit = span_lengths.quantile(0.999)\nspan_length_limit","metadata":{"execution":{"iopub.status.busy":"2023-01-11T21:00:23.563315Z","iopub.execute_input":"2023-01-11T21:00:23.563675Z","iopub.status.idle":"2023-01-11T21:00:23.575399Z","shell.execute_reply.started":"2023-01-11T21:00:23.563624Z","shell.execute_reply":"2023-01-11T21:00:23.574285Z"},"id":"Z16rujBBeQN5","outputId":"bb172bbb-1fac-4fc9-be15-9d127fcc4dbf","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bad_length_mask = (question_lengths > q_length_limit) | (answer_lengths > a_length_limit) | (span_lengths > span_length_limit)\nbad_length_mask.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-01-11T21:00:23.576737Z","iopub.execute_input":"2023-01-11T21:00:23.577935Z","iopub.status.idle":"2023-01-11T21:00:23.589632Z","shell.execute_reply.started":"2023-01-11T21:00:23.577899Z","shell.execute_reply":"2023-01-11T21:00:23.588757Z"},"id":"LzINwGJreQN5","outputId":"b522d9f1-1d9a-4840-ae55-44d5b0a32aac","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"excluded_stories = train_df[\"p\"][bad_length_mask].unique()\nlen(excluded_stories)","metadata":{"execution":{"iopub.status.busy":"2023-01-11T21:00:23.592467Z","iopub.execute_input":"2023-01-11T21:00:23.593181Z","iopub.status.idle":"2023-01-11T21:00:23.600425Z","shell.execute_reply.started":"2023-01-11T21:00:23.593155Z","shell.execute_reply":"2023-01-11T21:00:23.599487Z"},"id":"sxmcnFXbeQN5","outputId":"30af07d2-4477-4593-fa45-acade632bc0e","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"excluded_mask = ~train_df[\"p\"].isin(excluded_stories)\nexcluded_mask.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-01-11T21:00:23.601992Z","iopub.execute_input":"2023-01-11T21:00:23.602435Z","iopub.status.idle":"2023-01-11T21:00:23.614444Z","shell.execute_reply.started":"2023-01-11T21:00:23.602401Z","shell.execute_reply":"2023-01-11T21:00:23.613428Z"},"id":"sRrwwM2eeQN6","outputId":"c4a91a50-cc5b-4114-a24c-a07b4c3a9b11","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = train_df[excluded_mask]\ntrain_df.count()","metadata":{"execution":{"iopub.status.busy":"2023-01-11T21:00:23.616064Z","iopub.execute_input":"2023-01-11T21:00:23.616404Z","iopub.status.idle":"2023-01-11T21:00:23.644947Z","shell.execute_reply.started":"2023-01-11T21:00:23.616371Z","shell.execute_reply":"2023-01-11T21:00:23.643935Z"},"id":"5sPbSYmFeQN6","outputId":"aee405f5-5932-49c7-d405-c42d7e1938da","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train-Validation-Test split","metadata":{"id":"mm2QCJbR1mPd"}},{"cell_type":"code","source":"train_df = train_df.reset_index()","metadata":{"execution":{"iopub.status.busy":"2023-01-11T21:00:23.646184Z","iopub.execute_input":"2023-01-11T21:00:23.646601Z","iopub.status.idle":"2023-01-11T21:00:23.660060Z","shell.execute_reply.started":"2023-01-11T21:00:23.646567Z","shell.execute_reply":"2023-01-11T21:00:23.659048Z"},"id":"c4GiqoqneQN6","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_rows = len(train_df)\ntotal_rows","metadata":{"execution":{"iopub.status.busy":"2023-01-11T21:00:23.661308Z","iopub.execute_input":"2023-01-11T21:00:23.661885Z","iopub.status.idle":"2023-01-11T21:00:23.669609Z","shell.execute_reply.started":"2023-01-11T21:00:23.661845Z","shell.execute_reply":"2023-01-11T21:00:23.668611Z"},"id":"pehX7aazeQN7","outputId":"661947ce-d74d-452d-baea-a1bb16c096c8","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ideal_split_index = int(total_rows * 0.8)\nideal_split_index","metadata":{"execution":{"iopub.status.busy":"2023-01-11T21:00:23.671120Z","iopub.execute_input":"2023-01-11T21:00:23.671505Z","iopub.status.idle":"2023-01-11T21:00:23.679290Z","shell.execute_reply.started":"2023-01-11T21:00:23.671463Z","shell.execute_reply":"2023-01-11T21:00:23.678158Z"},"id":"_rxe3wDoeQN7","outputId":"4b697e68-ca27-4271-b797-a566005747f8","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[ ideal_split_index-3 : ideal_split_index+1 ]","metadata":{"execution":{"iopub.status.busy":"2023-01-11T21:00:23.681115Z","iopub.execute_input":"2023-01-11T21:00:23.681594Z","iopub.status.idle":"2023-01-11T21:00:23.697610Z","shell.execute_reply.started":"2023-01-11T21:00:23.681555Z","shell.execute_reply":"2023-01-11T21:00:23.696665Z"},"id":"T6_GsayreQN7","outputId":"d099a899-94c9-4d37-ee6e-768357334764","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"before_split_mask = pd.Series(np.linspace(0, total_rows, total_rows)) < ideal_split_index\nbefore_split_mask.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-01-11T21:00:23.699754Z","iopub.execute_input":"2023-01-11T21:00:23.700031Z","iopub.status.idle":"2023-01-11T21:00:23.712578Z","shell.execute_reply.started":"2023-01-11T21:00:23.700006Z","shell.execute_reply":"2023-01-11T21:00:23.711595Z"},"id":"3VaBpWTneQN7","outputId":"994982b6-0133-46aa-9a58-8fb8fbaeee20","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"split_story = train_df[\"p\"][ideal_split_index - 1]\nsplit_story_mask = train_df[\"p\"] == split_story\nsplit_story_mask.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-01-11T21:00:23.714157Z","iopub.execute_input":"2023-01-11T21:00:23.714575Z","iopub.status.idle":"2023-01-11T21:00:23.723884Z","shell.execute_reply.started":"2023-01-11T21:00:23.714541Z","shell.execute_reply":"2023-01-11T21:00:23.722902Z"},"id":"piLsdDEpeQN7","outputId":"7b39a5bd-8a1a-4db2-b7c6-ba26a8e5144c","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_mask = before_split_mask | split_story_mask\ntrain_mask.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-01-11T21:00:23.725141Z","iopub.execute_input":"2023-01-11T21:00:23.725891Z","iopub.status.idle":"2023-01-11T21:00:23.738421Z","shell.execute_reply.started":"2023-01-11T21:00:23.725858Z","shell.execute_reply":"2023-01-11T21:00:23.737522Z"},"id":"Eix1zlO9eQN8","outputId":"23f2e5c1-d988-4756-e0a9-26fc0891d1f1","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_df = train_df[~train_mask]\ntrain_df = train_df[train_mask]\nlen(val_df)","metadata":{"execution":{"iopub.status.busy":"2023-01-11T21:00:23.739466Z","iopub.execute_input":"2023-01-11T21:00:23.740447Z","iopub.status.idle":"2023-01-11T21:00:23.756216Z","shell.execute_reply.started":"2023-01-11T21:00:23.740413Z","shell.execute_reply":"2023-01-11T21:00:23.755568Z"},"id":"UdWGo8SaeQN8","outputId":"bbac7a93-c4da-4c50-ecbf-486d36346364","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.memory_usage()","metadata":{"execution":{"iopub.status.busy":"2023-01-11T21:00:23.757225Z","iopub.execute_input":"2023-01-11T21:00:23.758162Z","iopub.status.idle":"2023-01-11T21:00:23.767989Z","shell.execute_reply.started":"2023-01-11T21:00:23.758128Z","shell.execute_reply":"2023-01-11T21:00:23.767067Z"},"id":"HFMUopPIeQN8","outputId":"dbb86ede-0f2a-48d2-c92d-7df47eacd512","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_df.memory_usage()","metadata":{"execution":{"iopub.status.busy":"2023-01-11T21:00:23.769566Z","iopub.execute_input":"2023-01-11T21:00:23.770010Z","iopub.status.idle":"2023-01-11T21:00:23.777596Z","shell.execute_reply.started":"2023-01-11T21:00:23.769976Z","shell.execute_reply":"2023-01-11T21:00:23.776525Z"},"id":"wBD8UhMOeQN8","outputId":"63fbab49-1339-4c52-f175-6023c9473d05","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.memory_usage()","metadata":{"execution":{"iopub.status.busy":"2023-01-11T21:00:23.779329Z","iopub.execute_input":"2023-01-11T21:00:23.779758Z","iopub.status.idle":"2023-01-11T21:00:23.791394Z","shell.execute_reply.started":"2023-01-11T21:00:23.779724Z","shell.execute_reply":"2023-01-11T21:00:23.790355Z"},"id":"aoWZVRDyeQN8","outputId":"8ca01c43-dbd7-4121-dc4b-6cb9572b6ac2","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"8ajvOEG8eQN9","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Utilities","metadata":{"id":"6wuh0_ic1mPd"}},{"cell_type":"code","source":"import gc\nimport torch\ndef free_some_memory():\n    torch.cuda.empty_cache()\n    torch.cuda.reset_accumulated_memory_stats()\n    gc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-01-11T21:00:23.793198Z","iopub.execute_input":"2023-01-11T21:00:23.793585Z","iopub.status.idle":"2023-01-11T21:00:25.458963Z","shell.execute_reply.started":"2023-01-11T21:00:23.793548Z","shell.execute_reply":"2023-01-11T21:00:25.457932Z"},"id":"cQfcofYQeQN9","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#del excluded_stories, split_story, before_split_mask, split_story_mask, train_mask\n#free_some_memory()","metadata":{"execution":{"iopub.status.busy":"2023-01-11T21:00:25.460190Z","iopub.execute_input":"2023-01-11T21:00:25.460763Z","iopub.status.idle":"2023-01-11T21:00:25.657497Z","shell.execute_reply.started":"2023-01-11T21:00:25.460725Z","shell.execute_reply":"2023-01-11T21:00:25.656125Z"},"id":"CP-oyhY7eQN9","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import f1_score\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom typing import List, Dict, Callable\nimport random\nimport tensorflow_addons as tfa\nfrom tqdm import tqdm\nfrom timeit import default_timer as timer\nfrom transformers import TFAutoModel, AutoTokenizer","metadata":{"id":"4pKuTsYt1mPd","execution":{"iopub.status.busy":"2023-01-11T21:00:25.659175Z","iopub.execute_input":"2023-01-11T21:00:25.659878Z","iopub.status.idle":"2023-01-11T21:00:32.665848Z","shell.execute_reply.started":"2023-01-11T21:00:25.659839Z","shell.execute_reply":"2023-01-11T21:00:32.664667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n    try:\n        for gpu in gpus:\n            tf.config.experimental.set_memory_growth(gpu, True)\n    except RuntimeError as e:\n        print(e)","metadata":{"id":"61_GSxvB1mPe","execution":{"iopub.status.busy":"2023-01-11T21:00:32.711916Z","iopub.execute_input":"2023-01-11T21:00:32.712923Z","iopub.status.idle":"2023-01-11T21:00:32.730392Z","shell.execute_reply.started":"2023-01-11T21:00:32.712889Z","shell.execute_reply":"2023-01-11T21:00:32.729442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"###Reproducibility","metadata":{"id":"K_aTEeegKvYn"}},{"cell_type":"code","source":"def fix_seed(seed: int) -> None:\n    \"\"\"Fix all the possible sources of randomness.\n\n    Args:\n        seed: the seed to use. \n    \"\"\"\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    \n    torch.backends.cudnn.benchmark = False\n    torch.backends.cudnn.deterministic = True\n\n#fix_seed(seed=7)","metadata":{"id":"EhOiCAcW0R2i"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"###Pytorch Dataset","metadata":{"id":"Wr9lF2r5LJfQ"}},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\n\nclass CreateDataset(Dataset):\n    def __init__(self, encodings):\n        self.encodings = encodings\n\n    def __getitem__(self, idx):\n        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n\n    def __len__(self):\n        return len(self.encodings.input_ids)","metadata":{"execution":{"iopub.status.busy":"2023-01-11T21:14:26.719031Z","iopub.execute_input":"2023-01-11T21:14:26.719466Z","iopub.status.idle":"2023-01-11T21:14:26.728550Z","shell.execute_reply.started":"2023-01-11T21:14:26.719389Z","shell.execute_reply":"2023-01-11T21:14:26.727535Z"},"id":"YmIVbhWPkD31","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Train Functionalities\n","metadata":{"id":"SKp0Kz_C0z1K"}},{"cell_type":"code","source":"# Train one epoch\ndef train(model: torch.nn.Module,\n          train_loader:torch.utils.data.DataLoader,\n          device: torch.device,          \n          optimizer: torch.optim,\n          epoch: int) -> float:\n    \"\"\"Trains a neural network for one epoch.\n\n    Args:\n        model: the model to train.\n        train_loader: the data loader containing the training data.\n        device: the device to use to train the model.        \n        optimizer: the optimizer to use to train the model.\n        log_interval: the log interval.\n        epoch: the number of the current epoch.\n\n    Returns:\n        the cross entropy Loss value on the training data.\n    \"\"\"    \n    size_ds_train = len(train_loader.dataset)\n    num_batches = len(train_loader)\n    loss_score = []\n    loop = tqdm(train_loader)\n    #set training mode\n    model.train()\n    for idx_batch, batch in enumerate(loop):\n        optimizer.zero_grad()\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n        loss, outputs = model(input_ids,\n                              attention_mask=attention_mask,\n                              labels = labels\n                        )[:2]\n        loss_score.append(loss.item())\n        loss.backward()\n        optimizer.step() \n        loop.set_description(f'Epoch {epoch}')\n        #loop.set_postfix(loss=loss.item())\n\n    loss_train = np.mean(loss_score)\n    return loss_train\n\n# Validate one epoch\ndef validate(model: torch.nn.Module,\n             data_loader: torch.utils.data.DataLoader,\n             device: torch.device) -> float:\n    \"\"\"Evaluates the model.\n\n    Args:\n        model: the model to evalaute.\n        data_loader: the data loader containing the validation or test data.\n        device: the device to use to evaluate the model.\n\n    Returns:\n        the loss value on the validation data.\n    \"\"\"\n    loss_score = []\n    #set evaluation mode\n    model = model.eval()\n    with torch.no_grad():\n        for idx_batch, batch in enumerate(data_loader):\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['labels'].to(device)\n            loss, outputs = model(input_ids,\n                                  attention_mask=attention_mask,\n                                  labels = labels\n                            )[:2]\n            loss_score.append(loss.item())\n    loss_val = np.mean(loss_score)\n    return loss_val","metadata":{"id":"P-3GGR9O05dn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def training_loop(num_epochs: int,\n                  optimizer: torch.optim, \n                  model: torch.nn.Module, \n                  loader_train: torch.utils.data.DataLoader, \n                  loader_val: torch.utils.data.DataLoader, \n                  verbose: bool=True) -> Dict:\n    \"\"\"Executes the training loop.\n    \n        Args:\n            num_epochs: the number of epochs.\n            optimizer: the optimizer to use.\n            model: the mode to train.\n            loader_train: the data loader containing the training data.\n            loader_val: the data loader containing the validation data.\n            verbose: if true print the value of loss.\n\n        Returns:  \n            A dictionary with the statistics computed during the train:\n            the values for the train loss for each epoch.\n            the time of execution in seconds for the entire loop.\n    \"\"\"\n    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n    model.to(device)\n    loop_start = timer()\n    losses_values = []\n    for epoch in range(1, num_epochs + 1):\n        time_start = timer()\n        loss_train = train(model, loader_train, device, \n                                           optimizer, epoch)\n        loss_val = validate(model, loader_val, device)\n        time_end = timer()\n        losses_values.append(loss_train)\n        if verbose:            \n            print(f'Epoch: {epoch} '\n                  f' Lr: {lr:.8f} '\n                  f' Loss: Train = [{loss_train:.4f}] - Val = [{loss_val:.4f}] '\n                  f' Time one epoch (s): {(time_end - time_start):.4f} ')\n    loop_end = timer()\n    time_loop = loop_end - loop_start\n    if verbose:\n        print(f'Time for {num_epochs} epochs (s): {(time_loop):.3f}') \n        \n    return {'loss_values': losses_values,\n            'time': time_loop}","metadata":{"id":"ZRJmWE8R1bIB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Evaluation","metadata":{"id":"Z2D0z0w4LYst"}},{"cell_type":"markdown","source":"Instead of importing the whole allennlp library, we decided to copy from the source code only of the functions necessary for our task.","metadata":{"id":"3pDzWxTNLg1d"}},{"cell_type":"code","source":"#utility functions taken from the allennlp library for computing the F1-score\nimport collections\nimport re\nimport string\nfrom typing import Callable, Sequence, TypeVar, Tuple\n\ndef get_tokens(s):\n    if not s:\n        return []\n    return normalize_answer(s).split()\n\ndef normalize_answer(s):\n    \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n\n    def remove_articles(text):\n        regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n        return re.sub(regex, \" \", text)\n\n    def white_space_fix(text):\n        return \" \".join(text.split())\n\n    def remove_punc(text):\n        exclude = set(string.punctuation)\n        return \"\".join(ch for ch in text if ch not in exclude)\n\n    def lower(text):\n        return text.lower()\n\n    return white_space_fix(remove_articles(remove_punc(lower(s))))\n\ndef compute_f1(a_pred: str, a_gold: str) -> float:\n    pred_toks = get_tokens(a_pred)\n    gold_toks = get_tokens(a_gold)\n    common = collections.Counter(pred_toks) & collections.Counter(gold_toks)  # type: ignore[var-annotated]\n    num_same = sum(common.values())\n    if len(pred_toks) == 0 or len(gold_toks) == 0:\n        # If either is no-answer, then F1 is 1 if they agree, 0 otherwise\n        return float(pred_toks == gold_toks)\n    if num_same == 0:\n        return 0.0\n    precision = 1.0 * num_same / len(pred_toks)\n    recall = 1.0 * num_same / len(gold_toks)\n    f1 = (2 * precision * recall) / (precision + recall)\n    return f1","metadata":{"id":"9FKIPvM1CmVN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import EncoderDecoderModel, AutoTokenizer\n\ndef generate_answers(model: torch.nn.Module,\n                    df_input: pd.DataFrame,\n                    max_length: int,\n                    tokenizer: any):\n\n    '''\n    Given the model and the input, returns a dataframe cointaining the generated answers and relative F1-score\n    \n    Args:\n        model: Torch model used to generate answers\n        df_input: dataframe containing the input to the model\n        max_length: max length applied in the tokenization\n        tokenizer: generic tokenizer\n    '''\n\n    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n\n    input_values = tokenizer(list(df_input['q']),list(df_input['p']), \n                                padding=True, \n                                truncation=True, \n                                max_length = max_length)\n                                \n    input_ids, input_attention_mask = input_values['input_ids'], input_values['attention_mask']\n    list_generated = []\n    model.to(device)\n    # Set the model in evaluation mode\n    model.eval()\n    for input, mask in zip(input_ids,input_attention_mask):\n        input = np.expand_dims(np.array(input), axis=0)\n        mask = np.expand_dims(np.array(mask), axis=0)\n        generated = model.generate(input_ids=torch.tensor(input).to(device),\n                                                        max_length=20,\n                                                        repetition_penalty=5.,\n                                                        min_length=1,\n                                                        no_repeat_ngram_size=3,\n                                                        early_stopping=True,\n                                                        decoder_start_token_id = model.config.decoder_start_token_id,\n                                                        num_beams=2,\n                                                        )\n        generated = tokenizer.batch_decode(generated, skip_special_tokens=True)\n        list_generated.append(generated)\n\n    # Create a dataframe and insert the real answers\n    df_generated = pd.DataFrame(list_generated, columns = ['generated'])\n    df_generated['answers'] = df_input['a']\n\n    # Generate and insert the F1-score\n    score = []\n    for a_pred, a_gold in zip(df_generated['generated'], df_generated['answers']):\n        score.append(compute_f1(a_pred, a_gold))\n    df_generated['score'] = score\n\n    # Print average and len\n    average_score = np.mean(score)\n    total = len(df_generated[df_generated['score'] != 0])\n    \n    print(f'Average_score: {average_score}')\n    print(f'Length: {total} / {len(df_generated)}')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model definition","metadata":{"id":"SICbZ6vB1mPd"}},{"cell_type":"markdown","source":"### Question generation $f_\\theta(P, Q)$ with text passage $P$ and question $Q$","metadata":{"id":"1aFTVbjH1mPf"}},{"cell_type":"markdown","source":"### BERT2BERT Bert-Tiny","metadata":{"id":"pAG9J3GGfF76"}},{"cell_type":"code","source":"from transformers import EncoderDecoderModel, AutoTokenizer\nfrom tqdm import tqdm\n\nmodel_name = 'prajjwal1/bert-tiny'\n# tie_encoder_decoder to share weights and half the number of parameters\nmodel = EncoderDecoderModel.from_encoder_decoder_pretrained(model_name, model_name,\n                                                                        tie_encoder_decoder=True)\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\n# set special tokens\nmodel.config.decoder_start_token_id = tokenizer.cls_token_id\nmodel.config.eos_token_id = tokenizer.sep_token_id\nmodel.config.pad_token_id = tokenizer.pad_token_id\n\n# set decoding params                               \nmodel.config.early_stopping = True\nmodel.config.no_repeat_ngram_size = 3\nmodel.config.length_penalty = 2.0\nmodel.config.repetition_penalty = 5.0\nmodel.config.num_beams = 2\nmodel.config.vocab_size = model.config.encoder.vocab_size","metadata":{"outputId":"ced36129-0049-4bfe-cbb6-fa14e38b659e","id":"25WjYqJRfsZu","execution":{"iopub.status.busy":"2023-01-11T21:02:30.502529Z","iopub.execute_input":"2023-01-11T21:02:30.502998Z","iopub.status.idle":"2023-01-11T21:02:32.744150Z","shell.execute_reply.started":"2023-01-11T21:02:30.502970Z","shell.execute_reply":"2023-01-11T21:02:32.743009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#fix seed \nfix_seed(42)\n#take a subset from the training set\nmax_train = len(train_df)\nt_start = 0\nt_end = 80000\n#take a subset from the validation set\nmax_val = len(val_df)\nv_start = 0\nv_end = 20000\nprint(f'Training set shape: {(t_end-t_start)}\\nValidation set shape: {(v_end-v_start)}')","metadata":{"id":"oL3BVkcG5KZ8","outputId":"e438ec2b-01f3-4a26-f2c1-a197c956f462","execution":{"iopub.status.busy":"2023-01-11T21:02:30.468289Z","iopub.execute_input":"2023-01-11T21:02:30.468677Z","iopub.status.idle":"2023-01-11T21:02:30.473979Z","shell.execute_reply.started":"2023-01-11T21:02:30.468625Z","shell.execute_reply":"2023-01-11T21:02:30.472922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def encodings(tokenizer,encoder_max_length, decoder_max_length, questions, contexts, answers):\n  encodings = tokenizer(questions, contexts, \n                            padding=True,\n                            truncation= 'only_second',\n                            max_length = encoder_max_length,\n                            )\n  input_ids, input_attention_mask = encodings['input_ids'], encodings['attention_mask']\n  label_values = tokenizer(answers,\n                            padding=True,\n                            truncation=True,\n                            max_length = decoder_max_length,\n                            )\n  labels, labels_mask = label_values['input_ids'], label_values['attention_mask']\n  #Tokens with indices set to ``-100`` are ignored (masked) during training, the loss is only computed for the tokens with labels\n  masked_labels = [[-100 if token == tokenizer.pad_token_id else token for token in labels] for labels in labels]\n\n  #add the labels to the batch encodings dictionary, then this will be used to create a pytorch dataset\n  encodings.pop('token_type_ids')\n  encodings.update({'labels': masked_labels})\n  return encodings","metadata":{"id":"tmQuDvN1rq1D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoder_max_length = 499\ndecoder_max_length = 25\ntrain_encodings = encodings(tokenizer, encoder_max_length, decoder_max_length,\n                            list(train_df[t_start:t_end]['q']), \n                            list(train_df[t_start:t_end]['p']),\n                            list(train_df[t_start:t_end]['a']))\nval_encodings = encodings(tokenizer, encoder_max_length, decoder_max_length,\n                            list(val_df[v_start:v_end]['q']), \n                            list(val_df[v_start:v_end]['p']),\n                            list(val_df[v_start:v_end]['a']))","metadata":{"id":"dg0P8Cbe8-36"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def execute(model: torch.nn.Module,\n            starting_lr: float, \n            num_epochs: int, \n            data_loader_train: torch.utils.data.DataLoader,\n            data_loader_val: torch.utils.data.DataLoader) -> None:\n    \"\"\"Executes the training loop.\n\n    Args:\n        name_train: the name for the log subfolder.\n        model: the network to train.\n        starting_lr: the staring learning rate.\n        num_epochs: the number of epochs.\n        data_loader_train: the data loader with training data.\n        data_loader_val: the data loader with validation data.\n    \"\"\"\n    #Optimizer\n    optimizer = torch.optim.AdamW(model.parameters(), lr=starting_lr)\n    print(f'Start training.')\n    statistics = training_loop(num_epochs, optimizer, model,\n                               data_loader_train, data_loader_val)\n    print(f'Training complete.')\n","metadata":{"id":"_04W2EehrIH1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#parameters\nbatch_size = 16\nnum_epochs = 3\nlr = 4e-4","metadata":{"id":"Jqtjk7qM3r1r","execution":{"iopub.status.busy":"2023-01-11T21:03:30.999587Z","iopub.execute_input":"2023-01-11T21:03:30.999970Z","iopub.status.idle":"2023-01-11T21:03:31.007112Z","shell.execute_reply.started":"2023-01-11T21:03:30.999935Z","shell.execute_reply":"2023-01-11T21:03:31.006228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create training dataset\ntrain_dataset = CreateDataset(train_encodings)\n#create training dataloader\ntrain_ld = torch.utils.data.DataLoader(train_dataset,\n                                     batch_size=batch_size,\n                                     )\n#create validation dataset\nval_dataset = CreateDataset(val_encodings)\n#create validation dataloader\nval_ld = torch.utils.data.DataLoader(val_dataset,\n                                     batch_size=batch_size,\n                                     )\n#execute\nexecute(model, lr, num_epochs, train_ld, val_ld)","metadata":{"id":"vowXc6lgygac","outputId":"1156c138-3509-453d-84db-7e42ad709329"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del train_encodings, val_encodings\nfree_some_memory()","metadata":{"id":"PS4LyEvk1y88","execution":{"iopub.status.busy":"2023-01-11T21:09:53.586258Z","iopub.execute_input":"2023-01-11T21:09:53.587050Z","iopub.status.idle":"2023-01-11T21:09:54.598001Z","shell.execute_reply.started":"2023-01-11T21:09:53.587012Z","shell.execute_reply":"2023-01-11T21:09:54.596968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Generation","metadata":{"id":"1ezjXyEag7rc"}},{"cell_type":"markdown","source":"Encode test set using the tokenizer defined before.","metadata":{"id":"ZpudKS7ZhCN6"}},{"cell_type":"code","source":"df_generated = generate_answers(model=model, \n                                df_input=test_df,\n                                max_length = 499,\n                                tokenizer=tokenizer)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option('display.max_rows', None)\ncorrect_answers = df_generated[df_generated['score'] != 0].reset_index(drop=True)\ncorrect_answers.head(200)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# del tokenizer, input_values, input_ids, input_attention_mask, model, l, x, correct\ndel tokenizer, model, df_generated, correct_answers\n\nfree_some_memory()","metadata":{"execution":{"iopub.status.busy":"2023-01-11T21:12:57.472387Z","iopub.execute_input":"2023-01-11T21:12:57.472741Z","iopub.status.idle":"2023-01-11T21:12:58.492012Z","shell.execute_reply.started":"2023-01-11T21:12:57.472708Z","shell.execute_reply":"2023-01-11T21:12:58.491002Z"},"id":"haD4VPaceQOH","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### BERT2BERT Distilroberta-base","metadata":{"id":"G2-Rwv5gM8fS"}},{"cell_type":"code","source":"from transformers import EncoderDecoderModel, AutoTokenizer\nfrom tqdm import tqdm\n\n\nmodel_name = 'distilroberta-base'\n\n# tie_encoder_decoder to share weights and half the number of parameters\nmodel = EncoderDecoderModel.from_encoder_decoder_pretrained(model_name, model_name, tie_encoder_decoder=True)\n\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\n# set special tokens\nmodel.config.decoder_start_token_id = tokenizer.cls_token_id\nmodel.config.eos_token_id = tokenizer.sep_token_id\nmodel.config.pad_token_id = tokenizer.pad_token_id\n\n# set decoding params                               \nmodel.config.early_stopping = True\nmodel.config.no_repeat_ngram_size = 3\nmodel.config.repetition_penalty = 5.0\nmodel.config.num_beams = 2\nmodel.config.vocab_size = model.config.encoder.vocab_size\n","metadata":{"id":"5SwrherKM8fT","execution":{"iopub.status.busy":"2023-01-11T21:12:58.572799Z","iopub.execute_input":"2023-01-11T21:12:58.573172Z","iopub.status.idle":"2023-01-11T21:13:23.778191Z","shell.execute_reply.started":"2023-01-11T21:12:58.573136Z","shell.execute_reply":"2023-01-11T21:13:23.777267Z"},"outputId":"8fe25732-49d0-4a3f-e517-2aff0b4494e3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#fix seed \nfix_seed(42)\n#take a subset from the training set\nmax_train = len(train_df)\nt_start = 0\nt_end = 60000\n#take a subset from the validation set\nmax_val = len(val_df)\nv_start = 0\nv_end = 20000\nprint(f'Training set shape: {(t_end-t_start)}\\nValidation set shape: {(v_end-v_start)}')","metadata":{"execution":{"iopub.status.busy":"2023-01-11T21:02:30.468289Z","iopub.execute_input":"2023-01-11T21:02:30.468677Z","iopub.status.idle":"2023-01-11T21:02:30.473979Z","shell.execute_reply.started":"2023-01-11T21:02:30.468625Z","shell.execute_reply":"2023-01-11T21:02:30.472922Z"},"id":"lZvgC03rCilA","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def encodings(tokenizer,encoder_max_length, decoder_max_length, questions, contexts, answers):\n  encodings = tokenizer(questions, contexts, \n                            padding=True,\n                            truncation= 'only_second',\n                            max_length = encoder_max_length,\n                            )\n  input_ids, input_attention_mask = encodings['input_ids'], encodings['attention_mask']\n  label_values = tokenizer(answers,\n                            padding=True,\n                            truncation=True,\n                            max_length = decoder_max_length,\n                            )\n  labels, labels_mask = label_values['input_ids'], label_values['attention_mask']\n  #Tokens with indices set to ``-100`` are ignored (masked) during training, the loss is only computed for the tokens with labels\n  masked_labels = [[-100 if token == tokenizer.pad_token_id else token for token in labels] for labels in labels]\n\n  #add the masked_labels to the batch encodings dictionary, then this will be used to create a pytorch dataset\n  encodings.update({'labels': masked_labels})\n  return encodings","metadata":{"id":"yM3t8hS5CilB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoder_max_length = 512\ndecoder_max_length = 25\ntrain_encodings = encodings(tokenizer, encoder_max_length, decoder_max_length,\n                            list(train_df[t_start:t_end]['q']), \n                            list(train_df[t_start:t_end]['p']),\n                            list(train_df[t_start:t_end]['a']))\nval_encodings = encodings(tokenizer, encoder_max_length, decoder_max_length,\n                            list(val_df[v_start:v_end]['q']), \n                            list(val_df[v_start:v_end]['p']),\n                            list(val_df[v_start:v_end]['a']))","metadata":{"id":"GkE3BWLlCilB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def execute(model: torch.nn.Module,\n            starting_lr: float, \n            num_epochs: int, \n            data_loader_train: torch.utils.data.DataLoader,\n            data_loader_val: torch.utils.data.DataLoader) -> None:\n    \"\"\"Executes the training loop.\n\n    Args:\n        name_train: the name for the log subfolder.\n        model: the network to train.\n        starting_lr: the staring learning rate.\n        num_epochs: the number of epochs.\n        data_loader_train: the data loader with training data.\n        data_loader_val: the data loader with validation data.\n    \"\"\"\n    # Optimizer\n    optimizer = torch.optim.AdamW(model.parameters(), lr=starting_lr)\n    print(f'Start training.')\n    statistics = training_loop(num_epochs, optimizer, model, data_loader_train, data_loader_val)\n    print(f'Training complete.')","metadata":{"id":"Y_zDmrWoCilB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#parameters\nbatch_size = 16\nnum_epochs = 3\n#also try with lr = 4e-4\nlr = 4e-5","metadata":{"id":"b5qfLBOJM8fT","execution":{"iopub.status.busy":"2023-01-11T21:14:26.730131Z","iopub.execute_input":"2023-01-11T21:14:26.730503Z","iopub.status.idle":"2023-01-11T21:14:26.739484Z","shell.execute_reply.started":"2023-01-11T21:14:26.730470Z","shell.execute_reply":"2023-01-11T21:14:26.738522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create training dataset\ntrain_dataset = CreateDataset(train_encodings)\n#create training dataloader\ntrain_ld = torch.utils.data.DataLoader(train_dataset,\n                                     batch_size=batch_size,\n                                     )\n#create validation dataset\nval_dataset = CreateDataset(val_encodings)\n#create validation dataloader\nval_ld = torch.utils.data.DataLoader(val_dataset,\n                                     batch_size=batch_size,\n                                     )\n#execute\nexecute(model, lr, num_epochs, train_ld, val_ld)","metadata":{"id":"2L9sYoETCilB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del train_encodings, val_encodings\nfree_some_memory()","metadata":{"execution":{"iopub.status.busy":"2023-01-11T21:09:53.586258Z","iopub.execute_input":"2023-01-11T21:09:53.587050Z","iopub.status.idle":"2023-01-11T21:09:54.598001Z","shell.execute_reply.started":"2023-01-11T21:09:53.587012Z","shell.execute_reply":"2023-01-11T21:09:54.596968Z"},"id":"bPrIG-_BCilB","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Generation","metadata":{"id":"Xqq0pd7RM8fU"}},{"cell_type":"markdown","source":"Encode test set using the tokenizer defined before.","metadata":{"id":"IBgEOzIDM8fU"}},{"cell_type":"code","source":"df_generated = generate_answers(model=model, \n                                df_input=test_df,\n                                max_length = 512,\n                                tokenizer=tokenizer)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option('display.max_rows', None)\ncorrect_answers = df_generated[df_generated['score'] != 0]\ncorrect_answers = correct_answers.reset_index(drop=True)\ncorrect_answers.head(200)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Question generation $f_\\theta(P, Q, H)$ with text passage $P$, question $Q$ and dialogue history $H$","metadata":{"id":"scfOBhZf1mPp"}},{"cell_type":"code","source":"# TODO","metadata":{"id":"9maQVnw61mPp","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train and evaluate $f_\\theta(P, Q)$ and $f_\\theta(P, Q, H)$","metadata":{"id":"WpTttkRT1mPq"}},{"cell_type":"code","source":"# TODO","metadata":{"id":"j9Mb67HE1mPq","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Conclusions","metadata":{"id":"JmviMChy1mPq"}},{"cell_type":"code","source":"# TODO","metadata":{"id":"jDn-h3WL1mPq","trusted":true},"execution_count":null,"outputs":[]}]}