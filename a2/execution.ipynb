{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/Danysan1/ai-unibo-nlp-project/blob/main/a2/execution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: pandas in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (1.5.0)\n",
      "Requirement already satisfied: numpy in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (1.23.3)\n",
      "Requirement already satisfied: matplotlib in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (3.5.3)\n",
      "Requirement already satisfied: transformers in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (4.25.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from pandas) (2022.2.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from matplotlib) (9.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from matplotlib) (4.37.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from transformers) (0.11.1)\n",
      "Requirement already satisfied: requests in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: filelock in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from transformers) (3.8.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from requests->transformers) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from requests->transformers) (2022.6.15.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/daniele/.miniconda3/envs/tf/lib/python3.9/site-packages (from requests->transformers) (3.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas numpy matplotlib transformers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "from tqdm import tqdm\n",
    "\n",
    "class DownloadProgressBar(tqdm):\n",
    "    def update_to(self, b=1, bsize=1, tsize=None):\n",
    "        if tsize is not None:\n",
    "            self.total = tsize\n",
    "        self.update(b * bsize - self.n)\n",
    "        \n",
    "def download_url(url, output_path):\n",
    "    with DownloadProgressBar(unit='B', unit_scale=True,\n",
    "                             miniters=1, desc=url.split('/')[-1]) as t:\n",
    "        urllib.request.urlretrieve(url, filename=output_path, reporthook=t.update_to)\n",
    "\n",
    "def download_data(data_path, url_path, suffix):    \n",
    "    if not os.path.exists(data_path):\n",
    "        os.makedirs(data_path)\n",
    "        \n",
    "    data_path = os.path.join(data_path, f'{suffix}.json')\n",
    "    if not os.path.exists(data_path):\n",
    "        print(f\"Downloading CoQA {suffix} data split... (it may take a while)\")\n",
    "        download_url(url=url_path, output_path=data_path)\n",
    "        print(\"Download completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'Dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data\n",
    "train_url = \"https://nlp.stanford.edu/data/coqa/coqa-train-v1.0.json\"\n",
    "download_data(data_path=data_folder, url_path=train_url, suffix='train')\n",
    "\n",
    "# Test data\n",
    "test_url = \"https://nlp.stanford.edu/data/coqa/coqa-dev-v1.0.json\"\n",
    "download_data(data_path=data_folder, url_path=test_url, suffix='test')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "import json\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path.join(data_folder, 'test.json')) as test_file:\n",
    "    test_ds = json.load(test_file)[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_ds[0][\"questions\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_ds[0][\"answers\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = [\n",
    "    [\n",
    "        story[\"story\"],\n",
    "        story[\"questions\"][question_index][\"input_text\"],\n",
    "        story[\"answers\"][question_index][\"input_text\"],\n",
    "        story_index,\n",
    "        question_index,\n",
    "    ]\n",
    "    for story_index, story in enumerate(test_ds)\n",
    "    for question_index in range(len(story[\"questions\"]))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Once upon a time, in a barn near a farm house, there lived a little white kitten named Cotton. Cotton lived high up in a nice warm place above the barn where all of the farmer\\'s horses slept. But Cotton wasn\\'t alone in her little home above the barn, oh no. She shared her hay bed with her mommy and 5 other sisters. All of her sisters were cute and fluffy, like Cotton. But she was the only white one in the bunch. The rest of her sisters were all orange with beautiful white tiger stripes like Cotton\\'s mommy. Being different made Cotton quite sad. She often wished she looked like the rest of her family. So one day, when Cotton found a can of the old farmer\\'s orange paint, she used it to paint herself like them. When her mommy and sisters found her they started laughing. \\n\\n\"What are you doing, Cotton?!\" \\n\\n\"I only wanted to be more like you\". \\n\\nCotton\\'s mommy rubbed her face on Cotton\\'s and said \"Oh Cotton, but your fur is so pretty and special, like you. We would never want you to be any other way\". And with that, Cotton\\'s mommy picked her up and dropped her into a big bucket of water. When Cotton came out she was herself again. Her sisters licked her face until Cotton\\'s fur was all all dry. \\n\\n\"Don\\'t ever do that again, Cotton!\" they all cried. \"Next time you might mess up that pretty white fur of yours and we wouldn\\'t want that!\" \\n\\nThen Cotton thought, \"I change my mind. I like being special\".',\n",
       " 'What color was Cotton?',\n",
       " 'white',\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_ds = DataFrame(np.array(test_ds), columns=[\"p\", \"q\", \"a\", \"p_index\", \"q_index\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.count of                                                       p  \\\n",
       "0     Once upon a time, in a barn near a farm house,...   \n",
       "1     Once upon a time, in a barn near a farm house,...   \n",
       "2     Once upon a time, in a barn near a farm house,...   \n",
       "3     Once upon a time, in a barn near a farm house,...   \n",
       "4     Once upon a time, in a barn near a farm house,...   \n",
       "...                                                 ...   \n",
       "7978  Las Vegas (, Spanish for \"The Meadows\"), offic...   \n",
       "7979  Las Vegas (, Spanish for \"The Meadows\"), offic...   \n",
       "7980  Las Vegas (, Spanish for \"The Meadows\"), offic...   \n",
       "7981  Las Vegas (, Spanish for \"The Meadows\"), offic...   \n",
       "7982  Las Vegas (, Spanish for \"The Meadows\"), offic...   \n",
       "\n",
       "                                                  q  \\\n",
       "0                            What color was Cotton?   \n",
       "1                               Where did she live?   \n",
       "2                               Did she live alone?   \n",
       "3                            Who did she live with?   \n",
       "4                      What color were her sisters?   \n",
       "...                                             ...   \n",
       "7978  where does the nickname \"Sin City\" come from?   \n",
       "7979                          Which state is it in?   \n",
       "7980                     Is it located in a desert?   \n",
       "7981                what is the name of the desert?   \n",
       "7982                            is it a small city?   \n",
       "\n",
       "                                                      a p_index q_index  \n",
       "0                                                 white       0       0  \n",
       "1                                             in a barn       0       1  \n",
       "2                                                    no       0       2  \n",
       "3                          with her mommy and 5 sisters       0       3  \n",
       "4                                      orange and white       0       4  \n",
       "...                                                 ...     ...     ...  \n",
       "7978  The city's tolerance for numerous forms of adu...     499       7  \n",
       "7979                                             Nevada     499       8  \n",
       "7980                                                Yes     499       9  \n",
       "7981                                     Mojave Desert.     499      10  \n",
       "7982                                                 No     499      11  \n",
       "\n",
       "[7983 rows x 5 columns]>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                                                       p  \\\n",
       "0     Once upon a time, in a barn near a farm house,...   \n",
       "1     Once upon a time, in a barn near a farm house,...   \n",
       "2     Once upon a time, in a barn near a farm house,...   \n",
       "3     Once upon a time, in a barn near a farm house,...   \n",
       "4     Once upon a time, in a barn near a farm house,...   \n",
       "...                                                 ...   \n",
       "7978  Las Vegas (, Spanish for \"The Meadows\"), offic...   \n",
       "7979  Las Vegas (, Spanish for \"The Meadows\"), offic...   \n",
       "7980  Las Vegas (, Spanish for \"The Meadows\"), offic...   \n",
       "7981  Las Vegas (, Spanish for \"The Meadows\"), offic...   \n",
       "7982  Las Vegas (, Spanish for \"The Meadows\"), offic...   \n",
       "\n",
       "                                                  q  \\\n",
       "0                            What color was Cotton?   \n",
       "1                               Where did she live?   \n",
       "2                               Did she live alone?   \n",
       "3                            Who did she live with?   \n",
       "4                      What color were her sisters?   \n",
       "...                                             ...   \n",
       "7978  where does the nickname \"Sin City\" come from?   \n",
       "7979                          Which state is it in?   \n",
       "7980                     Is it located in a desert?   \n",
       "7981                what is the name of the desert?   \n",
       "7982                            is it a small city?   \n",
       "\n",
       "                                                      a p_index q_index  \n",
       "0                                                 white       0       0  \n",
       "1                                             in a barn       0       1  \n",
       "2                                                    no       0       2  \n",
       "3                          with her mommy and 5 sisters       0       3  \n",
       "4                                      orange and white       0       4  \n",
       "...                                                 ...     ...     ...  \n",
       "7978  The city's tolerance for numerous forms of adu...     499       7  \n",
       "7979                                             Nevada     499       8  \n",
       "7980                                                Yes     499       9  \n",
       "7981                                     Mojave Desert.     499      10  \n",
       "7982                                                 No     499      11  \n",
       "\n",
       "[7983 rows x 5 columns]>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Validation-Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-13 12:05:20.339843: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-13 12:05:21.279476: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-13 12:05:21.279509: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-13 12:05:21.369321: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-12-13 12:05:23.281641: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-13 12:05:23.281760: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-13 12:05:23.281770: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from typing import List, Dict, Callable\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_data(model: keras.Model,\n",
    "                x: np.ndarray,\n",
    "                prediction_info: Dict):\n",
    "    \"\"\"\n",
    "    Inference routine of a given input set of examples\n",
    "\n",
    "    :param model: Keras built and possibly trained model\n",
    "    :param x: input set of examples in np.ndarray format\n",
    "    :param prediction_info: dictionary storing model predict() argument information\n",
    "\n",
    "    :return\n",
    "        predictions: predicted labels in np.ndarray format\n",
    "    \"\"\"\n",
    "    print(f'Starting prediction: \\n{prediction_info}')\n",
    "    print(f'Predicting on {x.shape[0]} samples')\n",
    "    predictions = model.predict(x, **prediction_info)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_f1(model: keras.Model, \n",
    "             x: np.ndarray, \n",
    "             y: np.ndarray):\n",
    "    \"\"\"\n",
    "    Compute F1_score on the given data with corresponding labels\n",
    "\n",
    "    :param model: Keras built and possibly trained model\n",
    "    :param x: data in np.ndarray format\n",
    "    :param y: ground-truth labels in np.ndarray format\n",
    "\n",
    "    :return\n",
    "        score: f1_macro_score\n",
    "    \"\"\"\n",
    "    #predictions on the x set\n",
    "    prediction_info = {\n",
    "        'batch_size': 64,\n",
    "        'verbose': 1\n",
    "    }\n",
    "    y_pred = predict_data(model=model, x=x, prediction_info=prediction_info)\n",
    "\n",
    "    #compute argmax to take the best class for each sample\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    #compute the f1_macro\n",
    "    score = f1_score(y, y_pred, average ='macro')\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_reproducibility(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-13 12:05:26.263843: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-12-13 12:05:26.264039: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-13 12:05:26.264194: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-13 12:05:26.264316: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-13 12:05:26.316749: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-13 12:05:26.316952: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-13 12:05:26.317031: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-12-13 12:05:26.317046: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tqdm import tqdm\n",
    "from transformers import TFAutoModel, AutoTokenizer\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question generation $f_\\theta(P, Q)$ with text passage $P$ and question $Q$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTrainer(object):\n",
    "    \"\"\"\n",
    "    Simple wrapper class\n",
    "\n",
    "    train_op -> uses tf.GradientTape to compute the loss\n",
    "    batch_fit -> receives a batch and performs forward-backward passes (gradient included)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, encoder, decoder, max_length):\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.max_length = max_length\n",
    "        self.ce = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=1e-03)\n",
    "\n",
    "    @tf.function\n",
    "    def compute_loss(self, logits, target):\n",
    "        loss = self.ce(y_true=target, y_pred=logits)\n",
    "        mask = tf.logical_not(tf.math.equal(target, 0))\n",
    "        mask = tf.cast(mask, dtype=loss.dtype)\n",
    "        loss *= mask\n",
    "        return tf.reduce_mean(loss)\n",
    "\n",
    "    @tf.function\n",
    "    def train_op(self, inputs):\n",
    "        with tf.GradientTape() as tape:\n",
    "            encoder_output, encoder_h, encoder_s = self.encoder({'input_ids': inputs['encoder_input_ids'],\n",
    "                                                                 'hidden_state': inputs['encoder_state']})\n",
    "\n",
    "            decoder_input = inputs['decoder_target'][:, :-1]  # ignore <end>\n",
    "            real_target = inputs['decoder_target'][:, 1:]  # ignore <start>\n",
    "\n",
    "            decoder.attention.setup_memory(encoder_output)\n",
    "\n",
    "            decoder_initial_state = self.decoder.build_initial_state(decoder.batch_size, [encoder_h, encoder_s])\n",
    "            predicted = self.decoder({'input_ids': decoder_input,\n",
    "                                      'initial_state': decoder_initial_state}).rnn_output\n",
    "\n",
    "            loss = self.compute_loss(logits=predicted, target=real_target)\n",
    "\n",
    "        grads = tape.gradient(loss, self.encoder.trainable_variables + self.decoder.trainable_variables)\n",
    "        return loss, grads\n",
    "\n",
    "    @tf.function\n",
    "    def batch_fit(self, inputs):\n",
    "        loss, grads = self.train_op(inputs=inputs)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.encoder.trainable_variables + self.decoder.trainable_variables))\n",
    "        return loss\n",
    "\n",
    "    @tf.function\n",
    "    def generate(self, input_ids):\n",
    "        batch_size = input_ids.shape[0]\n",
    "        encoder_initial_state = [tf.zeros((batch_size, self.encoder.encoder_units)),\n",
    "                                 tf.zeros((batch_size, self.encoder.encoder_units))]\n",
    "        encoder_output, encoder_h, encoder_s = self.encoder({\n",
    "            'input_ids': input_ids,\n",
    "            'hidden_state': encoder_initial_state\n",
    "        })\n",
    "\n",
    "        start_tokens = tf.fill([batch_size], tokenizer.word_index['<start>'])\n",
    "        end_token = tokenizer.word_index['<end>']\n",
    "\n",
    "        greedy_sampler = tfa.seq2seq.GreedyEmbeddingSampler()\n",
    "        decoder_instance = tfa.seq2seq.BasicDecoder(cell=self.decoder.wrapped_decoder_cell,\n",
    "                                                    sampler=greedy_sampler,\n",
    "                                                    output_layer=self.decoder.generation_dense,\n",
    "                                                    maximum_iterations=self.max_length)\n",
    "        self.decoder.attention.setup_memory(encoder_output)\n",
    "\n",
    "        decoder_initial_state = self.decoder.build_initial_state(batch_size, [encoder_h, encoder_s])\n",
    "        decoder_embedding_matrix = self.decoder.embedding.variables[0]\n",
    "        outputs, _, _ = decoder_instance(decoder_embedding_matrix,\n",
    "                                         start_tokens=start_tokens,\n",
    "                                         end_token=end_token,\n",
    "                                         initial_state=decoder_initial_state)\n",
    "        return outputs\n",
    "\n",
    "    def translate(self, generated):\n",
    "        return tokenizer.sequences_to_texts(generated.sample_id.numpy())\n",
    "\n",
    "\n",
    "class Encoder(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, encoder_units):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.encoder_units = encoder_units\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(input_dim=vocab_size,\n",
    "                                                   output_dim=embedding_dim)\n",
    "        self.encoder_lstm = tf.keras.layers.LSTM(self.encoder_units,\n",
    "                                                 return_sequences=True,\n",
    "                                                 return_state=True)\n",
    "\n",
    "    def call(self, inputs, training=False, **kwargs):\n",
    "        input_ids = inputs['input_ids']\n",
    "        input_emb = self.embedding(input_ids)\n",
    "        encoder_output, lstm_hidden, lstm_states = self.encoder_lstm(input_emb, initial_state=inputs['hidden_state'])\n",
    "        return encoder_output, lstm_hidden, lstm_states\n",
    "\n",
    "    def initialize(self, batch_size):\n",
    "        return [tf.zeros((batch_size, self.encoder_units)), tf.zeros((batch_size, self.encoder_units))]\n",
    "\n",
    "\n",
    "class Decoder(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, vocab_size, max_sequence_length, embedding_dim, decoder_units, batch_size):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.max_sequence_length = max_sequence_length\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.decoder_units = decoder_units\n",
    "        self.embedding = tf.keras.layers.Embedding(input_dim=vocab_size,\n",
    "                                                   output_dim=embedding_dim)\n",
    "        self.decoder_lstm_cell = tf.keras.layers.LSTMCell(self.decoder_units)\n",
    "\n",
    "        self.attention = tfa.seq2seq.BahdanauAttention(units=self.decoder_units,\n",
    "                                                       memory=None,\n",
    "                                                       memory_sequence_length=self.batch_size * [max_sequence_length])\n",
    "\n",
    "        self.wrapped_decoder_cell = tfa.seq2seq.AttentionWrapper(self.decoder_lstm_cell,\n",
    "                                                                 self.attention,\n",
    "                                                                 attention_layer_size=self.decoder_units)\n",
    "\n",
    "        self.generation_dense = tf.keras.layers.Dense(vocab_size)\n",
    "        self.sampler = tfa.seq2seq.sampler.TrainingSampler()\n",
    "        self.decoder = tfa.seq2seq.BasicDecoder(self.wrapped_decoder_cell,\n",
    "                                                sampler=self.sampler,\n",
    "                                                output_layer=self.generation_dense)\n",
    "\n",
    "    def build_initial_state(self, batch_size, encoder_state):\n",
    "        initial_state = self.wrapped_decoder_cell.get_initial_state(batch_size=batch_size, dtype=tf.float32)\n",
    "        initial_state = initial_state.clone(cell_state=encoder_state)\n",
    "        return initial_state\n",
    "\n",
    "    def call(self, inputs, training=False, **kwargs):\n",
    "        input_ids = inputs['input_ids']\n",
    "        input_emb = self.embedding(input_ids)\n",
    "        decoder_output, _, _ = self.decoder(input_emb,\n",
    "                                            initial_state=inputs['initial_state'],\n",
    "                                            sequence_length=self.batch_size * [self.max_sequence_length - 1])\n",
    "        return decoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-13 12:05:26.482095: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 6, 16) -- (2, 16) -- (2, 16)\n",
      "(2, 5, 16)\n"
     ]
    }
   ],
   "source": [
    "# Sample\n",
    "input_sample = [\n",
    "    \"hello there how is it going\",\n",
    "    \"this assignment is hellish\"\n",
    "]\n",
    "output_sample = [\n",
    "    \"<start> it is going well <end>\",\n",
    "    \"<start> I agree <end>\"\n",
    "]\n",
    "\n",
    "batch_size = len(input_sample)\n",
    "\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='', oov_token='<UNK>')\n",
    "tokenizer.fit_on_texts(input_sample + output_sample)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "encoded_input_sample = tokenizer.texts_to_sequences(input_sample)\n",
    "max_input_length = max([len(item) for item in encoded_input_sample])\n",
    "\n",
    "encoded_output_sample = tokenizer.texts_to_sequences(output_sample)\n",
    "max_output_length = max([len(item) for item in encoded_output_sample])\n",
    "\n",
    "max_sequence_length = max(max_input_length, max_output_length)\n",
    "\n",
    "encoded_input_sample = tf.keras.preprocessing.sequence.pad_sequences(encoded_input_sample,\n",
    "                                                                        padding='post',\n",
    "                                                                        maxlen=max_sequence_length)\n",
    "encoded_output_sample = tf.keras.preprocessing.sequence.pad_sequences(encoded_output_sample,\n",
    "                                                                        padding='post',\n",
    "                                                                        maxlen=max_sequence_length)\n",
    "\n",
    "# Test encoder\n",
    "encoder = Encoder(vocab_size=vocab_size,\n",
    "                    embedding_dim=50,\n",
    "                    encoder_units=16)\n",
    "\n",
    "sample_hidden = encoder.initialize(batch_size=batch_size)\n",
    "encoder_sample_batch = {\n",
    "    'input_ids': tf.convert_to_tensor(encoded_input_sample, dtype=tf.int32),\n",
    "    'hidden_state': sample_hidden\n",
    "}\n",
    "\n",
    "sample_output, sample_h, sample_c = encoder(inputs=encoder_sample_batch)\n",
    "print(f'{sample_output.shape} -- {sample_h.shape} -- {sample_c.shape}')\n",
    "\n",
    "# Test decoder\n",
    "decoder = Decoder(vocab_size=vocab_size,\n",
    "                    embedding_dim=50,\n",
    "                    decoder_units=16,\n",
    "                    batch_size=batch_size,\n",
    "                    max_sequence_length=max_sequence_length)\n",
    "decoder.attention.setup_memory(sample_output)\n",
    "initial_state = decoder.build_initial_state(batch_size, [sample_h, sample_c])\n",
    "\n",
    "decoder_sample_batch = {\n",
    "    'input_ids': tf.convert_to_tensor(encoded_output_sample, tf.int32),\n",
    "    'initial_state': initial_state\n",
    "}\n",
    "sample_decoder_outputs = decoder(decoder_sample_batch).rnn_output\n",
    "print(f'{sample_decoder_outputs.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "trainer = MyTrainer(encoder=encoder,\n",
    "                    decoder=decoder,\n",
    "                    max_length=max_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss - 2.2189557552337646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/100 [00:07<01:28,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated - ['assignment going going assignment going going', 'how how going going going assignment']\n",
      "Loss - 2.2144834995269775\n",
      "Translated - ['<end> is is is this this', 'how this this this this this']\n",
      "Loss - 2.2099709510803223\n",
      "Translated - ['is <end> is is <end> is', 'how going going going going going']\n",
      "Loss - 2.2053885459899902\n",
      "Translated - ['is <end> is <end> is <end>', 'i this this this this this']\n",
      "Loss - 2.2007057666778564\n",
      "Translated - ['is <end>', 'i <end>']\n",
      "Loss - 2.195889949798584\n",
      "Translated - ['is <end>', 'i <end>']\n",
      "Loss - 2.190906524658203\n",
      "Translated - ['is <end>', 'i <end>']\n",
      "Loss - 2.1857199668884277\n",
      "Translated - ['is <end>', 'i <end>']\n",
      "Loss - 2.18029522895813\n",
      "Translated - ['is <end>', 'i <end>']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 16/100 [00:07<00:20,  4.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss - 2.1745972633361816\n",
      "Translated - ['is <end>', 'i <end>']\n",
      "Loss - 2.168591022491455\n",
      "Translated - ['is <end>', 'i <end>']\n",
      "Loss - 2.162238597869873\n",
      "Translated - ['is <end>', 'i <end>']\n",
      "Loss - 2.155500650405884\n",
      "Translated - ['is <end>', 'i <end>']\n",
      "Loss - 2.148333787918091\n",
      "Translated - ['is <end>', 'i <end>']\n",
      "Loss - 2.140690803527832\n",
      "Translated - ['is <end>', 'i <end>']\n",
      "Loss - 2.132521152496338\n",
      "Translated - ['is <end>', 'i <end>']\n",
      "Loss - 2.1237680912017822\n",
      "Translated - ['is <end>', 'i <end>']\n",
      "Loss - 2.114370822906494\n",
      "Translated - ['is <end>', 'i <end>']\n",
      "Loss - 2.104262590408325\n",
      "Translated - ['is <end>', 'i <end>']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 27/100 [00:08<00:07,  9.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss - 2.0933704376220703\n",
      "Translated - ['is <end>', 'i <end>']\n",
      "Loss - 2.081615924835205\n",
      "Translated - ['is <end>', 'i <end>']\n",
      "Loss - 2.0689127445220947\n",
      "Translated - ['is <end>', 'i <end>']\n",
      "Loss - 2.0551693439483643\n",
      "Translated - ['is <end>', 'i <end>']\n",
      "Loss - 2.0402884483337402\n",
      "Translated - ['is <end>', 'i <end>']\n",
      "Loss - 2.0241684913635254\n",
      "Translated - ['is <end>', 'i <end>']\n",
      "Loss - 2.0067062377929688\n",
      "Translated - ['is <end>', 'i <end>']\n",
      "Loss - 1.987802267074585\n",
      "Translated - ['is <end>', 'i <end>']\n",
      "Loss - 1.967365026473999\n",
      "Translated - ['is <end>', 'i <end>']\n",
      "Loss - 1.9453201293945312\n",
      "Translated - ['is <end>', 'i <end>']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 37/100 [00:08<00:03, 16.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss - 1.9216201305389404\n",
      "Translated - ['is <end>', 'i <end>']\n",
      "Loss - 1.8962604999542236\n",
      "Translated - ['is <end>', 'i <end>']\n",
      "Loss - 1.869288682937622\n",
      "Translated - ['is <end>', 'i <end>']\n",
      "Loss - 1.8408219814300537\n",
      "Translated - ['is <end>', 'i <end>']\n",
      "Loss - 1.8110557794570923\n",
      "Translated - ['is <end>', 'i <end>']\n",
      "Loss - 1.7802670001983643\n",
      "Translated - ['is <end>', 'i <end>']\n",
      "Loss - 1.7488090991973877\n",
      "Translated - ['is <end>', 'i <end>']\n",
      "Loss - 1.7170966863632202\n",
      "Translated - ['is <end>', 'i <end>']\n",
      "Loss - 1.685577392578125\n",
      "Translated - ['is <end>', 'i <end>']\n",
      "Loss - 1.6546974182128906\n",
      "Translated - ['is <end>', 'i <end>']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 49/100 [00:08<00:01, 27.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss - 1.6248639822006226\n",
      "Translated - ['is <end>', 'i <end>']\n",
      "Loss - 1.596404790878296\n",
      "Translated - ['is <end>', 'i <end>']\n",
      "Loss - 1.5695273876190186\n",
      "Translated - ['is <end>', 'i <end>']\n",
      "Loss - 1.5442887544631958\n",
      "Translated - ['is <end>', 'i <end>']\n",
      "Loss - 1.5205796957015991\n",
      "Translated - ['is <end>', 'i <end>']\n",
      "Loss - 1.4981400966644287\n",
      "Translated - ['is <end>', 'i <end>']\n",
      "Loss - 1.476603627204895\n",
      "Translated - ['is <end>', 'i <end>']\n",
      "Loss - 1.455561637878418\n",
      "Translated - ['is <end>', 'i <end>']\n",
      "Loss - 1.434630274772644\n",
      "Translated - ['is going <end>', 'i <end> <end>']\n",
      "Loss - 1.4135019779205322\n",
      "Translated - ['is going <end>', 'i <end> <end>']\n",
      "Loss - 1.3919742107391357\n",
      "Translated - ['is going <end>', 'i <end> <end>']\n",
      "Loss - 1.3699544668197632\n",
      "Translated - ['is going <end>', 'i <end> <end>']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 62/100 [00:08<00:05,  7.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss - 1.347447156906128\n",
      "Translated - ['is going <end>', 'i <end> <end>']\n",
      "Loss - 1.3245291709899902\n",
      "Translated - ['is going <end>', 'i <end> <end>']\n",
      "Loss - 1.3013197183609009\n",
      "Translated - ['is going <end>', 'i going <end>']\n",
      "Loss - 1.2779496908187866\n",
      "Translated - ['is going <end>', 'i going <end>']\n",
      "Loss - 1.2545359134674072\n",
      "Translated - ['is going <end>', 'i going <end>']\n",
      "Loss - 1.2311598062515259\n",
      "Translated - ['is going going <end>', 'i i <end> <end>']\n",
      "Loss - 1.2078630924224854\n",
      "Translated - ['is going going <end>', 'i i <end> <end>']\n",
      "Loss - 1.184653878211975\n",
      "Translated - ['is going going <end>', 'i i <end> <end>']\n",
      "Loss - 1.1615183353424072\n",
      "Translated - ['is going going <end>', 'i i <end> <end>']\n",
      "Loss - 1.1384286880493164\n",
      "Translated - ['it is going <end>', 'i i <end> <end>']\n",
      "Loss - 1.1153466701507568\n",
      "Translated - ['it is going <end>', 'i i <end> <end>']\n",
      "Loss - 1.0922244787216187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [80], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m loss \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39mbatch_fit(batch)\n\u001b[1;32m     10\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mLoss - \u001b[39m\u001b[39m{\u001b[39;00mloss\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m generated \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39;49mgenerate(input_ids\u001b[39m=\u001b[39;49mencoded_input_sample)\n\u001b[1;32m     13\u001b[0m translated \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39mtranslate(generated)\n\u001b[1;32m     14\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTranslated - \u001b[39m\u001b[39m{\u001b[39;00mtranslated\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:954\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    952\u001b[0m \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    953\u001b[0m \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 954\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateful_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    955\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[1;32m    956\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    957\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2495\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2492\u001b[0m \u001b[39m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[39;00m\n\u001b[1;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m-> 2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_function(args, kwargs)\n\u001b[1;32m   2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39m_call_flat(\n\u001b[1;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39mgraph_function\u001b[39m.\u001b[39mcaptured_inputs)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2714\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2690\u001b[0m \u001b[39m\"\"\"Gets a function for these inputs, defining it if necessary.\u001b[39;00m\n\u001b[1;32m   2691\u001b[0m \n\u001b[1;32m   2692\u001b[0m \u001b[39m`args` and `kwargs` can be None if this `Function` was created with an\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2710\u001b[0m \u001b[39m    shape relaxation retracing.\u001b[39;00m\n\u001b[1;32m   2711\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2712\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_signature \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m args \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2713\u001b[0m   args, kwargs, filtered_flat_args \u001b[39m=\u001b[39m (\n\u001b[0;32m-> 2714\u001b[0m       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_function_spec\u001b[39m.\u001b[39;49mcanonicalize_function_inputs(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs))\n\u001b[1;32m   2715\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2716\u001b[0m   filtered_flat_args \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function_spec.py:427\u001b[0m, in \u001b[0;36mFunctionSpec.canonicalize_function_inputs\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    424\u001b[0m       kwargs\u001b[39m.\u001b[39msetdefault(kwarg, default)\n\u001b[1;32m    426\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_signature \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 427\u001b[0m   inputs, flat_inputs, filtered_flat_inputs \u001b[39m=\u001b[39m _convert_numpy_inputs(inputs)\n\u001b[1;32m    428\u001b[0m   kwargs, flat_kwargs, filtered_flat_kwargs \u001b[39m=\u001b[39m _convert_numpy_inputs(kwargs)\n\u001b[1;32m    429\u001b[0m   flat_inputs \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m flat_kwargs\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function_spec.py:483\u001b[0m, in \u001b[0;36m_convert_numpy_inputs\u001b[0;34m(inputs)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(a, np\u001b[39m.\u001b[39mndarray):\n\u001b[1;32m    481\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe output of __array__ must be an np.ndarray, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    482\u001b[0m                   \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgot \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(a)\u001b[39m}\u001b[39;00m\u001b[39m from \u001b[39m\u001b[39m{\u001b[39;00mvalue\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 483\u001b[0m flat_inputs[index] \u001b[39m=\u001b[39m constant_op\u001b[39m.\u001b[39;49mconstant(a)\n\u001b[1;32m    484\u001b[0m filtered_flat_inputs\u001b[39m.\u001b[39mappend(flat_inputs[index])\n\u001b[1;32m    485\u001b[0m need_packing \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:267\u001b[0m, in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mconstant\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[])\n\u001b[1;32m    171\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconstant\u001b[39m(value, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, shape\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConst\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    172\u001b[0m   \u001b[39m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \n\u001b[1;32m    174\u001b[0m \u001b[39m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[39m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m   \u001b[39mreturn\u001b[39;00m _constant_impl(value, dtype, shape, name, verify_shape\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    268\u001b[0m                         allow_broadcast\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:279\u001b[0m, in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\u001b[39m\"\u001b[39m\u001b[39mtf.constant\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    278\u001b[0m       \u001b[39mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m--> 279\u001b[0m   \u001b[39mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[1;32m    281\u001b[0m g \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mget_default_graph()\n\u001b[1;32m    282\u001b[0m tensor_value \u001b[39m=\u001b[39m attr_value_pb2\u001b[39m.\u001b[39mAttrValue()\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:304\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_constant_eager_impl\u001b[39m(ctx, value, dtype, shape, verify_shape):\n\u001b[1;32m    303\u001b[0m   \u001b[39m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 304\u001b[0m   t \u001b[39m=\u001b[39m convert_to_eager_tensor(value, ctx, dtype)\n\u001b[1;32m    305\u001b[0m   \u001b[39mif\u001b[39;00m shape \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    306\u001b[0m     \u001b[39mreturn\u001b[39;00m t\n",
      "File \u001b[0;32m~/.miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[1;32m    101\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 102\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mEagerTensor(value, ctx\u001b[39m.\u001b[39;49mdevice_name, dtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    encoder_hidden_state = encoder.initialize(batch_size=batch_size)\n",
    "    batch = {\n",
    "        'encoder_input_ids': encoded_input_sample,\n",
    "        'encoder_state': encoder_hidden_state,\n",
    "        'decoder_target': encoded_output_sample\n",
    "    }\n",
    "    loss = trainer.batch_fit(batch)\n",
    "    print(f'Loss - {loss}')\n",
    "\n",
    "    generated = trainer.generate(input_ids=encoded_input_sample)\n",
    "    translated = trainer.translate(generated)\n",
    "    print(f'Translated - {translated}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question generation $f_\\theta(P, Q, H)$ with text passage $P$, question $Q$ and dialogue history $H$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evaluate $f_\\theta(P, Q)$ and $f_\\theta(P, Q, H)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e405b0a43b05ed5b511dac57849ab560497f023fc2f8f0bfd2781bf41b5f416c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
