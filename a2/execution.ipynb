{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAbMpqPm1mPC"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Danysan1/ai-unibo-nlp-project/blob/main/a2/execution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtlMx4kv1mPK"
      },
      "source": [
        "# Assignment 2 execution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "feevAAsT1mPL",
        "outputId": "e7b763fb-cdd4-4491-85bf-bfb749788be8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (1.3.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (1.21.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (3.2.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.25.1)\n",
            "Requirement already satisfied: dataset in /usr/local/lib/python3.8/dist-packages (1.5.2)\n",
            "Requirement already satisfied: tensorflow_addons in /usr/local/lib/python3.8/dist-packages (0.19.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2022.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.11.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.2 in /usr/local/lib/python3.8/dist-packages (from dataset) (1.4.45)\n",
            "Requirement already satisfied: banal>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from dataset) (1.0.6)\n",
            "Requirement already satisfied: alembic>=0.6.2 in /usr/local/lib/python3.8/dist-packages (from dataset) (1.9.1)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow_addons) (2.7.1)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.8/dist-packages (from alembic>=0.6.2->dataset) (1.2.4)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from alembic>=0.6.2->dataset) (5.2.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from alembic>=0.6.2->dataset) (5.10.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.8/dist-packages (from sqlalchemy>=1.3.2->dataset) (2.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->alembic>=0.6.2->dataset) (3.11.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.8/dist-packages (from Mako->alembic>=0.6.2->dataset) (2.0.1)\n"
          ]
        }
      ],
      "source": [
        "%pip install pandas numpy matplotlib transformers==4.25.1  dataset tensorflow_addons"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJSsWQg_1mPO"
      },
      "source": [
        "## Data loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mXm1Fpq1mPP"
      },
      "source": [
        "### Dataset download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oOqlik_a1mPP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import urllib.request\n",
        "from tqdm import tqdm\n",
        "\n",
        "class DownloadProgressBar(tqdm):\n",
        "    def update_to(self, b=1, bsize=1, tsize=None):\n",
        "        if tsize is not None:\n",
        "            self.total = tsize\n",
        "        self.update(b * bsize - self.n)\n",
        "        \n",
        "def download_url(url, output_path):\n",
        "    with DownloadProgressBar(unit='B', unit_scale=True,\n",
        "                             miniters=1, desc=url.split('/')[-1]) as t:\n",
        "        urllib.request.urlretrieve(url, filename=output_path, reporthook=t.update_to)\n",
        "\n",
        "def download_data(data_path, url_path, suffix):    \n",
        "    if not os.path.exists(data_path):\n",
        "        os.makedirs(data_path)\n",
        "        \n",
        "    data_path = os.path.join(data_path, f'{suffix}.json')\n",
        "    if not os.path.exists(data_path):\n",
        "        print(f\"Downloading CoQA {suffix} data split... (it may take a while)\")\n",
        "        download_url(url=url_path, output_path=data_path)\n",
        "        print(\"Download completed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sskRUOtB1mPR"
      },
      "outputs": [],
      "source": [
        "data_folder = 'Dataset'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CzsJWqI61mPR"
      },
      "outputs": [],
      "source": [
        "# Train data\n",
        "train_url = \"https://nlp.stanford.edu/data/coqa/coqa-train-v1.0.json\"\n",
        "download_data(data_path=data_folder, url_path=train_url, suffix='train')\n",
        "\n",
        "# Test data\n",
        "test_url = \"https://nlp.stanford.edu/data/coqa/coqa-dev-v1.0.json\"\n",
        "download_data(data_path=data_folder, url_path=test_url, suffix='test')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsM9znVV1mPT"
      },
      "source": [
        "### Dataset loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VRsmY5Wn1mPV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "from os import path\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lI74kMng1mPW"
      },
      "outputs": [],
      "source": [
        "def loadDataset(filename):\n",
        "    with open(path.join(data_folder, filename)) as file_obj:\n",
        "        df = json.load(file_obj)[\"data\"]\n",
        "    print(f'{len(df)} stories / {len(df[0][\"questions\"])} questions in the first row')\n",
        "\n",
        "    storyDType = pd.CategoricalDtype(pd.unique([story[\"story\"] for story in df]))\n",
        "    print(f\"{storyDType.categories.size} distinct stories\")\n",
        "\n",
        "    sourceDType = pd.CategoricalDtype(pd.unique([story[\"source\"] for story in df]))\n",
        "    print(f\"{sourceDType.categories.size} distinct sources: {sourceDType.categories}\")\n",
        "\n",
        "    df = np.array([\n",
        "        [\n",
        "            sourceDType.categories.get_loc(story[\"source\"]), # Sources factorization\n",
        "            storyDType.categories.get_loc(story[\"story\"]), # Sources factorization\n",
        "            story[\"questions\"][question_index][\"input_text\"],\n",
        "            story[\"answers\"][question_index][\"input_text\"],\n",
        "            story[\"answers\"][question_index][\"span_text\"],\n",
        "        ]\n",
        "        for story in df\n",
        "        for question_index in range(len(story[\"questions\"]))\n",
        "        if story[\"answers\"][question_index][\"input_text\"] != 'unknown'\n",
        "    ])\n",
        "    print(f'{df.shape} question-answer pairs x columns')\n",
        "    print(f'First row: {df[0]}')\n",
        "    \n",
        "    # https://marcobonzanini.com/2021/09/15/tips-for-saving-memory-with-pandas/\n",
        "    # https://pandas.pydata.org/docs/user_guide/categorical.html\n",
        "    df = pd.DataFrame({\n",
        "        \"source\": pd.Series(pd.Categorical.from_codes(df[:,0].astype(np.int16), dtype=sourceDType)),\n",
        "        \"p\": pd.Series(pd.Categorical.from_codes(df[:,1].astype(np.int16), dtype=storyDType)),\n",
        "        \"q\": df[:,2],\n",
        "        \"a\": df[:,3],\n",
        "        \"span\": df[:,4],\n",
        "    })\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsZrgF5d1mPX",
        "outputId": "0da854bb-f9f6-4d48-f1f0-60f8461abf02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7199 stories / 20 questions in the first row\n",
            "6605 distinct stories\n",
            "5 distinct sources: Index(['wikipedia', 'cnn', 'gutenberg', 'race', 'mctest'], dtype='object')\n",
            "(107276, 5) question-answer pairs x columns\n",
            "First row: ['0' '0' 'When was the Vat formally opened?'\n",
            " 'It was formally established in 1475' 'Formally established in 1475']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "source    107276\n",
              "p         107276\n",
              "q         107276\n",
              "a         107276\n",
              "span      107276\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "train_df = loadDataset(\"train.json\")\n",
        "train_df.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOQSe3Sc1mPY",
        "outputId": "108e74fe-6f6e-4d41-bc31-d88b4b21271a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6605"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "pd.unique(train_df[\"p\"]).size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJaLGY_p1mPZ",
        "outputId": "c2d31830-e668-4f22-e59c-5574a0a561a4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "99470"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "pd.unique(train_df[\"span\"]).size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_ml0A1b1mPZ",
        "outputId": "88bda1d9-bf6b-4d3c-ab86-e18033ffba97"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "pd.unique(train_df[\"source\"]).size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "G9VjurfZ1mPZ",
        "outputId": "a5f0827d-9f74-459d-f2ad-0a5acdc1c86f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      source                                                  p  \\\n",
              "0  wikipedia  The Vatican Apostolic Library (), more commonl...   \n",
              "1  wikipedia  The Vatican Apostolic Library (), more commonl...   \n",
              "2  wikipedia  The Vatican Apostolic Library (), more commonl...   \n",
              "3  wikipedia  The Vatican Apostolic Library (), more commonl...   \n",
              "4  wikipedia  The Vatican Apostolic Library (), more commonl...   \n",
              "\n",
              "                                   q                                    a  \\\n",
              "0  When was the Vat formally opened?  It was formally established in 1475   \n",
              "1           what is the library for?                             research   \n",
              "2                 for what subjects?                     history, and law   \n",
              "3                               and?     philosophy, science and theology   \n",
              "4          what was started in 2014?                           a  project   \n",
              "\n",
              "                                                span  \n",
              "0                       Formally established in 1475  \n",
              "1           he Vatican Library is a research library  \n",
              "2  Vatican Library is a research library for hist...  \n",
              "3  Vatican Library is a research library for hist...  \n",
              "4  March 2014, the Vatican Library began an initi...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-642896d6-1dee-48ef-8f64-93a692e3de04\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>p</th>\n",
              "      <th>q</th>\n",
              "      <th>a</th>\n",
              "      <th>span</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>wikipedia</td>\n",
              "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
              "      <td>When was the Vat formally opened?</td>\n",
              "      <td>It was formally established in 1475</td>\n",
              "      <td>Formally established in 1475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>wikipedia</td>\n",
              "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
              "      <td>what is the library for?</td>\n",
              "      <td>research</td>\n",
              "      <td>he Vatican Library is a research library</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>wikipedia</td>\n",
              "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
              "      <td>for what subjects?</td>\n",
              "      <td>history, and law</td>\n",
              "      <td>Vatican Library is a research library for hist...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>wikipedia</td>\n",
              "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
              "      <td>and?</td>\n",
              "      <td>philosophy, science and theology</td>\n",
              "      <td>Vatican Library is a research library for hist...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>wikipedia</td>\n",
              "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
              "      <td>what was started in 2014?</td>\n",
              "      <td>a  project</td>\n",
              "      <td>March 2014, the Vatican Library began an initi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-642896d6-1dee-48ef-8f64-93a692e3de04')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-642896d6-1dee-48ef-8f64-93a692e3de04 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-642896d6-1dee-48ef-8f64-93a692e3de04');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrRkHhES1mPa",
        "outputId": "f1736c82-64dc-4b69-ba5f-87e4dc3652b2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index          128\n",
              "source      107764\n",
              "p         14241201\n",
              "q          9110271\n",
              "a          7714559\n",
              "span      12090637\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "train_df.memory_usage(deep=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v5aer1n41mPa"
      },
      "outputs": [],
      "source": [
        "#test_df = loadDataset(\"test.json\")\n",
        "#test_df.count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRs7YHKY1mPa"
      },
      "source": [
        "## Data Pre-Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0GmOXam1mPb"
      },
      "source": [
        "### Check unanswerable questions in the Train Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Aq524zd1mPb",
        "outputId": "f6f42ea9-b280-4f34-ae88-e2ea8bdeb02f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "idx = (train_df.a == 'unknown')\n",
        "unanswerable = train_df[idx]\n",
        "unanswerable.q.count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTdjLFYI1mPb"
      },
      "source": [
        "All unanswerable questions in the Train Dataset have been already removed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maBslb2n1mPb"
      },
      "source": [
        "## Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VH5Ep77e1mPb",
        "outputId": "6f4b6b2c-ad95-43d9-e59f-12fe2a4aefc4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'CHAPTER VII. THE DAUGHTER OF WITHERSTEEN \\n\\n\"Lassiter, will you be my rider?\" Jane had asked him. \\n\\n\"I reckon so,\" he had replied. \\n\\nFew as the words were, Jane knew how infinitely much they implied. She wanted him to take charge of her cattle and horse and ranges, and save them if that were possible. Yet, though she could not have spoken aloud all she meant, she was perfectly honest with herself. Whatever the price to be paid, she must keep Lassiter close to her; she must shield from him the man who had led Milly Erne to Cottonwoods. In her fear she so controlled her mind that she did not whisper this Mormon\\'s name to her own soul, she did not even think it. Besides, beyond this thing she regarded as a sacred obligation thrust upon her, was the need of a helper, of a friend, of a champion in this critical time. If she could rule this gun-man, as Venters had called him, if she could even keep him from shedding blood, what strategy to play his flame and his presence against the game of oppression her churchmen were waging against her? Never would she forget the effect on Tull and his men when Venters shouted Lassiter\\'s name. If she could not wholly control Lassiter, then what she could do might put off the fatal day. \\n\\nOne of her safe racers was a dark bay, and she called him Bells because of the way he struck his iron shoes on the stones. When Jerd led out this slender, beautifully built horse Lassiter suddenly became all eyes. A rider\\'s love of a thoroughbred shone in them. Round and round Bells he walked, plainly weakening all the time in his determination not to take one of Jane\\'s favorite racers. '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "train_df[\"p\"][42]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYcgBVcG1mPc",
        "outputId": "8540b69c-d459-42df-a5b9-94793de5d8c2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Was Lassiter impressed with the horse?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "train_df[\"q\"][42]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zvn9Tv01mPc",
        "outputId": "c8d1810a-428d-4a57-a571-ac727b48a55e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Yes'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "train_df[\"a\"][42]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NokHfoLm1mPc",
        "outputId": "44e2cc0a-53bc-47f8-efb7-76c45b9e201f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'When Jerd led out this slender, beautifully built horse Lassiter suddenly became all eyes.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "train_df[\"span\"][42]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JskMPh-Y1mPc",
        "outputId": "674fce52-5190-43e1-8f88-c419b3ef350e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'gutenberg'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "train_df[\"source\"][42]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhdF4AR7ef05"
      },
      "source": [
        "### Distribution statistics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebBVUlveef05"
      },
      "source": [
        "Sources:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8lIuR9RO1mPd",
        "outputId": "6fba63dd-4283-4b29-e09e-58a28c87263b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fb294d8a5b0>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "train_df[\"source\"].hist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ax5uSP6Lef06"
      },
      "source": [
        "Occurrences of 25 most popular stories:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wUgsqg4Uef06",
        "outputId": "c72091e4-0ded-464a-e902-3fecc6ccc716",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fb294cdcf70>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "story_counts = train_df[\"p\"].cat.codes.value_counts(sort=True)\n",
        "story_counts[:25].plot(kind=\"bar\", figsize=(15,5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qL-m6SuVef06"
      },
      "source": [
        "Occurrences of 25 least popular stories:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jkiwEygzef06",
        "outputId": "26ee9a1b-c469-4287-dd92-7dd5afb82ca4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fb294787cd0>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3AAAAE+CAYAAADMJ/LiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZwldXnv8c+XRaPigmFcLjCMCyq4oU5QryTihqAGTDQJmCgalVwVURONuFyJeuNFEzXBaBCVi0YFjeuoKOIeNegM+46ICzNRGUVxwajAc//4VeOh6aYb6KlTNf15v17n1edUnXPq6VPrU1W/55eqQpIkSZI0fFtMOwBJkiRJ0uKYwEmSJEnSSJjASZIkSdJImMBJkiRJ0kiYwEmSJEnSSJjASZIkSdJIbDXtAOay3Xbb1apVq6YdhiRJkiRNxcknn/zDqloxe/ggE7hVq1axbt26aYchSZIkSVOR5DtzDfcWSkmSJEkaCRM4SZIkSRoJEzhJkiRJGgkTOEmSJEkaCRM4SZIkSRoJEzhJkiRJGgkTOEmSJEkaiQUTuCQ7Jvl8knOSnJ3keXO8J0mOSHJhkjOS3H9i3IFJvtE9Dlzqf0CSJEmSlovFdOR9BfA3VXVKklsCJyc5sarOmXjPPsDO3eOBwL8CD0xyW+AwYDVQ3WfXVNWPl/S/kCRJkqRlYMErcFX1vao6pXv+M+BcYPtZb9sPeFc1JwG3SXJH4NHAiVV1aZe0nQjsvaT/gSRJkiQtE4u5Ane1JKuA+wFfmzVqe+Diidfru2HzDZ/ruw8CDgJYuXLldcax6tBPLD7o6/Dtwx97o79jc4tlKeIAY5nPkGKRJEnS+Cy6iEmSbYAPAs+vqp8udSBVdVRVra6q1StWrFjqr5ckSZKk0VtUApdka1ry9p6q+tAcb9kA7Djxeodu2HzDJUmSJEnX02KqUAZ4B3BuVb1hnretAZ7SVaN8EHBZVX0POAHYK8m2SbYF9uqGSZIkSZKup8W0gXsI8GTgzCSndcNeCqwEqKojgeOBxwAXApcDT+vGXZrk1cDa7nOvqqpLly58SZIkSVo+FkzgqurLQBZ4TwHPmWfc0cDRNyg6SZIkSdLVFl3ERJIkSZI0XSZwkiRJkjQSJnCSJEmSNBImcJIkSZI0EiZwkiRJkjQSJnCSJEmSNBImcJIkSZI0EiZwkiRJkjQSJnCSJEmSNBImcJIkSZI0EiZwkiRJkjQSJnCSJEmSNBImcJIkSZI0EiZwkiRJkjQSJnCSJEmSNBImcJIkSZI0EiZwkiRJkjQSJnCSJEmSNBImcJIkSZI0EiZwkiRJkjQSJnCSJEmSNBImcJIkSZI0EiZwkiRJkjQSWy30hiRHA48DLqmqe80x/kXAn0983y7Aiqq6NMm3gZ8BVwJXVNXqpQpckiRJkpabxVyBOwbYe76RVfUPVbVbVe0GvAT4YlVdOvGWh3XjTd4kSZIk6UZYMIGrqi8Bly70vs4BwLE3KiJJkiRJ0pyWrA1ckpvTrtR9cGJwAZ9OcnKSg5ZqWpIkSZK0HC3YBu56+EPgK7Nun9yjqjYkuR1wYpLzuit619IleAcBrFy5cgnDkiRJkqTNw1JWodyfWbdPVtWG7u8lwIeB3ef7cFUdVVWrq2r1ihUrljAsSZIkSdo8LEkCl+TWwEOBj04Mu0WSW848B/YCzlqK6UmSJEnScrSYbgSOBfYEtkuyHjgM2Bqgqo7s3vZHwKer6hcTH7098OEkM9N5b1V9aulClyRJkqTlZcEErqoOWMR7jqF1NzA57CLgvjc0MEmSJEnSNS1lGzhJkiRJ0iZkAidJkiRJI2ECJ0mSJEkjYQInSZIkSSNhAidJkiRJI2ECJ0mSJEkjYQInSZIkSSNhAidJkiRJI2ECJ0mSJEkjYQInSZIkSSNhAidJkiRJI2ECJ0mSJEkjYQInSZIkSSNhAidJkiRJI2ECJ0mSJEkjYQInSZIkSSNhAidJkiRJI2ECJ0mSJEkjYQInSZIkSSNhAidJkiRJI2ECJ0mSJEkjYQInSZIkSSNhAidJkiRJI2ECJ0mSJEkjsWACl+ToJJckOWue8XsmuSzJad3jFRPj9k5yfpILkxy6lIFLkiRJ0nKzmCtwxwB7L/Ce/6iq3brHqwCSbAm8GdgH2BU4IMmuNyZYSZIkSVrOFkzgqupLwKU34Lt3By6sqouq6tfAccB+N+B7JEmSJEksXRu4Byc5Pcknk9yzG7Y9cPHEe9Z3w+aU5KAk65Ks27hx4xKFJUmSJEmbj6VI4E4Bdqqq+wJvAj5yQ76kqo6qqtVVtXrFihVLEJYkSZIkbV5udAJXVT+tqp93z48Htk6yHbAB2HHirTt0wyRJkiRJN8CNTuCS3CFJuue7d9/5I2AtsHOSOyW5CbA/sObGTk+SJEmSlqutFnpDkmOBPYHtkqwHDgO2BqiqI4EnAs9KcgXwS2D/qirgiiQHAycAWwJHV9XZm+S/kCRJkqRlYMEErqoOWGD8vwD/Ms+444Hjb1hokiRJkqRJS1WFUpIkSZK0iZnASZIkSdJImMBJkiRJ0kiYwEmSJEnSSJjASZIkSdJImMBJkiRJ0kiYwEmSJEnSSJjASZIkSdJImMBJkiRJ0kiYwEmSJEnSSJjASZIkSdJImMBJkiRJ0kiYwEmSJEnSSJjASZIkSdJImMBJkiRJ0kiYwEmSJEnSSJjASZIkSdJImMBJkiRJ0kiYwEmSJEnSSJjASZIkSdJImMBJkiRJ0kiYwEmSJEnSSJjASZIkSdJILJjAJTk6ySVJzppn/J8nOSPJmUm+muS+E+O+3Q0/Lcm6pQxckiRJkpabxVyBOwbY+zrGfwt4aFXdG3g1cNSs8Q+rqt2qavUNC1GSJEmSBLDVQm+oqi8lWXUd47868fIkYIcbH5YkSZIkabalbgP3dOCTE68L+HSSk5MctMTTkiRJkqRlZcErcIuV5GG0BG6PicF7VNWGJLcDTkxyXlV9aZ7PHwQcBLBy5cqlCkuSJEmSNhtLcgUuyX2AtwP7VdWPZoZX1Ybu7yXAh4Hd5/uOqjqqqlZX1eoVK1YsRViSJEmStFm50QlckpXAh4AnV9UFE8NvkeSWM8+BvYA5K1lKkiRJkha24C2USY4F9gS2S7IeOAzYGqCqjgReAfwu8JYkAFd0FSdvD3y4G7YV8N6q+tQm+B8kSZIkaVlYTBXKAxYY/wzgGXMMvwi477U/IUmSJEm6IZa6CqUkSZIkaRMxgZMkSZKkkTCBkyRJkqSRMIGTJEmSpJEwgZMkSZKkkTCBkyRJkqSRMIGTJEmSpJEwgZMkSZKkkTCBkyRJkqSRMIGTJEmSpJEwgZMkSZKkkTCBkyRJkqSRMIGTJEmSpJEwgZMkSZKkkTCBkyRJkqSRMIGTJEmSpJEwgZMkSZKkkTCBkyRJkqSRMIGTJEmSpJEwgZMkSZKkkTCBkyRJkqSRMIGTJEmSpJEwgZMkSZKkkTCBkyRJkqSRWFQCl+ToJJckOWue8UlyRJILk5yR5P4T4w5M8o3uceBSBS5JkiRJy81ir8AdA+x9HeP3AXbuHgcB/wqQ5LbAYcADgd2Bw5Jse0ODlSRJkqTlbFEJXFV9Cbj0Ot6yH/Cuak4CbpPkjsCjgROr6tKq+jFwItedCEqSJEmS5rHVEn3P9sDFE6/Xd8PmG34tSQ6iXb1j5cqVSxSWpPmsOvQTN/o7vn34YwcRBxjLfIYSy1LEAcYyH2PZNHGAscxnKLFsbsstGMt8hhLLENahwRQxqaqjqmp1Va1esWLFtMORJEmSpMFZqgRuA7DjxOsdumHzDZckSZIkXU9LlcCtAZ7SVaN8EHBZVX0POAHYK8m2XfGSvbphkiRJkqTraVFt4JIcC+wJbJdkPa2y5NYAVXUkcDzwGOBC4HLgad24S5O8GljbfdWrquq6iqFIkiRJkuaxqASuqg5YYHwBz5ln3NHA0dc/NEmSJEnSpMEUMZEkSZIkXTcTOEmSJEkaCRM4SZIkSRoJEzhJkiRJGgkTOEmSJEkaCRM4SZIkSRoJEzhJkiRJGgkTOEmSJEkaCRM4SZIkSRoJEzhJkiRJGgkTOEmSJEkaCRM4SZIkSRoJEzhJkiRJGgkTOEmSJEkaCRM4SZIkSRoJEzhJkiRJGgkTOEmSJEkaCRM4SZIkSRoJEzhJkiRJGgkTOEmSJEkaCRM4SZIkSRoJEzhJkiRJGgkTOEmSJEkaiUUlcEn2TnJ+kguTHDrH+DcmOa17XJDkJxPjrpwYt2Ypg5ckSZKk5WSrhd6QZEvgzcCjgPXA2iRrquqcmfdU1Qsm3v9c4H4TX/HLqtpt6UKWJEmSpOVpMVfgdgcurKqLqurXwHHAftfx/gOAY5ciOEmSJEnSby0mgdseuHji9fpu2LUk2Qm4E/C5icG/k2RdkpOSPH6+iSQ5qHvfuo0bNy4iLEmSJElaXpa6iMn+wAeq6sqJYTtV1WrgScA/JbnLXB+sqqOqanVVrV6xYsUShyVJkiRJ47eYBG4DsOPE6x26YXPZn1m3T1bVhu7vRcAXuGb7OEmSJEnSIi0mgVsL7JzkTkluQkvSrlVNMsk9gG2B/5wYtm2Sm3bPtwMeApwz+7OSJEmSpIUtWIWyqq5IcjBwArAlcHRVnZ3kVcC6qppJ5vYHjquqmvj4LsBbk1xFSxYPn6xeKUmSJElavAUTOICqOh44ftawV8x6/XdzfO6rwL1vRHySJEmSpM5SFzGRJEmSJG0iJnCSJEmSNBImcJIkSZI0EiZwkiRJkjQSJnCSJEmSNBImcJIkSZI0EiZwkiRJkjQSJnCSJEmSNBImcJIkSZI0EiZwkiRJkjQSJnCSJEmSNBImcJIkSZI0EiZwkiRJkjQSJnCSJEmSNBImcJIkSZI0EiZwkiRJkjQSJnCSJEmSNBImcJIkSZI0EiZwkiRJkjQSJnCSJEmSNBImcJIkSZI0EiZwkiRJkjQSJnCSJEmSNBKLSuCS7J3k/CQXJjl0jvFPTbIxyWnd4xkT4w5M8o3uceBSBi9JkiRJy8lWC70hyZbAm4FHAeuBtUnWVNU5s976vqo6eNZnbwscBqwGCji5++yPlyR6SZIkSVpGFnMFbnfgwqq6qKp+DRwH7LfI7380cGJVXdolbScCe9+wUCVJkiRpeVtMArc9cPHE6/XdsNmekOSMJB9IsuP1/KwkSZIkaQFLVcTkY8CqqroP7SrbO6/vFyQ5KMm6JOs2bty4RGFJkiRJ0uZjMQncBmDHidc7dMOuVlU/qqpfdS/fDjxgsZ+d+I6jqmp1Va1esWLFYmKXJEmSpGVlMQncWmDnJHdKchNgf2DN5BuS3HHi5b7Aud3zE4C9kmybZFtgr26YJEmSJOl6WrAKZVVdkeRgWuK1JXB0VZ2d5FXAuqpaAxySZF/gCuBS4KndZy9N8mpaEgjwqqq6dBP8H5IkSZK02VswgQOoquOB42cNe8XE85cAL5nns0cDR9+IGCVJkiRJLF0RE0mSJEnSJmYCJ0mSJEkjYQInSZIkSSNhAidJkiRJI2ECJ0mSJEkjYQInSZIkSSNhAidJkiRJI2ECJ0mSJEkjYQInSZIkSSNhAidJkiRJI2ECJ0mSJEkjYQInSZIkSSNhAidJkiRJI2ECJ0mSJEkjYQInSZIkSSNhAidJkiRJI2ECJ0mSJEkjYQInSZIkSSNhAidJkiRJI2ECJ0mSJEkjYQInSZIkSSNhAidJkiRJI2ECJ0mSJEkjYQInSZIkSSOxqAQuyd5Jzk9yYZJD5xj/10nOSXJGks8m2Wli3JVJTusea5YyeEmSJElaTrZa6A1JtgTeDDwKWA+sTbKmqs6ZeNupwOqqujzJs4DXAX/WjftlVe22xHFLkiRJ0rKzmCtwuwMXVtVFVfVr4Dhgv8k3VNXnq+ry7uVJwA5LG6YkSZIkaTEJ3PbAxROv13fD5vN04JMTr38nybokJyV5/HwfSnJQ9751GzduXERYkiRJkrS8LHgL5fWR5C+A1cBDJwbvVFUbktwZ+FySM6vqm7M/W1VHAUcBrF69upYyLkmSJEnaHCzmCtwGYMeJ1zt0w64hySOBlwH7VtWvZoZX1Ybu70XAF4D73Yh4JUmSJGnZWkwCtxbYOcmdktwE2B+4RjXJJPcD3kpL3i6ZGL5tkpt2z7cDHgJMFj+RJEmSJC3SgrdQVtUVSQ4GTgC2BI6uqrOTvApYV1VrgH8AtgH+PQnAd6tqX2AX4K1JrqIli4fPql4pSZIkSVqkRbWBq6rjgeNnDXvFxPNHzvO5rwL3vjEBSpIkSZKaRXXkLUmSJEmaPhM4SZIkSRoJEzhJkiRJGgkTOEmSJEkaCRM4SZIkSRoJEzhJkiRJGgkTOEmSJEkaCRM4SZIkSRoJEzhJkiRJGgkTOEmSJEkaCRM4SZIkSRoJEzhJkiRJGgkTOEmSJEkaCRM4SZIkSRoJEzhJkiRJGgkTOEmSJEkaCRM4SZIkSRoJEzhJkiRJGgkTOEmSJEkaCRM4SZIkSRoJEzhJkiRJGgkTOEmSJEkaCRM4SZIkSRqJRSVwSfZOcn6SC5McOsf4myZ5Xzf+a0lWTYx7STf8/CSPXrrQJUmSJGl5WTCBS7Il8GZgH2BX4IAku85629OBH1fVXYE3Aq/tPrsrsD9wT2Bv4C3d90mSJEmSrqfFXIHbHbiwqi6qql8DxwH7zXrPfsA7u+cfAB6RJN3w46rqV1X1LeDC7vskSZIkSddTquq635A8Edi7qp7RvX4y8MCqOnjiPWd171nfvf4m8EDg74CTqurd3fB3AJ+sqg/MMZ2DgIO6l3cHzr9x/xrbAT+8kd+xVIxlbsZybUOJA4xlPsYyN2OZ21BiGUocYCzzMZa5GcvchhLLUOKAzTOWnapqxeyBWy3BFy+JqjoKOGqpvi/JuqpavVTfd2MYy9yMZbhxgLHMx1jmZixzG0osQ4kDjGU+xjI3Y5nbUGIZShywvGJZzC2UG4AdJ17v0A2b8z1JtgJuDfxokZ+VJEmSJC3CYhK4tcDOSe6U5Ca0oiRrZr1nDXBg9/yJwOeq3Zu5Bti/q1J5J2Bn4OtLE7okSZIkLS8L3kJZVVckORg4AdgSOLqqzk7yKmBdVa0B3gH8W5ILgUtpSR7d+94PnANcATynqq7cRP/LbEt2O+YSMJa5Gcu1DSUOMJb5GMvcjGVuQ4llKHGAsczHWOZmLHMbSixDiQOWUSwLFjGRJEmSJA3DojryliRJkiRNnwmcJEmSJI2ECZwkSZIkjYQJnCRJkiSNxGaRwCU5JMmOC79zepI8akrTvUeSFyc5onu8OMkuPcewMsnvdM+T5GlJ3pTkWV2/gctWkjskuUP3fEWSP05yz2nHNU1J9p1ZXjQ8Q9veJtkiyRbd85skuX+S204hDpfbRUiyR5K/TrLXlKa/Msltuuerkjwxyb2mEctQJLlVkrvMMfw+04hnCIa2ndPckvxBkrt3zx+S5IVJHjuFOHpfXjaLKpRJLgN+AXwTOBb496raON2orinJd6tqZc/TfDFwAHAcsL4bvAOtm4fjqurwnuI4C9i9qi5P8lrgLsBHgIcDVNVf9hFHF8t2VfXDidd/AewOnAW8rXpcIZL8FXAoEOC1wFO7OPYAXldV7+gxljcAH6yqr/Q1zeuI5Ze09fmTtPX5hB67H5krnnsA+wHbd4M2AGuq6tzlGMuQtrdJHg+8FbgK+F/AS4GfA3cHnlVVH+sxlqEtt7cFDgb+i9bVz0uBBwPnAq+pqh/3FMfXq2r37vkzgecAHwb2Aj7W136om/6hwF8BvwL+EXgh8BXgQcA7quoNfcUylySvqaqX9jzNPwX+CbgE2Bp4alWt7cadUlX37zmeOwCH0dbpVwDPBZ5AW26fV1Xf6ymOwWznunhWApdU1X8nCe144f60brreVlVX9BzP7kBV1dokuwJ7A+dV1fE9xvBPtOO3rWhdnT2Ctv19KHBqVb2ox1h6X142lwTuVOABwCOBPwP2BU6m/Ygfqqqf9RTH7A7Orx4FPLyqbtFHHBPxXADcs6p+M2v4TYCzq2rnnuI4p6p27Z6fDPxeVV3VvT69qu7bRxzd9K7eISV5OfD7wHuBxwHrq+oFPcZyJvBA4GbAd4C7VtX3k2wLfL6qdusxlo1dDCuA9wHHVtWpfU1/Viyn0pL7J9JONtyLdsB3bFV9sedYBnESZEixDGV7OxHLPrR16HTatuX8JDvRTkis7jmWQSy3XTzHA2cCtwJ26Z6/H3gUcN+q2q+nOE6tqvt1z9cCj6mqjUluAZxUVffuI45u+mcDq4GbA98G7jwRy9eqqrcrcUmOmD0IeDLwLoCqOqSnOE4D9qmq73UH5e8CXlJVH56cd31J8ingE8AtgCcB76Htox8PPLLP5ZaBbOe6eIZ0Ivww2nZ3K+BE2nHM52nblhOq6u97iuNs2nb2ZrSTmdt3v8/WtASuz/W5/+Wlqkb/AE6Z9Xrr7sc7FtjYYxw/Bh5Ly/4nH3sCP5jC73IesNMcw3cCzu8xjhNoCSzAB2diAn4XOL3n3+TUyeUGuMXEMnNmz7GcMvH89FnjTu05llO7v3cD/jdwdrf8HAbcbVq/S/f6DsAhwH8CF/ccywXA1nMMvwnwjeUYy1C2t920J9fns64rzin8LlNbbrvpn9b9DbBhrnE9xXE6sG23vV833/zrKZYzur9b0q44bTHf8tNDLBcD7waeAhzYPTbOPO8xjjNnvb4j7cDzkL7XodnLBPDdWeP6XG4Hs53rpn/OxPOTZy27fR9HndmtQzcHfgrcqht+s5l1rKc4zur+/g7t+Ptm3estJ3+vzXV52VzaH2XyRbUrTmuANUlu3mMcJwGX1xxnW5Oc32McM54PfDbJN2g7C4CVwF1pt9b05RnAu5L8HXAZcFp31u82wF/3GAfAzZLcj9b+c8uq+gW0ZSZJ37c7VZKtu+X16nu2u3Y0fbdPLYCqugB4NfDqrv3DAcDxtGWmL7PX5+8DRwBHdFdW+nQV8D9oVycn3bEbtxxjGcr2tgWTbFHtiv5fTgzbkpbY9hrK5IspL7cAW3RX828JbJNkVVV9O8nv0u9vc2vaAWdo27w7Vrvasw2zfrMenJLkvbSrO58F3tld8Xk47Va0Pu1K29buDbywqv4ryWFV9c6e4/hZkrtU1TcBunnzMNrV42m0x57c973rOsZtaoPazgEXJ3l4VX2OdvV4R+A73frctyuq3R5+eZJvVtVPAarql0n63Bd9Isl/0BK4twPvT3IS7cLJl3qMA6awvGwut1DerTvw1Cxpjft355ptZtbWFNpmpBVPuRvtsvv6Lo5eD4KTfIEuWek8qdth/S7t0n+ft1ytBP6rZt27nmR7YJeq+kyPsfR+q8x8kuxZVV+YdhwASfYG/gWY8yRIVX1qucUypO1tkt+jXUH471nDVwF7VNW7e4xlMMstQJIDaG2bAJ4NPKt7vgvwyqo6aiqBdbqDmttX1bd6nOZWwJ/Q9gEfoO0bnwR8F3jzzAm9PiV5AK093ido6/Gqnqd/X9qJ52/MGr418KdV9Z6e43kVrQ34z2cNvytweFU9sac4BrOdA+gKZLyLdnXpMlpb+ZkT4S+sqs/2GMvXgIdVu11x5gQaSW5Na/7RW7vJJA+mtcU7Ka0Qzx/R1ucP9Hl8OY3lZbNI4ODqRIWquqpr43Uv4NtVdemU47rttGOYS5JtZm8gl7PujP1Nq+ryKcexb1XN15ZyU053cMtDktszceKhqn4wpTiGdBJk6rEkuU1V/aSv6Y3ZtNbnielvSdvPX9ElL7vR1qVeCkFMxDHI/fNQdEUpng08uKr+YgDxTHW5nZRkD7pCY1X16Z6nvRL4aVX9pDsptJpWqOOsPuOYFdMQToTftKp+Ncfw7YA7VtWZPcay1cxJ8O6q/j2Ai6axbel7O7e5dCPweOB7wIYk+wH/AfwDcEaSP+wxjockOTfJ2UkemOREYG2Si7uzBEPS2+0iSSZvbdo+yWeT/DjJV5Pcra84uunPWRa5qq7sO3lL6zJg8vEE4KiZ133GAvy6O4iYie1hSf4myT49x0GS3brbIL4AvK57fDHJSUl6rYgGbWNMqyx1Ee3q11nTSN5mYqmqk6rqg1X1QeD+U4jlh0k+k+Tp6cqxT0taNymfTPKJJHdJckySnyT5evrvLmVI6/NMsaqrJq7w/z7t1qLeiiN1cQxi/9zFcqsk/zfJvyV50qxxb+kzlonp3h64H62t5N9MYfpDW26/PvH8mbS7Dm4JHJZWRbSvOA4FvgiclOQZwKdohTvel6Tvph9Xq6pzq+qj3fb/9n0nb10M10jekty1W25u13Py9lTgB0ku6I5VzqBV9D69uwOhN9PYzm0WV+AykEpk3Ybn6cA2wMeAx1fVl7uDzjdV1UP6iGMinvk2MgFeVlW99JWUa1Z+fD/wGdr9yvvRbhl5RB9xdNO/knYgfhytOlzf7R4mY/kNrcDLJfz2/ukn0m7tqeq3qtTpwJ5V9eMkL6LdhnA87YBvXVW9pMdYTgP+qqq+Nmv4g4C3Vr9VS3eltWNaRbtd8VTgdrQd+/Oq6rIeY5lrfX4p8BqA6qkEelr11JfQ2kfuDXyZ1lD7o1X1yz5imIjlS7Sd5DbA4cCLaVVUHwc8v+dty2DW5y6eQazTQ9k/d7F8kHYS5iRam8nf0G6j/1V6LpmfZDfgSFobwQ3d4B2AnwDPrqpTeopjaMvtIKqWZkAVS7t45kqm30K7cktVfajHWD4P/ElV/TDJk2mFz75Eq0Z5VFW9qac4zgQeRkvwTwfuV1Xf7E6KnFhVvfVjOI3t3GZxBQ5ag/HuXvrvVtX53bDv0O//uHVVnVlV/0mrOvPlLo5TaDO1b6+hVf+65azHNkxv3t+tqo7qriR8GOi7w90zaAcyW9Aal56e5NC02yP69j9py8XaqnpaVT0N+GH3vNedJq2gy0y/UH8GPKKq/g9tg9R3p5i3mJ28AVTVSbTiA306GnhOVd2V1ubgvKq6E63vqN766eu8kraD3IbfrstbTjzvy2+q6uNV9ee0A873AH8KrE8rENGnW1bVx6rq2C6u46r5GG3b16chrc8woHV6IPtngLtU1aFV9ZGq2pdWifhzmU4hiGNoJ4F2qapHdo970IqP/ej16jIAAA2BSURBVL8e4xjacrtFkm27eZLq+tKq1j6xz77OruxOSP0E+CXwo4k4puF9tJMOjwP+sHvcovv7uJ5jWVG/7U/3ENqtv8+g7Z+e2WMcV1bVD7tty8/rt4V4ptLcou/t3OZShXIolcgmZ9Lss5t9V0SDtnP6SFWdPHtEd0tAX3ZI6/MmwIr8tvIitFKrfapq96+/DHhZWr83+wNfTuts/X/2GMjaJI8Cntud0Xox1yyw0qefJrlX99v8kFbV6Ze0bUTfB1mfTPIJWoPtmWIdO9LKbfdWNKRzs4kN8deTHNk9f9sUbqO5J/B62k77ldUakB9YVa/sOY6rb7XtDnDeT6v+dWtaX0192nLi+ewrkL1ucwe2PsOA1umB7J8BbjoRC1X190k20K4ebNNzLPOeqOqu8vRigMvtUKqWDqliKbRE+3Baov2vcHXhpKdNIZbfJNm+qjYAP6d1YA3wK665Td7Uvpvk/9JOYJ6X5PXAh2h9sfXazhf6385tLrdQDqISWZJ9gc/UrLZUaZVxnlBVr+sjjonp3h24tOboDT7J7fs6S5HkwFmD1nS39dwBOKSqXtpHHF0sc1ZbTBLgD2oKHe520/8ftIpxq6vqzlOY/n2Af6Nd+gd4CO2g5t7AG6qq1ysr3f3s+3HNYh1rqur4nuP4EO22yc8BfwxsW1V/mVah7ayqunuf8XQx7Qf8LfBGWrW2XpeXJC+sqn/sc5rzSfJXwHtq7op1B1fV86cU11TX5y6GQazTQ9k/d9N8HfDpmlXhN63C65uqauceYzmC1hnzXCeqvlVVfXb1MxPT9rTtytSW2/mk56qlGWbF0i2A59JOlL0YOG5Kxwt7Am+m9et7W+D+tNtw96BV8+5l/5DkVsBzaPPoX4BHA0+jzaNXV4/FmqaxndssEjhpsZI8qe9kZCy6M0V7cc0KVyfUMq44mFak46W0PptOp5Wx/ll3tWmX7rbOacS1Da2T9QdW1R9MIwYtrM8TZfNM33V6liR3pp2M2RG4ErgAeG91fVn1HMsgTlRpXIaQaHf7wCdxzW3LR6vqvGnEsxxtFglcklNol02PnbkHdkpxHEw7I/LD7gzw0cB9gPOBp1fPpWe7K1yH0Tr5fQXtzM0TgHNp9973cnai22G+HPgv2i0AbwQe3MXxoqr6dh9xDM088+ePgfPocf4MTXeW8UDasjp5kHVkDaifreWqSwqeQWv/9qmq+srEuJd37aymJskFVdVrddtuunO15z2FVmEwtUxL5ncnG/6Wtj7vAPyaVtX1yKo6pudYDqG1F/oS8Bja1fWf0NpFP3s5bl+Gvj5Py1COK8ciye2q6pKep3kH2rFTMeBjqCSfrKolr+i9uRQx2ZbWmeHn08pHv6C7haVvz5po2PnPwBur6ja0S91vnUI8x9Du1b4Y+Dyt/cNjaOVNj+w5jrW0e6VPoq1c+9DaMx3dYxwzt8rMPL91knckOSPJe7vKRX06hmvPn8fS//y5Tkk+2fMk3wHsREv2Pw98vBv28iTP7TOQJKuTfD7Ju5PsmOTEJJclWZuk147Pk2yT5FVp3ZRclmRjWtcKT+0zDtq27KG0Rv1HJJlse9Zr2fEkP0vy0+7xsyQ/A+4yM7zPWGjtzE6e9dielsSt6zmWmZL5h6eVzD9g1rg+S+a/h1b599G0QjxHAE8GHpbkNT3GAa3Awj5dUvJI4J5V9TJaNdU39hlIt/85PK3roUuT/Kh7fnj67Z5jMOvzwAzluBK4xvJy3pSXF5LcdvYD+Hpa8Zk+C9MdQ7sQMPVjqCT3n+fxADZR1y2bzRW4+m2Z+t+nlbf+Y9qMPbaqjuopjvNn2sQkWVtVvzcx7ozqsaRpN83JcrzfraqVE+NOq6pe+gNaII4526Rtwlgml5W3A98H3kZbXh5aVb0VYRjK/OmmN1/57AAfr6o79hjLNdaVJCdV1YOS3BQ4rap6698rrWuQw2g78tcBL6iqDyR5BPB/qqq3/h2TfBT4MK0bjj+lNa4/jnZ1e0NfbUkn509aO5G3ANvRtrsn9bw+H0GbNy+auVUxybeqVQrtVZK/AR7VxXLmNGPppj2IkvlJTq+Jrj9m9o3dlfZzqlVe7EVa2fHV3W+wLa3U+Opu3FnVY2n4JCfQ2ta+s6q+3w27A/BU4OFVtVdPcQxmfR6SoRxXTsQz3/JyIK3CbC/LSzfdq4DvzBq8A+02yurrts6BHUNdSeteaK5COw+qqiWvRL+5XIG7WlX9R1U9m3bm87W0W/X68oG0jmTvDHw4yfOT7JRkplFl3ybn77uuY9ymdlWSu6U18rx5kpkd5l3pt2LRbKur6uVV9Z2qeiOtr68+DWX+QLtC+o+0KoeTj3+kHSD36TdphX9mEstfw9Wdh/Z9xmnrqvpktTL1VVUf6GL5LK2qX59WVdUxVbW+Wp9v+1bVN2iNtvs8U351Ra2quqKqDqK1D/wcPVfyq6pDaHc7HJvkkC4pmMpZyap6Pe1WtFckeUOSW04rls5QSub/IskecHWhr0uhdUrP3Ac7m9LbgbVJ3kbrOPvNXVwrZuLq0aqqeu3MwThcXYb8cNodCH0ZzPo8VFM+rpwx3/LyWvpdXgBeRGsatG9V3ak7SbW+e95nm7whHUOdS+u/9mGzH7S7M5bc5tKNwAWzB1TVlbRb9HorO15VL+uStWNp1aVuChwEfAT4877imPDRJNtU1c+r6uUzA7vE6Vq/2Sb0t7SOza+iVU96SVqFtFvTfp8+3S6t/HuAWyVJ/fYydN8r/FDmD/x24/ON2SOSXDzH+zelF9FuW/kVbRu1fxfHCtrtlH367yR70ZbVSvL4qvpIkofS2ub16RdJ9qiqL88+EE7S54HwuiR7V9XV29aqemVaOfZ/7TGOmWmfnOSRwMG0M6B9J9aTsawH/qSbPyfSOgGelqGUzH8W8LYkOwNnA0+Hq9fnN/cYB1X1z0k+A+wCvL66ggvVKjX3XQzoO0n+lnZFZebq8e1pV+D63OYOan0ekEEcV04YyvJCVb0+yfuAN3bHB4cxnZNVQzqG+jvmP4bcJE0/NotbKGfrzvbtTivz/ekpx/JvVfXkKU37gcC5VfXTJDcDDqWVez0HeE1VXTaNuLrYPk47e3NVz9M9bNagt1TVxu5WhNdV1VP6jGfSNJfbJE+klcA9f45xj6+qj/Qcz4OBK6r1UbQrrY3KedV/NwL3pd06eRXwAtrB6IG0anHPrKqv9hjLfWhXEGYOhP+yqi7oDoQPqKojeoxld9oVyanOnzli+X3gYcC6acQyK67fp7Ut+vo09kMZVsn8XWhXL06qiS4fZicOy0l3C+ehtCqUt+sG/wBYQ6t2++P5PttDbO+a5r5wiKZ9XDnU5aU7WfVS2hXCO0wjholYpj2P7kHbzn2tj+3cZpHAJfl6Ve3ePX8mrV+ID9PKJ3+suyWhjzjWzDH44bRbEehuY+lNkrOB+1bVFUmOAi6n9WfyiG54L7ddDfB36XUlu444BrHcdtOfney/hFY9r/dkv0uy96FdfTuRtkH+Aq190QlV9fd9xXJdkjytqv7ftOOAfmOZY/48kNaAvPf5M6RlZY71+dm0uy96X58X0vPycgjttziP1pj/eVX10W5cb23xxqTn+TN7/xzaSZCp7J+HYkj754VMe1/UHTPcparO6nnZHcw86rZzz6HdzdTPdq6qRv8ATp14vhZY0T2/Be2qQl9xnAK8G9iTduZ1T1pv8A+lFcjo+3c5dzK2WeNO63P+DOV3oV3KPp92YPVtYL/5fqM+fpeJ51Nbbrtpng1s1T0/itYJ8R60WyM+1HMsZ9LaRt4c+Clwq274zYAz+oxlgTi/O+0YphHLkObPwGIZzPo8wOVlm+75KlpFzufN/s18TG3+DGb/PKSH6/PwYxnSPJrGdm5zaQO3RXd5eQvaVcWNAFX1iyRX9BjHauB5wMtolchOS/LLqvpijzFMmjwbcnqS1VW1LsndaBXJ+vIAhvO7HAQ8oKp+nmQVrfDMqqr6Z/pvUD+U5RZgi6qamebq+u3Zoi8nOa3nWK6o1tbg8iTfrK6D3ar6ZVr1q94kOWO+UUCv3U4MKJbBzJ+BxTKk9XlIy8sW1d3pUFXfTrInbbu7E/1vcwdjQPNnSPvnIXF9Hn4sQ5pHvW/nNpcE7ta0PndCKzRwx6r6XloHor3tIKq153pjkn/v/v6A6f7GzwD+OcnLaVVw/rNrcHpxN64XA/tdhnQwMYjltjOUZB/g10luXlWX0w4uAEhya1pbtD7dntZ/1ez2BQF6a/82sFiGNH+GFMuQ1mcYzvLygyS7VdVpAN3Js8fR+gC9d49xDM0g5s/A9s9D4vo8/FiGNI96385tFitpVa2aZ9RVwB/1GApwjUpkj6Xd1jMV1dotPTXJrYA70eb3+uoqGE0hniH8LoM5mBjYcjuIZL/zB9W6DJg5uJixNa2ASJ8+Trst4lpXIZN8YZnGMqT5M5hYBrY+w3CWl6cA1zgb3l3tf0qSt/YYx9AMZf4Ag9k/D4br8/BjGdg86n07t1kUMZEWK8kOtNuuvj/HuIdU1VemENZgDCXZlyRJ0txM4CRJkiRpJPruuFiSJEmSdAOZwEmSJEnSSJjASZIkSdJImMBJkiRJ0kj8fxBvzW/e6WhzAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "story_counts[-25:-1].plot(kind=\"bar\", figsize=(15,5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-EVRQQVef06"
      },
      "source": [
        "Histogram of story popularities:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJLPGCfcef07",
        "outputId": "903506fa-8eb0-4b2e-d820-6ce6399506b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fb2967b3160>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "story_counts.hist(log=True,bins=75,figsize=(15,5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kFobL8Upef07",
        "outputId": "f2d6a442-5f64-4792-a744-76e213be9e9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fb2943f0be0>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "q_lengths = train_df[\"q\"].str.len()\n",
        "q_lengths.hist(log=True,bins=75,figsize=(15,5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_7phh51Nef07",
        "outputId": "feec6821-80f7-421c-bc31-6bc0103f38f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fb294239ac0>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "a_lengths = train_df[\"a\"].str.len()\n",
        "a_lengths.hist(log=True,bins=75,figsize=(15,5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mm2QCJbR1mPd"
      },
      "source": [
        "## Train-Validation-Test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lmr_hj9-1mPd"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SICbZ6vB1mPd"
      },
      "source": [
        "## Model definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wuh0_ic1mPd"
      },
      "source": [
        "### Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4pKuTsYt1mPd",
        "outputId": "28dcc870-e8ed-46b7-ddb0-97709087727d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-12-31 16:31:49.632965: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-12-31 16:31:51.065293: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
            "2022-12-31 16:31:51.065318: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "2022-12-31 16:31:51.204447: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2022-12-31 16:31:53.199587: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
            "2022-12-31 16:31:53.200261: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
            "2022-12-31 16:31:53.200292: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from typing import List, Dict, Callable\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YutAeLih1mPe"
      },
      "outputs": [],
      "source": [
        "def predict_data(model: keras.Model,\n",
        "                x: np.ndarray,\n",
        "                prediction_info: Dict):\n",
        "    \"\"\"\n",
        "    Inference routine of a given input set of examples\n",
        "\n",
        "    :param model: Keras built and possibly trained model\n",
        "    :param x: input set of examples in np.ndarray format\n",
        "    :param prediction_info: dictionary storing model predict() argument information\n",
        "\n",
        "    :return\n",
        "        predictions: predicted labels in np.ndarray format\n",
        "    \"\"\"\n",
        "    print(f'Starting prediction: \\n{prediction_info}')\n",
        "    print(f'Predicting on {x.shape[0]} samples')\n",
        "    predictions = model.predict(x, **prediction_info)\n",
        "    return predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CS_dd2On1mPe"
      },
      "outputs": [],
      "source": [
        "def compute_f1(model: keras.Model, \n",
        "             x: np.ndarray, \n",
        "             y: np.ndarray):\n",
        "    \"\"\"\n",
        "    Compute F1_score on the given data with corresponding labels\n",
        "\n",
        "    :param model: Keras built and possibly trained model\n",
        "    :param x: data in np.ndarray format\n",
        "    :param y: ground-truth labels in np.ndarray format\n",
        "\n",
        "    :return\n",
        "        score: f1_macro_score\n",
        "    \"\"\"\n",
        "    #predictions on the x set\n",
        "    prediction_info = {\n",
        "        'batch_size': 64,\n",
        "        'verbose': 1\n",
        "    }\n",
        "    y_pred = predict_data(model=model, x=x, prediction_info=prediction_info)\n",
        "\n",
        "    #compute argmax to take the best class for each sample\n",
        "    y_pred = np.argmax(y_pred, axis=1)\n",
        "    #compute the f1_macro\n",
        "    score = f1_score(y, y_pred, average ='macro')\n",
        "    return score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-akLLJo1mPe"
      },
      "outputs": [],
      "source": [
        "def set_reproducibility(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    os.environ['TF_DETERMINISTIC_OPS'] = '1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61_GSxvB1mPe",
        "outputId": "917fa56f-5eb2-49a2-dbd3-834f0b79c8db"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-12-31 16:31:57.309692: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2022-12-31 16:31:57.309924: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
            "2022-12-31 16:31:57.310131: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
            "2022-12-31 16:31:57.310381: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
            "2022-12-31 16:31:57.358632: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
            "2022-12-31 16:31:57.358743: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
            "2022-12-31 16:31:57.358860: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
            "2022-12-31 16:31:57.358877: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "from tqdm import tqdm\n",
        "from transformers import TFAutoModel, AutoTokenizer\n",
        "\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    except RuntimeError as e:\n",
        "        print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1aFTVbjH1mPf"
      },
      "source": [
        "### Question generation $f_\\theta(P, Q)$ with text passage $P$ and question $Q$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxoRFA2j1mPf"
      },
      "source": [
        "### Seq2Seq LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZecoZhu1mPf"
      },
      "outputs": [],
      "source": [
        "class MyTrainer(object):\n",
        "    \"\"\"\n",
        "    Simple wrapper class\n",
        "\n",
        "    train_op -> uses tf.GradientTape to compute the loss\n",
        "    batch_fit -> receives a batch and performs forward-backward passes (gradient included)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, encoder, decoder, max_length):\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.max_length = max_length\n",
        "        self.ce = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=1e-03)\n",
        "\n",
        "    @tf.function\n",
        "    def compute_loss(self, logits, target):\n",
        "        loss = self.ce(y_true=target, y_pred=logits)\n",
        "        mask = tf.logical_not(tf.math.equal(target, 0))\n",
        "        mask = tf.cast(mask, dtype=loss.dtype)\n",
        "        loss *= mask\n",
        "        return tf.reduce_mean(loss)\n",
        "\n",
        "    @tf.function\n",
        "    def train_op(self, inputs):\n",
        "        with tf.GradientTape() as tape:\n",
        "            encoder_output, encoder_h, encoder_s = self.encoder({'input_ids': inputs['encoder_input_ids'],\n",
        "                                                                 'hidden_state': inputs['encoder_state']})\n",
        "\n",
        "            decoder_input = inputs['decoder_target'][:, :-1]  # ignore <end>\n",
        "            real_target = inputs['decoder_target'][:, 1:]  # ignore <start>\n",
        "\n",
        "            decoder.attention.setup_memory(encoder_output)\n",
        "\n",
        "            decoder_initial_state = self.decoder.build_initial_state(decoder.batch_size, [encoder_h, encoder_s])\n",
        "            predicted = self.decoder({'input_ids': decoder_input,\n",
        "                                      'initial_state': decoder_initial_state}).rnn_output\n",
        "\n",
        "            loss = self.compute_loss(logits=predicted, target=real_target)\n",
        "\n",
        "        grads = tape.gradient(loss, self.encoder.trainable_variables + self.decoder.trainable_variables)\n",
        "        return loss, grads\n",
        "\n",
        "    @tf.function\n",
        "    def batch_fit(self, inputs):\n",
        "        loss, grads = self.train_op(inputs=inputs)\n",
        "        self.optimizer.apply_gradients(zip(grads, self.encoder.trainable_variables + self.decoder.trainable_variables))\n",
        "        return loss\n",
        "\n",
        "    @tf.function\n",
        "    def generate(self, input_ids):\n",
        "        batch_size = input_ids.shape[0]\n",
        "        encoder_initial_state = [tf.zeros((batch_size, self.encoder.encoder_units)),\n",
        "                                 tf.zeros((batch_size, self.encoder.encoder_units))]\n",
        "        encoder_output, encoder_h, encoder_s = self.encoder({\n",
        "            'input_ids': input_ids,\n",
        "            'hidden_state': encoder_initial_state\n",
        "        })\n",
        "\n",
        "        start_tokens = tf.fill([batch_size], tokenizer.word_index['<start>'])\n",
        "        end_token = tokenizer.word_index['<end>']\n",
        "\n",
        "        greedy_sampler = tfa.seq2seq.GreedyEmbeddingSampler()\n",
        "        decoder_instance = tfa.seq2seq.BasicDecoder(cell=self.decoder.wrapped_decoder_cell,\n",
        "                                                    sampler=greedy_sampler,\n",
        "                                                    output_layer=self.decoder.generation_dense,\n",
        "                                                    maximum_iterations=self.max_length)\n",
        "        self.decoder.attention.setup_memory(encoder_output)\n",
        "\n",
        "        decoder_initial_state = self.decoder.build_initial_state(batch_size, [encoder_h, encoder_s])\n",
        "        decoder_embedding_matrix = self.decoder.embedding.variables[0]\n",
        "        outputs, _, _ = decoder_instance(decoder_embedding_matrix,\n",
        "                                         start_tokens=start_tokens,\n",
        "                                         end_token=end_token,\n",
        "                                         initial_state=decoder_initial_state)\n",
        "        return outputs\n",
        "\n",
        "    def translate(self, generated):\n",
        "        return tokenizer.sequences_to_texts(generated.sample_id.numpy())\n",
        "\n",
        "\n",
        "class Encoder(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, vocab_size, embedding_dim, encoder_units):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.encoder_units = encoder_units\n",
        "\n",
        "        self.embedding = tf.keras.layers.Embedding(input_dim=vocab_size,\n",
        "                                                   output_dim=embedding_dim)\n",
        "        self.encoder_lstm = tf.keras.layers.LSTM(self.encoder_units,\n",
        "                                                 return_sequences=True,\n",
        "                                                 return_state=True)\n",
        "\n",
        "    def call(self, inputs, training=False, **kwargs):\n",
        "        input_ids = inputs['input_ids']\n",
        "        input_emb = self.embedding(input_ids)\n",
        "        encoder_output, lstm_hidden, lstm_states = self.encoder_lstm(input_emb, initial_state=inputs['hidden_state'])\n",
        "        return encoder_output, lstm_hidden, lstm_states\n",
        "\n",
        "    def initialize(self, batch_size):\n",
        "        return [tf.zeros((batch_size, self.encoder_units)), tf.zeros((batch_size, self.encoder_units))]\n",
        "\n",
        "\n",
        "class Decoder(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, vocab_size, max_sequence_length, embedding_dim, decoder_units, batch_size):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.max_sequence_length = max_sequence_length\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.decoder_units = decoder_units\n",
        "        self.embedding = tf.keras.layers.Embedding(input_dim=vocab_size,\n",
        "                                                   output_dim=embedding_dim)\n",
        "        self.decoder_lstm_cell = tf.keras.layers.LSTMCell(self.decoder_units)\n",
        "\n",
        "        self.attention = tfa.seq2seq.BahdanauAttention(units=self.decoder_units,\n",
        "                                                       memory=None,\n",
        "                                                       memory_sequence_length=self.batch_size * [max_sequence_length])\n",
        "\n",
        "        self.wrapped_decoder_cell = tfa.seq2seq.AttentionWrapper(self.decoder_lstm_cell,\n",
        "                                                                 self.attention,\n",
        "                                                                 attention_layer_size=self.decoder_units)\n",
        "\n",
        "        self.generation_dense = tf.keras.layers.Dense(vocab_size)\n",
        "        self.sampler = tfa.seq2seq.sampler.TrainingSampler()\n",
        "        self.decoder = tfa.seq2seq.BasicDecoder(self.wrapped_decoder_cell,\n",
        "                                                sampler=self.sampler,\n",
        "                                                output_layer=self.generation_dense)\n",
        "\n",
        "    def build_initial_state(self, batch_size, encoder_state):\n",
        "        initial_state = self.wrapped_decoder_cell.get_initial_state(batch_size=batch_size, dtype=tf.float32)\n",
        "        initial_state = initial_state.clone(cell_state=encoder_state)\n",
        "        return initial_state\n",
        "\n",
        "    def call(self, inputs, training=False, **kwargs):\n",
        "        input_ids = inputs['input_ids']\n",
        "        input_emb = self.embedding(input_ids)\n",
        "        decoder_output, _, _ = self.decoder(input_emb,\n",
        "                                            initial_state=inputs['initial_state'],\n",
        "                                            sequence_length=self.batch_size * [self.max_sequence_length - 1])\n",
        "        return decoder_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t29CV-S41mPg",
        "outputId": "b15fcf00-b73a-41ca-f7aa-954a058ad5d1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-12-31 16:31:57.526536: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2, 6, 16) -- (2, 16) -- (2, 16)\n",
            "(2, 5, 16)\n"
          ]
        }
      ],
      "source": [
        "# Sample\n",
        "input_sample = [\n",
        "    \"hello there how is it going\",\n",
        "    \"this assignment is hellish\"\n",
        "]\n",
        "output_sample = [\n",
        "    \"<start> it is going well <end>\",\n",
        "    \"<start> I agree <end>\"\n",
        "]\n",
        "\n",
        "batch_size = len(input_sample)\n",
        "\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='', oov_token='<UNK>')\n",
        "tokenizer.fit_on_texts(input_sample + output_sample)\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "encoded_input_sample = tokenizer.texts_to_sequences(input_sample)\n",
        "max_input_length = max([len(item) for item in encoded_input_sample])\n",
        "\n",
        "encoded_output_sample = tokenizer.texts_to_sequences(output_sample)\n",
        "max_output_length = max([len(item) for item in encoded_output_sample])\n",
        "\n",
        "max_sequence_length = max(max_input_length, max_output_length)\n",
        "\n",
        "encoded_input_sample = tf.keras.preprocessing.sequence.pad_sequences(encoded_input_sample,\n",
        "                                                                        padding='post',\n",
        "                                                                        maxlen=max_sequence_length)\n",
        "encoded_output_sample = tf.keras.preprocessing.sequence.pad_sequences(encoded_output_sample,\n",
        "                                                                        padding='post',\n",
        "                                                                        maxlen=max_sequence_length)\n",
        "\n",
        "# Test encoder\n",
        "encoder = Encoder(vocab_size=vocab_size,\n",
        "                    embedding_dim=50,\n",
        "                    encoder_units=16)\n",
        "\n",
        "sample_hidden = encoder.initialize(batch_size=batch_size)\n",
        "encoder_sample_batch = {\n",
        "    'input_ids': tf.convert_to_tensor(encoded_input_sample, dtype=tf.int32),\n",
        "    'hidden_state': sample_hidden\n",
        "}\n",
        "\n",
        "sample_output, sample_h, sample_c = encoder(inputs=encoder_sample_batch)\n",
        "print(f'{sample_output.shape} -- {sample_h.shape} -- {sample_c.shape}')\n",
        "\n",
        "# Test decoder\n",
        "decoder = Decoder(vocab_size=vocab_size,\n",
        "                    embedding_dim=50,\n",
        "                    decoder_units=16,\n",
        "                    batch_size=batch_size,\n",
        "                    max_sequence_length=max_sequence_length)\n",
        "decoder.attention.setup_memory(sample_output)\n",
        "initial_state = decoder.build_initial_state(batch_size, [sample_h, sample_c])\n",
        "\n",
        "decoder_sample_batch = {\n",
        "    'input_ids': tf.convert_to_tensor(encoded_output_sample, tf.int32),\n",
        "    'initial_state': initial_state\n",
        "}\n",
        "sample_decoder_outputs = decoder(decoder_sample_batch).rnn_output\n",
        "print(f'{sample_decoder_outputs.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZhSq6V41mPg"
      },
      "outputs": [],
      "source": [
        "# Training\n",
        "trainer = MyTrainer(encoder=encoder,\n",
        "                    decoder=decoder,\n",
        "                    max_length=max_sequence_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d5lLS5pc1mPg",
        "outputId": "d8da62b6-89fe-47fe-ef85-061c004f53c7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss - 2.215960741043091\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  6%|         | 6/100 [00:07<01:30,  1.03it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Translated - ['it it <end> this <UNK> it', 'going i agree agree it it']\n",
            "Loss - 2.2101049423217773\n",
            "Translated - ['it it it <end> this it', 'i agree agree it it <end>']\n",
            "Loss - 2.204186201095581\n",
            "Translated - ['it it it it it it', 'i agree it it <end> agree']\n",
            "Loss - 2.1981472969055176\n",
            "Translated - ['it it it it it it', 'i agree it it <end> <end>']\n",
            "Loss - 2.1919312477111816\n",
            "Translated - ['it it it it it it', 'i agree it it <end> <end>']\n",
            "Loss - 2.18548583984375\n",
            "Translated - ['it it it it it it', 'i agree it it <end> <end>']\n",
            "Loss - 2.1787631511688232\n",
            "Translated - ['it it it it it it', 'i agree it it <end> <end>']\n",
            "Loss - 2.1717166900634766\n",
            "Translated - ['it it it it it it', 'i <end> agree <end> <end> <end>']\n",
            "Loss - 2.1643009185791016\n",
            "Translated - ['it it it it it it', 'i <end> <end> agree <end> <end>']\n",
            "Loss - 2.1564693450927734\n",
            "Translated - ['it it it it it it', 'i <end> <end> <end> <end> <end>']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 16%|        | 16/100 [00:08<00:21,  3.91it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss - 2.1481735706329346\n",
            "Translated - ['it it it it it it', 'it it it it it it']\n",
            "Loss - 2.13936185836792\n",
            "Translated - ['it it it it it it', 'it it it it it it']\n",
            "Loss - 2.129979133605957\n",
            "Translated - ['it it it it it it', 'it it it it it it']\n",
            "Loss - 2.119966506958008\n",
            "Translated - ['it it it it it it', 'it it it it it it']\n",
            "Loss - 2.1092593669891357\n",
            "Translated - ['it it it it it it', 'it it it it it it']\n",
            "Loss - 2.097790241241455\n",
            "Translated - ['it it it it it it', 'it it it it it it']\n",
            "Loss - 2.085484027862549\n",
            "Translated - ['it it it it it it', 'it it it it it it']\n",
            "Loss - 2.0722622871398926\n",
            "Translated - ['it it it it it it', 'it it it it it it']\n",
            "Loss - 2.058039903640747\n",
            "Translated - ['it it it it it it', 'it it it it it it']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 27%|       | 27/100 [00:08<00:07,  9.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss - 2.0427277088165283\n",
            "Translated - ['it it it it it it', 'it it it it it it']\n",
            "Loss - 2.026232957839966\n",
            "Translated - ['it it it it it it', 'it it it it it it']\n",
            "Loss - 2.008460283279419\n",
            "Translated - ['it it it it it it', 'it it it it it it']\n",
            "Loss - 1.989315390586853\n",
            "Translated - ['it it it it it it', 'it it it it <end> <end>']\n",
            "Loss - 1.9687080383300781\n",
            "Translated - ['it it it it it it', 'it it it <end> <end> <end>']\n",
            "Loss - 1.946556806564331\n",
            "Translated - ['it it it it it it', 'it it <end> <end> <end> <end>']\n",
            "Loss - 1.9227972030639648\n",
            "Translated - ['it it it it it it', 'it it <end> <end> <end> <end>']\n",
            "Loss - 1.8973890542984009\n",
            "Translated - ['it it it it it it', 'it it <end> <end> <end> <end>']\n",
            "Loss - 1.8703285455703735\n",
            "Translated - ['it it it it it it', 'it it <end> <end> <end> <end>']\n",
            "Loss - 1.8416589498519897\n",
            "Translated - ['it it it it it it', 'it it <end> <end> <end> <end>']\n",
            "Loss - 1.8114821910858154\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 38%|      | 38/100 [00:08<00:03, 17.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Translated - ['it it it it it <end>', 'it <end> <end> <end> <end> <end>']\n",
            "Loss - 1.7799694538116455\n",
            "Translated - ['it it it it <end>', 'it <end> <end> <end> <end>']\n",
            "Loss - 1.7473640441894531\n",
            "Translated - ['it it it <end>', 'it <end> <end> <end>']\n",
            "Loss - 1.7139848470687866\n",
            "Translated - ['it it it <end>', 'it <end> <end> <end>']\n",
            "Loss - 1.6802200078964233\n",
            "Translated - ['it it it <end>', 'it <end> <end> <end>']\n",
            "Loss - 1.6465171575546265\n",
            "Translated - ['it it <end>', 'it <end> <end>']\n",
            "Loss - 1.6133644580841064\n",
            "Translated - ['it it <end>', 'it <end> <end>']\n",
            "Loss - 1.5812695026397705\n",
            "Translated - ['it it <end>', 'it <end> <end>']\n",
            "Loss - 1.5507242679595947\n",
            "Translated - ['it it <end>', 'it <end> <end>']\n",
            "Loss - 1.5221532583236694\n",
            "Translated - ['it it <end>', 'it <end> <end>']\n",
            "Loss - 1.4958441257476807\n",
            "Translated - ['it <end>', 'it <end>']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 48%|     | 48/100 [00:08<00:02, 25.79it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss - 1.4718739986419678\n",
            "Translated - ['it <end>', 'it <end>']\n",
            "Loss - 1.4500696659088135\n",
            "Translated - ['it <end>', 'it <end>']\n",
            "Loss - 1.430027723312378\n",
            "Translated - ['it <end>', 'it <end>']\n",
            "Loss - 1.4111862182617188\n",
            "Translated - ['it <end>', 'it <end>']\n",
            "Loss - 1.392928123474121\n",
            "Translated - ['it <end>', 'it <end>']\n",
            "Loss - 1.374693751335144\n",
            "Translated - ['it <end>', 'it <end>']\n",
            "Loss - 1.3560700416564941\n",
            "Translated - ['it <end>', 'it <end>']\n",
            "Loss - 1.3368308544158936\n",
            "Translated - ['it <end>', 'it <end>']\n",
            "Loss - 1.3169281482696533\n",
            "Translated - ['it <end>', 'it <end>']\n",
            "Loss - 1.2964471578598022\n",
            "Translated - ['it <end>', 'it <end>']\n",
            "Loss - 1.2755507230758667\n",
            "Translated - ['it <end>', 'it <end>']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|    | 60/100 [00:08<00:01, 36.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss - 1.254421591758728\n",
            "Translated - ['it <end>', 'it <end>']\n",
            "Loss - 1.233214259147644\n",
            "Translated - ['it <end>', 'it <end>']\n",
            "Loss - 1.2120234966278076\n",
            "Translated - ['it it well <end>', 'it <end> <end> <end>']\n",
            "Loss - 1.190889596939087\n",
            "Translated - ['it it well <end>', 'it <end> <end> <end>']\n",
            "Loss - 1.1698271036148071\n",
            "Translated - ['it it well <end>', 'it <end> <end> <end>']\n",
            "Loss - 1.148860216140747\n",
            "Translated - ['it it well <end>', 'i <end> <end> <end>']\n",
            "Loss - 1.128030776977539\n",
            "Translated - ['it it well <end>', 'i <end> <end> <end>']\n",
            "Loss - 1.1073830127716064\n",
            "Translated - ['it is well <end>', 'i <end> <end> <end>']\n",
            "Loss - 1.086936593055725\n",
            "Translated - ['it going well <end>', 'i <end> <end> <end>']\n",
            "Loss - 1.0666611194610596\n",
            "Translated - ['it going well <end>', 'i agree <end> <end>']\n",
            "Loss - 1.046464204788208\n",
            "Translated - ['it going going <end>', 'i agree <end> <end>']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 73%|  | 73/100 [00:09<00:00, 46.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss - 1.026198387145996\n",
            "Translated - ['it going going <end>', 'i agree <end> <end>']\n",
            "Loss - 1.0056911706924438\n",
            "Translated - ['it going going <end>', 'i agree <end> <end>']\n",
            "Loss - 0.9847881197929382\n",
            "Translated - ['it going going <end>', 'i agree <end> <end>']\n",
            "Loss - 0.9633939862251282\n",
            "Translated - ['it going going <end>', 'i agree <end> <end>']\n",
            "Loss - 0.9414979815483093\n",
            "Translated - ['it going going <end>', 'i agree <end> <end>']\n",
            "Loss - 0.9191766977310181\n",
            "Translated - ['it going going <end>', 'i agree <end> <end>']\n",
            "Loss - 0.8965771794319153\n",
            "Translated - ['it going going <end>', 'i agree <end> <end>']\n",
            "Loss - 0.8738818168640137\n",
            "Translated - ['it going going well <end>', 'i agree <end> <end> <end>']\n",
            "Loss - 0.8512600660324097\n",
            "Translated - ['it going going well <end>', 'i agree <end> <end> <end>']\n",
            "Loss - 0.8288224935531616\n",
            "Translated - ['it going going well <end>', 'i agree <end> <end> <end>']\n",
            "Loss - 0.8066062927246094\n",
            "Translated - ['it going going well <end>', 'i agree <end> <end> <end>']\n",
            "Loss - 0.7846027612686157\n",
            "Translated - ['it going going well <end>', 'i agree <end> <end> <end>']\n",
            "Loss - 0.7628008127212524\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 86%| | 86/100 [00:09<00:00, 52.82it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Translated - ['it going going well <end>', 'i agree <end> <end> <end>']\n",
            "Loss - 0.7412184476852417\n",
            "Translated - ['it going going well <end>', 'i agree <end> <end> <end>']\n",
            "Loss - 0.7199094295501709\n",
            "Translated - ['it is going well <end>', 'i agree <end> <end> <end>']\n",
            "Loss - 0.6989539861679077\n",
            "Translated - ['it is going well <end>', 'i agree <end> <end> <end>']\n",
            "Loss - 0.6784437894821167\n",
            "Translated - ['it is going well <end>', 'i agree <end> <end> <end>']\n",
            "Loss - 0.6584662199020386\n",
            "Translated - ['it is going well <end>', 'i agree <end> <end> <end>']\n",
            "Loss - 0.6390868425369263\n",
            "Translated - ['it is going well <end>', 'i agree <end> <end> <end>']\n",
            "Loss - 0.6203412413597107\n",
            "Translated - ['it is going well <end>', 'i agree <end> <end> <end>']\n",
            "Loss - 0.6022309064865112\n",
            "Translated - ['it is going well <end>', 'i agree <end> <end> <end>']\n",
            "Loss - 0.5847277641296387\n",
            "Translated - ['it is going well <end>', 'i agree <end> <end> <end>']\n",
            "Loss - 0.567787766456604\n",
            "Translated - ['it is going well <end>', 'i agree <end> <end> <end>']\n",
            "Loss - 0.55136638879776\n",
            "Translated - ['it is going well <end>', 'i agree <end> <end> <end>']\n",
            "Loss - 0.5354311466217041\n",
            "Translated - ['it is going well <end>', 'i agree <end> <end> <end>']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 100/100 [00:09<00:00, 10.44it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss - 0.5199663043022156\n",
            "Translated - ['it is going well <end>', 'i agree <end> <end> <end>']\n",
            "Loss - 0.5049706101417542\n",
            "Translated - ['it is going well <end>', 'i agree <end> <end> <end>']\n",
            "Loss - 0.49044856429100037\n",
            "Translated - ['it is going well <end>', 'i agree <end> <end> <end>']\n",
            "Loss - 0.47640281915664673\n",
            "Translated - ['it is going well <end>', 'i agree <end> <end> <end>']\n",
            "Loss - 0.46282821893692017\n",
            "Translated - ['it is going well <end>', 'i agree <end> <end> <end>']\n",
            "Loss - 0.44971227645874023\n",
            "Translated - ['it is going well <end>', 'i agree <end> <end> <end>']\n",
            "Loss - 0.43703755736351013\n",
            "Translated - ['it is going well <end>', 'i agree <end> <end> <end>']\n",
            "Loss - 0.4247874319553375\n",
            "Translated - ['it is going well <end>', 'i agree <end> <end> <end>']\n",
            "Loss - 0.41294923424720764\n",
            "Translated - ['it is going well <end>', 'i agree <end> <end> <end>']\n",
            "Loss - 0.40151482820510864\n",
            "Translated - ['it is going well <end>', 'i agree <end> <end> <end>']\n",
            "Loss - 0.3904794752597809\n",
            "Translated - ['it is going well <end>', 'i agree <end> <end> <end>']\n",
            "Loss - 0.3798389434814453\n",
            "Translated - ['it is going well <end>', 'i agree <end> <end> <end>']\n",
            "Loss - 0.36958619952201843\n",
            "Translated - ['it is going well <end>', 'i agree <end> <end> <end>']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "epochs = 100\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    encoder_hidden_state = encoder.initialize(batch_size=batch_size)\n",
        "    batch = {\n",
        "        'encoder_input_ids': encoded_input_sample,\n",
        "        'encoder_state': encoder_hidden_state,\n",
        "        'decoder_target': encoded_output_sample\n",
        "    }\n",
        "    loss = trainer.batch_fit(batch)\n",
        "    print(f'Loss - {loss}')\n",
        "\n",
        "    generated = trainer.generate(input_ids=encoded_input_sample)\n",
        "    translated = trainer.translate(generated)\n",
        "    print(f'Translated - {translated}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Akd5eb5N1mPh"
      },
      "outputs": [],
      "source": [
        "#TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ia7JgdiF1mPh"
      },
      "source": [
        "### Seq2Seq Bert-Tiny"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tIz7Z9QV1mPh"
      },
      "outputs": [],
      "source": [
        "class MyTrainer(object):\n",
        "    \"\"\"\n",
        "    Simple wrapper class\n",
        "\n",
        "    train_op -> uses tf.GradientTape to compute the loss\n",
        "    batch_fit -> receives a batch and performs forward-backward passes (gradient included)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, encoder, decoder, max_length):\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.max_length = max_length\n",
        "        self.ce = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=1e-03)\n",
        "\n",
        "    @tf.function\n",
        "    def compute_loss(self, logits, target):\n",
        "        loss = self.ce(y_true=target, y_pred=logits)\n",
        "        mask = tf.logical_not(tf.math.equal(target, 0))\n",
        "        mask = tf.cast(mask, dtype=loss.dtype)\n",
        "        loss *= mask\n",
        "        return tf.reduce_mean(loss)\n",
        "\n",
        "    @tf.function\n",
        "    def train_op(self, inputs):\n",
        "        with tf.GradientTape() as tape:\n",
        "            encoder_output, encoder_h, encoder_s = self.encoder({'input_ids': inputs['encoder_input_ids'],\n",
        "                                                                 'attention_mask': inputs['encoder_attention_mask']})\n",
        "\n",
        "            decoder_input = inputs['decoder_target'][:, :-1]  # ignore <end>\n",
        "            real_target = inputs['decoder_target'][:, 1:]  # ignore <start>\n",
        "\n",
        "            decoder.attention.setup_memory(encoder_output)\n",
        "\n",
        "            decoder_initial_state = self.decoder.build_initial_state(decoder.batch_size, [encoder_h, encoder_s])\n",
        "            predicted = self.decoder({'input_ids': decoder_input,\n",
        "                                      'initial_state': decoder_initial_state}).rnn_output\n",
        "\n",
        "            loss = self.compute_loss(logits=predicted, target=real_target)\n",
        "\n",
        "        grads = tape.gradient(loss, self.encoder.trainable_variables + self.decoder.trainable_variables)\n",
        "        return loss, grads\n",
        "\n",
        "    @tf.function\n",
        "    def batch_fit(self, inputs):\n",
        "        loss, grads = self.train_op(inputs=inputs)\n",
        "        self.optimizer.apply_gradients(zip(grads, self.encoder.trainable_variables + self.decoder.trainable_variables))\n",
        "        return loss\n",
        "\n",
        "    # @tf.function\n",
        "    def generate(self, input_ids, attention_mask=None):\n",
        "        batch_size = input_ids.shape[0]\n",
        "        encoder_output, encoder_h, encoder_s = self.encoder({\n",
        "            'input_ids': input_ids,\n",
        "            'attention_mask': attention_mask\n",
        "        })\n",
        "\n",
        "        start_tokens = tf.fill([batch_size], output_tokenizer.word_index['<start>'])\n",
        "        end_token = output_tokenizer.word_index['<end>']\n",
        "\n",
        "        greedy_sampler = tfa.seq2seq.GreedyEmbeddingSampler()\n",
        "        decoder_instance = tfa.seq2seq.BasicDecoder(cell=self.decoder.wrapped_decoder_cell,\n",
        "                                                    sampler=greedy_sampler,\n",
        "                                                    output_layer=self.decoder.generation_dense,\n",
        "                                                    maximum_iterations=self.max_length)\n",
        "        self.decoder.attention.setup_memory(encoder_output)\n",
        "\n",
        "        decoder_initial_state = self.decoder.build_initial_state(batch_size, [encoder_h, encoder_s])\n",
        "        decoder_embedding_matrix = self.decoder.embedding.variables[0]\n",
        "        outputs, _, _ = decoder_instance(decoder_embedding_matrix,\n",
        "                                         start_tokens=start_tokens,\n",
        "                                         end_token=end_token,\n",
        "                                         initial_state=decoder_initial_state)\n",
        "        return outputs\n",
        "\n",
        "    def translate(self, generated):\n",
        "        return output_tokenizer.sequences_to_texts(generated.sample_id.numpy())\n",
        "\n",
        "\n",
        "class Encoder(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, model_name, decoder_units):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.model = TFAutoModel.from_pretrained(model_name, from_pt=True)\n",
        "        self.reducer = tf.keras.layers.Dense(decoder_units)\n",
        "\n",
        "    def call(self, inputs, training=False, **kwargs):\n",
        "        model_output = self.model(inputs)\n",
        "        all_outputs = model_output[0]\n",
        "        pooled_output = model_output[1]\n",
        "        pooled_output = self.reducer(pooled_output)\n",
        "        return all_outputs, pooled_output, pooled_output\n",
        "\n",
        "\n",
        "class Decoder(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, vocab_size, max_sequence_length, embedding_dim, decoder_units, batch_size):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.max_sequence_length = max_sequence_length\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.decoder_units = decoder_units\n",
        "        self.embedding = tf.keras.layers.Embedding(input_dim=vocab_size,\n",
        "                                                   output_dim=embedding_dim)\n",
        "        self.decoder_lstm_cell = tf.keras.layers.LSTMCell(self.decoder_units)\n",
        "\n",
        "        self.attention = tfa.seq2seq.BahdanauAttention(units=self.decoder_units,\n",
        "                                                       memory=None,\n",
        "                                                       memory_sequence_length=self.batch_size * [max_sequence_length])\n",
        "\n",
        "        self.wrapped_decoder_cell = tfa.seq2seq.AttentionWrapper(self.decoder_lstm_cell,\n",
        "                                                                 self.attention,\n",
        "                                                                 attention_layer_size=self.decoder_units)\n",
        "\n",
        "        self.generation_dense = tf.keras.layers.Dense(vocab_size)\n",
        "        self.sampler = tfa.seq2seq.sampler.TrainingSampler()\n",
        "        self.decoder = tfa.seq2seq.BasicDecoder(self.wrapped_decoder_cell,\n",
        "                                                sampler=self.sampler,\n",
        "                                                output_layer=self.generation_dense)\n",
        "\n",
        "    def build_initial_state(self, batch_size, encoder_state):\n",
        "        initial_state = self.wrapped_decoder_cell.get_initial_state(batch_size=batch_size, dtype=tf.float32)\n",
        "        initial_state = initial_state.clone(cell_state=encoder_state)\n",
        "        return initial_state\n",
        "\n",
        "    def call(self, inputs, training=False, **kwargs):\n",
        "        input_ids = inputs['input_ids']\n",
        "        input_emb = self.embedding(input_ids)\n",
        "        decoder_output, _, _ = self.decoder(input_emb,\n",
        "                                            initial_state=inputs['initial_state'],\n",
        "                                            sequence_length=self.batch_size * [self.max_sequence_length - 1])\n",
        "        return decoder_output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vV1rlQqR1mPi"
      },
      "outputs": [],
      "source": [
        "from transformers import BertForQuestionAnswering, AutoTokenizer, AutoConfig\n",
        "\n",
        "model_name = 'prajjwal1/bert-tiny'\n",
        "\n",
        "#config = AutoConfig.from_pretrained(model_name)\n",
        "#model = BertForQuestionAnswering.from_pretrained(model_name, config=config)\n",
        "input_tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kswqcr_m1mPi"
      },
      "source": [
        "The next block of code is an example of encoding of a question-context pair: in this case, the question is the first part of the encoding, and the context is the second part. There are two special tokens: [CLS] token at the start of the encoding, [SEP] token between the question and the context, and at the end of the encoding.\n",
        "\n",
        "In this case the context is the *span*, to provide a better example that explains the encoding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxqLjPlL1mPi",
        "outputId": "8b7d0cea-e17f-44ac-abb6-290888dc468a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Was Lassiter impressed with the horse?\n",
            "When Jerd led out this slender, beautifully built horse Lassiter suddenly became all eyes.\n",
            "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
            "101\t[CLS]\n",
            "2001\twas\n",
            "27333\tlass\n",
            "21646\t##iter\n",
            "7622\timpressed\n",
            "2007\twith\n",
            "1996\tthe\n",
            "3586\thorse\n",
            "1029\t?\n",
            "102\t[SEP]\n",
            "2043\twhen\n",
            "15333\tje\n",
            "4103\t##rd\n",
            "2419\tled\n",
            "2041\tout\n",
            "2023\tthis\n",
            "10944\tslender\n",
            "1010\t,\n",
            "17950\tbeautifully\n",
            "2328\tbuilt\n",
            "3586\thorse\n",
            "27333\tlass\n",
            "21646\t##iter\n",
            "3402\tsuddenly\n",
            "2150\tbecame\n",
            "2035\tall\n",
            "2159\teyes\n",
            "1012\t.\n",
            "102\t[SEP]\n"
          ]
        }
      ],
      "source": [
        "line = 42\n",
        "\n",
        "encoded_question = input_tokenizer(train_df['q'][line], return_tensors='tf', padding=True)\n",
        "print(train_df['q'][line])\n",
        "\n",
        "encoded_span = input_tokenizer(train_df['span'][line], return_tensors='tf', padding=True)\n",
        "print(train_df['span'][line])\n",
        "\n",
        "encoded_qs = input_tokenizer(train_df['q'][line], train_df['span'][line], return_tensors='tf', padding=True)\n",
        "\n",
        "print('= '*40)\n",
        "for idx, tok in zip(encoded_qs.input_ids.numpy()[0], input_tokenizer.convert_ids_to_tokens(encoded_qs.input_ids[0])):\n",
        "    print(\"{}\\t{}\".format(idx, tok))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYZk4xQk1mPi"
      },
      "source": [
        "Lets encode a part of the dataset in sentences of: [CLS] question [SEP] passage [SEP]. Otherwise, the training would be very slow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xBycfrq51mPj"
      },
      "outputs": [],
      "source": [
        "max_length = 512  # The maximum length of a feature (question and context)\n",
        "doc_stride = (\n",
        "    128  # The authorized overlap between two part of the context when splitting\n",
        ")\n",
        "sentences = 20\n",
        "sample = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZhjywqdM1mPj"
      },
      "outputs": [],
      "source": [
        "# Input\n",
        "qs = train_df['q'][range(sentences)] # questions\n",
        "cs = train_df['p'][range(sentences)] # contexts\n",
        "\n",
        "batch_size = len(qs)\n",
        "\n",
        "encoded_inputs = input_tokenizer(\n",
        "    qs.values.tolist(),\n",
        "    cs.values.tolist(),\n",
        "    #train_df['q'].values.tolist(),\n",
        "    #train_df['p'].values.tolist(),\n",
        "    truncation=\"only_second\",\n",
        "    max_length=max_length,\n",
        "    stride=doc_stride,\n",
        "    return_overflowing_tokens=True,\n",
        "    return_offsets_mapping=True,\n",
        "    padding=\"max_length\",\n",
        "    return_tensors='tf'\n",
        ")\n",
        "\n",
        "input_ids, attention_mask = encoded_inputs.input_ids, encoded_inputs.attention_mask\n",
        "max_input_length = input_ids.shape[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "emIgycXc1mPk",
        "outputId": "c171e250-6167-456b-deb7-761b923cbcce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "max_input_length: 512\n",
            "encoded_inputs shape = (20, 512)\n"
          ]
        }
      ],
      "source": [
        "print(\"max_input_length:\", max_input_length)\n",
        "print(\"encoded_inputs shape =\", encoded_inputs['input_ids'].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cpxq9qK1mPl"
      },
      "source": [
        "The 'token_type_ids' encodes wether the encoded id is part of the question (=0) or the context (=1). The Attention Mask indicates if the input is needed (=1) or it's padding (=0)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIGwPsUg1mPm"
      },
      "source": [
        "Prepare also the expected outputs, for the training (this code follows the example given by the tutors, but I'm not convinced that this is the proper formatting for a QA Bert model)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "APmOG4gv1mPm",
        "outputId": "77cb34f3-579d-4a83-d2d7-065f8cb61331"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2, 30, 5, 31, 10, 5, 32, 33, 3]\n"
          ]
        }
      ],
      "source": [
        "# Output\n",
        "outputs = \"<start> \" + train_df['a'][range(sentences)] + \" <end>\"\n",
        "\n",
        "output_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='', oov_token='<UNK>')\n",
        "output_tokenizer.fit_on_texts(outputs)\n",
        "\n",
        "output_vocab_size = len(output_tokenizer.word_index) + 1\n",
        "\n",
        "encoded_output = output_tokenizer.texts_to_sequences(outputs)\n",
        "print(encoded_output[sample])\n",
        "max_output_length = max([len(item) for item in encoded_output])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4wdmkDs1mPn",
        "outputId": "17d82207-b850-4b54-f679-e886186ee5c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "max_output_length: 11\n",
            "max_sequence_length: 512\n"
          ]
        }
      ],
      "source": [
        "max_sequence_length = max(max_input_length, max_output_length)\n",
        "\n",
        "print(\"max_output_length: {}\".format(max_output_length))\n",
        "print(\"max_sequence_length: {}\".format(max_sequence_length))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cNunTdpj1mPn",
        "outputId": "341ad36a-a211-4744-818d-8c4785f05a5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 2 30  5 31 10  5 32 33  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0]\n"
          ]
        }
      ],
      "source": [
        "encoded_output = tf.keras.preprocessing.sequence.pad_sequences(encoded_output,\n",
        "                                                                        padding='post',\n",
        "                                                                        maxlen=max_sequence_length)\n",
        "print(encoded_output[sample])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-G1IKYO61mPo",
        "outputId": "51413bbc-b166-4320-8cbb-11d6ef001804"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'bert.embeddings.position_ids', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(20, 512, 128) - (20, 16) - (20, 16)\n"
          ]
        }
      ],
      "source": [
        "# Test encoder\n",
        "encoder = Encoder(model_name=model_name,\n",
        "                    decoder_units=16)\n",
        "encoder_output, encoder_h, encoder_s = encoder({'input_ids': input_ids,\n",
        "                                                'attention_mask': attention_mask})\n",
        "print(f'{encoder_output.shape} - {encoder_h.shape} - {encoder_s.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zkKbWjm11mPo",
        "outputId": "b0e3ad8e-c144-4efd-a827-7c97d69e1f85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(20, 511, 63)\n"
          ]
        }
      ],
      "source": [
        "# Test decoder\n",
        "decoder = Decoder(vocab_size=output_vocab_size,\n",
        "                    embedding_dim=50,\n",
        "                    decoder_units=16,\n",
        "                    batch_size=batch_size,\n",
        "                    max_sequence_length=max_sequence_length)\n",
        "decoder.attention.setup_memory(encoder_output)\n",
        "initial_state = decoder.build_initial_state(batch_size, [encoder_h, encoder_s])\n",
        "\n",
        "decoder_batch = {\n",
        "    'input_ids': tf.convert_to_tensor(encoded_output, tf.int32),\n",
        "    'initial_state': initial_state\n",
        "}\n",
        "decoder_outputs = decoder(decoder_batch).rnn_output\n",
        "print(f'{decoder_outputs.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RueCJjXO1mPp"
      },
      "outputs": [],
      "source": [
        "# Training\n",
        "trainer = MyTrainer(encoder=encoder,\n",
        "                    decoder=decoder,\n",
        "                    max_length=max_sequence_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l5H1c5ZN1mPp",
        "outputId": "d56bee8b-043a-4526-e4d9-efca762bd374"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/3 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss - 0.040791284292936325\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 33%|      | 1/3 [00:13<00:27, 13.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Translated - ['<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>']\n",
            "Loss - 0.0352395623922348\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 67%|   | 2/3 [00:20<00:09,  9.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Translated - ['<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>']\n",
            "Loss - 0.035170719027519226\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 3/3 [00:26<00:00,  8.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Translated - ['<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>', '<end>']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "epochs = 3\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    batch = {\n",
        "        'encoder_input_ids': input_ids,\n",
        "        'encoder_attention_mask': attention_mask,\n",
        "        'decoder_target': encoded_output\n",
        "    }\n",
        "    loss = trainer.batch_fit(batch)\n",
        "    print(f'Loss - {loss}')\n",
        "\n",
        "    generated = trainer.generate(input_ids=input_ids,\n",
        "                                    attention_mask=attention_mask)\n",
        "    translated = trainer.translate(generated)\n",
        "    print(f'Translated - {translated}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3vOKrD11mPp"
      },
      "source": [
        "An example of answered question by the pretrained (*original*) model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "09T-nztL1mPp",
        "outputId": "a3e7b98e-9407-4984-f02a-b40253b9f6a0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertForQuestionAnswering: ['bert.embeddings.position_ids']\n",
            "- This IS expected if you are initializing TFBertForQuestionAnswering from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertForQuestionAnswering from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights or buffers of the TF 2.0 model TFBertForQuestionAnswering were not initialized from the PyTorch model and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForQuestionAnswering: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model outputs: {'score': 2.5508483304292895e-05, 'start': 343, 'end': 386, 'answer': 'codices from throughout history, as well as'}\n",
            "\n",
            "official results are (from train.json):\n",
            "span_start: 151\n",
            "span_end: 179\n",
            "span_text: Formally established in 1475\n",
            "input_text: It was formally established in 1475\n"
          ]
        }
      ],
      "source": [
        "from transformers import TFBertForQuestionAnswering, pipeline\n",
        "\n",
        "model = TFBertForQuestionAnswering.from_pretrained(model_name, from_pt=True)\n",
        "\n",
        "question_answerer = pipeline(\"question-answering\", model=model_name)\n",
        "\n",
        "outputs = question_answerer(question=train_df['q'][0], context=train_df['p'][0])\n",
        "\n",
        "print(\"model outputs:\", outputs)\n",
        "print()\n",
        "print(\"official results are (from train.json):\") \n",
        "print(\"span_start: 151\")\n",
        "print(\"span_end: 179\")\n",
        "print(\"span_text: Formally established in 1475\")\n",
        "print(\"input_text: It was formally established in 1475\")\n",
        "#print(\"start scores: {}\".format(start_scores))\n",
        "#print(\"end scores: {}\".format(end_scores))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkhJeOxIVG9U"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###BERT2BERT Bert-Tiny"
      ],
      "metadata": {
        "id": "pAG9J3GGfF76"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#entire dataset\n",
        "contexts = list(train_df['p'])\n",
        "questions = list(train_df['q'])\n",
        "answers = list(train_df['a'])"
      ],
      "metadata": {
        "id": "bBtg7iiwp6DJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#take a subset from the training set\n",
        "start = 0\n",
        "end = 95000\n",
        "contexts = list(train_df['p'])\n",
        "questions = list(train_df['q'])\n",
        "answers = list(train_df['a'])\n",
        "contexts = contexts[start:end]\n",
        "questions = questions[start:end]\n",
        "answers = answers[start:end]\n",
        "len(contexts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oL3BVkcG5KZ8",
        "outputId": "5dd2bf70-2ed5-42a0-b0d4-25b3c43d4561"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "95000"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import EncoderDecoderModel, AutoTokenizer\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "model_name = 'prajjwal1/bert-tiny'\n",
        "\n",
        "# tie_encoder_decoder to share weights and half the number of parameters\n",
        "model = EncoderDecoderModel.from_encoder_decoder_pretrained(model_name, model_name,\n",
        "                                                                        #encoder_from_pt=True,\n",
        "                                                                        #decoder_from_pt=True,\n",
        "                                                                        tie_encoder_decoder=True)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# set special tokens\n",
        "model.config.decoder_start_token_id = tokenizer.cls_token_id\n",
        "model.config.eos_token_id = tokenizer.sep_token_id\n",
        "model.config.pad_token_id = tokenizer.pad_token_id\n",
        "\n",
        "# set decoding params                               \n",
        "model.config.early_stopping = True\n",
        "model.config.no_repeat_ngram_size = 3\n",
        "model.config.length_penalty = 2.0\n",
        "model.config.repetition_penalty = 5.0\n",
        "model.config.num_beams = 2\n",
        "model.config.vocab_size = model.config.encoder.vocab_size\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a75cb503-137a-4b43-8cf0-0567a309fe71",
        "id": "25WjYqJRfsZu"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertLMHeadModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertLMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertLMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertLMHeadModel were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.1.crossattention.self.query.bias', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.1.crossattention.self.value.weight', 'bert.encoder.layer.1.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.1.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.1.crossattention.output.dense.bias', 'bert.encoder.layer.1.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.1.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.1.crossattention.self.value.bias', 'bert.encoder.layer.1.crossattention.output.LayerNorm.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "The following encoder weights were not tied to the decoder ['bert/pooler']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encodings = tokenizer(questions, contexts, \n",
        "                          padding=True,\n",
        "                          truncation= 'only_second',\n",
        "                          max_length = 499,\n",
        "                          )\n",
        "input_ids, input_attention_mask = encodings['input_ids'], encodings['attention_mask']\n",
        "label_values = tokenizer(answers,\n",
        "                          padding=True,\n",
        "                          truncation=True,\n",
        "                          max_length = 25,\n",
        "                          )\n",
        "labels, labels_mask = label_values['input_ids'], label_values['attention_mask']\n",
        "\n",
        "\n",
        "\n",
        "#Tokens with indices set to ``-100`` are ignored (masked) during training, the loss is only computed for the tokens with labels\n",
        "masked_labels = [[-100 if token == tokenizer.pad_token_id else token for token in labels] for labels in labels]\n",
        "print(f'length of input_ids: {np.shape(input_ids)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_J9fZwmgqJZo",
        "outputId": "d6b584f6-209c-408a-8a83-e13a17756085"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of input_ids: (95000, 499)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encodings.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0919455-47eb-47f3-cf13-9a9b27449329",
        "id": "TXROfeJ0fsZu"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encodings.pop('token_type_ids')\n",
        "encodings.update({#'decoder_input_ids': labels,\n",
        "                 #'decoder_attention_mask': labels_mask,\n",
        "                 'labels': masked_labels\n",
        "                 })\n",
        "encodings.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15a092d1-a926-4d0a-9dcc-6c0350013947",
        "id": "AEAZjiqdfsZv"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'attention_mask', 'labels'])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class CustomTextDataset(Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings.input_ids)"
      ],
      "metadata": {
        "id": "6zawXNuzfsZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#parameters\n",
        "batch_size = 16\n",
        "num_epochs = 3\n",
        "lr = 4e-4"
      ],
      "metadata": {
        "id": "Jqtjk7qM3r1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from timeit import default_timer as timer\n",
        "#create training dataset\n",
        "train_dataset = CustomTextDataset(encodings)\n",
        "#create training dataloader\n",
        "train_ld = torch.utils.data.DataLoader(train_dataset,\n",
        "                                     batch_size=batch_size,\n",
        "                                     )\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model.to(device)\n",
        "optim = torch.optim.AdamW(model.parameters(), lr=lr)\n",
        "loop_start = timer()\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    loss_score = []\n",
        "    loop = tqdm(train_ld)\n",
        "    for batch in loop:\n",
        "        optim.zero_grad()\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        loss, outputs = model(input_ids,\n",
        "                              attention_mask=attention_mask,\n",
        "                              labels = labels\n",
        "                        )[:2]\n",
        "        loss_score.append(loss.item())\n",
        "        #loss = outputs[0]\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "\n",
        "        loop.set_description(f'Epoch {epoch}')\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "    average_loss = np.mean(loss_score)\n",
        "    print(f\"\\nEpoch: {epoch}, average Loss: {average_loss}\")\n",
        "loop_end = timer()\n",
        "time_loop = loop_end - loop_start\n",
        "print(f'\\nTime for {num_epochs} epochs (s): {(time_loop):.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5d4f349-9488-4833-80d4-f76df98efda9",
        "id": "AvaNFc8WfsZv"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5938 [00:00<?, ?it/s]/usr/local/lib/python3.8/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "Epoch 0: 100%|| 5938/5938 [04:37<00:00, 21.38it/s, loss=4.23]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 0, average Loss: 4.0387366513444665\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|| 5938/5938 [04:31<00:00, 21.88it/s, loss=3.29]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1, average Loss: 3.370025049238825\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|| 5938/5938 [04:12<00:00, 23.50it/s, loss=2.52]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2, average Loss: 3.095795498768783\n",
            "\n",
            "Time for 3 epochs (s): 801.803\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Free some memory\n",
        "import gc\n",
        "del encodings,input_ids,input_attention_mask,labels\n",
        "torch.cuda.empty_cache()\n",
        "torch.cuda.reset_accumulated_memory_stats()\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "PS4LyEvk1y88",
        "outputId": "4224b9df-5f72-419d-b753-7e415545734f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Generation"
      ],
      "metadata": {
        "id": "1ezjXyEag7rc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load test dataset."
      ],
      "metadata": {
        "id": "ZpudKS7ZhCN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = loadDataset(\"test.json\")\n",
        "test_df.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdxS-LfwuUYc",
        "outputId": "3c241dad-a623-4853-c8b4-e6fb294a7cb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "500 stories / 12 questions in the first row\n",
            "499 distinct stories\n",
            "5 distinct sources: Index(['mctest', 'race', 'cnn', 'wikipedia', 'gutenberg'], dtype='object')\n",
            "(7917, 5) question-answer pairs x columns\n",
            "First row: ['0' '0' 'What color was Cotton?' 'white'\n",
            " 'a little white kitten named Cotton']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "source    7917\n",
              "p         7917\n",
              "q         7917\n",
              "a         7917\n",
              "span      7917\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_test = list(test_df['p'])\n",
        "question_test = list(test_df['q'])\n",
        "answer_test = list(test_df['a'])"
      ],
      "metadata": {
        "id": "N4oPk8gWl7Ob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_values = tokenizer(question_test,context_test, padding=True, truncation=True, max_length = 499)\n",
        "input_ids, input_attention_mask = input_values['input_ids'], input_values['attention_mask']"
      ],
      "metadata": {
        "id": "XeQC8zqgghs6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "l = []\n",
        "model.to(device)\n",
        "model.eval()\n",
        "for input, mask in zip(input_ids,input_attention_mask):\n",
        "  input = np.expand_dims(np.array(input), axis=0)\n",
        "  mask = np.expand_dims(np.array(mask), axis=0)\n",
        "  generated = model.generate(input_ids=torch.tensor(input).to(device),\n",
        "                             #attention_mask=torch.tensor(mask).to(device), \n",
        "                                                 max_length=20,\n",
        "                                                 repetition_penalty=5.,\n",
        "                                                 min_length=1,\n",
        "                                                 no_repeat_ngram_size=3,\n",
        "                                                 early_stopping=True,\n",
        "                                                decoder_start_token_id = model.config.decoder_start_token_id,\n",
        "                                                 num_beams=2,\n",
        "                                                 )\n",
        "  generated = tokenizer.batch_decode(generated, skip_special_tokens=True)\n",
        "  l.append(generated)"
      ],
      "metadata": {
        "id": "Af_Oia8-GeN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = pd.DataFrame(l, columns = ['generated'])\n",
        "x['answers'] = answer_test\n",
        "#pd.set_option('display.max_rows', None)\n",
        "#x.head(300)"
      ],
      "metadata": {
        "id": "gWei4De6ghs6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#utility functions taken from the allennlp library for computing the F1-score\n",
        "import collections\n",
        "import re\n",
        "import string\n",
        "from typing import Callable, Sequence, TypeVar, Tuple\n",
        "\n",
        "def get_tokens(s):\n",
        "    if not s:\n",
        "        return []\n",
        "    return normalize_answer(s).split()\n",
        "\n",
        "def normalize_answer(s):\n",
        "    \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n",
        "\n",
        "    def remove_articles(text):\n",
        "        regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n",
        "        return re.sub(regex, \" \", text)\n",
        "\n",
        "    def white_space_fix(text):\n",
        "        return \" \".join(text.split())\n",
        "\n",
        "    def remove_punc(text):\n",
        "        exclude = set(string.punctuation)\n",
        "        return \"\".join(ch for ch in text if ch not in exclude)\n",
        "\n",
        "    def lower(text):\n",
        "        return text.lower()\n",
        "\n",
        "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
        "\n",
        "def compute_f1(a_pred: str, a_gold: str) -> float:\n",
        "    pred_toks = get_tokens(a_pred)\n",
        "    gold_toks = get_tokens(a_gold)\n",
        "    common = collections.Counter(pred_toks) & collections.Counter(gold_toks)  # type: ignore[var-annotated]\n",
        "    num_same = sum(common.values())\n",
        "    if len(pred_toks) == 0 or len(gold_toks) == 0:\n",
        "        # If either is no-answer, then F1 is 1 if they agree, 0 otherwise\n",
        "        return float(pred_toks == gold_toks)\n",
        "    if num_same == 0:\n",
        "        return 0.0\n",
        "    precision = 1.0 * num_same / len(pred_toks)\n",
        "    recall = 1.0 * num_same / len(gold_toks)\n",
        "    f1 = (2 * precision * recall) / (precision + recall)\n",
        "    return f1"
      ],
      "metadata": {
        "id": "svvWfoUD89sR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = []\n",
        "predictions = x['generated']\n",
        "true_answers = x['answers']\n",
        "for a_pred, a_gold in zip(predictions, true_answers):\n",
        "  score.append(compute_f1(a_pred, a_gold))\n",
        "\n",
        "average_score = np.mean(score)\n",
        "print(f'average_score: {average_score}')\n",
        "x['score'] = score\n",
        "total = len(x[x['score'] != 0])\n",
        "print(f'length: {total} / {len(x)}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "247cee84-a44c-444f-9902-3d44a5a0785d",
        "id": "-A27frM4BF37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average_score: 0.16181801619251537\n",
            "length: 1723 / 7917\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_rows', None)\n",
        "correct = x[x['score'] != 0]\n",
        "correct = correct.reset_index(drop=True)\n",
        "correct.head(500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dGdF3olw61_b",
        "outputId": "93298116-94e3-437a-ef3d-6890abd50846"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             generated  \\\n",
              "0                                           her mother   \n",
              "1                             she would go to the barn   \n",
              "2                                                  yes   \n",
              "3                                                  yes   \n",
              "4                                                  yes   \n",
              "5                                                  yes   \n",
              "6                                                  yes   \n",
              "7                                                  yes   \n",
              "8                           she was not to go with her   \n",
              "9                                                 soup   \n",
              "10                                                 yes   \n",
              "11                                                 yes   \n",
              "12                                                 yes   \n",
              "13                                  he was a car crash   \n",
              "14                                       he was a shot   \n",
              "15                                   his role in a car   \n",
              "16                                  go to his homework   \n",
              "17                                                 yes   \n",
              "18                         he would go to his homework   \n",
              "19                                        to the house   \n",
              "20                                       new york city   \n",
              "21                                            new york   \n",
              "22                                                 yes   \n",
              "23                                       new york city   \n",
              "24   the new york city was not allowed to live in b...   \n",
              "25                                                 yes   \n",
              "26                                                 yes   \n",
              "27                                      the fbi agents   \n",
              "28                                          eight feet   \n",
              "29                                                 yes   \n",
              "30                                                 yes   \n",
              "31                                 she would be a cake   \n",
              "32                                         in the lake   \n",
              "33                                                 yes   \n",
              "34                    he was not to be in the hospital   \n",
              "35                                                 yes   \n",
              "36                                                 yes   \n",
              "37                                                 yes   \n",
              "38                                                hans   \n",
              "39                                                 yes   \n",
              "40              he was not to be ready for his brother   \n",
              "41                                                 yes   \n",
              "42                                              spotty   \n",
              "43                                                 ted   \n",
              "44                                                 yes   \n",
              "45                                                 yes   \n",
              "46                                                 yes   \n",
              "47                                                 yes   \n",
              "48                                                 yes   \n",
              "49                                                 yes   \n",
              "50                                               a dog   \n",
              "51                                           the woods   \n",
              "52                                        he was sorry   \n",
              "53                                    he was not sorry   \n",
              "54                                                 yes   \n",
              "55                              he was shot in his car   \n",
              "56                                     in the hospital   \n",
              "57                                                  no   \n",
              "58                                       he was a shot   \n",
              "59                                                 yes   \n",
              "60                                        in the house   \n",
              "61                                 a sign of the house   \n",
              "62                                                 yes   \n",
              "63                                       in the garage   \n",
              "64                                                  no   \n",
              "65                                                 yes   \n",
              "66                                                 two   \n",
              "67                                                 yes   \n",
              "68                                   she couldn't care   \n",
              "69                                                 yes   \n",
              "70                                        the hospital   \n",
              "71                                       new york city   \n",
              "72                                                 yes   \n",
              "73                                                 yes   \n",
              "74                                                 yes   \n",
              "75                                                 yes   \n",
              "76                                     peter and peter   \n",
              "77                                               a dog   \n",
              "78                                               false   \n",
              "79                                               false   \n",
              "80                                             january   \n",
              "81                                                2008   \n",
              "82                                                 yes   \n",
              "83                                                 yes   \n",
              "84                                                 yes   \n",
              "85                                                 yes   \n",
              "86                                                 yes   \n",
              "87                                                 yes   \n",
              "88                                                 yes   \n",
              "89                                                 yes   \n",
              "90                                                 yes   \n",
              "91                                                 yes   \n",
              "92                                                 yes   \n",
              "93                                                 mom   \n",
              "94                                                 yes   \n",
              "95                                                 yes   \n",
              "96                                                 yes   \n",
              "97                                                 yes   \n",
              "98                                              philip   \n",
              "99                                                 yes   \n",
              "100                           he would go to the party   \n",
              "101                                        a few miles   \n",
              "102                                                yes   \n",
              "103                                                yes   \n",
              "104                                                yes   \n",
              "105                                                yes   \n",
              "106                                                yes   \n",
              "107                                  to take the party   \n",
              "108                                                yes   \n",
              "109                                                yes   \n",
              "110                            in the north west wales   \n",
              "111                                                yes   \n",
              "112                                                yes   \n",
              "113                                the city of england   \n",
              "114                                                yes   \n",
              "115                           a princess of his mother   \n",
              "116                                                yes   \n",
              "117                                          his heart   \n",
              "118                                                yes   \n",
              "119                                                yes   \n",
              "120                                                yes   \n",
              "121                                   he was not sorry   \n",
              "122                             he was not to be a car   \n",
              "123                                                yes   \n",
              "124   because of the cats were not allowed to buy them   \n",
              "125   because of the cats were not allowed to buy them   \n",
              "126                                      black and red   \n",
              "127                      he was not to go in the house   \n",
              "128                                                yes   \n",
              "129                                                yes   \n",
              "130                           he was not to be a crash   \n",
              "131                                               five   \n",
              "132                                                yes   \n",
              "133               he was not to be ready for the house   \n",
              "134                       he was not to be a new house   \n",
              "135                                                yes   \n",
              "136                                                yes   \n",
              "137                    he would have to be a new house   \n",
              "138                       he was not to be a new house   \n",
              "139                                         basketball   \n",
              "140                        he would go to his homework   \n",
              "141                                      adam and paul   \n",
              "142                                                yes   \n",
              "143                                                yes   \n",
              "144                                                yes   \n",
              "145                                    after the train   \n",
              "146                                                yes   \n",
              "147                                  in the late 1960s   \n",
              "148                                pope benedict xviii   \n",
              "149                              pope john xxiiiiiiiii   \n",
              "150                         he would go to the village   \n",
              "151                                                yes   \n",
              "152                                                yes   \n",
              "153                                  go to the village   \n",
              "154                                                two   \n",
              "155                                he would be a horse   \n",
              "156                                                yes   \n",
              "157                                            a horse   \n",
              "158                                                yes   \n",
              "159                                                yes   \n",
              "160                                           the city   \n",
              "161                                                yes   \n",
              "162                           in the late 19th century   \n",
              "163                                                yes   \n",
              "164                           in the late 19th century   \n",
              "165              the city was not divided by the state   \n",
              "166                                the city of germany   \n",
              "167           he was not to be ready to take the sword   \n",
              "168                                                yes   \n",
              "169                                           the boat   \n",
              "170                                          bob smith   \n",
              "171                                               1966   \n",
              "172                                                yes   \n",
              "173                                               1966   \n",
              "174                                   the farm company   \n",
              "175                                                yes   \n",
              "176                                              harry   \n",
              "177                                                yes   \n",
              "178                                             a week   \n",
              "179                                              harry   \n",
              "180                                                yes   \n",
              "181                                                yes   \n",
              "182                                              harry   \n",
              "183                                    in the hospital   \n",
              "184                                                two   \n",
              "185                                         six months   \n",
              "186                                                yes   \n",
              "187                                         six months   \n",
              "188                                                yes   \n",
              "189                                                yes   \n",
              "190                                                yes   \n",
              "191                            he would go to the wind   \n",
              "192                                                yes   \n",
              "193                                         chapter xv   \n",
              "194                  he would be ready to get the wind   \n",
              "195                 he would be ready to get his hands   \n",
              "196                                                yes   \n",
              "197                                                yes   \n",
              "198                                       january 2009   \n",
              "199                                                yes   \n",
              "200                                                yes   \n",
              "201                                                yes   \n",
              "202                                       de montfort,   \n",
              "203                                                yes   \n",
              "204                the spanish grand duchy of portugal   \n",
              "205                                       in the house   \n",
              "206                                                yes   \n",
              "207                               about two miles away   \n",
              "208                                to be a great house   \n",
              "209                                                yes   \n",
              "210                                               four   \n",
              "211                                                yes   \n",
              "212                 he would have to go with his house   \n",
              "213                                                yes   \n",
              "214                                                yes   \n",
              "215                                                yes   \n",
              "216                       he would go to his homework.   \n",
              "217                                                yes   \n",
              "218                                                yes   \n",
              "219                                                yes   \n",
              "220                                         basketball   \n",
              "221                                                yes   \n",
              "222                                                yes   \n",
              "223                                                yes   \n",
              "224                                                yes   \n",
              "225                  he was not to go for the hospital   \n",
              "226                           he was shot in his heart   \n",
              "227                                                yes   \n",
              "228                                                yes   \n",
              "229                                    michael jackson   \n",
              "230                                                yes   \n",
              "231                                                cnn   \n",
              "232                                         a hospital   \n",
              "233                                                yes   \n",
              "234                                                yes   \n",
              "235                                                yes   \n",
              "236                                                yes   \n",
              "237                          to improve the windows xp   \n",
              "238                                                yes   \n",
              "239                                      he was a shot   \n",
              "240                                                yes   \n",
              "241                             he was a heart surgery   \n",
              "242                             he was a heart surgery   \n",
              "243                                                yes   \n",
              "244                                                yes   \n",
              "245               scientific and scientific literature   \n",
              "246  scientific and scientific books were not impor...   \n",
              "247                                              billy   \n",
              "248                                his sheep and sheep   \n",
              "249                                                yes   \n",
              "250                                                yes   \n",
              "251                                        9 : 30 p. m   \n",
              "252                                in the 17th century   \n",
              "253                                                yes   \n",
              "254                                the duke of england   \n",
              "255                                        in the park   \n",
              "256                                   joseph and billy   \n",
              "257                                                 no   \n",
              "258                                         his father   \n",
              "259                                 the city of europe   \n",
              "260                                     in the country   \n",
              "261                                  greece and greece   \n",
              "262                                  greece and greece   \n",
              "263                                                yes   \n",
              "264                                                yes   \n",
              "265                                                yes   \n",
              "266                                       miss collega   \n",
              "267                                                yes   \n",
              "268                                                yes   \n",
              "269                                                yes   \n",
              "270    he was not to be an agreement with the official   \n",
              "271                                      in the garage   \n",
              "272                           he would go to the house   \n",
              "273                      he was not to go in his house   \n",
              "274                                                yes   \n",
              "275                                                yes   \n",
              "276                                                yes   \n",
              "277                                                yes   \n",
              "278                                                yes   \n",
              "279                                the origin of birds   \n",
              "280                                                yes   \n",
              "281                      he was not to go in the house   \n",
              "282                                           the park   \n",
              "283                                                yes   \n",
              "284                                           the park   \n",
              "285                                                yes   \n",
              "286                                                yes   \n",
              "287                                                yes   \n",
              "288                         to speak with the language   \n",
              "289                                                yes   \n",
              "290                                                yes   \n",
              "291                                                yes   \n",
              "292                       he was not to be ready to go   \n",
              "293                                                yes   \n",
              "294                                                yes   \n",
              "295                                                yes   \n",
              "296                                                yes   \n",
              "297                he was not to be caught in the wind   \n",
              "298                                      new york city   \n",
              "299                                                 no   \n",
              "300                              new york and new york   \n",
              "301                           in the late 19th century   \n",
              "302                                                yes   \n",
              "303                                  he would be a car   \n",
              "304                                                yes   \n",
              "305                                                yes   \n",
              "306                                                yes   \n",
              "307                      he was not to go with his car   \n",
              "308                                               joey   \n",
              "309                                                yes   \n",
              "310                         his leg fell down the yard   \n",
              "311                                       he was sorry   \n",
              "312                        he would go to his homework   \n",
              "313                       he would go to his homework.   \n",
              "314                                       ken finnelli   \n",
              "315                                         republican   \n",
              "316                              the police department   \n",
              "317                                                yes   \n",
              "318                                               paul   \n",
              "319                                               paul   \n",
              "320                                          the store   \n",
              "321                            he was not to be a shot   \n",
              "322                                                yes   \n",
              "323                                      he was a shot   \n",
              "324                              he was not to be shot   \n",
              "325                                                yes   \n",
              "326                                                yes   \n",
              "327                                       he was shot.   \n",
              "328                             he was not to be shot.   \n",
              "329                                                yes   \n",
              "330                                         tom hooper   \n",
              "331                                                yes   \n",
              "332                                                yes   \n",
              "333                        he was not to buy the book.   \n",
              "334                                                yes   \n",
              "335                                                yes   \n",
              "336                       he was not to be ready to go   \n",
              "337                                                yes   \n",
              "338                                      cricket match   \n",
              "339                                         late 1970s   \n",
              "340                         the match of cricket balls   \n",
              "341                                      cricket match   \n",
              "342                                              billy   \n",
              "343                      he was not to be a little man   \n",
              "344                           he would go to the party   \n",
              "345                                    peter and peter   \n",
              "346                                       to the house   \n",
              "347                           he would go to the party   \n",
              "348                                    peter and peter   \n",
              "349                                       to the house   \n",
              "350                                    peter and peter   \n",
              "351                                              black   \n",
              "352                                    the israeli war   \n",
              "353                                              false   \n",
              "354                                                yes   \n",
              "355                                    the israeli war   \n",
              "356                                    the israeli war   \n",
              "357                                                yes   \n",
              "358                          the israeli war in israel   \n",
              "359                                                yes   \n",
              "360                                  in the late 1960s   \n",
              "361                                                two   \n",
              "362                                                 15   \n",
              "363                                       he was a car   \n",
              "364                                 he was not to run.   \n",
              "365                                  the gospel of god   \n",
              "366                                                yes   \n",
              "367                                               1933   \n",
              "368                                                yes   \n",
              "369                                 to be a little boy   \n",
              "370                                  the football club   \n",
              "371                                                two   \n",
              "372                                               four   \n",
              "373                                                yes   \n",
              "374                                 the premier league   \n",
              "375                                                yes   \n",
              "376                           in the late 19th century   \n",
              "377                           in the late 19th century   \n",
              "378                                                yes   \n",
              "379                                                two   \n",
              "380                                                two   \n",
              "381                                                yes   \n",
              "382                     the weimar republic of germany   \n",
              "383                                        in the city   \n",
              "384                                                two   \n",
              "385                           the city of buenos aires   \n",
              "386                                    catholic church   \n",
              "387  the catholic reformation and protestant reform...   \n",
              "388                                 the city of europe   \n",
              "389                                                yes   \n",
              "390                                                yes   \n",
              "391                               to improve the speed   \n",
              "392                                                yes   \n",
              "393                               to improve the speed   \n",
              "394                                                yes   \n",
              "395                                            jupiter   \n",
              "396                                           hydrogen   \n",
              "397                                                two   \n",
              "398                                                yes   \n",
              "399                                  late 19th century   \n",
              "400                                                yes   \n",
              "401                                                yes   \n",
              "402                                   $ 1, 200 million   \n",
              "403                                                yes   \n",
              "404                                  peter and michael   \n",
              "405                                     james and john   \n",
              "406                                   to get the book.   \n",
              "407                                   to get the book.   \n",
              "408                       to buy the new york business   \n",
              "409                                                yes   \n",
              "410                                                yes   \n",
              "411                                   go to the school   \n",
              "412                                when he was a week.   \n",
              "413                       he would go to take the time   \n",
              "414                                to get his homework   \n",
              "415                                           new york   \n",
              "416                                                yes   \n",
              "417            he would have to get the worst of them.   \n",
              "418                                                yes   \n",
              "419                                                yes   \n",
              "420                                                yes   \n",
              "421                                                yes   \n",
              "422                                                yes   \n",
              "423                                                yes   \n",
              "424                                           the park   \n",
              "425                                           saturday   \n",
              "426                            he would go to the park   \n",
              "427                                               male   \n",
              "428                                    in the hospital   \n",
              "429                               he would be a horse.   \n",
              "430                                                yes   \n",
              "431                                                yes   \n",
              "432                                                yes   \n",
              "433                                                yes   \n",
              "434                                                yes   \n",
              "435                                        his manager   \n",
              "436          he was not to be ready to go to the house   \n",
              "437                                      dick and jack   \n",
              "438                                                yes   \n",
              "439                                 in the afghanistan   \n",
              "440                                                yes   \n",
              "441                                                yes   \n",
              "442                                                yes   \n",
              "443                                                yes   \n",
              "444                                                yes   \n",
              "445                                                yes   \n",
              "446                                                yes   \n",
              "447                                                yes   \n",
              "448                                                yes   \n",
              "449                                                yes   \n",
              "450                                                yes   \n",
              "451                                                yes   \n",
              "452                                                yes   \n",
              "453                             he would go to the car   \n",
              "454                                  in the late 1970s   \n",
              "455                                                 16   \n",
              "456                             he was shot in his car   \n",
              "457                                    new york county   \n",
              "458                                      he was a shot   \n",
              "459                                                yes   \n",
              "460                                             a cake   \n",
              "461                                      joseph stalin   \n",
              "462                                              false   \n",
              "463                                            ukraine   \n",
              "464                                                yes   \n",
              "465                                       soviet union   \n",
              "466                                              false   \n",
              "467                                   democratic party   \n",
              "468                                                yes   \n",
              "469                                       in the woods   \n",
              "470                                                yes   \n",
              "471                                                yes   \n",
              "472                                                yes   \n",
              "473                                                yes   \n",
              "474                                                yes   \n",
              "475                                                yes   \n",
              "476                                                yes   \n",
              "477                                                yes   \n",
              "478                                                yes   \n",
              "479                                                yes   \n",
              "480                         it was the largest in asia   \n",
              "481                                                yes   \n",
              "482                                                yes   \n",
              "483                              the duke of st. clare   \n",
              "484                a princess of wales, and the french   \n",
              "485                                the top of his coat   \n",
              "486                he was not to be ready for the door   \n",
              "487                                      new york city   \n",
              "488                                         john locke   \n",
              "489               the north carolina and new hampshire   \n",
              "490                                      new york city   \n",
              "491                                           new york   \n",
              "492                                                yes   \n",
              "493                                                yes   \n",
              "494                                   to get the money   \n",
              "495                                                yes   \n",
              "496                                                two   \n",
              "497                          micronesia, and polynesia   \n",
              "498                                                yes   \n",
              "499                                            in 2008   \n",
              "\n",
              "                                               answers     score  \n",
              "0                         with her mommy and 5 sisters  0.250000  \n",
              "1                                  she painted herself  0.250000  \n",
              "2                                                  Yes  1.000000  \n",
              "3                                                  Yes  1.000000  \n",
              "4                                                  yes  1.000000  \n",
              "5                                                  Yes  1.000000  \n",
              "6                                                  Yes  1.000000  \n",
              "7                                                  Yes  1.000000  \n",
              "8    I am having heart surgery soon, so her mother ...  0.090909  \n",
              "9    hot soup and a container with rice, vegetables...  0.105263  \n",
              "10                                                 Yes  1.000000  \n",
              "11                                                Yes.  1.000000  \n",
              "12                                                 Yes  1.000000  \n",
              "13                           Farina was cast in a film  0.222222  \n",
              "14                           He joined a TV show cast.  0.250000  \n",
              "15                                    An expensive car  0.333333  \n",
              "16                               go to Quentin's house  0.500000  \n",
              "17                                                 yes  1.000000  \n",
              "18                            everything would be okay  0.200000  \n",
              "19                                      to the dentist  0.500000  \n",
              "20                                       New York City  1.000000  \n",
              "21                                            New York  1.000000  \n",
              "22                                                 Yes  1.000000  \n",
              "23                        In the southwest of the city  0.285714  \n",
              "24   because the inhabitants feel neglected by the ...  0.117647  \n",
              "25                                                 Yes  1.000000  \n",
              "26                                                 Yes  1.000000  \n",
              "27                                                 FBI  0.666667  \n",
              "28                                 may be 30 feet tall  0.285714  \n",
              "29                                                 yes  1.000000  \n",
              "30                                                 Yes  1.000000  \n",
              "31                         She already has two blouses  0.222222  \n",
              "32                          by a big lake by the woods  0.285714  \n",
              "33                                                 yes  1.000000  \n",
              "34                       The hospital had been bombed.  0.181818  \n",
              "35                                                 Yes  1.000000  \n",
              "36                               Yes, for twenty years  0.400000  \n",
              "37                                                 Yes  1.000000  \n",
              "38                                        Hans Bussman  0.666667  \n",
              "39                                    Yes, Franz does.  0.500000  \n",
              "40                           He assumed Hans was dead.  0.285714  \n",
              "41                                                 Yes  1.000000  \n",
              "42                                  Brownie and Spotty  0.500000  \n",
              "43                                                Ted,  1.000000  \n",
              "44                                                 yes  1.000000  \n",
              "45                                                 Yes  1.000000  \n",
              "46                                                 yes  1.000000  \n",
              "47                                                 Yes  1.000000  \n",
              "48                                                 yes  1.000000  \n",
              "49      yes, They went looking for him with no success  0.200000  \n",
              "50                                   A girl and a dog.  0.500000  \n",
              "51                                           the woods  1.000000  \n",
              "52                                   He was interested  0.666667  \n",
              "53                                       not surprised  0.333333  \n",
              "54                                                 yes  1.000000  \n",
              "55             10-year-old boy fatally shot his father  0.333333  \n",
              "56                          in the front seat of a SUV  0.285714  \n",
              "57                                                  no  1.000000  \n",
              "58   He exited the back of the vehicle and continue...  0.142857  \n",
              "59                                                 Yes  1.000000  \n",
              "60                                        in the Duomo  0.500000  \n",
              "61                             a sign from Baldassarre  0.333333  \n",
              "62                                                 yes  1.000000  \n",
              "63                                          in Seattle  0.500000  \n",
              "64                                                  no  1.000000  \n",
              "65                                                 yes  1.000000  \n",
              "66                                                 Two  1.000000  \n",
              "67                                                 yes  1.000000  \n",
              "68                                        she liked it  0.333333  \n",
              "69                                                Yes.  1.000000  \n",
              "70                                    A local hospital  0.666667  \n",
              "71                                      New York City.  1.000000  \n",
              "72                                                Yes.  1.000000  \n",
              "73                                                Yes.  1.000000  \n",
              "74                                                Yes.  1.000000  \n",
              "75                                                Yes.  1.000000  \n",
              "76                                               Peter  0.500000  \n",
              "77                                        an alien dog  0.666667  \n",
              "78                                               false  1.000000  \n",
              "79                                               False  1.000000  \n",
              "80                                             January  1.000000  \n",
              "81                                               2008.  1.000000  \n",
              "82                                                 yes  1.000000  \n",
              "83                                                 yes  1.000000  \n",
              "84                                                 yes  1.000000  \n",
              "85                                                 Yes  1.000000  \n",
              "86                                                 Yes  1.000000  \n",
              "87                                                 yes  1.000000  \n",
              "88                                                 yes  1.000000  \n",
              "89                                                 yes  1.000000  \n",
              "90                                                 yes  1.000000  \n",
              "91                                                 yes  1.000000  \n",
              "92                                                 yes  1.000000  \n",
              "93                                             Her mom  0.666667  \n",
              "94                                                 yes  1.000000  \n",
              "95                                                 Yes  1.000000  \n",
              "96                                                Yes.  1.000000  \n",
              "97                                                Yes.  1.000000  \n",
              "98                                              Philip  1.000000  \n",
              "99                                                 yes  1.000000  \n",
              "100                          to look after the horses,  0.222222  \n",
              "101                                  twelve miles away  0.400000  \n",
              "102                                                yes  1.000000  \n",
              "103                                                yes  1.000000  \n",
              "104                                                yes  1.000000  \n",
              "105                                               .yes  1.000000  \n",
              "106                                                yes  1.000000  \n",
              "107                     for carrying  the news to them  0.250000  \n",
              "108                                                yes  1.000000  \n",
              "109                                                yes  1.000000  \n",
              "110                                 South West England  0.285714  \n",
              "111                                                yes  1.000000  \n",
              "112                                                yes  1.000000  \n",
              "113  large areas of the country came into the posse...  0.133333  \n",
              "114                                               Yes.  1.000000  \n",
              "115       the constant thought of the grief and horror  0.200000  \n",
              "116                                               .yes  1.000000  \n",
              "117               and some other ads in his text books  0.200000  \n",
              "118                                                yes  1.000000  \n",
              "119                                                yes  1.000000  \n",
              "120                                                yes  1.000000  \n",
              "121         he was so full of wrath he could not speak  0.428571  \n",
              "122  he was flat on his back with half a dozen fata...  0.235294  \n",
              "123                                                yes  1.000000  \n",
              "124                              because he loves them  0.307692  \n",
              "125           because those foods aren't good for cats  0.250000  \n",
              "126                  orange, black, spotted, and white  0.500000  \n",
              "127       To see whether he is coming for Thanksgiving  0.266667  \n",
              "128                                                Yes  1.000000  \n",
              "129                                                Yes  1.000000  \n",
              "130                          injured in a traing crash  0.200000  \n",
              "131                              five dollars per week  0.400000  \n",
              "132                                                yes  1.000000  \n",
              "133                        That it was wonderful news.  0.153846  \n",
              "134          that they were to start a regular theatre  0.142857  \n",
              "135                                                yes  1.000000  \n",
              "136                                                yes  1.000000  \n",
              "137                      he had already engaged a hall  0.166667  \n",
              "138  it would be converted into a first-class place...  0.125000  \n",
              "139                                         basketball  1.000000  \n",
              "140               all get to play on a basketball team  0.153846  \n",
              "141                                  Josh, Ty, and Max  0.285714  \n",
              "142                                               Yes.  1.000000  \n",
              "143                                               Yes.  1.000000  \n",
              "144                                                Yes  1.000000  \n",
              "145                          soon after eleven o'clock  0.333333  \n",
              "146                                                Yes  1.000000  \n",
              "147                                            in 2013  0.400000  \n",
              "148                                               Pope  0.500000  \n",
              "149                                  Pope John Paul II  0.571429  \n",
              "150                           he was in his right mind  0.181818  \n",
              "151                                                yes  1.000000  \n",
              "152                                                yes  1.000000  \n",
              "153                               ride to Carpen Falls  0.285714  \n",
              "154                                                two  1.000000  \n",
              "155                              he knew Captain Grady  0.250000  \n",
              "156                                                yes  1.000000  \n",
              "157    tell the men that he is a downright horse thief  0.222222  \n",
              "158                                                yes  1.000000  \n",
              "159                                                yes  1.000000  \n",
              "160            Bonn is a city. Do you mean in Germany?  0.222222  \n",
              "161                                                yes  1.000000  \n",
              "162                                 in the 1st century  0.571429  \n",
              "163                                                Yes  1.000000  \n",
              "164                                            in 1770  0.333333  \n",
              "165                        the Basic Law, was declared  0.200000  \n",
              "166  primary seat of six federal government ministries  0.200000  \n",
              "167                            He was their only hope.  0.285714  \n",
              "168                                                yes  1.000000  \n",
              "169                                    the second boat  0.666667  \n",
              "170                                      Bob Goldstein  0.500000  \n",
              "171                                          July 1966  0.666667  \n",
              "172                                                yes  1.000000  \n",
              "173                                   August 10, 1966,  0.500000  \n",
              "174                          the Crooked Creek Company  0.400000  \n",
              "175                                               Yes.  1.000000  \n",
              "176                                              Harry  1.000000  \n",
              "177                                               Yes.  1.000000  \n",
              "178                                       About a week  0.666667  \n",
              "179                                              harry  1.000000  \n",
              "180                                               Yes.  1.000000  \n",
              "181                                               Yes.  1.000000  \n",
              "182                                              Harry  1.000000  \n",
              "183                    at the Royal Liverpool hospital  0.333333  \n",
              "184                                                Two  1.000000  \n",
              "185                                          six hours  0.500000  \n",
              "186                                                yes  1.000000  \n",
              "187                               less than six months  0.666667  \n",
              "188                                                yes  1.000000  \n",
              "189                                                Yes  1.000000  \n",
              "190                                                Yes  1.000000  \n",
              "191                           He wanted to be a seaman  0.400000  \n",
              "192                                                Yes  1.000000  \n",
              "193                                         Chapter 6.  0.500000  \n",
              "194  the boys head would have sustained a severe i...  0.142857  \n",
              "195                                          He dodged  0.200000  \n",
              "196                                                yes  1.000000  \n",
              "197                                                yes  1.000000  \n",
              "198                                       January 2004  0.500000  \n",
              "199                                                Yes  1.000000  \n",
              "200                                                Yes  1.000000  \n",
              "201                                                yes  1.000000  \n",
              "202                                 Gonzalo de Cordoba  0.400000  \n",
              "203                                                yes  1.000000  \n",
              "204                                Prince of Squillace  0.250000  \n",
              "205                                      at Park House  0.400000  \n",
              "206                                                yes  1.000000  \n",
              "207                                  about a mile away  0.571429  \n",
              "208                                to swim in the pool  0.250000  \n",
              "209                                                yes  1.000000  \n",
              "210                                               four  1.000000  \n",
              "211                                                yes  1.000000  \n",
              "212                                        His honesty  0.200000  \n",
              "213                                                Yes  1.000000  \n",
              "214                                                Yes  1.000000  \n",
              "215                                                Yes  1.000000  \n",
              "216                He wanted to help the poor students  0.333333  \n",
              "217                                                yes  1.000000  \n",
              "218                                                yes  1.000000  \n",
              "219                                                yes  1.000000  \n",
              "220                                         basketball  1.000000  \n",
              "221                                                yes  1.000000  \n",
              "222                                                yes  1.000000  \n",
              "223                                                Yes  1.000000  \n",
              "224                                                Yes  1.000000  \n",
              "225                                      He was burned  0.400000  \n",
              "226                               over 65% of his body  0.181818  \n",
              "227                                                Yes  1.000000  \n",
              "228                                                Yes  1.000000  \n",
              "229  Valerie Brewer and her husband Michael Brewer,...  0.200000  \n",
              "230                                                Yes  1.000000  \n",
              "231                                                CNN  1.000000  \n",
              "232  University of Miami's Jackson Memorial Hospita...  0.222222  \n",
              "233                                                Yes  1.000000  \n",
              "234                                                Yes  1.000000  \n",
              "235                                                Yes  1.000000  \n",
              "236                                                Yes  1.000000  \n",
              "237          to improve its user experience on tablets  0.363636  \n",
              "238                                                yes  1.000000  \n",
              "239                                               shot  0.500000  \n",
              "240                                                yes  1.000000  \n",
              "241                     it was their 13th anniversary.  0.222222  \n",
              "242  celebrate never having a day without him in he...  0.153846  \n",
              "243                                                yes  1.000000  \n",
              "244                                                yes  1.000000  \n",
              "245  the study of humans and their societies in the...  0.142857  \n",
              "246      social anthropology and cultural anthropology  0.166667  \n",
              "247                                              Billy  1.000000  \n",
              "248                            his brother's birthday.  0.285714  \n",
              "249                                                yes  1.000000  \n",
              "250                                                yes  1.000000  \n",
              "251                                              9 p.m  0.333333  \n",
              "252                                in attacking France  0.333333  \n",
              "253                                                yes  1.000000  \n",
              "254                                 union with England  0.333333  \n",
              "255                                  in the maple tree  0.400000  \n",
              "256                         Her grandmother and mother  0.285714  \n",
              "257                                                 no  1.000000  \n",
              "258                          his father's best friend.  0.333333  \n",
              "259                           the Republic of Slovenia  0.333333  \n",
              "260                         in southern Central Europe  0.333333  \n",
              "261             as part of Eastern and Southern Europe  0.200000  \n",
              "262                         to the south and southeast  0.285714  \n",
              "263                                                yes  1.000000  \n",
              "264                                                yes  1.000000  \n",
              "265                                                yes  1.000000  \n",
              "266                                         Miss Mohun  0.500000  \n",
              "267                                                yes  1.000000  \n",
              "268                                                yes  1.000000  \n",
              "269                                                Yes  1.000000  \n",
              "270                                 to hear he is free  0.307692  \n",
              "271              in a train car at the railroad tracks  0.250000  \n",
              "272                                   to keep him safe  0.222222  \n",
              "273             the people in the town didn't like him  0.142857  \n",
              "274                                                yes  1.000000  \n",
              "275                                                yes  1.000000  \n",
              "276                                                yes  1.000000  \n",
              "277                                                Yes  1.000000  \n",
              "278                                               Yes.  1.000000  \n",
              "279  The ecological state of a species being unique...  0.153846  \n",
              "280                                                yes  1.000000  \n",
              "281                                     he passed away  0.200000  \n",
              "282                                           the park  1.000000  \n",
              "283                                                yes  1.000000  \n",
              "284                                           the park  1.000000  \n",
              "285                                                yes  1.000000  \n",
              "286                                                yes  1.000000  \n",
              "287                                                yes  1.000000  \n",
              "288                                 A new language use  0.285714  \n",
              "289                                                yes  1.000000  \n",
              "290                                                yes  1.000000  \n",
              "291                                                yes  1.000000  \n",
              "292                         he was so heavy and drowsy  0.285714  \n",
              "293                                                yes  1.000000  \n",
              "294                                                yes  1.000000  \n",
              "295                                                yes  1.000000  \n",
              "296  Yes, Hannah dog paddled to Syb's board and he ...  0.105263  \n",
              "297      \"I was in his territory, she wasn't in mine,\"  0.235294  \n",
              "298                          the New Netherland colony  0.333333  \n",
              "299                                                 No  1.000000  \n",
              "300  Ireland, Germany Italy, Puerto Rico, Jamaica a...  0.142857  \n",
              "301                     In the 19th and 20th centuries  0.444444  \n",
              "302                                                yes  1.000000  \n",
              "303                                       he threw him  0.285714  \n",
              "304                                                yes  1.000000  \n",
              "305                                                yes  1.000000  \n",
              "306                                                yes  1.000000  \n",
              "307                  see his dying 2-year-old grandson  0.153846  \n",
              "308                                               Joey  1.000000  \n",
              "309                                                Yes  1.000000  \n",
              "310                   His friend said his breath stunk  0.181818  \n",
              "311                                       He was angry  0.666667  \n",
              "312                               He brushed his teeth  0.400000  \n",
              "313                              His mom forced him to  0.363636  \n",
              "314                                     Ken Cuccinelli  0.500000  \n",
              "315                                         Republican  1.000000  \n",
              "316           Las Vegas Metropolitan Police Department  0.571429  \n",
              "317                                                yes  1.000000  \n",
              "318                                               Paul  1.000000  \n",
              "319                      Paul and Arthur were brothers  0.333333  \n",
              "320                                      the pet store  0.666667  \n",
              "321           he shouldn't have gotten out of that car  0.142857  \n",
              "322                                                yes  1.000000  \n",
              "323         Zimmerman's \"heart was in the right place\"  0.222222  \n",
              "324             wanting to catch these people so badly  0.153846  \n",
              "325                                                yes  1.000000  \n",
              "326                                                yes  1.000000  \n",
              "327                                     he shot Martin  0.666667  \n",
              "328                             he feared for his life  0.181818  \n",
              "329                                                yes  1.000000  \n",
              "330                                         Tom Seaton  0.500000  \n",
              "331                                                yes  1.000000  \n",
              "332                                                yes  1.000000  \n",
              "333                   to make the atmosphere sociable.  0.200000  \n",
              "334                                                Yes  1.000000  \n",
              "335                                                yes  1.000000  \n",
              "336                his life was threatened by gangrene  0.142857  \n",
              "337                                                yes  1.000000  \n",
              "338                                  Cricket World Cup  0.400000  \n",
              "339                             late twentieth-century  0.500000  \n",
              "340             rival World Series Cricket competition  0.222222  \n",
              "341  many of the features of One Day International ...  0.200000  \n",
              "342                                              Billy  1.000000  \n",
              "343                          the situation was exposed  0.200000  \n",
              "344  He was at a new school, and the other students...  0.133333  \n",
              "345                                              Peter  0.500000  \n",
              "346                              to a different school  0.400000  \n",
              "347                          He asked another student,  0.222222  \n",
              "348                                              Peter  0.500000  \n",
              "349                                      Peter's house  0.500000  \n",
              "350                                              Peter  0.500000  \n",
              "351                                              black  1.000000  \n",
              "352         Egypt had blocked them to Israeli shipping  0.222222  \n",
              "353                                              false  1.000000  \n",
              "354                                                yes  1.000000  \n",
              "355                                       the June War  0.500000  \n",
              "356   1967 ArabIsraeli War, or Third ArabIsraeli War  0.222222  \n",
              "357                                                yes  1.000000  \n",
              "358  Israel launched what it claimed were a series ...  0.117647  \n",
              "359                                                yes  1.000000  \n",
              "360                                        in late May  0.666667  \n",
              "361                                                Two  1.000000  \n",
              "362                                                 15  1.000000  \n",
              "363              he heard them but didn't say anything  0.200000  \n",
              "364                                  he is not so tall  0.400000  \n",
              "365                        established orders of monks  0.285714  \n",
              "366                                                Yes  1.000000  \n",
              "367                              between 1919 and 1933  0.400000  \n",
              "368                                                Yes  1.000000  \n",
              "369                                   to be forbearing  0.571429  \n",
              "370                              Arena Football League  0.400000  \n",
              "371                                                two  1.000000  \n",
              "372                                               four  1.000000  \n",
              "373                                                yes  1.000000  \n",
              "374     reasons not associated with League operations.  0.250000  \n",
              "375                                                yes  1.000000  \n",
              "376                                            In 1871  0.333333  \n",
              "377                                            In 1933  0.333333  \n",
              "378                                                Yes  1.000000  \n",
              "379                                               Two.  1.000000  \n",
              "380                                                Two  1.000000  \n",
              "381                                                Yes  1.000000  \n",
              "382                       Federal Republic of Germany,  0.750000  \n",
              "383                                          in Madrid  0.500000  \n",
              "384                                                Two  1.000000  \n",
              "385  the adoption of the system of autonomous commu...  0.200000  \n",
              "386                  The Protestant Evangelical Church  0.400000  \n",
              "387                     Catholic migration from Poland  0.222222  \n",
              "388                   Southern Europe and West Germany  0.250000  \n",
              "389                                                Yes  1.000000  \n",
              "390                                                yes  1.000000  \n",
              "391                bring the fighter to a safe landing  0.250000  \n",
              "392                                                yes  1.000000  \n",
              "393                           in a text message to him  0.250000  \n",
              "394                                                Yes  1.000000  \n",
              "395                                            Jupiter  1.000000  \n",
              "396                                           hydrogen  1.000000  \n",
              "397                                                two  1.000000  \n",
              "398                                                yes  1.000000  \n",
              "399                                   the 17th century  0.400000  \n",
              "400                                                yes  1.000000  \n",
              "401                                                Yes  1.000000  \n",
              "402                                       $567 million  0.400000  \n",
              "403                                                Yes  1.000000  \n",
              "404                                            Michael  0.500000  \n",
              "405                                              James  0.500000  \n",
              "406                                  They like to read  0.285714  \n",
              "407                    he has to read a book for class  0.400000  \n",
              "408                          buy a fast car and travel  0.200000  \n",
              "409                                                yes  1.000000  \n",
              "410                                                yes  1.000000  \n",
              "411                        to find work for the father  0.250000  \n",
              "412  When the boy gave an exhibition of what he lea...  0.333333  \n",
              "413  That he is hard on people under him for instru...  0.125000  \n",
              "414        That his friends were so deeply interested.  0.181818  \n",
              "415                                           New York  1.000000  \n",
              "416                                                yes  1.000000  \n",
              "417                         it will show signs of rust  0.142857  \n",
              "418                                                yes  1.000000  \n",
              "419                                                yes  1.000000  \n",
              "420                                                yes  1.000000  \n",
              "421                                                yes  1.000000  \n",
              "422                                                yes  1.000000  \n",
              "423                                                yes  1.000000  \n",
              "424                                           the park  1.000000  \n",
              "425                                           Saturday  1.000000  \n",
              "426       fun to play with and didn't do dumb things l  0.133333  \n",
              "427                                               male  1.000000  \n",
              "428                                        in Scotland  0.500000  \n",
              "429                     his own life would be hazarded  0.400000  \n",
              "430                                                Yes  1.000000  \n",
              "431                                                Yes  1.000000  \n",
              "432                                                yes  1.000000  \n",
              "433                                                yes  1.000000  \n",
              "434                                                yes  1.000000  \n",
              "435                                      sheep manager  0.500000  \n",
              "436  he felt that the purchase of such expensive cr...  0.240000  \n",
              "437                                               Dick  0.500000  \n",
              "438                                                Yes  1.000000  \n",
              "439                                 in a British court  0.400000  \n",
              "440                                                yes  1.000000  \n",
              "441                                                yes  1.000000  \n",
              "442                                                yes  1.000000  \n",
              "443                                                yes  1.000000  \n",
              "444                                                yes  1.000000  \n",
              "445                                                yes  1.000000  \n",
              "446                                                yes  1.000000  \n",
              "447                                                yes  1.000000  \n",
              "448                                                yes  1.000000  \n",
              "449                                                yes  1.000000  \n",
              "450                                                yes  1.000000  \n",
              "451                                                yes  1.000000  \n",
              "452                                                yes  1.000000  \n",
              "453                          to get an accident report  0.222222  \n",
              "454                                       in the 1980s  0.400000  \n",
              "455                                                 16  1.000000  \n",
              "456                  He ignored his route suggestions.  0.363636  \n",
              "457                                  Lackawanna County  0.400000  \n",
              "458     He said \"my homies died, everybody gotta die.\"  0.181818  \n",
              "459                                               Yes.  1.000000  \n",
              "460                                   A piece of cake.  0.500000  \n",
              "461                                      Joseph Stalin  1.000000  \n",
              "462                                              false  1.000000  \n",
              "463                                    Soviet Ukraine,  0.666667  \n",
              "464                                                yes  1.000000  \n",
              "465                Union of Soviet Socialist Republics  0.571429  \n",
              "466                                              false  1.000000  \n",
              "467                    governed by the Communist Party  0.333333  \n",
              "468                                                yes  1.000000  \n",
              "469                                  in a beach chair.  0.400000  \n",
              "470                                                yes  1.000000  \n",
              "471                                                yes  1.000000  \n",
              "472                                                yes  1.000000  \n",
              "473                                                yes  1.000000  \n",
              "474                                                yes  1.000000  \n",
              "475                                                yes  1.000000  \n",
              "476                                                yes  1.000000  \n",
              "477                                                Yes  1.000000  \n",
              "478                                                Yes  1.000000  \n",
              "479                                                Yes  1.000000  \n",
              "480               Mumbai was named an alpha world city  0.181818  \n",
              "481                                                Yes  1.000000  \n",
              "482                                                yes  1.000000  \n",
              "483                              King of Great Britain  0.250000  \n",
              "484                            venison, trout and carp  0.222222  \n",
              "485             gorgeous liveries of scarlet and azure  0.200000  \n",
              "486                      There was a knock at the door  0.307692  \n",
              "487                                          New Haven  0.400000  \n",
              "488                                     John Davenport  0.500000  \n",
              "489                            Quinnipiacs and Pequots  0.250000  \n",
              "490                                   New Haven Harbor  0.333333  \n",
              "491                                      New York City  0.800000  \n",
              "492                                                yes  1.000000  \n",
              "493                                                yes  1.000000  \n",
              "494                                    plenty of money  0.333333  \n",
              "495                                                yes  1.000000  \n",
              "496                                                Two  1.000000  \n",
              "497                                English and Spanish  0.333333  \n",
              "498                                                yes  1.000000  \n",
              "499                                    in October 1998  0.400000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6dc6b67f-d144-4452-ab45-551b2cfe6798\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>generated</th>\n",
              "      <th>answers</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>her mother</td>\n",
              "      <td>with her mommy and 5 sisters</td>\n",
              "      <td>0.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>she would go to the barn</td>\n",
              "      <td>she painted herself</td>\n",
              "      <td>0.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>she was not to go with her</td>\n",
              "      <td>I am having heart surgery soon, so her mother ...</td>\n",
              "      <td>0.090909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>soup</td>\n",
              "      <td>hot soup and a container with rice, vegetables...</td>\n",
              "      <td>0.105263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes.</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>he was a car crash</td>\n",
              "      <td>Farina was cast in a film</td>\n",
              "      <td>0.222222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>he was a shot</td>\n",
              "      <td>He joined a TV show cast.</td>\n",
              "      <td>0.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>his role in a car</td>\n",
              "      <td>An expensive car</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>go to his homework</td>\n",
              "      <td>go to Quentin's house</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>he would go to his homework</td>\n",
              "      <td>everything would be okay</td>\n",
              "      <td>0.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>to the house</td>\n",
              "      <td>to the dentist</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>new york city</td>\n",
              "      <td>New York City</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>new york</td>\n",
              "      <td>New York</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>new york city</td>\n",
              "      <td>In the southwest of the city</td>\n",
              "      <td>0.285714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>the new york city was not allowed to live in b...</td>\n",
              "      <td>because the inhabitants feel neglected by the ...</td>\n",
              "      <td>0.117647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>the fbi agents</td>\n",
              "      <td>FBI</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>eight feet</td>\n",
              "      <td>may be 30 feet tall</td>\n",
              "      <td>0.285714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>she would be a cake</td>\n",
              "      <td>She already has two blouses</td>\n",
              "      <td>0.222222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>in the lake</td>\n",
              "      <td>by a big lake by the woods</td>\n",
              "      <td>0.285714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>he was not to be in the hospital</td>\n",
              "      <td>The hospital had been bombed.</td>\n",
              "      <td>0.181818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes, for twenty years</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>hans</td>\n",
              "      <td>Hans Bussman</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes, Franz does.</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>he was not to be ready for his brother</td>\n",
              "      <td>He assumed Hans was dead.</td>\n",
              "      <td>0.285714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>spotty</td>\n",
              "      <td>Brownie and Spotty</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>ted</td>\n",
              "      <td>Ted,</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes, They went looking for him with no success</td>\n",
              "      <td>0.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>a dog</td>\n",
              "      <td>A girl and a dog.</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>the woods</td>\n",
              "      <td>the woods</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>he was sorry</td>\n",
              "      <td>He was interested</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>he was not sorry</td>\n",
              "      <td>not surprised</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>he was shot in his car</td>\n",
              "      <td>10-year-old boy fatally shot his father</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>in the hospital</td>\n",
              "      <td>in the front seat of a SUV</td>\n",
              "      <td>0.285714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>he was a shot</td>\n",
              "      <td>He exited the back of the vehicle and continue...</td>\n",
              "      <td>0.142857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>in the house</td>\n",
              "      <td>in the Duomo</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>a sign of the house</td>\n",
              "      <td>a sign from Baldassarre</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>in the garage</td>\n",
              "      <td>in Seattle</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>two</td>\n",
              "      <td>Two</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>she couldn't care</td>\n",
              "      <td>she liked it</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes.</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>the hospital</td>\n",
              "      <td>A local hospital</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>new york city</td>\n",
              "      <td>New York City.</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes.</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes.</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes.</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes.</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>peter and peter</td>\n",
              "      <td>Peter</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>a dog</td>\n",
              "      <td>an alien dog</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>false</td>\n",
              "      <td>false</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>false</td>\n",
              "      <td>False</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>january</td>\n",
              "      <td>January</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>2008</td>\n",
              "      <td>2008.</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>mom</td>\n",
              "      <td>Her mom</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes.</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes.</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>philip</td>\n",
              "      <td>Philip</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>he would go to the party</td>\n",
              "      <td>to look after the horses,</td>\n",
              "      <td>0.222222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>a few miles</td>\n",
              "      <td>twelve miles away</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105</th>\n",
              "      <td>yes</td>\n",
              "      <td>.yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107</th>\n",
              "      <td>to take the party</td>\n",
              "      <td>for carrying  the news to them</td>\n",
              "      <td>0.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>in the north west wales</td>\n",
              "      <td>South West England</td>\n",
              "      <td>0.285714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>the city of england</td>\n",
              "      <td>large areas of the country came into the posse...</td>\n",
              "      <td>0.133333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes.</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>a princess of his mother</td>\n",
              "      <td>the constant thought of the grief and horror</td>\n",
              "      <td>0.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>yes</td>\n",
              "      <td>.yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>his heart</td>\n",
              "      <td>and some other ads in his text books</td>\n",
              "      <td>0.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121</th>\n",
              "      <td>he was not sorry</td>\n",
              "      <td>he was so full of wrath he could not speak</td>\n",
              "      <td>0.428571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122</th>\n",
              "      <td>he was not to be a car</td>\n",
              "      <td>he was flat on his back with half a dozen fata...</td>\n",
              "      <td>0.235294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>124</th>\n",
              "      <td>because of the cats were not allowed to buy them</td>\n",
              "      <td>because he loves them</td>\n",
              "      <td>0.307692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125</th>\n",
              "      <td>because of the cats were not allowed to buy them</td>\n",
              "      <td>because those foods aren't good for cats</td>\n",
              "      <td>0.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126</th>\n",
              "      <td>black and red</td>\n",
              "      <td>orange, black, spotted, and white</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127</th>\n",
              "      <td>he was not to go in the house</td>\n",
              "      <td>To see whether he is coming for Thanksgiving</td>\n",
              "      <td>0.266667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130</th>\n",
              "      <td>he was not to be a crash</td>\n",
              "      <td>injured in a traing crash</td>\n",
              "      <td>0.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131</th>\n",
              "      <td>five</td>\n",
              "      <td>five dollars per week</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133</th>\n",
              "      <td>he was not to be ready for the house</td>\n",
              "      <td>That it was wonderful news.</td>\n",
              "      <td>0.153846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>134</th>\n",
              "      <td>he was not to be a new house</td>\n",
              "      <td>that they were to start a regular theatre</td>\n",
              "      <td>0.142857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137</th>\n",
              "      <td>he would have to be a new house</td>\n",
              "      <td>he had already engaged a hall</td>\n",
              "      <td>0.166667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>138</th>\n",
              "      <td>he was not to be a new house</td>\n",
              "      <td>it would be converted into a first-class place...</td>\n",
              "      <td>0.125000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>139</th>\n",
              "      <td>basketball</td>\n",
              "      <td>basketball</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140</th>\n",
              "      <td>he would go to his homework</td>\n",
              "      <td>all get to play on a basketball team</td>\n",
              "      <td>0.153846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141</th>\n",
              "      <td>adam and paul</td>\n",
              "      <td>Josh, Ty, and Max</td>\n",
              "      <td>0.285714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes.</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes.</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>144</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>after the train</td>\n",
              "      <td>soon after eleven o'clock</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>in the late 1960s</td>\n",
              "      <td>in 2013</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>pope benedict xviii</td>\n",
              "      <td>Pope</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>pope john xxiiiiiiiii</td>\n",
              "      <td>Pope John Paul II</td>\n",
              "      <td>0.571429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>he would go to the village</td>\n",
              "      <td>he was in his right mind</td>\n",
              "      <td>0.181818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153</th>\n",
              "      <td>go to the village</td>\n",
              "      <td>ride to Carpen Falls</td>\n",
              "      <td>0.285714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>154</th>\n",
              "      <td>two</td>\n",
              "      <td>two</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>155</th>\n",
              "      <td>he would be a horse</td>\n",
              "      <td>he knew Captain Grady</td>\n",
              "      <td>0.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>157</th>\n",
              "      <td>a horse</td>\n",
              "      <td>tell the men that he is a downright horse thief</td>\n",
              "      <td>0.222222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>158</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>160</th>\n",
              "      <td>the city</td>\n",
              "      <td>Bonn is a city. Do you mean in Germany?</td>\n",
              "      <td>0.222222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>162</th>\n",
              "      <td>in the late 19th century</td>\n",
              "      <td>in the 1st century</td>\n",
              "      <td>0.571429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>163</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>164</th>\n",
              "      <td>in the late 19th century</td>\n",
              "      <td>in 1770</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165</th>\n",
              "      <td>the city was not divided by the state</td>\n",
              "      <td>the Basic Law, was declared</td>\n",
              "      <td>0.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>166</th>\n",
              "      <td>the city of germany</td>\n",
              "      <td>primary seat of six federal government ministries</td>\n",
              "      <td>0.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167</th>\n",
              "      <td>he was not to be ready to take the sword</td>\n",
              "      <td>He was their only hope.</td>\n",
              "      <td>0.285714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>168</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>169</th>\n",
              "      <td>the boat</td>\n",
              "      <td>the second boat</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>170</th>\n",
              "      <td>bob smith</td>\n",
              "      <td>Bob Goldstein</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>171</th>\n",
              "      <td>1966</td>\n",
              "      <td>July 1966</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>1966</td>\n",
              "      <td>August 10, 1966,</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>the farm company</td>\n",
              "      <td>the Crooked Creek Company</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes.</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>harry</td>\n",
              "      <td>Harry</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes.</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178</th>\n",
              "      <td>a week</td>\n",
              "      <td>About a week</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>179</th>\n",
              "      <td>harry</td>\n",
              "      <td>harry</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes.</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>181</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes.</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>182</th>\n",
              "      <td>harry</td>\n",
              "      <td>Harry</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>183</th>\n",
              "      <td>in the hospital</td>\n",
              "      <td>at the Royal Liverpool hospital</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>184</th>\n",
              "      <td>two</td>\n",
              "      <td>Two</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>185</th>\n",
              "      <td>six months</td>\n",
              "      <td>six hours</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>186</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>187</th>\n",
              "      <td>six months</td>\n",
              "      <td>less than six months</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>190</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>191</th>\n",
              "      <td>he would go to the wind</td>\n",
              "      <td>He wanted to be a seaman</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>193</th>\n",
              "      <td>chapter xv</td>\n",
              "      <td>Chapter 6.</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>194</th>\n",
              "      <td>he would be ready to get the wind</td>\n",
              "      <td>the boys head would have sustained a severe i...</td>\n",
              "      <td>0.142857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>he would be ready to get his hands</td>\n",
              "      <td>He dodged</td>\n",
              "      <td>0.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>january 2009</td>\n",
              "      <td>January 2004</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>201</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>202</th>\n",
              "      <td>de montfort,</td>\n",
              "      <td>Gonzalo de Cordoba</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204</th>\n",
              "      <td>the spanish grand duchy of portugal</td>\n",
              "      <td>Prince of Squillace</td>\n",
              "      <td>0.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>205</th>\n",
              "      <td>in the house</td>\n",
              "      <td>at Park House</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>206</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>207</th>\n",
              "      <td>about two miles away</td>\n",
              "      <td>about a mile away</td>\n",
              "      <td>0.571429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>208</th>\n",
              "      <td>to be a great house</td>\n",
              "      <td>to swim in the pool</td>\n",
              "      <td>0.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>209</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>210</th>\n",
              "      <td>four</td>\n",
              "      <td>four</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>211</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>212</th>\n",
              "      <td>he would have to go with his house</td>\n",
              "      <td>His honesty</td>\n",
              "      <td>0.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>213</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>214</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>215</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>216</th>\n",
              "      <td>he would go to his homework.</td>\n",
              "      <td>He wanted to help the poor students</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>217</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>218</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>219</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>220</th>\n",
              "      <td>basketball</td>\n",
              "      <td>basketball</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>221</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>222</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>224</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>225</th>\n",
              "      <td>he was not to go for the hospital</td>\n",
              "      <td>He was burned</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>226</th>\n",
              "      <td>he was shot in his heart</td>\n",
              "      <td>over 65% of his body</td>\n",
              "      <td>0.181818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>227</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>228</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>229</th>\n",
              "      <td>michael jackson</td>\n",
              "      <td>Valerie Brewer and her husband Michael Brewer,...</td>\n",
              "      <td>0.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>230</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>231</th>\n",
              "      <td>cnn</td>\n",
              "      <td>CNN</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>232</th>\n",
              "      <td>a hospital</td>\n",
              "      <td>University of Miami's Jackson Memorial Hospita...</td>\n",
              "      <td>0.222222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>233</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>234</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>235</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>236</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237</th>\n",
              "      <td>to improve the windows xp</td>\n",
              "      <td>to improve its user experience on tablets</td>\n",
              "      <td>0.363636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>238</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>239</th>\n",
              "      <td>he was a shot</td>\n",
              "      <td>shot</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>240</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>241</th>\n",
              "      <td>he was a heart surgery</td>\n",
              "      <td>it was their 13th anniversary.</td>\n",
              "      <td>0.222222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>242</th>\n",
              "      <td>he was a heart surgery</td>\n",
              "      <td>celebrate never having a day without him in he...</td>\n",
              "      <td>0.153846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>243</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>245</th>\n",
              "      <td>scientific and scientific literature</td>\n",
              "      <td>the study of humans and their societies in the...</td>\n",
              "      <td>0.142857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>246</th>\n",
              "      <td>scientific and scientific books were not impor...</td>\n",
              "      <td>social anthropology and cultural anthropology</td>\n",
              "      <td>0.166667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>247</th>\n",
              "      <td>billy</td>\n",
              "      <td>Billy</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>248</th>\n",
              "      <td>his sheep and sheep</td>\n",
              "      <td>his brother's birthday.</td>\n",
              "      <td>0.285714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>250</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>251</th>\n",
              "      <td>9 : 30 p. m</td>\n",
              "      <td>9 p.m</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>252</th>\n",
              "      <td>in the 17th century</td>\n",
              "      <td>in attacking France</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>253</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>254</th>\n",
              "      <td>the duke of england</td>\n",
              "      <td>union with England</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>255</th>\n",
              "      <td>in the park</td>\n",
              "      <td>in the maple tree</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>256</th>\n",
              "      <td>joseph and billy</td>\n",
              "      <td>Her grandmother and mother</td>\n",
              "      <td>0.285714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>257</th>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258</th>\n",
              "      <td>his father</td>\n",
              "      <td>his father's best friend.</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>259</th>\n",
              "      <td>the city of europe</td>\n",
              "      <td>the Republic of Slovenia</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>260</th>\n",
              "      <td>in the country</td>\n",
              "      <td>in southern Central Europe</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>261</th>\n",
              "      <td>greece and greece</td>\n",
              "      <td>as part of Eastern and Southern Europe</td>\n",
              "      <td>0.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>262</th>\n",
              "      <td>greece and greece</td>\n",
              "      <td>to the south and southeast</td>\n",
              "      <td>0.285714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>263</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>264</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>265</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>266</th>\n",
              "      <td>miss collega</td>\n",
              "      <td>Miss Mohun</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>267</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>268</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>269</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>270</th>\n",
              "      <td>he was not to be an agreement with the official</td>\n",
              "      <td>to hear he is free</td>\n",
              "      <td>0.307692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>271</th>\n",
              "      <td>in the garage</td>\n",
              "      <td>in a train car at the railroad tracks</td>\n",
              "      <td>0.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>272</th>\n",
              "      <td>he would go to the house</td>\n",
              "      <td>to keep him safe</td>\n",
              "      <td>0.222222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>273</th>\n",
              "      <td>he was not to go in his house</td>\n",
              "      <td>the people in the town didn't like him</td>\n",
              "      <td>0.142857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>274</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>275</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>276</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>277</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>278</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes.</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>279</th>\n",
              "      <td>the origin of birds</td>\n",
              "      <td>The ecological state of a species being unique...</td>\n",
              "      <td>0.153846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>280</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>281</th>\n",
              "      <td>he was not to go in the house</td>\n",
              "      <td>he passed away</td>\n",
              "      <td>0.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>282</th>\n",
              "      <td>the park</td>\n",
              "      <td>the park</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>283</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284</th>\n",
              "      <td>the park</td>\n",
              "      <td>the park</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>285</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>286</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>287</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>288</th>\n",
              "      <td>to speak with the language</td>\n",
              "      <td>A new language use</td>\n",
              "      <td>0.285714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>289</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>290</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>291</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>292</th>\n",
              "      <td>he was not to be ready to go</td>\n",
              "      <td>he was so heavy and drowsy</td>\n",
              "      <td>0.285714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>293</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>294</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>295</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>296</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes, Hannah dog paddled to Syb's board and he ...</td>\n",
              "      <td>0.105263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>297</th>\n",
              "      <td>he was not to be caught in the wind</td>\n",
              "      <td>\"I was in his territory, she wasn't in mine,\"</td>\n",
              "      <td>0.235294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>new york city</td>\n",
              "      <td>the New Netherland colony</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299</th>\n",
              "      <td>no</td>\n",
              "      <td>No</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>300</th>\n",
              "      <td>new york and new york</td>\n",
              "      <td>Ireland, Germany Italy, Puerto Rico, Jamaica a...</td>\n",
              "      <td>0.142857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>301</th>\n",
              "      <td>in the late 19th century</td>\n",
              "      <td>In the 19th and 20th centuries</td>\n",
              "      <td>0.444444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>302</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>303</th>\n",
              "      <td>he would be a car</td>\n",
              "      <td>he threw him</td>\n",
              "      <td>0.285714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>304</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>305</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>306</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>307</th>\n",
              "      <td>he was not to go with his car</td>\n",
              "      <td>see his dying 2-year-old grandson</td>\n",
              "      <td>0.153846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>308</th>\n",
              "      <td>joey</td>\n",
              "      <td>Joey</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>309</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>310</th>\n",
              "      <td>his leg fell down the yard</td>\n",
              "      <td>His friend said his breath stunk</td>\n",
              "      <td>0.181818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>311</th>\n",
              "      <td>he was sorry</td>\n",
              "      <td>He was angry</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>312</th>\n",
              "      <td>he would go to his homework</td>\n",
              "      <td>He brushed his teeth</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>313</th>\n",
              "      <td>he would go to his homework.</td>\n",
              "      <td>His mom forced him to</td>\n",
              "      <td>0.363636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>314</th>\n",
              "      <td>ken finnelli</td>\n",
              "      <td>Ken Cuccinelli</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>315</th>\n",
              "      <td>republican</td>\n",
              "      <td>Republican</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>316</th>\n",
              "      <td>the police department</td>\n",
              "      <td>Las Vegas Metropolitan Police Department</td>\n",
              "      <td>0.571429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>317</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>318</th>\n",
              "      <td>paul</td>\n",
              "      <td>Paul</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>319</th>\n",
              "      <td>paul</td>\n",
              "      <td>Paul and Arthur were brothers</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>320</th>\n",
              "      <td>the store</td>\n",
              "      <td>the pet store</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>321</th>\n",
              "      <td>he was not to be a shot</td>\n",
              "      <td>he shouldn't have gotten out of that car</td>\n",
              "      <td>0.142857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>322</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>323</th>\n",
              "      <td>he was a shot</td>\n",
              "      <td>Zimmerman's \"heart was in the right place\"</td>\n",
              "      <td>0.222222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>324</th>\n",
              "      <td>he was not to be shot</td>\n",
              "      <td>wanting to catch these people so badly</td>\n",
              "      <td>0.153846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>325</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>326</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>327</th>\n",
              "      <td>he was shot.</td>\n",
              "      <td>he shot Martin</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>328</th>\n",
              "      <td>he was not to be shot.</td>\n",
              "      <td>he feared for his life</td>\n",
              "      <td>0.181818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>329</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>330</th>\n",
              "      <td>tom hooper</td>\n",
              "      <td>Tom Seaton</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>331</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>332</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>333</th>\n",
              "      <td>he was not to buy the book.</td>\n",
              "      <td>to make the atmosphere sociable.</td>\n",
              "      <td>0.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>334</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>335</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>336</th>\n",
              "      <td>he was not to be ready to go</td>\n",
              "      <td>his life was threatened by gangrene</td>\n",
              "      <td>0.142857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>337</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>338</th>\n",
              "      <td>cricket match</td>\n",
              "      <td>Cricket World Cup</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>339</th>\n",
              "      <td>late 1970s</td>\n",
              "      <td>late twentieth-century</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>340</th>\n",
              "      <td>the match of cricket balls</td>\n",
              "      <td>rival World Series Cricket competition</td>\n",
              "      <td>0.222222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>341</th>\n",
              "      <td>cricket match</td>\n",
              "      <td>many of the features of One Day International ...</td>\n",
              "      <td>0.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>342</th>\n",
              "      <td>billy</td>\n",
              "      <td>Billy</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>343</th>\n",
              "      <td>he was not to be a little man</td>\n",
              "      <td>the situation was exposed</td>\n",
              "      <td>0.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>344</th>\n",
              "      <td>he would go to the party</td>\n",
              "      <td>He was at a new school, and the other students...</td>\n",
              "      <td>0.133333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>345</th>\n",
              "      <td>peter and peter</td>\n",
              "      <td>Peter</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>346</th>\n",
              "      <td>to the house</td>\n",
              "      <td>to a different school</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>347</th>\n",
              "      <td>he would go to the party</td>\n",
              "      <td>He asked another student,</td>\n",
              "      <td>0.222222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>348</th>\n",
              "      <td>peter and peter</td>\n",
              "      <td>Peter</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>349</th>\n",
              "      <td>to the house</td>\n",
              "      <td>Peter's house</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>350</th>\n",
              "      <td>peter and peter</td>\n",
              "      <td>Peter</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>351</th>\n",
              "      <td>black</td>\n",
              "      <td>black</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>352</th>\n",
              "      <td>the israeli war</td>\n",
              "      <td>Egypt had blocked them to Israeli shipping</td>\n",
              "      <td>0.222222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>353</th>\n",
              "      <td>false</td>\n",
              "      <td>false</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>354</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>355</th>\n",
              "      <td>the israeli war</td>\n",
              "      <td>the June War</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>356</th>\n",
              "      <td>the israeli war</td>\n",
              "      <td>1967 ArabIsraeli War, or Third ArabIsraeli War</td>\n",
              "      <td>0.222222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>357</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>358</th>\n",
              "      <td>the israeli war in israel</td>\n",
              "      <td>Israel launched what it claimed were a series ...</td>\n",
              "      <td>0.117647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>359</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>360</th>\n",
              "      <td>in the late 1960s</td>\n",
              "      <td>in late May</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>361</th>\n",
              "      <td>two</td>\n",
              "      <td>Two</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>362</th>\n",
              "      <td>15</td>\n",
              "      <td>15</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>363</th>\n",
              "      <td>he was a car</td>\n",
              "      <td>he heard them but didn't say anything</td>\n",
              "      <td>0.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>364</th>\n",
              "      <td>he was not to run.</td>\n",
              "      <td>he is not so tall</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>365</th>\n",
              "      <td>the gospel of god</td>\n",
              "      <td>established orders of monks</td>\n",
              "      <td>0.285714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>366</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>367</th>\n",
              "      <td>1933</td>\n",
              "      <td>between 1919 and 1933</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>368</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>369</th>\n",
              "      <td>to be a little boy</td>\n",
              "      <td>to be forbearing</td>\n",
              "      <td>0.571429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>370</th>\n",
              "      <td>the football club</td>\n",
              "      <td>Arena Football League</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>371</th>\n",
              "      <td>two</td>\n",
              "      <td>two</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>372</th>\n",
              "      <td>four</td>\n",
              "      <td>four</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>373</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>374</th>\n",
              "      <td>the premier league</td>\n",
              "      <td>reasons not associated with League operations.</td>\n",
              "      <td>0.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>375</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>376</th>\n",
              "      <td>in the late 19th century</td>\n",
              "      <td>In 1871</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>377</th>\n",
              "      <td>in the late 19th century</td>\n",
              "      <td>In 1933</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>378</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>379</th>\n",
              "      <td>two</td>\n",
              "      <td>Two.</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>380</th>\n",
              "      <td>two</td>\n",
              "      <td>Two</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>381</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>382</th>\n",
              "      <td>the weimar republic of germany</td>\n",
              "      <td>Federal Republic of Germany,</td>\n",
              "      <td>0.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>383</th>\n",
              "      <td>in the city</td>\n",
              "      <td>in Madrid</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>384</th>\n",
              "      <td>two</td>\n",
              "      <td>Two</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>385</th>\n",
              "      <td>the city of buenos aires</td>\n",
              "      <td>the adoption of the system of autonomous commu...</td>\n",
              "      <td>0.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>386</th>\n",
              "      <td>catholic church</td>\n",
              "      <td>The Protestant Evangelical Church</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>387</th>\n",
              "      <td>the catholic reformation and protestant reform...</td>\n",
              "      <td>Catholic migration from Poland</td>\n",
              "      <td>0.222222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>388</th>\n",
              "      <td>the city of europe</td>\n",
              "      <td>Southern Europe and West Germany</td>\n",
              "      <td>0.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>389</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>390</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>391</th>\n",
              "      <td>to improve the speed</td>\n",
              "      <td>bring the fighter to a safe landing</td>\n",
              "      <td>0.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>392</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>393</th>\n",
              "      <td>to improve the speed</td>\n",
              "      <td>in a text message to him</td>\n",
              "      <td>0.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>394</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>395</th>\n",
              "      <td>jupiter</td>\n",
              "      <td>Jupiter</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>396</th>\n",
              "      <td>hydrogen</td>\n",
              "      <td>hydrogen</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397</th>\n",
              "      <td>two</td>\n",
              "      <td>two</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>398</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399</th>\n",
              "      <td>late 19th century</td>\n",
              "      <td>the 17th century</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>400</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>401</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>402</th>\n",
              "      <td>$ 1, 200 million</td>\n",
              "      <td>$567 million</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>403</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>404</th>\n",
              "      <td>peter and michael</td>\n",
              "      <td>Michael</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>405</th>\n",
              "      <td>james and john</td>\n",
              "      <td>James</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>406</th>\n",
              "      <td>to get the book.</td>\n",
              "      <td>They like to read</td>\n",
              "      <td>0.285714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>407</th>\n",
              "      <td>to get the book.</td>\n",
              "      <td>he has to read a book for class</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>408</th>\n",
              "      <td>to buy the new york business</td>\n",
              "      <td>buy a fast car and travel</td>\n",
              "      <td>0.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>409</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>410</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>411</th>\n",
              "      <td>go to the school</td>\n",
              "      <td>to find work for the father</td>\n",
              "      <td>0.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>412</th>\n",
              "      <td>when he was a week.</td>\n",
              "      <td>When the boy gave an exhibition of what he lea...</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>413</th>\n",
              "      <td>he would go to take the time</td>\n",
              "      <td>That he is hard on people under him for instru...</td>\n",
              "      <td>0.125000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>414</th>\n",
              "      <td>to get his homework</td>\n",
              "      <td>That his friends were so deeply interested.</td>\n",
              "      <td>0.181818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>415</th>\n",
              "      <td>new york</td>\n",
              "      <td>New York</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>416</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>417</th>\n",
              "      <td>he would have to get the worst of them.</td>\n",
              "      <td>it will show signs of rust</td>\n",
              "      <td>0.142857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>418</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>419</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>420</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>421</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>422</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>423</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>424</th>\n",
              "      <td>the park</td>\n",
              "      <td>the park</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>425</th>\n",
              "      <td>saturday</td>\n",
              "      <td>Saturday</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>426</th>\n",
              "      <td>he would go to the park</td>\n",
              "      <td>fun to play with and didn't do dumb things l</td>\n",
              "      <td>0.133333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>427</th>\n",
              "      <td>male</td>\n",
              "      <td>male</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>428</th>\n",
              "      <td>in the hospital</td>\n",
              "      <td>in Scotland</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>429</th>\n",
              "      <td>he would be a horse.</td>\n",
              "      <td>his own life would be hazarded</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>430</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>431</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>432</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>433</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>434</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>435</th>\n",
              "      <td>his manager</td>\n",
              "      <td>sheep manager</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>436</th>\n",
              "      <td>he was not to be ready to go to the house</td>\n",
              "      <td>he felt that the purchase of such expensive cr...</td>\n",
              "      <td>0.240000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>437</th>\n",
              "      <td>dick and jack</td>\n",
              "      <td>Dick</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>438</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>439</th>\n",
              "      <td>in the afghanistan</td>\n",
              "      <td>in a British court</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>440</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>441</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>442</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>443</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>444</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>445</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>446</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>447</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>448</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>449</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>450</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>451</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>452</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>453</th>\n",
              "      <td>he would go to the car</td>\n",
              "      <td>to get an accident report</td>\n",
              "      <td>0.222222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>454</th>\n",
              "      <td>in the late 1970s</td>\n",
              "      <td>in the 1980s</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>455</th>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>456</th>\n",
              "      <td>he was shot in his car</td>\n",
              "      <td>He ignored his route suggestions.</td>\n",
              "      <td>0.363636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>457</th>\n",
              "      <td>new york county</td>\n",
              "      <td>Lackawanna County</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>458</th>\n",
              "      <td>he was a shot</td>\n",
              "      <td>He said \"my homies died, everybody gotta die.\"</td>\n",
              "      <td>0.181818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>459</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes.</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>460</th>\n",
              "      <td>a cake</td>\n",
              "      <td>A piece of cake.</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>461</th>\n",
              "      <td>joseph stalin</td>\n",
              "      <td>Joseph Stalin</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>462</th>\n",
              "      <td>false</td>\n",
              "      <td>false</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>463</th>\n",
              "      <td>ukraine</td>\n",
              "      <td>Soviet Ukraine,</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>464</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>465</th>\n",
              "      <td>soviet union</td>\n",
              "      <td>Union of Soviet Socialist Republics</td>\n",
              "      <td>0.571429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>466</th>\n",
              "      <td>false</td>\n",
              "      <td>false</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>467</th>\n",
              "      <td>democratic party</td>\n",
              "      <td>governed by the Communist Party</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>468</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>469</th>\n",
              "      <td>in the woods</td>\n",
              "      <td>in a beach chair.</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>470</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>471</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>472</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>473</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>474</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>475</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>476</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>477</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>478</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>479</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>480</th>\n",
              "      <td>it was the largest in asia</td>\n",
              "      <td>Mumbai was named an alpha world city</td>\n",
              "      <td>0.181818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>481</th>\n",
              "      <td>yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>482</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>483</th>\n",
              "      <td>the duke of st. clare</td>\n",
              "      <td>King of Great Britain</td>\n",
              "      <td>0.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>484</th>\n",
              "      <td>a princess of wales, and the french</td>\n",
              "      <td>venison, trout and carp</td>\n",
              "      <td>0.222222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>485</th>\n",
              "      <td>the top of his coat</td>\n",
              "      <td>gorgeous liveries of scarlet and azure</td>\n",
              "      <td>0.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>486</th>\n",
              "      <td>he was not to be ready for the door</td>\n",
              "      <td>There was a knock at the door</td>\n",
              "      <td>0.307692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>487</th>\n",
              "      <td>new york city</td>\n",
              "      <td>New Haven</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>488</th>\n",
              "      <td>john locke</td>\n",
              "      <td>John Davenport</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>489</th>\n",
              "      <td>the north carolina and new hampshire</td>\n",
              "      <td>Quinnipiacs and Pequots</td>\n",
              "      <td>0.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>490</th>\n",
              "      <td>new york city</td>\n",
              "      <td>New Haven Harbor</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>491</th>\n",
              "      <td>new york</td>\n",
              "      <td>New York City</td>\n",
              "      <td>0.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>492</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>493</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>494</th>\n",
              "      <td>to get the money</td>\n",
              "      <td>plenty of money</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>two</td>\n",
              "      <td>Two</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>micronesia, and polynesia</td>\n",
              "      <td>English and Spanish</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>in 2008</td>\n",
              "      <td>in October 1998</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6dc6b67f-d144-4452-ab45-551b2cfe6798')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6dc6b67f-d144-4452-ab45-551b2cfe6798 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6dc6b67f-d144-4452-ab45-551b2cfe6798');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###BERT2BERT Distilroberta-base"
      ],
      "metadata": {
        "id": "G2-Rwv5gM8fS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#entire dataset\n",
        "contexts = list(train_df['p'])\n",
        "questions = list(train_df['q'])\n",
        "answers = list(train_df['a'])"
      ],
      "metadata": {
        "id": "7fSwmQReM8fS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#take a subset from the training set\n",
        "start = 0\n",
        "end = 95000\n",
        "contexts = list(train_df['p'])\n",
        "questions = list(train_df['q'])\n",
        "answers = list(train_df['a'])\n",
        "contexts = contexts[start:end]\n",
        "questions = questions[start:end]\n",
        "answers = answers[start:end]\n",
        "len(contexts)"
      ],
      "metadata": {
        "id": "x_gmV73fM8fS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import EncoderDecoderModel, AutoTokenizer\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "model_name = 'distilroberta-base'\n",
        "\n",
        "# tie_encoder_decoder to share weights and half the number of parameters\n",
        "model = EncoderDecoderModel.from_encoder_decoder_pretrained(model_name, model_name, tie_encoder_decoder=True)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# set special tokens\n",
        "model.config.decoder_start_token_id = tokenizer.cls_token_id\n",
        "model.config.eos_token_id = tokenizer.sep_token_id\n",
        "model.config.pad_token_id = tokenizer.pad_token_id\n",
        "\n",
        "# set decoding params                               \n",
        "model.config.early_stopping = True\n",
        "model.config.no_repeat_ngram_size = 3\n",
        "model.config.repetition_penalty = 5.0\n",
        "model.config.num_beams = 2\n",
        "model.config.vocab_size = model.config.encoder.vocab_size\n"
      ],
      "metadata": {
        "id": "5SwrherKM8fT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encodings = tokenizer(questions, contexts, \n",
        "                          padding=True,\n",
        "                          truncation= True,\n",
        "                          max_length = 512,\n",
        "                          )\n",
        "input_ids, input_attention_mask = encodings['input_ids'], encodings['attention_mask']\n",
        "label_values = tokenizer(answers,\n",
        "                          padding=True,\n",
        "                          truncation=True,\n",
        "                          max_length = 25,\n",
        "                          )\n",
        "labels, labels_mask = label_values['input_ids'], label_values['attention_mask']\n",
        "\n",
        "\n",
        "\n",
        "#Tokens with indices set to ``-100`` are ignored (masked) during training, the loss is only computed for the tokens with labels\n",
        "masked_labels = [[-100 if token == tokenizer.pad_token_id else token for token in labels] for labels in labels]\n",
        "print(f'length of input_ids: {np.shape(input_ids)}')"
      ],
      "metadata": {
        "id": "OxXjWb25M8fT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encodings.keys()"
      ],
      "metadata": {
        "id": "XfyOa50nM8fT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encodings.update({'labels': masked_labels})\n",
        "encodings.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15a092d1-a926-4d0a-9dcc-6c0350013947",
        "id": "2TQ6POAgM8fT"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'attention_mask', 'labels'])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class CreateDataset(Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings.input_ids)"
      ],
      "metadata": {
        "id": "dxTWgEfWM8fT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#parameters\n",
        "batch_size = 16\n",
        "num_epochs = 3\n",
        "#also try with lr = 4e-4\n",
        "lr = 4e-5"
      ],
      "metadata": {
        "id": "b5qfLBOJM8fT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from timeit import default_timer as timer\n",
        "#create training dataset\n",
        "train_dataset = CreateDataset(encodings)\n",
        "#create training dataloader\n",
        "train_ld = torch.utils.data.DataLoader(train_dataset,\n",
        "                                     batch_size=batch_size,\n",
        "                                     )\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model.to(device)\n",
        "optim = torch.optim.AdamW(model.parameters(), lr=lr)\n",
        "loop_start = timer()\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    loss_score = []\n",
        "    loop = tqdm(train_ld)\n",
        "    for batch in loop:\n",
        "        optim.zero_grad()\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        loss, outputs = model(input_ids,\n",
        "                              attention_mask=attention_mask,\n",
        "                              labels = labels\n",
        "                        )[:2]\n",
        "        loss_score.append(loss.item())\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "\n",
        "        loop.set_description(f'Epoch {epoch}')\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "    average_loss = np.mean(loss_score)\n",
        "    print(f\"Epoch: {epoch}, average Loss: {average_loss}\")\n",
        "loop_end = timer()\n",
        "time_loop = loop_end - loop_start\n",
        "print(f'\\nTime for {num_epochs} epochs (s): {(time_loop):.3f}')"
      ],
      "metadata": {
        "id": "xKdl21v2M8fU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Free some memory\n",
        "import gc\n",
        "del encodings,input_ids,input_attention_mask,labels\n",
        "torch.cuda.empty_cache()\n",
        "torch.cuda.reset_accumulated_memory_stats()\n",
        "gc.collect()"
      ],
      "metadata": {
        "outputId": "4224b9df-5f72-419d-b753-7e415545734f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9UrY8RhM8fU"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Generation"
      ],
      "metadata": {
        "id": "Xqq0pd7RM8fU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load test dataset."
      ],
      "metadata": {
        "id": "IBgEOzIDM8fU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = loadDataset(\"test.json\")\n",
        "test_df.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c241dad-a623-4853-c8b4-e6fb294a7cb2",
        "id": "j0jqxRQLM8fU"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "500 stories / 12 questions in the first row\n",
            "499 distinct stories\n",
            "5 distinct sources: Index(['mctest', 'race', 'cnn', 'wikipedia', 'gutenberg'], dtype='object')\n",
            "(7917, 5) question-answer pairs x columns\n",
            "First row: ['0' '0' 'What color was Cotton?' 'white'\n",
            " 'a little white kitten named Cotton']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "source    7917\n",
              "p         7917\n",
              "q         7917\n",
              "a         7917\n",
              "span      7917\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_test = list(test_df['p'])\n",
        "question_test = list(test_df['q'])\n",
        "answer_test = list(test_df['a'])"
      ],
      "metadata": {
        "id": "gkMeNLtqM8fU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_values = tokenizer(question_test,context_test, padding=True, truncation=True, max_length = 512)\n",
        "input_ids, input_attention_mask = input_values['input_ids'], input_values['attention_mask']"
      ],
      "metadata": {
        "id": "LYdbBdsgM8fV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#utility functions taken from the allennlp library for computing the F1-score\n",
        "import collections\n",
        "import re\n",
        "import string\n",
        "from typing import Callable, Sequence, TypeVar, Tuple\n",
        "\n",
        "def get_tokens(s):\n",
        "    if not s:\n",
        "        return []\n",
        "    return normalize_answer(s).split()\n",
        "\n",
        "def normalize_answer(s):\n",
        "    \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n",
        "\n",
        "    def remove_articles(text):\n",
        "        regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n",
        "        return re.sub(regex, \" \", text)\n",
        "\n",
        "    def white_space_fix(text):\n",
        "        return \" \".join(text.split())\n",
        "\n",
        "    def remove_punc(text):\n",
        "        exclude = set(string.punctuation)\n",
        "        return \"\".join(ch for ch in text if ch not in exclude)\n",
        "\n",
        "    def lower(text):\n",
        "        return text.lower()\n",
        "\n",
        "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
        "\n",
        "def compute_f1(a_pred: str, a_gold: str) -> float:\n",
        "    pred_toks = get_tokens(a_pred)\n",
        "    gold_toks = get_tokens(a_gold)\n",
        "    common = collections.Counter(pred_toks) & collections.Counter(gold_toks)  # type: ignore[var-annotated]\n",
        "    num_same = sum(common.values())\n",
        "    if len(pred_toks) == 0 or len(gold_toks) == 0:\n",
        "        # If either is no-answer, then F1 is 1 if they agree, 0 otherwise\n",
        "        return float(pred_toks == gold_toks)\n",
        "    if num_same == 0:\n",
        "        return 0.0\n",
        "    precision = 1.0 * num_same / len(pred_toks)\n",
        "    recall = 1.0 * num_same / len(gold_toks)\n",
        "    f1 = (2 * precision * recall) / (precision + recall)\n",
        "    return f1"
      ],
      "metadata": {
        "id": "WcL-JtVqM8fV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "l = []\n",
        "model.to(device)\n",
        "#set the model in evaluation mode\n",
        "model.eval()\n",
        "for input, mask in zip(input_ids,input_attention_mask):\n",
        "  input = np.expand_dims(np.array(input), axis=0)\n",
        "  mask = np.expand_dims(np.array(mask), axis=0)\n",
        "  generated = model.generate(input_ids=torch.tensor(input).to(device),\n",
        "                                                 max_length=20,\n",
        "                                                 repetition_penalty=5.,\n",
        "                                                 min_length=1,\n",
        "                                                 no_repeat_ngram_size=3,\n",
        "                                                 early_stopping=True,\n",
        "                                                decoder_start_token_id = model.config.decoder_start_token_id,\n",
        "                                                 num_beams=2,\n",
        "                                                 )\n",
        "  generated = tokenizer.batch_decode(generated, skip_special_tokens=True)\n",
        "  l.append(generated)"
      ],
      "metadata": {
        "id": "H1h4HFwTM8fV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = pd.DataFrame(l, columns = ['generated'])\n",
        "x['answers'] = answer_test\n",
        "#pd.set_option('display.max_rows', None)\n",
        "#x.head(300)"
      ],
      "metadata": {
        "id": "ESKHnK6uM8fV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = []\n",
        "predictions = x['generated']\n",
        "true_answers = x['answers']\n",
        "for a_pred, a_gold in zip(predictions, true_answers):\n",
        "  score.append(compute_f1(a_pred, a_gold))\n",
        "average_score = np.mean(score)\n",
        "print(f'average_score: {average_score}')\n",
        "x['score'] = score\n",
        "total = len(x[x['score'] != 0])\n",
        "print(f'length: {total} / {len(x)}')\n"
      ],
      "metadata": {
        "id": "uUnYQmXGM8fV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_rows', None)\n",
        "correct = x[x['score'] != 0]\n",
        "correct = correct.reset_index(drop=True)\n",
        "correct.head(500)"
      ],
      "metadata": {
        "id": "rH5l9jFTM8fV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scfOBhZf1mPp"
      },
      "source": [
        "### Question generation $f_\\theta(P, Q, H)$ with text passage $P$, question $Q$ and dialogue history $H$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9maQVnw61mPp"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpTttkRT1mPq"
      },
      "source": [
        "## Train and evaluate $f_\\theta(P, Q)$ and $f_\\theta(P, Q, H)$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j9Mb67HE1mPq"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmviMChy1mPq"
      },
      "source": [
        "## Conclusions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jDn-h3WL1mPq"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "tf",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "e405b0a43b05ed5b511dac57849ab560497f023fc2f8f0bfd2781bf41b5f416c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}