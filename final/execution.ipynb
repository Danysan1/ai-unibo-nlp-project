{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final project"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Initial Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /opt/miniconda3/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /home/daniel/.local/lib/python3.10/site-packages (2.1.3)\n",
      "Requirement already satisfied: numpy in /home/daniel/.local/lib/python3.10/site-packages (1.23.5)\n",
      "Requirement already satisfied: matplotlib in /home/daniel/.local/lib/python3.10/site-packages (3.7.1)\n",
      "Requirement already satisfied: transformers==4.25.1 in /home/daniel/.local/lib/python3.10/site-packages (4.25.1)\n",
      "Requirement already satisfied: dataset in /home/daniel/.local/lib/python3.10/site-packages (1.6.2)\n",
      "Requirement already satisfied: filelock in /home/daniel/.local/lib/python3.10/site-packages (from transformers==4.25.1) (3.12.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /home/daniel/.local/lib/python3.10/site-packages (from transformers==4.25.1) (0.19.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/daniel/.local/lib/python3.10/site-packages (from transformers==4.25.1) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers==4.25.1) (5.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/daniel/.local/lib/python3.10/site-packages (from transformers==4.25.1) (2023.10.3)\n",
      "Requirement already satisfied: requests in /home/daniel/.local/lib/python3.10/site-packages (from transformers==4.25.1) (2.30.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/daniel/.local/lib/python3.10/site-packages (from transformers==4.25.1) (0.13.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.25.1) (4.65.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/daniel/.local/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/daniel/.local/lib/python3.10/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/daniel/.local/lib/python3.10/site-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/daniel/.local/lib/python3.10/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/daniel/.local/lib/python3.10/site-packages (from matplotlib) (4.40.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/daniel/.local/lib/python3.10/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/daniel/.local/lib/python3.10/site-packages (from matplotlib) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/daniel/.local/lib/python3.10/site-packages (from matplotlib) (3.1.0)\n",
      "Requirement already satisfied: sqlalchemy<2.0.0,>=1.3.2 in /home/daniel/.local/lib/python3.10/site-packages (from dataset) (1.4.50)\n",
      "Requirement already satisfied: alembic>=0.6.2 in /home/daniel/.local/lib/python3.10/site-packages (from dataset) (1.12.1)\n",
      "Requirement already satisfied: banal>=1.0.1 in /home/daniel/.local/lib/python3.10/site-packages (from dataset) (1.0.6)\n",
      "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=0.6.2->dataset) (1.1.3)\n",
      "Requirement already satisfied: typing-extensions>=4 in /home/daniel/.local/lib/python3.10/site-packages (from alembic>=0.6.2->dataset) (4.5.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/daniel/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers==4.25.1) (2023.10.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/daniel/.local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/daniel/.local/lib/python3.10/site-packages (from sqlalchemy<2.0.0,>=1.3.2->dataset) (3.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/daniel/.local/lib/python3.10/site-packages (from requests->transformers==4.25.1) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/daniel/.local/lib/python3.10/site-packages (from requests->transformers==4.25.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/daniel/.local/lib/python3.10/site-packages (from requests->transformers==4.25.1) (2.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/daniel/.local/lib/python3.10/site-packages (from requests->transformers==4.25.1) (2023.5.7)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas numpy matplotlib transformers==4.25.1  dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import pandas as pd\n",
    "from os import path\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the random state to 42\n",
    "SEED = 42\n",
    "\n",
    "def fix_seed(seed: int) -> None:\n",
    "    \"\"\"Fix all the possible sources of randomness.\n",
    "\n",
    "    Args:\n",
    "        seed: the seed to use. \n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    \n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "fix_seed(SEED)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'Dataset'\n",
    "\n",
    "def load__dataset(filename:str) -> pd.DataFrame:\n",
    "    with open(path.join(data_folder, filename)) as file_obj:\n",
    "        data = pd.read_json(file_obj, dtype={'episode':str,'speakers':np.array})\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode</th>\n",
       "      <th>speakers</th>\n",
       "      <th>emotions</th>\n",
       "      <th>utterances</th>\n",
       "      <th>triggers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>utterance_0</td>\n",
       "      <td>[Chandler, The Interviewer, Chandler, The Inte...</td>\n",
       "      <td>[neutral, neutral, neutral, neutral, surprise]</td>\n",
       "      <td>[also I was the point person on my company's t...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>utterance_1</td>\n",
       "      <td>[Chandler, The Interviewer, Chandler, The Inte...</td>\n",
       "      <td>[neutral, neutral, neutral, neutral, surprise,...</td>\n",
       "      <td>[also I was the point person on my company's t...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>utterance_2</td>\n",
       "      <td>[Chandler, The Interviewer, Chandler, The Inte...</td>\n",
       "      <td>[neutral, neutral, neutral, neutral, surprise,...</td>\n",
       "      <td>[also I was the point person on my company's t...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>utterance_3</td>\n",
       "      <td>[Chandler, The Interviewer, Chandler, The Inte...</td>\n",
       "      <td>[neutral, neutral, neutral, neutral, surprise,...</td>\n",
       "      <td>[also I was the point person on my company's t...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>utterance_4</td>\n",
       "      <td>[Joey, Rachel, Joey, Rachel]</td>\n",
       "      <td>[surprise, sadness, surprise, fear]</td>\n",
       "      <td>[But then who? The waitress I went out with la...</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       episode                                           speakers  \\\n",
       "0  utterance_0  [Chandler, The Interviewer, Chandler, The Inte...   \n",
       "1  utterance_1  [Chandler, The Interviewer, Chandler, The Inte...   \n",
       "2  utterance_2  [Chandler, The Interviewer, Chandler, The Inte...   \n",
       "3  utterance_3  [Chandler, The Interviewer, Chandler, The Inte...   \n",
       "4  utterance_4                       [Joey, Rachel, Joey, Rachel]   \n",
       "\n",
       "                                            emotions  \\\n",
       "0     [neutral, neutral, neutral, neutral, surprise]   \n",
       "1  [neutral, neutral, neutral, neutral, surprise,...   \n",
       "2  [neutral, neutral, neutral, neutral, surprise,...   \n",
       "3  [neutral, neutral, neutral, neutral, surprise,...   \n",
       "4                [surprise, sadness, surprise, fear]   \n",
       "\n",
       "                                          utterances  \\\n",
       "0  [also I was the point person on my company's t...   \n",
       "1  [also I was the point person on my company's t...   \n",
       "2  [also I was the point person on my company's t...   \n",
       "3  [also I was the point person on my company's t...   \n",
       "4  [But then who? The waitress I went out with la...   \n",
       "\n",
       "                                            triggers  \n",
       "0                          [0.0, 0.0, 0.0, 1.0, 0.0]  \n",
       "1                [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]  \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...  \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "4                               [0.0, 0.0, 1.0, 0.0]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set_fn = 'MELD_train_efr.json'\n",
    "\n",
    "dataset = load__dataset(training_set_fn)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index_none_triggers(df:pd.DataFrame, column:str) -> list:\n",
    "    has_none = []\n",
    "    for i in df[column].index:\n",
    "        is_none = np.where(np.array(df[column][i]) == None, 1, 0).any() \n",
    "        if is_none:\n",
    "            has_none.append(i)\n",
    "    return has_none\n",
    "\n",
    "def clean_none(df:pd.DataFrame, column:str, indexes:list) -> pd.DataFrame:\n",
    "    for i in indexes:\n",
    "        df[column][i] = [el if el is not None else 0.0 for el in df[column][i]]\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check how many triggers do have a None value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 trigger rows have None values.\n",
      "\n",
      "2671                                [0.0, 0.0, 1.0, None]\n",
      "2693                      [0.0, 0.0, 0.0, 0.0, 1.0, None]\n",
      "3105    [0.0, 0.0, 0.0, None, 0.0, 0.0, 0.0, 1.0, 1.0,...\n",
      "3157    [0.0, 0.0, None, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0,...\n",
      "3171    [0.0, 0.0, 0.0, 0.0, 0.0, None, 0.0, 0.0, 1.0,...\n",
      "3204    [None, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...\n",
      "3266    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, None, 0.0, 1.0,...\n",
      "3351    [0.0, 0.0, 0.0, None, 0.0, 0.0, 0.0, 0.0, 0.0,...\n",
      "3359    [0.0, None, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...\n",
      "Name: triggers, dtype: object\n"
     ]
    }
   ],
   "source": [
    "indexes_none = get_index_none_triggers(dataset, column='triggers')\n",
    "print(\"{} trigger rows have None values.\\n\".format(len(indexes_none)))\n",
    "if len(indexes_none) > 0:\n",
    "    print(dataset['triggers'][indexes_none])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we clean the dataset and then check the previous lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After cleaning, 0 trigger rows have None values.\n",
      "\n",
      "2671                                 [0.0, 0.0, 1.0, 0.0]\n",
      "2693                       [0.0, 0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "3105    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, ...\n",
      "3157    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...\n",
      "3171    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...\n",
      "3204    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
      "3266    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...\n",
      "3351    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
      "3359    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
      "Name: triggers, dtype: object\n"
     ]
    }
   ],
   "source": [
    "dataset = clean_none(dataset, column='triggers', indexes=indexes_none)\n",
    "indexes_none_clean = get_index_none_triggers(dataset, column='triggers')\n",
    "print(\"\\nAfter cleaning, {} trigger rows have None values.\\n\".format(len(indexes_none_clean)))\n",
    "if len(indexes_none) > 0:\n",
    "    print(dataset['triggers'][indexes_none])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Val-Test splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    1,    2, ..., 3997, 3998, 3999])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.index.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 3600\n",
      "Number of test samples: 400\n",
      "Number of validation examples: 400\n"
     ]
    }
   ],
   "source": [
    "idx_train, idx_test = train_test_split(dataset.index.to_numpy(),\n",
    "                                     random_state=SEED,\n",
    "                                     test_size=0.1)\n",
    "print('Number of training samples: {}'.format(idx_train.shape[0]))\n",
    "print('Number of test samples: {}'.format(idx_test.shape[0]))\n",
    "\n",
    "idx_train, idx_val = train_test_split(idx_train,\n",
    "                                     random_state=SEED,\n",
    "                                     test_size=idx_test.shape[0])\n",
    "print('Number of validation examples: {}'.format(idx_val.shape[0]))\n",
    "\n",
    "df_train = dataset.iloc[idx_train]\n",
    "df_val = dataset.iloc[idx_val]\n",
    "df_test = dataset.iloc[idx_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode</th>\n",
       "      <th>speakers</th>\n",
       "      <th>emotions</th>\n",
       "      <th>utterances</th>\n",
       "      <th>triggers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>utterance_555</td>\n",
       "      <td>[Phoebe, Phoebe]</td>\n",
       "      <td>[sadness, anger]</td>\n",
       "      <td>[Look, I feel really bad about how I freaked y...</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3491</th>\n",
       "      <td>utterance_3491</td>\n",
       "      <td>[Phoebe, Eric, Phoebe, Eric]</td>\n",
       "      <td>[surprise, fear, surprise, sadness]</td>\n",
       "      <td>[You-youyou had sex with Ursula?!, Uh, a litt...</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>utterance_527</td>\n",
       "      <td>[Mona, Ross, Dr. Green, Ross]</td>\n",
       "      <td>[fear, neutral, anger, sadness]</td>\n",
       "      <td>[Oh my God! Oh my God! I'm so sorry!, Aw forge...</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3925</th>\n",
       "      <td>utterance_3925</td>\n",
       "      <td>[Chandler, Chandler, Chandler, Chandler]</td>\n",
       "      <td>[neutral, neutral, neutral, disgust]</td>\n",
       "      <td>[I can blow dry it., I can put gel on it., It ...</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2989</th>\n",
       "      <td>utterance_2989</td>\n",
       "      <td>[Ross, Phoebe, Ross]</td>\n",
       "      <td>[joy, joy, neutral]</td>\n",
       "      <td>[You're gonna love me so much. I got Sting tic...</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             episode                                  speakers  \\\n",
       "555    utterance_555                          [Phoebe, Phoebe]   \n",
       "3491  utterance_3491              [Phoebe, Eric, Phoebe, Eric]   \n",
       "527    utterance_527             [Mona, Ross, Dr. Green, Ross]   \n",
       "3925  utterance_3925  [Chandler, Chandler, Chandler, Chandler]   \n",
       "2989  utterance_2989                      [Ross, Phoebe, Ross]   \n",
       "\n",
       "                                  emotions  \\\n",
       "555                       [sadness, anger]   \n",
       "3491   [surprise, fear, surprise, sadness]   \n",
       "527        [fear, neutral, anger, sadness]   \n",
       "3925  [neutral, neutral, neutral, disgust]   \n",
       "2989                   [joy, joy, neutral]   \n",
       "\n",
       "                                             utterances              triggers  \n",
       "555   [Look, I feel really bad about how I freaked y...            [0.0, 0.0]  \n",
       "3491  [You-you\n",
       "you had sex with Ursula?!, Uh, a litt...  [0.0, 0.0, 1.0, 0.0]  \n",
       "527   [Oh my God! Oh my God! I'm so sorry!, Aw forge...  [0.0, 0.0, 1.0, 0.0]  \n",
       "3925  [I can blow dry it., I can put gel on it., It ...  [0.0, 0.0, 1.0, 0.0]  \n",
       "2989  [You're gonna love me so much. I got Sting tic...       [0.0, 1.0, 0.0]  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
