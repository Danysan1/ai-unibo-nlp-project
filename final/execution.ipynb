{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlJhpqc_0Jmk"
      },
      "source": [
        "# Final project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6HWqCPE0Jmo"
      },
      "source": [
        "## Imports and Initial Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFpxvvaX0Jmp",
        "outputId": "31fecf5d-ad54-4e24-e859-5d0f2d72cc19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: pandas in /home/daniel/.local/lib/python3.10/site-packages (2.1.3)\n",
            "Requirement already satisfied: numpy in /home/daniel/.local/lib/python3.10/site-packages (1.23.5)\n",
            "Requirement already satisfied: matplotlib in /home/daniel/.local/lib/python3.10/site-packages (3.7.1)\n",
            "Requirement already satisfied: transformers in /home/daniel/.local/lib/python3.10/site-packages (4.25.1)\n",
            "Requirement already satisfied: dataset in /home/daniel/.local/lib/python3.10/site-packages (1.6.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/daniel/.local/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas) (2022.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /home/daniel/.local/lib/python3.10/site-packages (from pandas) (2023.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /home/daniel/.local/lib/python3.10/site-packages (from matplotlib) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/daniel/.local/lib/python3.10/site-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /home/daniel/.local/lib/python3.10/site-packages (from matplotlib) (4.40.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /home/daniel/.local/lib/python3.10/site-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/daniel/.local/lib/python3.10/site-packages (from matplotlib) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /home/daniel/.local/lib/python3.10/site-packages (from matplotlib) (9.5.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /home/daniel/.local/lib/python3.10/site-packages (from matplotlib) (3.1.0)\n",
            "Requirement already satisfied: filelock in /home/daniel/.local/lib/python3.10/site-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /home/daniel/.local/lib/python3.10/site-packages (from transformers) (0.19.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers) (5.4.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /home/daniel/.local/lib/python3.10/site-packages (from transformers) (2023.10.3)\n",
            "Requirement already satisfied: requests in /home/daniel/.local/lib/python3.10/site-packages (from transformers) (2.30.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/daniel/.local/lib/python3.10/site-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: sqlalchemy<2.0.0,>=1.3.2 in /home/daniel/.local/lib/python3.10/site-packages (from dataset) (1.4.50)\n",
            "Requirement already satisfied: alembic>=0.6.2 in /home/daniel/.local/lib/python3.10/site-packages (from dataset) (1.12.1)\n",
            "Requirement already satisfied: banal>=1.0.1 in /home/daniel/.local/lib/python3.10/site-packages (from dataset) (1.0.6)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=0.6.2->dataset) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4 in /home/daniel/.local/lib/python3.10/site-packages (from alembic>=0.6.2->dataset) (4.5.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /home/daniel/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (2023.10.0)\n",
            "Requirement already satisfied: six>=1.5 in /home/daniel/.local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /home/daniel/.local/lib/python3.10/site-packages (from sqlalchemy<2.0.0,>=1.3.2->dataset) (3.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/daniel/.local/lib/python3.10/site-packages (from requests->transformers) (3.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/daniel/.local/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/daniel/.local/lib/python3.10/site-packages (from requests->transformers) (2.0.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/daniel/.local/lib/python3.10/site-packages (from requests->transformers) (2023.5.7)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install pandas numpy matplotlib transformers dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TsB9AQ1l0Jmr"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-11-15 14:36:36.120695: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-15 14:36:37.113880: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import pandas as pd\n",
        "from os import path\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "import gc\n",
        "import torch\n",
        "import transformers\n",
        "from tqdm import tqdm\n",
        "from typing import Callable, Dict, List, Tuple\n",
        "from timeit import default_timer as timer\n",
        "from transformers import EncoderDecoderModel, AutoTokenizer, PreTrainedTokenizer, BatchEncoding\n",
        "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vXIZjw9y0Jms"
      },
      "outputs": [],
      "source": [
        "# Fix the random state to 42\n",
        "SEED = 42\n",
        "\n",
        "def fix_seed(seed: int) -> None:\n",
        "    \"\"\"Fix all the possible sources of randomness.\n",
        "\n",
        "    Args:\n",
        "        seed: the seed to use.\n",
        "    \"\"\"\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "fix_seed(SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4QiHmU60Jms"
      },
      "source": [
        "## Dataset Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "aqJX5H4D0Jms"
      },
      "outputs": [],
      "source": [
        "data_folder = 'Dataset'\n",
        "\n",
        "def load__dataset(filename:str) -> pd.DataFrame:\n",
        "    with open(path.join(data_folder, filename)) as file_obj:\n",
        "        data = pd.read_json(file_obj, dtype={'episode':str,'speakers':np.array})\n",
        "        return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "q4MOSXg70Jmt",
        "outputId": "bd541aba-99be-4bde-f3a2-d0f1a5e9d47c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>episode</th>\n",
              "      <th>speakers</th>\n",
              "      <th>emotions</th>\n",
              "      <th>utterances</th>\n",
              "      <th>triggers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>utterance_0</td>\n",
              "      <td>[Chandler, The Interviewer, Chandler, The Inte...</td>\n",
              "      <td>[neutral, neutral, neutral, neutral, surprise]</td>\n",
              "      <td>[also I was the point person on my company's t...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>utterance_1</td>\n",
              "      <td>[Chandler, The Interviewer, Chandler, The Inte...</td>\n",
              "      <td>[neutral, neutral, neutral, neutral, surprise,...</td>\n",
              "      <td>[also I was the point person on my company's t...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>utterance_2</td>\n",
              "      <td>[Chandler, The Interviewer, Chandler, The Inte...</td>\n",
              "      <td>[neutral, neutral, neutral, neutral, surprise,...</td>\n",
              "      <td>[also I was the point person on my company's t...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>utterance_3</td>\n",
              "      <td>[Chandler, The Interviewer, Chandler, The Inte...</td>\n",
              "      <td>[neutral, neutral, neutral, neutral, surprise,...</td>\n",
              "      <td>[also I was the point person on my company's t...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>utterance_4</td>\n",
              "      <td>[Joey, Rachel, Joey, Rachel]</td>\n",
              "      <td>[surprise, sadness, surprise, fear]</td>\n",
              "      <td>[But then who? The waitress I went out with la...</td>\n",
              "      <td>[0.0, 0.0, 1.0, 0.0]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       episode                                           speakers  \\\n",
              "0  utterance_0  [Chandler, The Interviewer, Chandler, The Inte...   \n",
              "1  utterance_1  [Chandler, The Interviewer, Chandler, The Inte...   \n",
              "2  utterance_2  [Chandler, The Interviewer, Chandler, The Inte...   \n",
              "3  utterance_3  [Chandler, The Interviewer, Chandler, The Inte...   \n",
              "4  utterance_4                       [Joey, Rachel, Joey, Rachel]   \n",
              "\n",
              "                                            emotions  \\\n",
              "0     [neutral, neutral, neutral, neutral, surprise]   \n",
              "1  [neutral, neutral, neutral, neutral, surprise,...   \n",
              "2  [neutral, neutral, neutral, neutral, surprise,...   \n",
              "3  [neutral, neutral, neutral, neutral, surprise,...   \n",
              "4                [surprise, sadness, surprise, fear]   \n",
              "\n",
              "                                          utterances  \\\n",
              "0  [also I was the point person on my company's t...   \n",
              "1  [also I was the point person on my company's t...   \n",
              "2  [also I was the point person on my company's t...   \n",
              "3  [also I was the point person on my company's t...   \n",
              "4  [But then who? The waitress I went out with la...   \n",
              "\n",
              "                                            triggers  \n",
              "0                          [0.0, 0.0, 0.0, 1.0, 0.0]  \n",
              "1                [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]  \n",
              "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...  \n",
              "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
              "4                               [0.0, 0.0, 1.0, 0.0]  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training_set_fn = 'MELD_train_efr.json'\n",
        "\n",
        "dataset = load__dataset(training_set_fn)\n",
        "dataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "6DK5u2OJ0Jmt"
      },
      "outputs": [],
      "source": [
        "def get_index_none_triggers(df:pd.DataFrame, column:str) -> list:\n",
        "    has_none = []\n",
        "    for i in df[column].index:\n",
        "        is_none = np.where(np.array(df[column][i]) == None, 1, 0).any()\n",
        "        if is_none:\n",
        "            has_none.append(i)\n",
        "    return has_none\n",
        "\n",
        "def clean_none(df:pd.DataFrame, column:str, indexes:list) -> pd.DataFrame:\n",
        "    for i in indexes:\n",
        "        df[column][i] = [el if el is not None else 0.0 for el in df[column][i]]\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wI-4EU1z0Jmu"
      },
      "source": [
        "Check how many triggers do have a None value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xj71vdjp0Jmu",
        "outputId": "89bf36b2-c319-4b1a-8f43-3859f388499e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9 trigger rows have None values.\n",
            "\n",
            "2671                                [0.0, 0.0, 1.0, None]\n",
            "2693                      [0.0, 0.0, 0.0, 0.0, 1.0, None]\n",
            "3105    [0.0, 0.0, 0.0, None, 0.0, 0.0, 0.0, 1.0, 1.0,...\n",
            "3157    [0.0, 0.0, None, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0,...\n",
            "3171    [0.0, 0.0, 0.0, 0.0, 0.0, None, 0.0, 0.0, 1.0,...\n",
            "3204    [None, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...\n",
            "3266    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, None, 0.0, 1.0,...\n",
            "3351    [0.0, 0.0, 0.0, None, 0.0, 0.0, 0.0, 0.0, 0.0,...\n",
            "3359    [0.0, None, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...\n",
            "Name: triggers, dtype: object\n"
          ]
        }
      ],
      "source": [
        "indexes_none = get_index_none_triggers(dataset, column='triggers')\n",
        "print(\"{} trigger rows have None values.\\n\".format(len(indexes_none)))\n",
        "if len(indexes_none) > 0:\n",
        "    print(dataset['triggers'][indexes_none])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B231vfKs0Jmu"
      },
      "source": [
        "Now we clean the dataset and then check the previous lists."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2AN_kyP0Jmu",
        "outputId": "0cad1c4d-d86f-48bb-8a0a-534a6bee99bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "After cleaning, 0 trigger rows have None values.\n",
            "\n",
            "2671                                 [0.0, 0.0, 1.0, 0.0]\n",
            "2693                       [0.0, 0.0, 0.0, 0.0, 1.0, 0.0]\n",
            "3105    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, ...\n",
            "3157    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...\n",
            "3171    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...\n",
            "3204    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
            "3266    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...\n",
            "3351    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
            "3359    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
            "Name: triggers, dtype: object\n"
          ]
        }
      ],
      "source": [
        "dataset = clean_none(dataset, column='triggers', indexes=indexes_none)\n",
        "indexes_none_clean = get_index_none_triggers(dataset, column='triggers')\n",
        "print(\"\\nAfter cleaning, {} trigger rows have None values.\\n\".format(len(indexes_none_clean)))\n",
        "if len(indexes_none) > 0:\n",
        "    print(dataset['triggers'][indexes_none])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmF7DFMn0Jmv"
      },
      "source": [
        "## Train-Val-Test splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "tRZJyZw37hWP"
      },
      "outputs": [],
      "source": [
        "tot = len(dataset)\n",
        "data = []\n",
        "for r in range(tot):\n",
        "  text = dataset['utterances'][r]\n",
        "  em = dataset['emotions'][r]\n",
        "  trig = dataset['triggers'][r]\n",
        "  for i in range(1,len(text)+1):\n",
        "    t = []\n",
        "    for q in range(i):\n",
        "      t.append(text[q])\n",
        "    data.append(\n",
        "        {'episode': dataset['episode'][r],\n",
        "        'utterance': t,\n",
        "        'emotion': em[i-1],\n",
        "        'trigger': trig[i-1]\n",
        "              })\n",
        "data = pd.DataFrame(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FEln12COiVeW",
        "outputId": "4f579915-8f47-4471-bddf-5b650577b5a0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "35000"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "rrkX3Ta1-0IO"
      },
      "outputs": [],
      "source": [
        "episodes = data['episode'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hm8PMxsgBAO7",
        "outputId": "2764232d-7a52-421b-f0f2-01646e923b6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of training samples: 27850\n",
            "Number of test samples: 3612\n",
            "Number of validation examples: 3538\n"
          ]
        }
      ],
      "source": [
        "idx_train, idx_test = train_test_split(episodes,\n",
        "                                     random_state=SEED,\n",
        "                                     test_size=0.1)\n",
        "idx_train, idx_val = train_test_split(idx_train,\n",
        "                                     random_state=SEED,\n",
        "                                     test_size=idx_test.shape[0])\n",
        "df_train = data[data['episode'].isin(idx_train)]\n",
        "df_test = data[data['episode'].isin(idx_test)]\n",
        "df_val = data[data['episode'].isin(idx_val)]\n",
        "print('Number of training samples: {}'.format(df_train.shape[0]))\n",
        "print('Number of test samples: {}'.format(df_test.shape[0]))\n",
        "print('Number of validation examples: {}'.format(df_val.shape[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "q9ziL6sQBrJj",
        "outputId": "e8548092-f532-4f0d-8a6f-a378067bcb1a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>episode</th>\n",
              "      <th>utterance</th>\n",
              "      <th>emotion</th>\n",
              "      <th>trigger</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>utterance_0</td>\n",
              "      <td>[also I was the point person on my company's t...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>utterance_0</td>\n",
              "      <td>[also I was the point person on my company's t...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>utterance_0</td>\n",
              "      <td>[also I was the point person on my company's t...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>utterance_0</td>\n",
              "      <td>[also I was the point person on my company's t...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>utterance_0</td>\n",
              "      <td>[also I was the point person on my company's t...</td>\n",
              "      <td>surprise</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       episode                                          utterance   emotion  \\\n",
              "0  utterance_0  [also I was the point person on my company's t...   neutral   \n",
              "1  utterance_0  [also I was the point person on my company's t...   neutral   \n",
              "2  utterance_0  [also I was the point person on my company's t...   neutral   \n",
              "3  utterance_0  [also I was the point person on my company's t...   neutral   \n",
              "4  utterance_0  [also I was the point person on my company's t...  surprise   \n",
              "\n",
              "   trigger  \n",
              "0      0.0  \n",
              "1      0.0  \n",
              "2      0.0  \n",
              "3      1.0  \n",
              "4      0.0  "
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMfuoxzy0Jmv",
        "outputId": "463b399b-ea78-48f2-b7cc-1c1eded10720"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"\\nidx_train, idx_test = train_test_split(dataset.index.to_numpy(),\\n                                     random_state=SEED,\\n                                     test_size=0.1)\\nprint('Number of training samples: {}'.format(idx_train.shape[0]))\\nprint('Number of test samples: {}'.format(idx_test.shape[0]))\\n\\nidx_train, idx_val = train_test_split(idx_train,\\n                                     random_state=SEED,\\n                                     test_size=idx_test.shape[0])\\nprint('Number of validation examples: {}'.format(idx_val.shape[0]))\\n\\ndf_train = dataset.iloc[idx_train]\\ndf_val = dataset.iloc[idx_val]\\ndf_test = dataset.iloc[idx_test]\\n\""
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "idx_train, idx_test = train_test_split(dataset.index.to_numpy(),\n",
        "                                     random_state=SEED,\n",
        "                                     test_size=0.1)\n",
        "print('Number of training samples: {}'.format(idx_train.shape[0]))\n",
        "print('Number of test samples: {}'.format(idx_test.shape[0]))\n",
        "\n",
        "idx_train, idx_val = train_test_split(idx_train,\n",
        "                                     random_state=SEED,\n",
        "                                     test_size=idx_test.shape[0])\n",
        "print('Number of validation examples: {}'.format(idx_val.shape[0]))\n",
        "\n",
        "df_train = dataset.iloc[idx_train]\n",
        "df_val = dataset.iloc[idx_val]\n",
        "df_test = dataset.iloc[idx_test]\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "EkDrRjKi0Jmv",
        "outputId": "9839450e-8a1d-497c-903c-3c8e05fc5bdb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>episode</th>\n",
              "      <th>utterance</th>\n",
              "      <th>emotion</th>\n",
              "      <th>trigger</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>utterance_8</td>\n",
              "      <td>[Hey, Mon.]</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>utterance_8</td>\n",
              "      <td>[Hey, Mon., Hey-hey-hey. You wanna hear someth...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>utterance_8</td>\n",
              "      <td>[Hey, Mon., Hey-hey-hey. You wanna hear someth...</td>\n",
              "      <td>joy</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>utterance_8</td>\n",
              "      <td>[Hey, Mon., Hey-hey-hey. You wanna hear someth...</td>\n",
              "      <td>sadness</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>utterance_12</td>\n",
              "      <td>[Hey, Mon.]</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         episode                                          utterance  emotion  \\\n",
              "55   utterance_8                                        [Hey, Mon.]  neutral   \n",
              "56   utterance_8  [Hey, Mon., Hey-hey-hey. You wanna hear someth...  neutral   \n",
              "57   utterance_8  [Hey, Mon., Hey-hey-hey. You wanna hear someth...      joy   \n",
              "58   utterance_8  [Hey, Mon., Hey-hey-hey. You wanna hear someth...  sadness   \n",
              "77  utterance_12                                        [Hey, Mon.]  neutral   \n",
              "\n",
              "    trigger  \n",
              "55      0.0  \n",
              "56      0.0  \n",
              "57      0.0  \n",
              "58      1.0  \n",
              "77      0.0  "
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_test.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Majority Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'neutral': 12055,\n",
              " 'surprise': 3728,\n",
              " 'fear': 910,\n",
              " 'sadness': 2121,\n",
              " 'joy': 5040,\n",
              " 'disgust': 852,\n",
              " 'anger': 3144}"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def update_count_dictionary(key:str, d_em:dict):\n",
        "    ''' Given in input a dictionary and a string key, it counts the times\n",
        "        that key has been added.'''\n",
        "    if key in d_em.keys():\n",
        "        d_em[key] += 1\n",
        "    else:\n",
        "        d_em[key] = 1\n",
        "\n",
        "emotions_dict = dict()\n",
        "\n",
        "[update_count_dictionary(emotion, emotions_dict) for emotion in df_train['emotion']]\n",
        "emotions_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The majority emotion is: neutral\n",
            "The majority trigger is: 0.0\n",
            "\n",
            "A test for the dumb majority classifier:\n",
            "\t\tinput: Oh God! I'm dumb..\n",
            "\t\toutput: emotion:neutral, trigger:0.0\n"
          ]
        }
      ],
      "source": [
        "class Majority_Classifier():\n",
        "    '''It is trained on a dataset using the emotion and trigger columns.\n",
        "        It's output on the forward method will be always the majority class\n",
        "        for emotion and trigger, calculated in the training set.'''\n",
        "\n",
        "    def __init__(self):\n",
        "        self.emotion = \"\"\n",
        "        self.trigger = 0.0\n",
        "\n",
        "    def train(self, dataset:pd.DataFrame):\n",
        "        '''Input a dataset with the emotion and trigger columns.'''\n",
        "\n",
        "        emotions_count = dict()\n",
        "        triggers_count = dict()\n",
        "\n",
        "        for em, tr in dataset[['emotion','trigger']].values:\n",
        "            update_count_dictionary(em, emotions_count)\n",
        "            update_count_dictionary(tr, triggers_count)\n",
        "\n",
        "        # get the majority class for the emotion column\n",
        "        max_count = -1\n",
        "        for emotion, value in emotions_count.items():\n",
        "            if value > max_count:\n",
        "                max_count = value\n",
        "                self.emotion = emotion \n",
        "\n",
        "        # get the majority class for the trigger column\n",
        "        max_count = -1\n",
        "        for trigger, value in triggers_count.items():\n",
        "            if value > max_count:\n",
        "                max_count = value\n",
        "                self.trigger = trigger \n",
        "\n",
        "    def forward(self, utterance):\n",
        "        '''The input is ignored. This method can be modified. It is intended to\n",
        "            mimic the forward method of an ML model such that it usable in the same way.'''\n",
        "        return self.emotion, self.trigger\n",
        "\n",
        "\n",
        "dumb_majority = Majority_Classifier()\n",
        "dumb_majority.train(df_train)\n",
        "\n",
        "print(\"The majority emotion is: {}\".format(dumb_majority.emotion))\n",
        "print(\"The majority trigger is: {}\".format(dumb_majority.trigger))\n",
        "print()\n",
        "print(\"A test for the dumb majority classifier:\")\n",
        "print(\"\\t\\tinput: Oh God! I'm dumb..\")\n",
        "\n",
        "e, t = dumb_majority.forward(\"Oh God! I'm dumb..\")\n",
        "print(\"\\t\\toutput: emotion:{}, trigger:{}\".format(e,t))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
